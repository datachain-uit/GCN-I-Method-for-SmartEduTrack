{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544f247d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:53:33.012711Z",
     "iopub.status.busy": "2024-12-20T10:53:33.012327Z",
     "iopub.status.idle": "2024-12-20T10:53:33.019308Z",
     "shell.execute_reply": "2024-12-20T10:53:33.018237Z"
    },
    "papermill": {
     "duration": 0.01691,
     "end_time": "2024-12-20T10:53:33.021201",
     "exception": false,
     "start_time": "2024-12-20T10:53:33.004291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "five_fold_files = {\n",
    "    \"week1\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_1.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_2.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_3.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_4.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_5.csv\"\n",
    "    ],\n",
    "    \"week2\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_1.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_2.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_3.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_4.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_5.csv\"\n",
    "    ],\n",
    "    \"week3\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_1.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_2.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_3.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_4.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_5.csv\"\n",
    "    ],\n",
    "    \"week4\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_1.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_2.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_3.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_4.csv\",\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_5.csv\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "file_validation = {\n",
    "    \"week1\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/val/val_week1.csv\"\n",
    "    ],\n",
    "    \"week2\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week2/val/val_week1_2.csv\"\n",
    "    ],\n",
    "    \"week3\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week3/val/val_week1_2_3.csv\"\n",
    "    ],\n",
    "    \"week4\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week4/val/val_week1_2_3_4.csv\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "file_test = {\n",
    "    \"week1\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/test/test_week1.csv\"\n",
    "    ],\n",
    "    \"week2\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/test/test_week2.csv\"\n",
    "    ],\n",
    "    \"week3\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/test/test_week3.csv\"\n",
    "    ],\n",
    "    \"week4\": [\n",
    "        \"/kaggle/input/new-clean-mooccubex/clean_week1/test/test_week4.csv\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceaf243a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:53:33.032074Z",
     "iopub.status.busy": "2024-12-20T10:53:33.031655Z",
     "iopub.status.idle": "2024-12-20T10:53:35.519977Z",
     "shell.execute_reply": "2024-12-20T10:53:35.518909Z"
    },
    "papermill": {
     "duration": 2.495625,
     "end_time": "2024-12-20T10:53:35.521868",
     "exception": false,
     "start_time": "2024-12-20T10:53:33.026243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45e60e",
   "metadata": {
    "papermill": {
     "duration": 0.004359,
     "end_time": "2024-12-20T10:53:35.531197",
     "exception": false,
     "start_time": "2024-12-20T10:53:35.526838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tìm siêu tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e232bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:53:35.542168Z",
     "iopub.status.busy": "2024-12-20T10:53:35.541471Z",
     "iopub.status.idle": "2024-12-20T10:53:35.550412Z",
     "shell.execute_reply": "2024-12-20T10:53:35.549346Z"
    },
    "papermill": {
     "duration": 0.016296,
     "end_time": "2024-12-20T10:53:35.552062",
     "exception": false,
     "start_time": "2024-12-20T10:53:35.535766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo hàm train cho từng tuần\n",
    "def train_week_model(week_number, file_paths_train, file_validataion):\n",
    "       # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(file_paths_train)\n",
    "    val_data = pd.read_csv(file_validataion)\n",
    "    \n",
    "    # Tách đặc trưng và nhãn\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "    X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_val = val_data[\"classification_encoded\"]\n",
    "    \n",
    "    # Áp dụng Over-sampling cho dữ liệu huấn luyện bằng SMOTE\n",
    "    oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "       # # # Khởi tạo RandomSearch tuner\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [100, 200, 300],\n",
    "    #     'max_depth': [3, 5, 7],\n",
    "    #     'learning_rate': [0.05, 0.1, 0.2],\n",
    "    #     'num_leaves': [20, 30, 40],\n",
    "    #     'min_child_samples': [20, 30],\n",
    "    #     'subsample': [0.8, 1.0],\n",
    "    #     'colsample_bytree': [0.8, 1.0],\n",
    "    #     'reg_alpha': [0, 0.1],\n",
    "    #     'reg_lambda': [0, 0.1, 0.5]\n",
    "    # }\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],  # Thêm lựa chọn entropy\n",
    "        'max_depth': [3, 5, 7],  # Tăng độ sâu lên 7 để tăng khả năng học\n",
    "        'min_samples_split': [2, 5, 10],  # Giảm giới hạn số mẫu để chia nhánh\n",
    "        'min_samples_leaf': [1, 2, 5],  # Giảm yêu cầu số mẫu tối thiểu trong lá\n",
    "}\n",
    " \n",
    "    # Khởi tạo RandomSearch tuner\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='accuracy',\n",
    "                              verbose=2, n_jobs=-1)\n",
    "        \n",
    "    \n",
    "   # Huấn luyện mô hình với các siêu tham số tốt nhất\n",
    "    grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # Đánh giá mô hình\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    # Trả về kết quả tối ưu cho tuần\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e2bb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:53:35.562807Z",
     "iopub.status.busy": "2024-12-20T10:53:35.562478Z",
     "iopub.status.idle": "2024-12-20T10:53:35.567576Z",
     "shell.execute_reply": "2024-12-20T10:53:35.566270Z"
    },
    "papermill": {
     "duration": 0.012405,
     "end_time": "2024-12-20T10:53:35.569330",
     "exception": false,
     "start_time": "2024-12-20T10:53:35.556925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa đường dẫn đến dữ liệu cho từng tuần\n",
    "file_paths_train = {\n",
    "    \"week1\": \"/kaggle/input/new-clean-mooccubex/clean_week1/train/clean_data_week1.csv\",\n",
    "    \"week2\": \"/kaggle/input/new-clean-mooccubex/clean_week2/train/clean_data_week2.csv\",\n",
    "    \"week3\": \"/kaggle/input/new-clean-mooccubex/clean_week3/train/clean_data_week3.csv\",\n",
    "    \"week4\": \"/kaggle/input/new-clean-mooccubex/clean_week4/train/clean_data_week4.csv\"\n",
    "}\n",
    "\n",
    "file_validation = {\n",
    "    \"week1\": \"/kaggle/input/new-clean-mooccubex/clean_week1/val/val_week1.csv\",\n",
    "    \"week2\": \"/kaggle/input/new-clean-mooccubex/clean_week2/val/val_week1_2.csv\",\n",
    "    \"week3\": \"/kaggle/input/new-clean-mooccubex/clean_week3/val/val_week1_2_3.csv\",\n",
    "    \"week4\": \"/kaggle/input/new-clean-mooccubex/clean_week4/val/val_week1_2_3_4.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1d684",
   "metadata": {
    "papermill": {
     "duration": 0.0043,
     "end_time": "2024-12-20T10:53:35.578444",
     "exception": false,
     "start_time": "2024-12-20T10:53:35.574144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bbf3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:53:35.588885Z",
     "iopub.status.busy": "2024-12-20T10:53:35.588542Z",
     "iopub.status.idle": "2024-12-20T10:56:07.982156Z",
     "shell.execute_reply": "2024-12-20T10:56:07.980891Z"
    },
    "papermill": {
     "duration": 152.405246,
     "end_time": "2024-12-20T10:56:07.988357",
     "exception": false,
     "start_time": "2024-12-20T10:53:35.583111",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "Best Parameters for Week 1:\n",
      "criterion: gini\n",
      "max_depth: 7\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "\n",
      "Best Parameters for Week 2:\n",
      "criterion: entropy\n",
      "max_depth: 7\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "\n",
      "Best Parameters for Week 3:\n",
      "criterion: gini\n",
      "max_depth: 7\n",
      "min_samples_leaf: 5\n",
      "min_samples_split: 2\n",
      "\n",
      "Best Parameters for Week 4:\n",
      "criterion: gini\n",
      "max_depth: 7\n",
      "min_samples_leaf: 5\n",
      "min_samples_split: 2\n"
     ]
    }
   ],
   "source": [
    "# Tìm tham số tốt nhất cho từng tuần\n",
    "best_params_week1 = train_week_model(1, file_paths_train[\"week1\"], file_validation[\"week1\"])\n",
    "best_params_week2 = train_week_model(2, file_paths_train[\"week2\"], file_validation[\"week2\"])\n",
    "best_params_week3 = train_week_model(3, file_paths_train[\"week3\"], file_validation[\"week3\"])\n",
    "best_params_week4 = train_week_model(4, file_paths_train[\"week4\"], file_validation[\"week4\"])\n",
    "\n",
    "# In thông tin chi tiết các tham số tối ưu\n",
    "print(\"Best Parameters for Week 1:\")\n",
    "for param_name, param_value in best_params_week1.items():\n",
    "       print(f\"{param_name}: {param_value}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 2:\")\n",
    "for param_name, param_value in best_params_week2.items():\n",
    "       print(f\"{param_name}: {param_value}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 3:\")\n",
    "for param_name, param_value in best_params_week3.items():\n",
    "       print(f\"{param_name}: {param_value}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 4:\")\n",
    "for param_name, param_value in best_params_week4.items():\n",
    "       print(f\"{param_name}: {param_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16424f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:07.999584Z",
     "iopub.status.busy": "2024-12-20T10:56:07.999242Z",
     "iopub.status.idle": "2024-12-20T10:56:08.003816Z",
     "shell.execute_reply": "2024-12-20T10:56:08.002717Z"
    },
    "papermill": {
     "duration": 0.012191,
     "end_time": "2024-12-20T10:56:08.005501",
     "exception": false,
     "start_time": "2024-12-20T10:56:07.993310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Danh sách tham số tốt nhất\n",
    "best_params = {\n",
    "    \"week1\": best_params_week1,\n",
    "    \"week2\": best_params_week2,\n",
    "    \"week3\": best_params_week3,\n",
    "    \"week4\": best_params_week4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a02c0",
   "metadata": {
    "papermill": {
     "duration": 0.004587,
     "end_time": "2024-12-20T10:56:08.015206",
     "exception": false,
     "start_time": "2024-12-20T10:56:08.010619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM với các tham sốt nhất cho mỗi tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e8ad38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:08.026519Z",
     "iopub.status.busy": "2024-12-20T10:56:08.026138Z",
     "iopub.status.idle": "2024-12-20T10:56:10.975602Z",
     "shell.execute_reply": "2024-12-20T10:56:10.974269Z"
    },
    "papermill": {
     "duration": 2.957444,
     "end_time": "2024-12-20T10:56:10.977569",
     "exception": false,
     "start_time": "2024-12-20T10:56:08.020125",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing week1 with best parameters...\n",
      "best parameters for week1: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Fold 1: Using file /kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_1.csv as test set\n",
      "Fold 2: Using file /kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_2.csv as test set\n",
      "Fold 3: Using file /kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_3.csv as test set\n",
      "Fold 4: Using file /kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_4.csv as test set\n",
      "Fold 5: Using file /kaggle/input/new-clean-mooccubex/clean_week1/train/5-folds/data_part_5.csv as test set\n",
      "\n",
      "=== Average Precision, Recall, F1-Score per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.999001        0.999000          0.999000\n",
      "1      1           0.995402        0.993156          0.994273\n",
      "2      2           0.998788        0.997576          0.998180\n",
      "3      3           0.996414        0.994012          0.995202\n",
      "4      4           0.999377        0.999875          0.999626\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  599.4   0.0    0.0    0.0     0.6\n",
      "1    0.2  87.0    0.0    0.4     0.0\n",
      "2    0.2   0.0  164.0    0.2     0.0\n",
      "3    0.0   0.4    0.2  166.0     0.4\n",
      "4    0.2   0.0    0.0    0.0  1603.2\n",
      "\n",
      "Processing week2 with best parameters...\n",
      "best parameters for week2: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Fold 1: Using file /kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_1.csv as test set\n",
      "Fold 2: Using file /kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_2.csv as test set\n",
      "Fold 3: Using file /kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_3.csv as test set\n",
      "Fold 4: Using file /kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_4.csv as test set\n",
      "Fold 5: Using file /kaggle/input/new-clean-mooccubex/clean_week2/train/5-folds/data_part_5.csv as test set\n",
      "\n",
      "=== Average Precision, Recall, F1-Score per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.999002        0.999333          0.999167\n",
      "1      1           0.995428        0.997701          0.996558\n",
      "2      2           0.997576        0.996364          0.996960\n",
      "3      3           1.000000        0.998802          0.999399\n",
      "4      4           1.000000        1.000000          1.000000\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  599.6   0.0    0.4    0.0     0.0\n",
      "1    0.2  87.4    0.0    0.0     0.0\n",
      "2    0.2   0.4  163.8    0.0     0.0\n",
      "3    0.2   0.0    0.0  166.8     0.0\n",
      "4    0.0   0.0    0.0    0.0  1603.4\n",
      "\n",
      "Processing week3 with best parameters...\n",
      "best parameters for week3: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Fold 1: Using file /kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_1.csv as test set\n",
      "Fold 2: Using file /kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_2.csv as test set\n",
      "Fold 3: Using file /kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_3.csv as test set\n",
      "Fold 4: Using file /kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_4.csv as test set\n",
      "Fold 5: Using file /kaggle/input/new-clean-mooccubex/clean_week3/train/5-folds/data_part_5.csv as test set\n",
      "\n",
      "=== Average Precision, Recall, F1-Score per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.997354        0.999667          0.998505\n",
      "1      1           1.000000        0.990857          0.995389\n",
      "2      2           0.996378        0.998788          0.997576\n",
      "3      3           1.000000        1.000000          1.000000\n",
      "4      4           0.999751        0.999127          0.999438\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  599.8   0.0    0.0    0.0     0.2\n",
      "1    0.0  86.8    0.6    0.0     0.2\n",
      "2    0.2   0.0  164.2    0.0     0.0\n",
      "3    0.0   0.0    0.0  167.0     0.0\n",
      "4    1.4   0.0    0.0    0.0  1602.0\n",
      "\n",
      "Processing week4 with best parameters...\n",
      "best parameters for week4: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Fold 1: Using file /kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_1.csv as test set\n",
      "Fold 2: Using file /kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_2.csv as test set\n",
      "Fold 3: Using file /kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_3.csv as test set\n",
      "Fold 4: Using file /kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_4.csv as test set\n",
      "Fold 5: Using file /kaggle/input/new-clean-mooccubex/clean_week4/train/5-folds/data_part_5.csv as test set\n",
      "\n",
      "=== Average Precision, Recall, F1-Score per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.998343        0.999667          0.999002\n",
      "1      1           0.995556        0.993156          0.994298\n",
      "2      2           0.996378        0.996349          0.996349\n",
      "3      3           1.000000        1.000000          1.000000\n",
      "4      4           0.999751        0.999376          0.999563\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  599.8   0.0    0.0    0.0     0.2\n",
      "1    0.0  87.0    0.6    0.0     0.0\n",
      "2    0.0   0.4  163.8    0.0     0.2\n",
      "3    0.0   0.0    0.0  167.0     0.0\n",
      "4    1.0   0.0    0.0    0.0  1602.4\n"
     ]
    }
   ],
   "source": [
    "# Biến lưu kết quả tổng quát\n",
    "overall_results_5folds = []\n",
    "\n",
    "# Lặp qua từng tuần\n",
    "for week, file_paths in five_fold_files.items():\n",
    "    print(f\"\\nProcessing {week} with best parameters...\")\n",
    "    params = best_params[week]\n",
    "    print(f\"best parameters for {week}: {params}\")\n",
    "    \n",
    "    # Biến lưu kết quả cho từng tuần\n",
    "    week_results = {\n",
    "        \"week\": week,\n",
    "        \"accuracy_per_fold\": [],\n",
    "        \"precision_per_label\": [],\n",
    "        \"recall_per_label\": [],\n",
    "        \"f1_score_per_label\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"train_times\": [],\n",
    "        \"test_times\": []\n",
    "    }\n",
    "\n",
    "    # Lặp qua từng fold\n",
    "    for i in range(len(file_paths)):\n",
    "        print(f\"Fold {i+1}: Using file {file_paths[i]} as test set\")\n",
    "        \n",
    "        # Tải dữ liệu\n",
    "        test_data = pd.read_csv(file_paths[i])\n",
    "        train_data = pd.concat([pd.read_csv(file_paths[j]) for j in range(len(file_paths)) if j != i])\n",
    "        \n",
    "        # Tách X và y\n",
    "        X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                           \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_train = train_data['classification_encoded']\n",
    "        \n",
    "        X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                         \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_test = test_data['classification_encoded']\n",
    "\n",
    "\n",
    "        # Xây dựng mô hình với tham số tốt nhất\n",
    "        model = DecisionTreeClassifier(**params)\n",
    "        \n",
    "        # Bắt đầu tính thời gian huấn luyện\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_train = time.time()\n",
    "        \n",
    "        # Bắt đầu tính thời gian kiểm thử\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        \n",
    "        # Tính thời gian và lưu lại\n",
    "        train_time = end_train - start_train\n",
    "        test_time = end_test - start_test\n",
    "        week_results[\"train_times\"].append(train_time)\n",
    "        week_results[\"test_times\"].append(test_time)\n",
    "\n",
    "        # Đánh giá mô hình trên tập kiểm thử của fold hiện tại\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        week_results[\"accuracy_per_fold\"].append(accuracy)\n",
    "        # Dự đoán\n",
    "\n",
    "        \n",
    "        # Tính các chỉ số cho mỗi fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        week_results[\"precision_per_label\"].append(precision)\n",
    "        week_results[\"recall_per_label\"].append(recall)\n",
    "        week_results[\"f1_score_per_label\"].append(f1)\n",
    "        week_results[\"confusion_matrices\"].append(conf_matrix)\n",
    "\n",
    "    # Tính trung bình cho từng nhãn\n",
    "    average_precision_per_label = np.mean(week_results[\"precision_per_label\"], axis=0)\n",
    "    average_recall_per_label = np.mean(week_results[\"recall_per_label\"], axis=0)\n",
    "    average_f1_per_label = np.mean(week_results[\"f1_score_per_label\"], axis=0)\n",
    "    average_confusion_matrix = np.mean(week_results[\"confusion_matrices\"], axis=0)\n",
    "    average_train_time = sum(week_results[\"train_times\"]) / len(week_results[\"train_times\"])\n",
    "    average_test_time = sum(week_results[\"test_times\"]) / len(week_results[\"test_times\"])\n",
    "    \n",
    "    # Tạo DataFrame cho precision, recall, f1-score\n",
    "    labels = np.unique(y_test)  # Lấy nhãn từ y_test_classes\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Average Precision\": average_precision_per_label,\n",
    "        \"Average Recall\": average_recall_per_label,\n",
    "        \"Average F1-Score\": average_f1_per_label\n",
    "    })\n",
    "    \n",
    "    # Tạo DataFrame cho confusion matrix|\n",
    "    confusion_df = pd.DataFrame(average_confusion_matrix, index=labels, columns=labels)\n",
    "    \n",
    "    # In kết quả\n",
    "    print(\"\\n=== Average Precision, Recall, F1-Score per Label ===\")\n",
    "    print(metrics_df)\n",
    "    print(\"\\n=== Average Confusion Matrix ===\")\n",
    "    print(confusion_df)\n",
    "\n",
    "    # Lưu kết quả tuần vào kết quả tổng quát\n",
    "    week_results[\"average_train_times\"] = average_train_time\n",
    "    week_results[\"average_test_times\"] = average_test_time\n",
    "    week_results[\"average_metrics_df\"] = metrics_df\n",
    "    week_results[\"average_confusion_matrix\"] = confusion_df\n",
    "    overall_results_5folds.append(week_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676d89c",
   "metadata": {
    "papermill": {
     "duration": 0.005743,
     "end_time": "2024-12-20T10:56:10.989429",
     "exception": false,
     "start_time": "2024-12-20T10:56:10.983686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kết quả 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a29c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:11.002419Z",
     "iopub.status.busy": "2024-12-20T10:56:11.002077Z",
     "iopub.status.idle": "2024-12-20T10:56:11.031175Z",
     "shell.execute_reply": "2024-12-20T10:56:11.029924Z"
    },
    "papermill": {
     "duration": 0.038106,
     "end_time": "2024-12-20T10:56:11.033293",
     "exception": false,
     "start_time": "2024-12-20T10:56:10.995187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for week1 ===\n",
      "Average Train Time: 0.0133 seconds\n",
      "Average Test Time: 0.0017 seconds\n",
      "\n",
      "Average Precision, Recall, F1-Score per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.999001        0.999000          0.999000\n",
      "1      1           0.995402        0.993156          0.994273\n",
      "2      2           0.998788        0.997576          0.998180\n",
      "3      3           0.996414        0.994012          0.995202\n",
      "4      4           0.999377        0.999875          0.999626\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  599.4   0.0    0.0    0.0     0.6\n",
      "1    0.2  87.0    0.0    0.4     0.0\n",
      "2    0.2   0.0  164.0    0.2     0.0\n",
      "3    0.0   0.4    0.2  166.0     0.4\n",
      "4    0.2   0.0    0.0    0.0  1603.2\n",
      "\n",
      "=== Results for week2 ===\n",
      "Average Train Time: 0.0156 seconds\n",
      "Average Test Time: 0.0020 seconds\n",
      "\n",
      "Average Precision, Recall, F1-Score per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.999002        0.999333          0.999167\n",
      "1      1           0.995428        0.997701          0.996558\n",
      "2      2           0.997576        0.996364          0.996960\n",
      "3      3           1.000000        0.998802          0.999399\n",
      "4      4           1.000000        1.000000          1.000000\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  599.6   0.0    0.4    0.0     0.0\n",
      "1    0.2  87.4    0.0    0.0     0.0\n",
      "2    0.2   0.4  163.8    0.0     0.0\n",
      "3    0.2   0.0    0.0  166.8     0.0\n",
      "4    0.0   0.0    0.0    0.0  1603.4\n",
      "\n",
      "=== Results for week3 ===\n",
      "Average Train Time: 0.0156 seconds\n",
      "Average Test Time: 0.0021 seconds\n",
      "\n",
      "Average Precision, Recall, F1-Score per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.997354        0.999667          0.998505\n",
      "1      1           1.000000        0.990857          0.995389\n",
      "2      2           0.996378        0.998788          0.997576\n",
      "3      3           1.000000        1.000000          1.000000\n",
      "4      4           0.999751        0.999127          0.999438\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  599.8   0.0    0.0    0.0     0.2\n",
      "1    0.0  86.8    0.6    0.0     0.2\n",
      "2    0.2   0.0  164.2    0.0     0.0\n",
      "3    0.0   0.0    0.0  167.0     0.0\n",
      "4    1.4   0.0    0.0    0.0  1602.0\n",
      "\n",
      "=== Results for week4 ===\n",
      "Average Train Time: 0.0168 seconds\n",
      "Average Test Time: 0.0022 seconds\n",
      "\n",
      "Average Precision, Recall, F1-Score per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score\n",
      "0      0           0.998343        0.999667          0.999002\n",
      "1      1           0.995556        0.993156          0.994298\n",
      "2      2           0.996378        0.996349          0.996349\n",
      "3      3           1.000000        1.000000          1.000000\n",
      "4      4           0.999751        0.999376          0.999563\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  599.8   0.0    0.0    0.0     0.2\n",
      "1    0.0  87.0    0.6    0.0     0.0\n",
      "2    0.0   0.4  163.8    0.0     0.2\n",
      "3    0.0   0.0    0.0  167.0     0.0\n",
      "4    1.0   0.0    0.0    0.0  1602.4\n"
     ]
    }
   ],
   "source": [
    "# Duyệt qua các tuần trong overall_results\n",
    "for week_result in overall_results_5folds:\n",
    "    week = week_result[\"week\"]\n",
    "    average_train_time = np.mean(week_result[\"train_times\"])\n",
    "    average_test_time = np.mean(week_result[\"test_times\"])\n",
    "    average_metrics_df = week_result[\"average_metrics_df\"]\n",
    "    average_confusion_matrix = week_result[\"average_confusion_matrix\"]\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n=== Results for {week} ===\")\n",
    "    print(f\"Average Train Time: {average_train_time:.4f} seconds\")\n",
    "    print(f\"Average Test Time: {average_test_time:.4f} seconds\")\n",
    "    print(\"\\nAverage Precision, Recall, F1-Score per Label:\")\n",
    "    print(average_metrics_df)\n",
    "    print(\"\\nAverage Confusion Matrix:\")\n",
    "    print(average_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17015d7",
   "metadata": {
    "papermill": {
     "duration": 0.005851,
     "end_time": "2024-12-20T10:56:11.045524",
     "exception": false,
     "start_time": "2024-12-20T10:56:11.039673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df81542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:11.059432Z",
     "iopub.status.busy": "2024-12-20T10:56:11.058977Z",
     "iopub.status.idle": "2024-12-20T10:56:11.068599Z",
     "shell.execute_reply": "2024-12-20T10:56:11.067397Z"
    },
    "papermill": {
     "duration": 0.018524,
     "end_time": "2024-12-20T10:56:11.070244",
     "exception": false,
     "start_time": "2024-12-20T10:56:11.051720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mảng lưu dữ liệu của các tuần\n",
    "results = []\n",
    "\n",
    "def process_week(week_num, best_params, results):\n",
    "    print(f\"\\n=== Processing Week {week_num} ===\")\n",
    "    params = best_params[week]\n",
    "    # Đường dẫn tới dữ liệu tuần tương ứng\n",
    "    train_path = f\"/kaggle/input/new-clean-mooccubex/clean_week{week_num}/train/clean_data_week{week_num}.csv\"\n",
    "    test_path = f\"/kaggle/input/new-clean-mooccubex/clean_week{week_num}/test/test_week{week_num}.csv\"\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                       \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data['classification_encoded']\n",
    "    \n",
    "    X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                     \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_test = test_data['classification_encoded']\n",
    "\n",
    "    # Áp dụng SMOTE cho tập huấn luyện\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Xây dựng mô hình với tham số tốt nhất\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Kiểm thử mô hình\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    # Tính thời gian huấn luyện và kiểm thử\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Lưu kết quả vào mảng\n",
    "    results.append({\n",
    "        \"week\": week_num,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    })\n",
    "    \n",
    "    print(\"\\n=== Precision, Recall, F1-Score per Label ===\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Label\": np.unique(y_test),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }))\n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(pd.DataFrame(conf_matrix, index=np.unique(y_test), columns=np.unique(y_test)))\n",
    "    \n",
    "    print(f\"\\nTrain Time: {train_time:.2f} seconds\")\n",
    "    print(f\"Test Time: {test_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b119b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:11.084416Z",
     "iopub.status.busy": "2024-12-20T10:56:11.084075Z",
     "iopub.status.idle": "2024-12-20T10:56:11.272105Z",
     "shell.execute_reply": "2024-12-20T10:56:11.270856Z"
    },
    "papermill": {
     "duration": 0.197633,
     "end_time": "2024-12-20T10:56:11.274157",
     "exception": false,
     "start_time": "2024-12-20T10:56:11.076524",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 1 ===\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0    0.99734  1.000000  0.998668\n",
      "1      1    1.00000  1.000000  1.000000\n",
      "2      2    1.00000  0.990291  0.995122\n",
      "3      3    1.00000  1.000000  1.000000\n",
      "4      4    1.00000  1.000000  1.000000\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1    2    3     4\n",
      "0  375   0    0    0     0\n",
      "1    0  54    0    0     0\n",
      "2    1   0  102    0     0\n",
      "3    0   0    0  105     0\n",
      "4    0   0    0    0  1003\n",
      "\n",
      "Train Time: 0.02 seconds\n",
      "Test Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(1, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871f1aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:11.288968Z",
     "iopub.status.busy": "2024-12-20T10:56:11.288577Z",
     "iopub.status.idle": "2024-12-20T10:56:11.502959Z",
     "shell.execute_reply": "2024-12-20T10:56:11.501480Z"
    },
    "papermill": {
     "duration": 0.224428,
     "end_time": "2024-12-20T10:56:11.504897",
     "exception": false,
     "start_time": "2024-12-20T10:56:11.280469",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 2 ===\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision  Recall  F1-Score\n",
      "0      0        1.0     1.0       1.0\n",
      "1      1        1.0     1.0       1.0\n",
      "2      2        1.0     1.0       1.0\n",
      "3      3        1.0     1.0       1.0\n",
      "4      4        1.0     1.0       1.0\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1    2    3     4\n",
      "0  375   0    0    0     0\n",
      "1    0  54    0    0     0\n",
      "2    0   0  103    0     0\n",
      "3    0   0    0  105     0\n",
      "4    0   0    0    0  1003\n",
      "\n",
      "Train Time: 0.02 seconds\n",
      "Test Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(2, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64fa8ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:11.521015Z",
     "iopub.status.busy": "2024-12-20T10:56:11.520637Z",
     "iopub.status.idle": "2024-12-20T10:56:11.788297Z",
     "shell.execute_reply": "2024-12-20T10:56:11.787125Z"
    },
    "papermill": {
     "duration": 0.278331,
     "end_time": "2024-12-20T10:56:11.790262",
     "exception": false,
     "start_time": "2024-12-20T10:56:11.511931",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 3 ===\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision  Recall  F1-Score\n",
      "0      0        1.0     1.0       1.0\n",
      "1      1        1.0     1.0       1.0\n",
      "2      2        1.0     1.0       1.0\n",
      "3      3        1.0     1.0       1.0\n",
      "4      4        1.0     1.0       1.0\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1    2    3     4\n",
      "0  375   0    0    0     0\n",
      "1    0  54    0    0     0\n",
      "2    0   0  103    0     0\n",
      "3    0   0    0  105     0\n",
      "4    0   0    0    0  1003\n",
      "\n",
      "Train Time: 0.02 seconds\n",
      "Test Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(3, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21670c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:11.804867Z",
     "iopub.status.busy": "2024-12-20T10:56:11.804500Z",
     "iopub.status.idle": "2024-12-20T10:56:12.124690Z",
     "shell.execute_reply": "2024-12-20T10:56:12.123459Z"
    },
    "papermill": {
     "duration": 0.329672,
     "end_time": "2024-12-20T10:56:12.126618",
     "exception": false,
     "start_time": "2024-12-20T10:56:11.796946",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 4 ===\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision  Recall  F1-Score\n",
      "0      0        1.0     1.0       1.0\n",
      "1      1        1.0     1.0       1.0\n",
      "2      2        1.0     1.0       1.0\n",
      "3      3        1.0     1.0       1.0\n",
      "4      4        1.0     1.0       1.0\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1    2    3     4\n",
      "0  375   0    0    0     0\n",
      "1    0  54    0    0     0\n",
      "2    0   0  103    0     0\n",
      "3    0   0    0  105     0\n",
      "4    0   0    0    0  1003\n",
      "\n",
      "Train Time: 0.02 seconds\n",
      "Test Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(4, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "431200e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T10:56:12.141456Z",
     "iopub.status.busy": "2024-12-20T10:56:12.141110Z",
     "iopub.status.idle": "2024-12-20T10:56:12.156061Z",
     "shell.execute_reply": "2024-12-20T10:56:12.154907Z"
    },
    "papermill": {
     "duration": 0.024765,
     "end_time": "2024-12-20T10:56:12.158265",
     "exception": false,
     "start_time": "2024-12-20T10:56:12.133500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Results for All Weeks ===\n",
      "Week 1:\n",
      "  Train Time: 0.02 seconds\n",
      "  Test Time: 0.00 seconds\n",
      "  Precision: [0.99734043 1.         1.         1.         1.        ]\n",
      "  Recall: [1.         1.         0.99029126 1.         1.        ]\n",
      "  F1-Score: [0.99866844 1.         0.99512195 1.         1.        ]\n",
      "  Confusion Matrix:\n",
      "[[ 375    0    0    0    0]\n",
      " [   0   54    0    0    0]\n",
      " [   1    0  102    0    0]\n",
      " [   0    0    0  105    0]\n",
      " [   0    0    0    0 1003]]\n",
      "Week 2:\n",
      "  Train Time: 0.02 seconds\n",
      "  Test Time: 0.00 seconds\n",
      "  Precision: [1. 1. 1. 1. 1.]\n",
      "  Recall: [1. 1. 1. 1. 1.]\n",
      "  F1-Score: [1. 1. 1. 1. 1.]\n",
      "  Confusion Matrix:\n",
      "[[ 375    0    0    0    0]\n",
      " [   0   54    0    0    0]\n",
      " [   0    0  103    0    0]\n",
      " [   0    0    0  105    0]\n",
      " [   0    0    0    0 1003]]\n",
      "Week 3:\n",
      "  Train Time: 0.02 seconds\n",
      "  Test Time: 0.00 seconds\n",
      "  Precision: [1. 1. 1. 1. 1.]\n",
      "  Recall: [1. 1. 1. 1. 1.]\n",
      "  F1-Score: [1. 1. 1. 1. 1.]\n",
      "  Confusion Matrix:\n",
      "[[ 375    0    0    0    0]\n",
      " [   0   54    0    0    0]\n",
      " [   0    0  103    0    0]\n",
      " [   0    0    0  105    0]\n",
      " [   0    0    0    0 1003]]\n",
      "Week 4:\n",
      "  Train Time: 0.02 seconds\n",
      "  Test Time: 0.00 seconds\n",
      "  Precision: [1. 1. 1. 1. 1.]\n",
      "  Recall: [1. 1. 1. 1. 1.]\n",
      "  F1-Score: [1. 1. 1. 1. 1.]\n",
      "  Confusion Matrix:\n",
      "[[ 375    0    0    0    0]\n",
      " [   0   54    0    0    0]\n",
      " [   0    0  103    0    0]\n",
      " [   0    0    0  105    0]\n",
      " [   0    0    0    0 1003]]\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu của các tuần\n",
    "print(\"\\n=== Summary Results for All Weeks ===\")\n",
    "for result in results:\n",
    "    print(f\"Week {result['week']}:\")\n",
    "    print(f\"  Train Time: {result['train_time']:.2f} seconds\")\n",
    "    print(f\"  Test Time: {result['test_time']:.2f} seconds\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1-Score: {result['f1_score']}\")\n",
    "    print(f\"  Confusion Matrix:\\n{result['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bbf70",
   "metadata": {
    "papermill": {
     "duration": 0.006509,
     "end_time": "2024-12-20T10:56:12.171839",
     "exception": false,
     "start_time": "2024-12-20T10:56:12.165330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6328310,
     "sourceId": 10238263,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6342752,
     "sourceId": 10253909,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 162.179296,
   "end_time": "2024-12-20T10:56:12.899273",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-20T10:53:30.719977",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
