{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578d082b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-05T05:16:56.906907Z",
     "iopub.status.busy": "2025-04-05T05:16:56.906307Z",
     "iopub.status.idle": "2025-04-05T05:16:58.906457Z",
     "shell.execute_reply": "2025-04-05T05:16:58.905058Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.009482,
     "end_time": "2025-04-05T05:16:58.908255",
     "exception": false,
     "start_time": "2025-04-05T05:16:56.898773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clean_raw_data.csv\n",
      "/kaggle/input/clean_data_mean.csv\n",
      "/kaggle/input/raw_data.csv\n",
      "/kaggle/input/clean_data_GCN.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_data_minmax_fill-zero.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_data_minmax_GCN_version4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_data_Fill-1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_data_minmax_Fill-1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_data_minmax_GCN_version3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_data_minmax_KNN.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_5.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550968ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T05:16:58.920262Z",
     "iopub.status.busy": "2025-04-05T05:16:58.919855Z",
     "iopub.status.idle": "2025-04-05T05:17:15.824571Z",
     "shell.execute_reply": "2025-04-05T05:17:15.823560Z"
    },
    "papermill": {
     "duration": 16.912237,
     "end_time": "2025-04-05T05:17:15.826317",
     "exception": false,
     "start_time": "2025-04-05T05:16:58.914080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc69537e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T05:17:15.838595Z",
     "iopub.status.busy": "2025-04-05T05:17:15.838034Z",
     "iopub.status.idle": "2025-04-05T05:17:15.843041Z",
     "shell.execute_reply": "2025-04-05T05:17:15.842400Z"
    },
    "papermill": {
     "duration": 0.012283,
     "end_time": "2025-04-05T05:17:15.844300",
     "exception": false,
     "start_time": "2025-04-05T05:17:15.832017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Biến global cho base path\n",
    "BASE_PATH = \"/kaggle/input/Mean_minmax_baseline\"\n",
    "# Tuần và số phần fold\n",
    "weeks = ['week1', 'week2', 'week3', 'week4']\n",
    "fold_parts = 5\n",
    "\n",
    "# Tạo five_fold_files\n",
    "five_fold_files = {\n",
    "    week: [\n",
    "        f\"{BASE_PATH}/clean_{week}/train/5-folds/data_part_{i}.csv\"\n",
    "        for i in range(1, fold_parts + 1)\n",
    "    ]\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Tạo file_validation\n",
    "file_validation = {\n",
    "    'week1': [f\"{BASE_PATH}/clean_week1/val/val_week1.csv\"],\n",
    "    'week2': [f\"{BASE_PATH}/clean_week2/val/val_week1_2.csv\"],\n",
    "    'week3': [f\"{BASE_PATH}/clean_week3/val/val_week1_2_3.csv\"],\n",
    "    'week4': [f\"{BASE_PATH}/clean_week4/val/val_week1_2_3_4.csv\"]\n",
    "}\n",
    "\n",
    "# Tạo file_test\n",
    "file_test = {\n",
    "    week: [f\"{BASE_PATH}/clean_{week}/test/test_{week}.csv\"]\n",
    "    for week in weeks\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631399c2",
   "metadata": {
    "papermill": {
     "duration": 0.004662,
     "end_time": "2025-04-05T05:17:15.854319",
     "exception": false,
     "start_time": "2025-04-05T05:17:15.849657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tìm siêu tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b22ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T05:17:15.865171Z",
     "iopub.status.busy": "2025-04-05T05:17:15.864919Z",
     "iopub.status.idle": "2025-04-05T05:17:15.875275Z",
     "shell.execute_reply": "2025-04-05T05:17:15.874634Z"
    },
    "papermill": {
     "duration": 0.017275,
     "end_time": "2025-04-05T05:17:15.876548",
     "exception": false,
     "start_time": "2025-04-05T05:17:15.859273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Tạo hàm train cho từng tuần\n",
    "def train_week_model(week_number, file_paths_train, file_validataion):\n",
    "    # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(file_paths_train)\n",
    "    val_data = pd.read_csv(file_validataion)\n",
    "    \n",
    "    # Tách đặc trưng và nhãn\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "    X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_val = val_data[\"classification_encoded\"]\n",
    "    \n",
    "    # Áp dụng Over-sampling cho dữ liệu huấn luyện bằng SMOTE\n",
    "    oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Reshape dữ liệu cho mô hình BiLSTM\n",
    "    X_train_res = X_train_res.values.reshape(X_train_res.shape[0], X_train_res.shape[1], 1)\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    \n",
    "    # One-hot encode nhãn\n",
    "    y_train_res = tf.keras.utils.to_categorical(y_train_res, num_classes=5)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "    \n",
    "    def build_model(hp):\n",
    "        inputs = tf.keras.Input(shape=(X_train_res.shape[1], 1))  # Khởi tạo đầu vào\n",
    "        \n",
    "        # Chỉ sử dụng một lớp Bidirectional LSTM\n",
    "        x = layers.Bidirectional(layers.LSTM(\n",
    "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=False  # Thay đổi thành False vì đây là lớp LSTM duy nhất\n",
    "        ))(inputs)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # Lớp đầu ra\n",
    "        outputs = layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        # Khởi tạo mô hình\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile với Focal Loss\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                          learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                      loss=focal_loss(gamma=2., alpha=0.25),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    # Khởi tạo RandomSearch tuner\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='my_dir',\n",
    "        project_name=f'bilstm_tuning_week{week_number}'\n",
    "    )\n",
    "    \n",
    "    # Tìm kiếm siêu tham số tốt nhất\n",
    "    tuner.search(X_train_res, y_train_res,\n",
    "                 epochs=20,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 batch_size=32)\n",
    "    \n",
    "    # Trả về kết quả tối ưu cho tuần\n",
    "    best_params = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569569a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T05:17:15.888121Z",
     "iopub.status.busy": "2025-04-05T05:17:15.887846Z",
     "iopub.status.idle": "2025-04-05T05:17:15.891700Z",
     "shell.execute_reply": "2025-04-05T05:17:15.891042Z"
    },
    "papermill": {
     "duration": 0.011103,
     "end_time": "2025-04-05T05:17:15.893022",
     "exception": false,
     "start_time": "2025-04-05T05:17:15.881919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa đường dẫn đến dữ liệu cho từng tuần\n",
    "file_paths_train = {\n",
    "    week: f\"{BASE_PATH}/clean_{week}/train/clean_data_{week}.csv\"\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Định nghĩa file_validation theo quy luật riêng\n",
    "file_validation = {\n",
    "    f\"week{idx + 1}\": f\"{BASE_PATH}/clean_week{idx + 1}/val/val_week{'_'.join(str(i) for i in range(1, idx + 2))}.csv\"\n",
    "    for idx in range(len(weeks))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed87cfc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T05:17:15.904375Z",
     "iopub.status.busy": "2025-04-05T05:17:15.904091Z",
     "iopub.status.idle": "2025-04-05T07:07:55.181665Z",
     "shell.execute_reply": "2025-04-05T07:07:55.180470Z"
    },
    "papermill": {
     "duration": 6639.285012,
     "end_time": "2025-04-05T07:07:55.183360",
     "exception": false,
     "start_time": "2025-04-05T05:17:15.898348",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 03m 00s]\n",
      "val_accuracy: 0.9945088624954224\n",
      "\n",
      "Best val_accuracy So Far: 0.9993898868560791\n",
      "Total elapsed time: 00h 29m 50s\n",
      "Best Parameters for Week 1:\n",
      "units_1: 256\n",
      "dropout_1: 0.2\n",
      "learning_rate: 0.002149933259913922\n",
      "\n",
      "Best Parameters for Week 2:\n",
      "units_1: 224\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.003982481621996575\n",
      "\n",
      "Best Parameters for Week 3:\n",
      "units_1: 32\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.004094138113214621\n",
      "\n",
      "Best Parameters for Week 4:\n",
      "units_1: 256\n",
      "dropout_1: 0.4\n",
      "learning_rate: 0.0007744958865587234\n"
     ]
    }
   ],
   "source": [
    "# Tìm tham số tốt nhất cho từng tuần\n",
    "best_params_week1 = train_week_model(1, file_paths_train[\"week1\"], file_validation[\"week1\"])\n",
    "best_params_week2 = train_week_model(2, file_paths_train[\"week2\"], file_validation[\"week2\"])\n",
    "best_params_week3 = train_week_model(3, file_paths_train[\"week3\"], file_validation[\"week3\"])\n",
    "best_params_week4 = train_week_model(4, file_paths_train[\"week4\"], file_validation[\"week4\"])\n",
    "\n",
    "# In thông tin chi tiết các tham số tối ưu\n",
    "print(\"Best Parameters for Week 1:\")\n",
    "for param_name in best_params_week1.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week1.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 2:\")\n",
    "for param_name in best_params_week2.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week2.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 3:\")\n",
    "for param_name in best_params_week3.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week3.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 4:\")\n",
    "for param_name in best_params_week4.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week4.get(param_name)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f05a3",
   "metadata": {
    "papermill": {
     "duration": 0.005162,
     "end_time": "2025-04-05T07:07:55.194914",
     "exception": false,
     "start_time": "2025-04-05T07:07:55.189752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Danh sách tham số tốt nhất của từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b38779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:07:55.206703Z",
     "iopub.status.busy": "2025-04-05T07:07:55.206337Z",
     "iopub.status.idle": "2025-04-05T07:07:55.210543Z",
     "shell.execute_reply": "2025-04-05T07:07:55.209650Z"
    },
    "papermill": {
     "duration": 0.011681,
     "end_time": "2025-04-05T07:07:55.211959",
     "exception": false,
     "start_time": "2025-04-05T07:07:55.200278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Danh sách tham số tốt nhất\n",
    "best_params = {\n",
    "    \"week1\": best_params_week1,\n",
    "    \"week2\": best_params_week2,\n",
    "    \"week3\": best_params_week3,\n",
    "    \"week4\": best_params_week4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dabc1e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:07:55.224244Z",
     "iopub.status.busy": "2025-04-05T07:07:55.223976Z",
     "iopub.status.idle": "2025-04-05T07:07:55.231964Z",
     "shell.execute_reply": "2025-04-05T07:07:55.231210Z"
    },
    "papermill": {
     "duration": 0.015406,
     "end_time": "2025-04-05T07:07:55.233310",
     "exception": false,
     "start_time": "2025-04-05T07:07:55.217904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "# # Xây dựng mô hình BiLSTM\n",
    "# def build_Bilstm_model(params, input_shape):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "#     # Bidirectional LSTM layer 1\n",
    "#     x = layers.Bidirectional(layers.LSTM(\n",
    "#         units=params.get('units_1'),\n",
    "#         return_sequences=True\n",
    "#     ))(inputs)\n",
    "#     x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "#     # Bidirectional LSTM layer 2\n",
    "#     x = layers.Bidirectional(layers.LSTM(\n",
    "#         units=params.get('units_2', 32),\n",
    "#         return_sequences=False\n",
    "#     ))(x)\n",
    "#     x = layers.Dropout(rate=params.get('dropout_2', 0.2))(x)\n",
    "    \n",
    "#     # Lớp đầu ra\n",
    "#     outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "#     # Khởi tạo mô hình\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     # Compile với Focal Loss\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "#                       learning_rate=params['learning_rate']),\n",
    "#                   loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "def build_Bilstm_model(params, input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "    # Chỉ sử dụng một lớp Bidirectional LSTM\n",
    "    x = layers.Bidirectional(layers.LSTM(\n",
    "        units=params.get('units_1', 64),\n",
    "        return_sequences=False  # Đặt thành False vì đây là lớp LSTM cuối cùng\n",
    "    ))(inputs)\n",
    "    x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile với Focal Loss\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e3f258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:07:55.245229Z",
     "iopub.status.busy": "2025-04-05T07:07:55.244971Z",
     "iopub.status.idle": "2025-04-05T07:40:58.371048Z",
     "shell.execute_reply": "2025-04-05T07:40:58.370060Z"
    },
    "papermill": {
     "duration": 1983.133891,
     "end_time": "2025-04-05T07:40:58.372666",
     "exception": false,
     "start_time": "2025-04-05T07:07:55.238775",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing week1 with best parameters...\n",
      "best parameters for week1: {'units_1': 256, 'dropout_1': 0.2, 'learning_rate': 0.002149933259913922}\n",
      "Fold 1: Using file /kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6446 - loss: 0.1305 - val_accuracy: 0.6828 - val_loss: 0.1142\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6709 - loss: 0.1181 - val_accuracy: 0.6954 - val_loss: 0.1121\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6907 - loss: 0.1139 - val_accuracy: 0.7080 - val_loss: 0.1119\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7126 - loss: 0.1096 - val_accuracy: 0.7518 - val_loss: 0.0982\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7356 - loss: 0.1031 - val_accuracy: 0.7568 - val_loss: 0.0988\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7449 - loss: 0.1003 - val_accuracy: 0.7575 - val_loss: 0.0953\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7377 - loss: 0.1028 - val_accuracy: 0.7575 - val_loss: 0.1005\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7574 - loss: 0.0962 - val_accuracy: 0.7747 - val_loss: 0.0882\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7545 - loss: 0.0984 - val_accuracy: 0.7720 - val_loss: 0.0897\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7616 - loss: 0.0956 - val_accuracy: 0.7888 - val_loss: 0.0896\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7751 - loss: 0.0906 - val_accuracy: 0.7903 - val_loss: 0.0874\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.0893 - val_accuracy: 0.7922 - val_loss: 0.0880\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7690 - loss: 0.0934 - val_accuracy: 0.7812 - val_loss: 0.0877\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7605 - loss: 0.0958 - val_accuracy: 0.8018 - val_loss: 0.0859\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.0938 - val_accuracy: 0.8105 - val_loss: 0.0836\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7735 - loss: 0.0962 - val_accuracy: 0.7937 - val_loss: 0.0832\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7734 - loss: 0.0918 - val_accuracy: 0.8018 - val_loss: 0.0872\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7636 - loss: 0.0956 - val_accuracy: 0.7846 - val_loss: 0.0996\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7728 - loss: 0.0906 - val_accuracy: 0.8048 - val_loss: 0.0789\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.0901 - val_accuracy: 0.8025 - val_loss: 0.0795\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7776 - loss: 0.0910 - val_accuracy: 0.7918 - val_loss: 0.0899\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.0893 - val_accuracy: 0.7953 - val_loss: 0.0830\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7761 - loss: 0.0908 - val_accuracy: 0.7949 - val_loss: 0.0810\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 0.0840 - val_accuracy: 0.8056 - val_loss: 0.0794\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7779 - loss: 0.0880 - val_accuracy: 0.7896 - val_loss: 0.0852\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.0886 - val_accuracy: 0.8140 - val_loss: 0.0798\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7754 - loss: 0.0882 - val_accuracy: 0.8029 - val_loss: 0.0810\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7874 - loss: 0.0888 - val_accuracy: 0.8166 - val_loss: 0.0762\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.0851 - val_accuracy: 0.7880 - val_loss: 0.0872\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7896 - loss: 0.0842 - val_accuracy: 0.8136 - val_loss: 0.0777\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.0859 - val_accuracy: 0.7949 - val_loss: 0.0813\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7858 - loss: 0.0872 - val_accuracy: 0.8063 - val_loss: 0.0792\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7822 - loss: 0.0866 - val_accuracy: 0.8147 - val_loss: 0.0743\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7767 - loss: 0.0900 - val_accuracy: 0.7865 - val_loss: 0.0958\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7837 - loss: 0.0857 - val_accuracy: 0.8216 - val_loss: 0.0728\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.0867 - val_accuracy: 0.8246 - val_loss: 0.0719\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7925 - loss: 0.0834 - val_accuracy: 0.7857 - val_loss: 0.0868\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.0844 - val_accuracy: 0.8246 - val_loss: 0.0734\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8003 - loss: 0.0830 - val_accuracy: 0.8090 - val_loss: 0.0708\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.0817 - val_accuracy: 0.8216 - val_loss: 0.0717\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8037 - loss: 0.0800 - val_accuracy: 0.8288 - val_loss: 0.0718\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7975 - loss: 0.0812 - val_accuracy: 0.8181 - val_loss: 0.0737\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.0831 - val_accuracy: 0.8342 - val_loss: 0.0683\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7986 - loss: 0.0818 - val_accuracy: 0.8033 - val_loss: 0.0777\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 0.0794 - val_accuracy: 0.8223 - val_loss: 0.0778\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7921 - loss: 0.0835 - val_accuracy: 0.8201 - val_loss: 0.0688\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7947 - loss: 0.0795 - val_accuracy: 0.8155 - val_loss: 0.0703\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7940 - loss: 0.0817 - val_accuracy: 0.8216 - val_loss: 0.0711\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.0804 - val_accuracy: 0.8239 - val_loss: 0.0686\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.0799 - val_accuracy: 0.8364 - val_loss: 0.0639\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6270 - loss: 0.1376 - val_accuracy: 0.6752 - val_loss: 0.1126\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6842 - loss: 0.1187 - val_accuracy: 0.7148 - val_loss: 0.1060\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6994 - loss: 0.1106 - val_accuracy: 0.6603 - val_loss: 0.1170\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7097 - loss: 0.1122 - val_accuracy: 0.7312 - val_loss: 0.1036\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7402 - loss: 0.1017 - val_accuracy: 0.7701 - val_loss: 0.0895\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7278 - loss: 0.1050 - val_accuracy: 0.7720 - val_loss: 0.0903\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7349 - loss: 0.1023 - val_accuracy: 0.7617 - val_loss: 0.0927\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7424 - loss: 0.1012 - val_accuracy: 0.7766 - val_loss: 0.0918\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7689 - loss: 0.0975 - val_accuracy: 0.7976 - val_loss: 0.0871\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7523 - loss: 0.1039 - val_accuracy: 0.7663 - val_loss: 0.0923\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7587 - loss: 0.1033 - val_accuracy: 0.8033 - val_loss: 0.0841\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 0.0955 - val_accuracy: 0.7869 - val_loss: 0.0839\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7718 - loss: 0.0922 - val_accuracy: 0.7800 - val_loss: 0.0907\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7495 - loss: 0.1006 - val_accuracy: 0.7960 - val_loss: 0.0843\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7637 - loss: 0.0944 - val_accuracy: 0.7934 - val_loss: 0.0879\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.0915 - val_accuracy: 0.8040 - val_loss: 0.0810\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.0951 - val_accuracy: 0.8044 - val_loss: 0.0812\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7737 - loss: 0.0923 - val_accuracy: 0.8075 - val_loss: 0.0781\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.0916 - val_accuracy: 0.7907 - val_loss: 0.0905\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.0916 - val_accuracy: 0.8124 - val_loss: 0.0818\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7820 - loss: 0.0891 - val_accuracy: 0.8079 - val_loss: 0.0772\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.0941 - val_accuracy: 0.7930 - val_loss: 0.0863\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.0917 - val_accuracy: 0.8105 - val_loss: 0.0777\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7770 - loss: 0.0883 - val_accuracy: 0.8018 - val_loss: 0.0789\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7809 - loss: 0.0889 - val_accuracy: 0.7945 - val_loss: 0.0844\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7687 - loss: 0.0940 - val_accuracy: 0.8018 - val_loss: 0.0798\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.0919 - val_accuracy: 0.7972 - val_loss: 0.0788\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7874 - loss: 0.0875 - val_accuracy: 0.8079 - val_loss: 0.0754\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7836 - loss: 0.0883 - val_accuracy: 0.8128 - val_loss: 0.0781\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7648 - loss: 0.0930 - val_accuracy: 0.7758 - val_loss: 0.0839\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.0934 - val_accuracy: 0.8288 - val_loss: 0.0760\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7859 - loss: 0.0863 - val_accuracy: 0.8136 - val_loss: 0.0768\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7847 - loss: 0.0878 - val_accuracy: 0.8181 - val_loss: 0.0738\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7942 - loss: 0.0851 - val_accuracy: 0.8185 - val_loss: 0.0770\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7717 - loss: 0.0882 - val_accuracy: 0.8140 - val_loss: 0.0763\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7859 - loss: 0.0856 - val_accuracy: 0.8056 - val_loss: 0.0748\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 0.0883 - val_accuracy: 0.8250 - val_loss: 0.0751\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.0880 - val_accuracy: 0.8174 - val_loss: 0.0743\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.0863 - val_accuracy: 0.8059 - val_loss: 0.0745\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7788 - loss: 0.0880 - val_accuracy: 0.8174 - val_loss: 0.0736\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 0.0874 - val_accuracy: 0.8143 - val_loss: 0.0770\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7915 - loss: 0.0845 - val_accuracy: 0.8010 - val_loss: 0.0774\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.0862 - val_accuracy: 0.8098 - val_loss: 0.0813\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7908 - loss: 0.0851 - val_accuracy: 0.8227 - val_loss: 0.0740\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7895 - loss: 0.0849 - val_accuracy: 0.8033 - val_loss: 0.0755\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.0852 - val_accuracy: 0.8056 - val_loss: 0.0786\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.0841 - val_accuracy: 0.8006 - val_loss: 0.0802\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7906 - loss: 0.0843 - val_accuracy: 0.8075 - val_loss: 0.0740\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8024 - loss: 0.0801 - val_accuracy: 0.8242 - val_loss: 0.0725\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7944 - loss: 0.0851 - val_accuracy: 0.8098 - val_loss: 0.0753\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Using file /kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6356 - loss: 0.1325 - val_accuracy: 0.7030 - val_loss: 0.1177\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6730 - loss: 0.1185 - val_accuracy: 0.7156 - val_loss: 0.1114\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6950 - loss: 0.1148 - val_accuracy: 0.7144 - val_loss: 0.1124\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.1077 - val_accuracy: 0.7716 - val_loss: 0.1012\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7261 - loss: 0.1070 - val_accuracy: 0.7465 - val_loss: 0.0990\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7396 - loss: 0.1027 - val_accuracy: 0.7869 - val_loss: 0.0913\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7544 - loss: 0.0979 - val_accuracy: 0.7815 - val_loss: 0.0902\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.0983 - val_accuracy: 0.7896 - val_loss: 0.0876\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7576 - loss: 0.0943 - val_accuracy: 0.7693 - val_loss: 0.0938\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7586 - loss: 0.0968 - val_accuracy: 0.7896 - val_loss: 0.0875\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7615 - loss: 0.0965 - val_accuracy: 0.7899 - val_loss: 0.0854\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7623 - loss: 0.0933 - val_accuracy: 0.7861 - val_loss: 0.0893\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7678 - loss: 0.0943 - val_accuracy: 0.7930 - val_loss: 0.0831\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7776 - loss: 0.0917 - val_accuracy: 0.7892 - val_loss: 0.0857\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7666 - loss: 0.0927 - val_accuracy: 0.7815 - val_loss: 0.0922\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7738 - loss: 0.0925 - val_accuracy: 0.7705 - val_loss: 0.0877\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7726 - loss: 0.0897 - val_accuracy: 0.7911 - val_loss: 0.0882\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.0912 - val_accuracy: 0.7972 - val_loss: 0.0857\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7730 - loss: 0.0892 - val_accuracy: 0.7937 - val_loss: 0.0869\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7760 - loss: 0.0925 - val_accuracy: 0.7995 - val_loss: 0.0839\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7714 - loss: 0.0920 - val_accuracy: 0.8040 - val_loss: 0.0864\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7671 - loss: 0.0920 - val_accuracy: 0.8048 - val_loss: 0.0808\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.0871 - val_accuracy: 0.8002 - val_loss: 0.0806\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7750 - loss: 0.0902 - val_accuracy: 0.7957 - val_loss: 0.0847\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 0.0892 - val_accuracy: 0.8018 - val_loss: 0.0877\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.0863 - val_accuracy: 0.8044 - val_loss: 0.0814\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7747 - loss: 0.0886 - val_accuracy: 0.8109 - val_loss: 0.0828\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7797 - loss: 0.0865 - val_accuracy: 0.7998 - val_loss: 0.0795\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7899 - loss: 0.0860 - val_accuracy: 0.8094 - val_loss: 0.0838\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7793 - loss: 0.0857 - val_accuracy: 0.8063 - val_loss: 0.0821\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7869 - loss: 0.0868 - val_accuracy: 0.8002 - val_loss: 0.0856\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7934 - loss: 0.0854 - val_accuracy: 0.8075 - val_loss: 0.0772\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.0851 - val_accuracy: 0.7819 - val_loss: 0.0902\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7810 - loss: 0.0886 - val_accuracy: 0.8059 - val_loss: 0.0788\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 0.0821 - val_accuracy: 0.7949 - val_loss: 0.0790\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.0836 - val_accuracy: 0.8170 - val_loss: 0.0814\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7874 - loss: 0.0849 - val_accuracy: 0.8170 - val_loss: 0.0765\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.0831 - val_accuracy: 0.8136 - val_loss: 0.0769\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7880 - loss: 0.0850 - val_accuracy: 0.7979 - val_loss: 0.0801\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.0855 - val_accuracy: 0.8197 - val_loss: 0.0738\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7944 - loss: 0.0834 - val_accuracy: 0.8178 - val_loss: 0.0779\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.0835 - val_accuracy: 0.8033 - val_loss: 0.0742\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7821 - loss: 0.0863 - val_accuracy: 0.7983 - val_loss: 0.0775\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.0820 - val_accuracy: 0.8029 - val_loss: 0.0827\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7946 - loss: 0.0820 - val_accuracy: 0.8002 - val_loss: 0.0764\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.0831 - val_accuracy: 0.8120 - val_loss: 0.0797\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.0837 - val_accuracy: 0.8212 - val_loss: 0.0747\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7908 - loss: 0.0808 - val_accuracy: 0.8174 - val_loss: 0.0760\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.0855 - val_accuracy: 0.8262 - val_loss: 0.0690\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.0799 - val_accuracy: 0.7876 - val_loss: 0.0732\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 4: Using file /kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6220 - loss: 0.1376 - val_accuracy: 0.6854 - val_loss: 0.1150\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6775 - loss: 0.1171 - val_accuracy: 0.7235 - val_loss: 0.1072\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.1140 - val_accuracy: 0.7334 - val_loss: 0.1025\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.1087 - val_accuracy: 0.7204 - val_loss: 0.1049\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7389 - loss: 0.1011 - val_accuracy: 0.7761 - val_loss: 0.0928\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.1028 - val_accuracy: 0.7777 - val_loss: 0.0888\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.0983 - val_accuracy: 0.7296 - val_loss: 0.0969\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7432 - loss: 0.0999 - val_accuracy: 0.7574 - val_loss: 0.0936\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.0977 - val_accuracy: 0.7815 - val_loss: 0.0910\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 0.0946 - val_accuracy: 0.7811 - val_loss: 0.0858\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.0957 - val_accuracy: 0.7818 - val_loss: 0.0868\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.0938 - val_accuracy: 0.7979 - val_loss: 0.0859\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7580 - loss: 0.0958 - val_accuracy: 0.7899 - val_loss: 0.0877\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7548 - loss: 0.0962 - val_accuracy: 0.7971 - val_loss: 0.0818\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7723 - loss: 0.0931 - val_accuracy: 0.7803 - val_loss: 0.0828\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.0956 - val_accuracy: 0.8028 - val_loss: 0.0841\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7688 - loss: 0.0934 - val_accuracy: 0.7998 - val_loss: 0.0815\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.0944 - val_accuracy: 0.8055 - val_loss: 0.0786\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.0903 - val_accuracy: 0.8101 - val_loss: 0.0799\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.0922 - val_accuracy: 0.7822 - val_loss: 0.0891\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.0912 - val_accuracy: 0.7990 - val_loss: 0.0838\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.0883 - val_accuracy: 0.7998 - val_loss: 0.0800\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.0898 - val_accuracy: 0.7906 - val_loss: 0.0881\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7749 - loss: 0.0913 - val_accuracy: 0.8085 - val_loss: 0.0774\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 0.0878 - val_accuracy: 0.7952 - val_loss: 0.0806\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7796 - loss: 0.0899 - val_accuracy: 0.7967 - val_loss: 0.0871\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.0908 - val_accuracy: 0.8082 - val_loss: 0.0810\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7902 - loss: 0.0836 - val_accuracy: 0.7948 - val_loss: 0.0815\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.0888 - val_accuracy: 0.8101 - val_loss: 0.0773\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.0887 - val_accuracy: 0.8139 - val_loss: 0.0798\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7863 - loss: 0.0860 - val_accuracy: 0.8005 - val_loss: 0.0781\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.0834 - val_accuracy: 0.8188 - val_loss: 0.0756\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7741 - loss: 0.0893 - val_accuracy: 0.8124 - val_loss: 0.0787\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.0865 - val_accuracy: 0.8124 - val_loss: 0.0799\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.0859 - val_accuracy: 0.8036 - val_loss: 0.0799\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.0850 - val_accuracy: 0.8085 - val_loss: 0.0800\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.0827 - val_accuracy: 0.8162 - val_loss: 0.0750\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7831 - loss: 0.0878 - val_accuracy: 0.8162 - val_loss: 0.0744\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7895 - loss: 0.0851 - val_accuracy: 0.8143 - val_loss: 0.0769\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7776 - loss: 0.0866 - val_accuracy: 0.8089 - val_loss: 0.0825\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7902 - loss: 0.0838 - val_accuracy: 0.8097 - val_loss: 0.0801\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7938 - loss: 0.0823 - val_accuracy: 0.8120 - val_loss: 0.0757\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.0836 - val_accuracy: 0.8127 - val_loss: 0.0786\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7983 - loss: 0.0812 - val_accuracy: 0.8074 - val_loss: 0.0763\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7973 - loss: 0.0800 - val_accuracy: 0.8181 - val_loss: 0.0764\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7841 - loss: 0.0840 - val_accuracy: 0.8181 - val_loss: 0.0723\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7982 - loss: 0.0824 - val_accuracy: 0.8005 - val_loss: 0.0758\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7954 - loss: 0.0830 - val_accuracy: 0.8257 - val_loss: 0.0723\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8008 - loss: 0.0800 - val_accuracy: 0.8127 - val_loss: 0.0752\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7921 - loss: 0.0820 - val_accuracy: 0.8024 - val_loss: 0.0786\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Using file /kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6282 - loss: 0.1321 - val_accuracy: 0.6926 - val_loss: 0.1164\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6738 - loss: 0.1175 - val_accuracy: 0.7483 - val_loss: 0.1064\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7014 - loss: 0.1109 - val_accuracy: 0.7330 - val_loss: 0.1019\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7352 - loss: 0.1043 - val_accuracy: 0.7490 - val_loss: 0.1022\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7308 - loss: 0.1043 - val_accuracy: 0.7818 - val_loss: 0.0907\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7475 - loss: 0.1012 - val_accuracy: 0.7674 - val_loss: 0.0960\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7504 - loss: 0.0994 - val_accuracy: 0.7712 - val_loss: 0.0987\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7486 - loss: 0.0980 - val_accuracy: 0.7765 - val_loss: 0.0875\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7430 - loss: 0.1008 - val_accuracy: 0.7731 - val_loss: 0.0883\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7638 - loss: 0.0982 - val_accuracy: 0.7838 - val_loss: 0.0889\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7628 - loss: 0.0953 - val_accuracy: 0.7757 - val_loss: 0.0934\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7589 - loss: 0.0977 - val_accuracy: 0.7887 - val_loss: 0.0881\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7611 - loss: 0.0956 - val_accuracy: 0.7662 - val_loss: 0.1033\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7503 - loss: 0.1019 - val_accuracy: 0.7510 - val_loss: 0.0933\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7694 - loss: 0.0955 - val_accuracy: 0.7952 - val_loss: 0.0836\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7730 - loss: 0.0931 - val_accuracy: 0.7960 - val_loss: 0.0836\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7636 - loss: 0.0953 - val_accuracy: 0.7941 - val_loss: 0.0867\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.0925 - val_accuracy: 0.7899 - val_loss: 0.0866\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7649 - loss: 0.0946 - val_accuracy: 0.8013 - val_loss: 0.0835\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7725 - loss: 0.0934 - val_accuracy: 0.7830 - val_loss: 0.0865\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7664 - loss: 0.0935 - val_accuracy: 0.7883 - val_loss: 0.0827\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7639 - loss: 0.0952 - val_accuracy: 0.7952 - val_loss: 0.0806\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7788 - loss: 0.0894 - val_accuracy: 0.8166 - val_loss: 0.0806\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.0878 - val_accuracy: 0.7933 - val_loss: 0.0829\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7729 - loss: 0.0933 - val_accuracy: 0.7921 - val_loss: 0.0835\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7739 - loss: 0.0930 - val_accuracy: 0.7902 - val_loss: 0.0829\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.0876 - val_accuracy: 0.8074 - val_loss: 0.0798\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7801 - loss: 0.0911 - val_accuracy: 0.8093 - val_loss: 0.0819\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7732 - loss: 0.0921 - val_accuracy: 0.7826 - val_loss: 0.0918\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.0888 - val_accuracy: 0.7960 - val_loss: 0.0849\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 0.0935 - val_accuracy: 0.8108 - val_loss: 0.0788\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.0879 - val_accuracy: 0.8196 - val_loss: 0.0763\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7895 - loss: 0.0848 - val_accuracy: 0.7948 - val_loss: 0.0834\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7777 - loss: 0.0910 - val_accuracy: 0.8135 - val_loss: 0.0774\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.0890 - val_accuracy: 0.8181 - val_loss: 0.0745\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7815 - loss: 0.0889 - val_accuracy: 0.8143 - val_loss: 0.0726\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.0878 - val_accuracy: 0.8089 - val_loss: 0.0755\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.0834 - val_accuracy: 0.7998 - val_loss: 0.0829\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.0847 - val_accuracy: 0.8177 - val_loss: 0.0749\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.0855 - val_accuracy: 0.8173 - val_loss: 0.0734\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 0.0808 - val_accuracy: 0.8063 - val_loss: 0.0768\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7975 - loss: 0.0832 - val_accuracy: 0.8139 - val_loss: 0.0751\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7851 - loss: 0.0869 - val_accuracy: 0.8257 - val_loss: 0.0735\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7890 - loss: 0.0839 - val_accuracy: 0.8265 - val_loss: 0.0720\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7915 - loss: 0.0836 - val_accuracy: 0.8230 - val_loss: 0.0718\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7888 - loss: 0.0838 - val_accuracy: 0.8074 - val_loss: 0.0719\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.0799 - val_accuracy: 0.8013 - val_loss: 0.0791\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7954 - loss: 0.0840 - val_accuracy: 0.8166 - val_loss: 0.0781\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.0826 - val_accuracy: 0.8112 - val_loss: 0.0746\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 0.0846 - val_accuracy: 0.8288 - val_loss: 0.0697\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average Accuracy ===\n",
      "0.8130\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.5984\n",
      "Macro Recall: 0.5702\n",
      "Macro F1-Score: 0.5694\n",
      "Macro AUC-ROC: 0.9167\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7956\n",
      "Weighted Recall: 0.8130\n",
      "Weighted F1-Score: 0.7991\n",
      "Weighted AUC-ROC: 0.9419\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.685389        0.781333          0.728221     0.928917\n",
      "1      1           0.050000        0.002273          0.004348     0.868808\n",
      "2      2           0.757116        0.476918          0.578019     0.901484\n",
      "3      3           0.597322        0.672220          0.627065     0.927783\n",
      "4      4           0.902021        0.918187          0.909502     0.956321\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2      3       4\n",
      "0  468.8  0.4  11.2   26.8    92.8\n",
      "1   59.0  0.2   1.4   13.2    13.6\n",
      "2   40.2  0.2  78.4   16.6    29.0\n",
      "3   25.4  0.0   3.6  112.4    25.8\n",
      "4   95.8  0.2  11.2   24.0  1472.4\n",
      "\n",
      "Processing week2 with best parameters...\n",
      "best parameters for week2: {'units_1': 224, 'dropout_1': 0.1, 'learning_rate': 0.003982481621996575}\n",
      "Fold 1: Using file /kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6449 - loss: 0.1303 - val_accuracy: 0.6691 - val_loss: 0.1269\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6868 - loss: 0.1169 - val_accuracy: 0.6908 - val_loss: 0.1081\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.1045 - val_accuracy: 0.7884 - val_loss: 0.0914\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 0.0956 - val_accuracy: 0.8349 - val_loss: 0.0788\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.0900 - val_accuracy: 0.8059 - val_loss: 0.0794\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8020 - loss: 0.0864 - val_accuracy: 0.8250 - val_loss: 0.0773\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.0831 - val_accuracy: 0.7945 - val_loss: 0.0871\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8004 - loss: 0.0894 - val_accuracy: 0.8189 - val_loss: 0.0819\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.0827 - val_accuracy: 0.7941 - val_loss: 0.0894\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8113 - loss: 0.0806 - val_accuracy: 0.8132 - val_loss: 0.0801\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8283 - loss: 0.0785 - val_accuracy: 0.7846 - val_loss: 0.1012\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.0866 - val_accuracy: 0.8422 - val_loss: 0.0665\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.0831 - val_accuracy: 0.8460 - val_loss: 0.0674\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.0817 - val_accuracy: 0.8330 - val_loss: 0.0890\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7971 - loss: 0.0904 - val_accuracy: 0.8410 - val_loss: 0.0767\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8195 - loss: 0.0802 - val_accuracy: 0.8422 - val_loss: 0.0695\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8310 - loss: 0.0751 - val_accuracy: 0.8406 - val_loss: 0.0713\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8183 - loss: 0.0809 - val_accuracy: 0.8494 - val_loss: 0.0676\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.0772 - val_accuracy: 0.8342 - val_loss: 0.0737\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.0753 - val_accuracy: 0.8399 - val_loss: 0.0693\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8297 - loss: 0.0776 - val_accuracy: 0.8460 - val_loss: 0.0732\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8295 - loss: 0.0774 - val_accuracy: 0.8380 - val_loss: 0.0750\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.0766 - val_accuracy: 0.8227 - val_loss: 0.0825\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8289 - loss: 0.0746 - val_accuracy: 0.8441 - val_loss: 0.0665\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8242 - loss: 0.0772 - val_accuracy: 0.8418 - val_loss: 0.0769\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.0853 - val_accuracy: 0.8498 - val_loss: 0.0671\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.0747 - val_accuracy: 0.8742 - val_loss: 0.0591\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 0.0721 - val_accuracy: 0.8525 - val_loss: 0.0627\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.0768 - val_accuracy: 0.8159 - val_loss: 0.0790\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.0786 - val_accuracy: 0.8399 - val_loss: 0.0677\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8252 - loss: 0.0775 - val_accuracy: 0.8406 - val_loss: 0.0653\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8309 - loss: 0.0737 - val_accuracy: 0.8334 - val_loss: 0.0681\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8201 - loss: 0.0758 - val_accuracy: 0.8384 - val_loss: 0.0646\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.0729 - val_accuracy: 0.8464 - val_loss: 0.0732\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.0772 - val_accuracy: 0.8448 - val_loss: 0.0704\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8231 - loss: 0.0819 - val_accuracy: 0.8669 - val_loss: 0.0572\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8475 - loss: 0.0676 - val_accuracy: 0.8353 - val_loss: 0.0724\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8332 - loss: 0.0705 - val_accuracy: 0.8551 - val_loss: 0.0653\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.0744 - val_accuracy: 0.8422 - val_loss: 0.0755\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8347 - loss: 0.0717 - val_accuracy: 0.8528 - val_loss: 0.0546\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.0709 - val_accuracy: 0.8384 - val_loss: 0.0649\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8446 - loss: 0.0676 - val_accuracy: 0.8811 - val_loss: 0.0532\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8505 - loss: 0.0659 - val_accuracy: 0.8841 - val_loss: 0.0535\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8491 - loss: 0.0641 - val_accuracy: 0.8738 - val_loss: 0.0601\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.0599 - val_accuracy: 0.8891 - val_loss: 0.0546\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8517 - loss: 0.0635 - val_accuracy: 0.8944 - val_loss: 0.0523\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.0635 - val_accuracy: 0.8467 - val_loss: 0.0620\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 0.0609 - val_accuracy: 0.8830 - val_loss: 0.0569\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.0601 - val_accuracy: 0.8872 - val_loss: 0.0440\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.0636 - val_accuracy: 0.8868 - val_loss: 0.0541\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6604 - loss: 0.1262 - val_accuracy: 0.7320 - val_loss: 0.1136\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6805 - loss: 0.1200 - val_accuracy: 0.8021 - val_loss: 0.0934\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7707 - loss: 0.0973 - val_accuracy: 0.8338 - val_loss: 0.0824\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.0918 - val_accuracy: 0.8300 - val_loss: 0.0707\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7993 - loss: 0.0848 - val_accuracy: 0.8113 - val_loss: 0.0888\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.0880 - val_accuracy: 0.8441 - val_loss: 0.0728\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7976 - loss: 0.0874 - val_accuracy: 0.8239 - val_loss: 0.0767\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8048 - loss: 0.0871 - val_accuracy: 0.8429 - val_loss: 0.0713\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.0870 - val_accuracy: 0.8364 - val_loss: 0.0744\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7860 - loss: 0.0925 - val_accuracy: 0.8239 - val_loss: 0.0750\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.0845 - val_accuracy: 0.8364 - val_loss: 0.0695\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.0904 - val_accuracy: 0.8532 - val_loss: 0.0676\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.0851 - val_accuracy: 0.8063 - val_loss: 0.0758\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.0871 - val_accuracy: 0.8239 - val_loss: 0.0782\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.0843 - val_accuracy: 0.8509 - val_loss: 0.0660\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.0832 - val_accuracy: 0.8437 - val_loss: 0.0681\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.0820 - val_accuracy: 0.8467 - val_loss: 0.0682\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.0800 - val_accuracy: 0.8597 - val_loss: 0.0682\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.0802 - val_accuracy: 0.8593 - val_loss: 0.0646\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.0785 - val_accuracy: 0.8235 - val_loss: 0.0715\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.0808 - val_accuracy: 0.8364 - val_loss: 0.0637\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8066 - loss: 0.0834 - val_accuracy: 0.8567 - val_loss: 0.0603\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.0786 - val_accuracy: 0.8525 - val_loss: 0.0616\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 0.0748 - val_accuracy: 0.8593 - val_loss: 0.0605\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8271 - loss: 0.0746 - val_accuracy: 0.8673 - val_loss: 0.0569\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8238 - loss: 0.0755 - val_accuracy: 0.8597 - val_loss: 0.0634\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8283 - loss: 0.0722 - val_accuracy: 0.8772 - val_loss: 0.0545\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8291 - loss: 0.0737 - val_accuracy: 0.8708 - val_loss: 0.0596\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.0769 - val_accuracy: 0.8711 - val_loss: 0.0638\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8182 - loss: 0.0757 - val_accuracy: 0.8753 - val_loss: 0.0571\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.0780 - val_accuracy: 0.8547 - val_loss: 0.0596\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.0731 - val_accuracy: 0.8727 - val_loss: 0.0582\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8308 - loss: 0.0717 - val_accuracy: 0.8654 - val_loss: 0.0622\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.0736 - val_accuracy: 0.8746 - val_loss: 0.0560\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8291 - loss: 0.0722 - val_accuracy: 0.8719 - val_loss: 0.0628\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.0748 - val_accuracy: 0.8567 - val_loss: 0.0620\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.0704 - val_accuracy: 0.8475 - val_loss: 0.0589\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8357 - loss: 0.0724 - val_accuracy: 0.8700 - val_loss: 0.0643\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8352 - loss: 0.0706 - val_accuracy: 0.8750 - val_loss: 0.0510\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 0.0682 - val_accuracy: 0.8902 - val_loss: 0.0515\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.0713 - val_accuracy: 0.8479 - val_loss: 0.0625\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.0672 - val_accuracy: 0.8891 - val_loss: 0.0547\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.0698 - val_accuracy: 0.8753 - val_loss: 0.0530\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.0666 - val_accuracy: 0.8567 - val_loss: 0.0583\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8369 - loss: 0.0704 - val_accuracy: 0.8563 - val_loss: 0.0645\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8367 - loss: 0.0680 - val_accuracy: 0.8910 - val_loss: 0.0514\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8381 - loss: 0.0689 - val_accuracy: 0.8532 - val_loss: 0.0570\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.0692 - val_accuracy: 0.8879 - val_loss: 0.0527\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8421 - loss: 0.0674 - val_accuracy: 0.8643 - val_loss: 0.0596\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8417 - loss: 0.0660 - val_accuracy: 0.8753 - val_loss: 0.0594\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Using file /kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6430 - loss: 0.1338 - val_accuracy: 0.6664 - val_loss: 0.1132\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7148 - loss: 0.1130 - val_accuracy: 0.7846 - val_loss: 0.0954\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7777 - loss: 0.0940 - val_accuracy: 0.8292 - val_loss: 0.0816\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.0918 - val_accuracy: 0.8185 - val_loss: 0.0801\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7910 - loss: 0.0900 - val_accuracy: 0.8239 - val_loss: 0.0833\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7960 - loss: 0.0873 - val_accuracy: 0.8353 - val_loss: 0.0756\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7985 - loss: 0.0841 - val_accuracy: 0.8075 - val_loss: 0.0814\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7955 - loss: 0.0868 - val_accuracy: 0.8433 - val_loss: 0.0757\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8164 - loss: 0.0810 - val_accuracy: 0.8223 - val_loss: 0.0754\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8105 - loss: 0.0833 - val_accuracy: 0.8483 - val_loss: 0.0709\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.0801 - val_accuracy: 0.8406 - val_loss: 0.0791\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8186 - loss: 0.0835 - val_accuracy: 0.8277 - val_loss: 0.0760\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 0.0812 - val_accuracy: 0.8437 - val_loss: 0.0688\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.0820 - val_accuracy: 0.7876 - val_loss: 0.1298\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.0805 - val_accuracy: 0.8685 - val_loss: 0.0676\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.0783 - val_accuracy: 0.8284 - val_loss: 0.0741\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.0770 - val_accuracy: 0.8620 - val_loss: 0.0653\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8419 - loss: 0.0731 - val_accuracy: 0.8410 - val_loss: 0.0753\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.0737 - val_accuracy: 0.8460 - val_loss: 0.0675\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.0716 - val_accuracy: 0.8551 - val_loss: 0.0651\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8361 - loss: 0.0728 - val_accuracy: 0.8719 - val_loss: 0.0637\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8517 - loss: 0.0690 - val_accuracy: 0.8685 - val_loss: 0.0591\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8442 - loss: 0.0732 - val_accuracy: 0.8578 - val_loss: 0.0607\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8421 - loss: 0.0756 - val_accuracy: 0.8658 - val_loss: 0.0623\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8451 - loss: 0.0713 - val_accuracy: 0.8502 - val_loss: 0.0666\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8519 - loss: 0.0686 - val_accuracy: 0.8521 - val_loss: 0.0796\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8305 - loss: 0.0761 - val_accuracy: 0.8582 - val_loss: 0.0700\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8612 - loss: 0.0647 - val_accuracy: 0.8826 - val_loss: 0.0550\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.0653 - val_accuracy: 0.8475 - val_loss: 0.0790\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.0696 - val_accuracy: 0.8841 - val_loss: 0.0557\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 0.0633 - val_accuracy: 0.8811 - val_loss: 0.0577\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8618 - loss: 0.0636 - val_accuracy: 0.8795 - val_loss: 0.0531\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.0625 - val_accuracy: 0.8925 - val_loss: 0.0535\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8599 - loss: 0.0637 - val_accuracy: 0.8830 - val_loss: 0.0501\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8493 - loss: 0.0656 - val_accuracy: 0.8864 - val_loss: 0.0517\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.0620 - val_accuracy: 0.8872 - val_loss: 0.0502\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 0.0627 - val_accuracy: 0.8708 - val_loss: 0.0533\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 0.0610 - val_accuracy: 0.8898 - val_loss: 0.0463\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8653 - loss: 0.0597 - val_accuracy: 0.8936 - val_loss: 0.0471\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8676 - loss: 0.0571 - val_accuracy: 0.9005 - val_loss: 0.0413\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8734 - loss: 0.0551 - val_accuracy: 0.8662 - val_loss: 0.0688\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.0616 - val_accuracy: 0.8868 - val_loss: 0.0478\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8617 - loss: 0.0590 - val_accuracy: 0.8891 - val_loss: 0.0481\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.0571 - val_accuracy: 0.9028 - val_loss: 0.0410\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8777 - loss: 0.0531 - val_accuracy: 0.8677 - val_loss: 0.0546\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.0492 - val_accuracy: 0.9093 - val_loss: 0.0373\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8731 - loss: 0.0538 - val_accuracy: 0.9020 - val_loss: 0.0408\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.0548 - val_accuracy: 0.9100 - val_loss: 0.0445\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.0542 - val_accuracy: 0.8944 - val_loss: 0.0444\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8735 - loss: 0.0532 - val_accuracy: 0.8883 - val_loss: 0.0533\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 4: Using file /kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6505 - loss: 0.1291 - val_accuracy: 0.7399 - val_loss: 0.1101\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7082 - loss: 0.1147 - val_accuracy: 0.7799 - val_loss: 0.0959\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.1014 - val_accuracy: 0.8196 - val_loss: 0.0787\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7823 - loss: 0.0920 - val_accuracy: 0.8307 - val_loss: 0.0722\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.0926 - val_accuracy: 0.8227 - val_loss: 0.0766\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.0885 - val_accuracy: 0.8310 - val_loss: 0.0742\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8006 - loss: 0.0867 - val_accuracy: 0.8169 - val_loss: 0.0774\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.0848 - val_accuracy: 0.8410 - val_loss: 0.0710\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.0810 - val_accuracy: 0.7319 - val_loss: 0.1025\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7931 - loss: 0.0864 - val_accuracy: 0.8288 - val_loss: 0.0722\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.0873 - val_accuracy: 0.8333 - val_loss: 0.0771\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.0831 - val_accuracy: 0.8459 - val_loss: 0.0715\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.0772 - val_accuracy: 0.8459 - val_loss: 0.0710\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.0784 - val_accuracy: 0.8509 - val_loss: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.0766 - val_accuracy: 0.8215 - val_loss: 0.0764\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.0818 - val_accuracy: 0.8444 - val_loss: 0.0714\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8242 - loss: 0.0821 - val_accuracy: 0.8596 - val_loss: 0.0605\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8207 - loss: 0.0813 - val_accuracy: 0.8387 - val_loss: 0.0703\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8262 - loss: 0.0789 - val_accuracy: 0.8707 - val_loss: 0.0596\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8378 - loss: 0.0736 - val_accuracy: 0.7693 - val_loss: 0.0766\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8330 - loss: 0.0750 - val_accuracy: 0.8455 - val_loss: 0.0659\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8360 - loss: 0.0741 - val_accuracy: 0.8375 - val_loss: 0.0662\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.0680 - val_accuracy: 0.8738 - val_loss: 0.0509\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8520 - loss: 0.0633 - val_accuracy: 0.8852 - val_loss: 0.0510\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.0615 - val_accuracy: 0.8825 - val_loss: 0.0504\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.0626 - val_accuracy: 0.9039 - val_loss: 0.0419\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.0591 - val_accuracy: 0.8768 - val_loss: 0.0557\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8594 - loss: 0.0597 - val_accuracy: 0.8783 - val_loss: 0.0466\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.0566 - val_accuracy: 0.8898 - val_loss: 0.0512\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8555 - loss: 0.0626 - val_accuracy: 0.8947 - val_loss: 0.0425\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8711 - loss: 0.0543 - val_accuracy: 0.8680 - val_loss: 0.0563\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.0594 - val_accuracy: 0.9027 - val_loss: 0.0425\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8599 - loss: 0.0577 - val_accuracy: 0.8829 - val_loss: 0.0496\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.0596 - val_accuracy: 0.8570 - val_loss: 0.0726\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.0582 - val_accuracy: 0.9027 - val_loss: 0.0422\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.0518 - val_accuracy: 0.9020 - val_loss: 0.0358\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.0581 - val_accuracy: 0.8764 - val_loss: 0.0506\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8576 - loss: 0.0612 - val_accuracy: 0.8940 - val_loss: 0.0405\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.0541 - val_accuracy: 0.9134 - val_loss: 0.0375\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8639 - loss: 0.0568 - val_accuracy: 0.8997 - val_loss: 0.0421\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8687 - loss: 0.0530 - val_accuracy: 0.9058 - val_loss: 0.0373\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.0504 - val_accuracy: 0.9088 - val_loss: 0.0367\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.0496 - val_accuracy: 0.8253 - val_loss: 0.0623\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.0559 - val_accuracy: 0.8928 - val_loss: 0.0516\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.0530 - val_accuracy: 0.9027 - val_loss: 0.0343\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.0550 - val_accuracy: 0.8947 - val_loss: 0.0417\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8785 - loss: 0.0507 - val_accuracy: 0.8856 - val_loss: 0.0416\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.0476 - val_accuracy: 0.9172 - val_loss: 0.0311\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.0461 - val_accuracy: 0.9123 - val_loss: 0.0381\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8911 - loss: 0.0448 - val_accuracy: 0.9039 - val_loss: 0.0410\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 5: Using file /kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6430 - loss: 0.1331 - val_accuracy: 0.6400 - val_loss: 0.1174\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6965 - loss: 0.1139 - val_accuracy: 0.7986 - val_loss: 0.0900\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7552 - loss: 0.1020 - val_accuracy: 0.8127 - val_loss: 0.0804\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.0937 - val_accuracy: 0.7933 - val_loss: 0.0836\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.0933 - val_accuracy: 0.8253 - val_loss: 0.0825\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.0912 - val_accuracy: 0.8280 - val_loss: 0.0779\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7947 - loss: 0.0882 - val_accuracy: 0.8028 - val_loss: 0.0818\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.0845 - val_accuracy: 0.7860 - val_loss: 0.0895\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8028 - loss: 0.0873 - val_accuracy: 0.8425 - val_loss: 0.0694\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.0839 - val_accuracy: 0.7704 - val_loss: 0.0900\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8181 - loss: 0.0800 - val_accuracy: 0.8284 - val_loss: 0.0761\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.0792 - val_accuracy: 0.8242 - val_loss: 0.0693\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8287 - loss: 0.0772 - val_accuracy: 0.8276 - val_loss: 0.0747\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.0784 - val_accuracy: 0.8619 - val_loss: 0.0665\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8207 - loss: 0.0779 - val_accuracy: 0.8455 - val_loss: 0.0708\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.0778 - val_accuracy: 0.8608 - val_loss: 0.0607\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 0.0718 - val_accuracy: 0.8471 - val_loss: 0.0675\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 0.0728 - val_accuracy: 0.8276 - val_loss: 0.0746\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8291 - loss: 0.0773 - val_accuracy: 0.8566 - val_loss: 0.0586\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8375 - loss: 0.0715 - val_accuracy: 0.8326 - val_loss: 0.0652\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8282 - loss: 0.0754 - val_accuracy: 0.8520 - val_loss: 0.0663\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.0749 - val_accuracy: 0.8516 - val_loss: 0.0682\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.0741 - val_accuracy: 0.8524 - val_loss: 0.0589\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8308 - loss: 0.0710 - val_accuracy: 0.8410 - val_loss: 0.0804\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.0698 - val_accuracy: 0.8490 - val_loss: 0.0693\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.0736 - val_accuracy: 0.8539 - val_loss: 0.0626\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8291 - loss: 0.0750 - val_accuracy: 0.8486 - val_loss: 0.0695\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8368 - loss: 0.0699 - val_accuracy: 0.8589 - val_loss: 0.0583\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.0667 - val_accuracy: 0.8600 - val_loss: 0.0569\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8349 - loss: 0.0696 - val_accuracy: 0.8555 - val_loss: 0.0614\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.0678 - val_accuracy: 0.8002 - val_loss: 0.0782\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8461 - loss: 0.0673 - val_accuracy: 0.8692 - val_loss: 0.0567\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8380 - loss: 0.0679 - val_accuracy: 0.8627 - val_loss: 0.0508\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.0652 - val_accuracy: 0.8421 - val_loss: 0.0678\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8329 - loss: 0.0692 - val_accuracy: 0.8436 - val_loss: 0.0618\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8435 - loss: 0.0654 - val_accuracy: 0.8425 - val_loss: 0.0632\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8487 - loss: 0.0644 - val_accuracy: 0.8963 - val_loss: 0.0475\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8419 - loss: 0.0647 - val_accuracy: 0.8783 - val_loss: 0.0566\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.0742 - val_accuracy: 0.8886 - val_loss: 0.0496\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8515 - loss: 0.0600 - val_accuracy: 0.8871 - val_loss: 0.0546\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8468 - loss: 0.0642 - val_accuracy: 0.8818 - val_loss: 0.0486\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.0627 - val_accuracy: 0.8955 - val_loss: 0.0450\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.0626 - val_accuracy: 0.8787 - val_loss: 0.0514\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.0627 - val_accuracy: 0.8719 - val_loss: 0.0589\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.0629 - val_accuracy: 0.8669 - val_loss: 0.0681\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.0677 - val_accuracy: 0.8715 - val_loss: 0.0466\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8498 - loss: 0.0626 - val_accuracy: 0.8947 - val_loss: 0.0494\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8647 - loss: 0.0593 - val_accuracy: 0.8959 - val_loss: 0.0424\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8570 - loss: 0.0584 - val_accuracy: 0.8909 - val_loss: 0.0434\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.0568 - val_accuracy: 0.8738 - val_loss: 0.0428\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.8856\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7876\n",
      "Macro Recall: 0.7260\n",
      "Macro F1-Score: 0.7368\n",
      "Macro AUC-ROC: 0.9654\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.8893\n",
      "Weighted Recall: 0.8856\n",
      "Weighted F1-Score: 0.8813\n",
      "Weighted AUC-ROC: 0.9770\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.879232        0.866667          0.867808     0.975514\n",
      "1      1           0.683568        0.452090          0.521319     0.971996\n",
      "2      2           0.746275        0.598278          0.637489     0.942540\n",
      "3      3           0.688948        0.753564          0.708649     0.952946\n",
      "4      4           0.939846        0.959468          0.948850     0.983897\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2      3       4\n",
      "0  520.0   2.0   7.6   26.2    44.2\n",
      "1   14.4  39.6   7.6   11.0    14.8\n",
      "2   13.4   4.0  98.4   22.0    26.6\n",
      "3   14.6   1.2  10.2  126.0    15.2\n",
      "4   36.4   2.2  19.6    6.8  1538.6\n",
      "\n",
      "Processing week3 with best parameters...\n",
      "best parameters for week3: {'units_1': 32, 'dropout_1': 0.1, 'learning_rate': 0.004094138113214621}\n",
      "Fold 1: Using file /kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6057 - loss: 0.1445 - val_accuracy: 0.7339 - val_loss: 0.1105\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7456 - loss: 0.1035 - val_accuracy: 0.8056 - val_loss: 0.0831\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.0860 - val_accuracy: 0.8532 - val_loss: 0.0689\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.0765 - val_accuracy: 0.8551 - val_loss: 0.0660\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8508 - loss: 0.0690 - val_accuracy: 0.8669 - val_loss: 0.0590\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.0707 - val_accuracy: 0.8509 - val_loss: 0.0675\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8707 - loss: 0.0606 - val_accuracy: 0.9104 - val_loss: 0.0425\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8868 - loss: 0.0527 - val_accuracy: 0.8494 - val_loss: 0.0668\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8807 - loss: 0.0534 - val_accuracy: 0.8986 - val_loss: 0.0397\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8902 - loss: 0.0487 - val_accuracy: 0.9108 - val_loss: 0.0360\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.0473 - val_accuracy: 0.9161 - val_loss: 0.0386\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9013 - loss: 0.0433 - val_accuracy: 0.9146 - val_loss: 0.0447\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.0455 - val_accuracy: 0.9218 - val_loss: 0.0296\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.0377 - val_accuracy: 0.9093 - val_loss: 0.0387\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.0386 - val_accuracy: 0.9108 - val_loss: 0.0308\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.0427 - val_accuracy: 0.9302 - val_loss: 0.0321\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.0373 - val_accuracy: 0.9108 - val_loss: 0.0333\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.0357 - val_accuracy: 0.9390 - val_loss: 0.0256\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.0324 - val_accuracy: 0.9131 - val_loss: 0.0376\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.0402 - val_accuracy: 0.9279 - val_loss: 0.0243\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9065 - loss: 0.0377 - val_accuracy: 0.9287 - val_loss: 0.0244\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.0350 - val_accuracy: 0.9360 - val_loss: 0.0240\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9122 - loss: 0.0348 - val_accuracy: 0.9363 - val_loss: 0.0226\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.0317 - val_accuracy: 0.9375 - val_loss: 0.0223\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.0300 - val_accuracy: 0.9173 - val_loss: 0.0337\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9217 - loss: 0.0307 - val_accuracy: 0.9340 - val_loss: 0.0259\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.0330 - val_accuracy: 0.9241 - val_loss: 0.0270\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.0305 - val_accuracy: 0.9440 - val_loss: 0.0185\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.0269 - val_accuracy: 0.9462 - val_loss: 0.0196\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9302 - loss: 0.0266 - val_accuracy: 0.9279 - val_loss: 0.0222\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.0286 - val_accuracy: 0.9653 - val_loss: 0.0164\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9212 - loss: 0.0289 - val_accuracy: 0.9238 - val_loss: 0.0318\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.0355 - val_accuracy: 0.9440 - val_loss: 0.0206\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9294 - loss: 0.0250 - val_accuracy: 0.9550 - val_loss: 0.0158\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9361 - loss: 0.0240 - val_accuracy: 0.9382 - val_loss: 0.0254\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.0287 - val_accuracy: 0.9470 - val_loss: 0.0193\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.0274 - val_accuracy: 0.9581 - val_loss: 0.0134\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.0261 - val_accuracy: 0.9356 - val_loss: 0.0322\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9366 - loss: 0.0234 - val_accuracy: 0.9413 - val_loss: 0.0233\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.0348 - val_accuracy: 0.9409 - val_loss: 0.0187\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9255 - loss: 0.0294 - val_accuracy: 0.9516 - val_loss: 0.0155\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.0250 - val_accuracy: 0.9604 - val_loss: 0.0148\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.0236 - val_accuracy: 0.9459 - val_loss: 0.0232\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9276 - loss: 0.0262 - val_accuracy: 0.9653 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.0269 - val_accuracy: 0.9493 - val_loss: 0.0164\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9173 - loss: 0.0291 - val_accuracy: 0.9424 - val_loss: 0.0232\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9329 - loss: 0.0238 - val_accuracy: 0.9485 - val_loss: 0.0158\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9320 - loss: 0.0241 - val_accuracy: 0.9348 - val_loss: 0.0187\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.0245 - val_accuracy: 0.9535 - val_loss: 0.0131\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 0.0244 - val_accuracy: 0.9482 - val_loss: 0.0203\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6198 - loss: 0.1374 - val_accuracy: 0.7442 - val_loss: 0.1048\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.1016 - val_accuracy: 0.8170 - val_loss: 0.0800\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 0.0924 - val_accuracy: 0.8509 - val_loss: 0.0726\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.0814 - val_accuracy: 0.8654 - val_loss: 0.0672\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8019 - loss: 0.0853 - val_accuracy: 0.8536 - val_loss: 0.0690\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8306 - loss: 0.0739 - val_accuracy: 0.8753 - val_loss: 0.0616\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.0692 - val_accuracy: 0.8906 - val_loss: 0.0543\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.0634 - val_accuracy: 0.8902 - val_loss: 0.0508\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8642 - loss: 0.0591 - val_accuracy: 0.9066 - val_loss: 0.0463\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.0544 - val_accuracy: 0.9192 - val_loss: 0.0396\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8586 - loss: 0.0577 - val_accuracy: 0.9119 - val_loss: 0.0442\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.0501 - val_accuracy: 0.9192 - val_loss: 0.0386\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8833 - loss: 0.0465 - val_accuracy: 0.9264 - val_loss: 0.0304\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.0545 - val_accuracy: 0.9150 - val_loss: 0.0353\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.0446 - val_accuracy: 0.9333 - val_loss: 0.0265\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.0462 - val_accuracy: 0.9215 - val_loss: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.0445 - val_accuracy: 0.9241 - val_loss: 0.0283\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8887 - loss: 0.0426 - val_accuracy: 0.9142 - val_loss: 0.0374\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.0453 - val_accuracy: 0.9318 - val_loss: 0.0237\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.0409 - val_accuracy: 0.9291 - val_loss: 0.0283\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.0478 - val_accuracy: 0.9321 - val_loss: 0.0227\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.0394 - val_accuracy: 0.9299 - val_loss: 0.0275\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.0416 - val_accuracy: 0.9440 - val_loss: 0.0222\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8960 - loss: 0.0379 - val_accuracy: 0.9287 - val_loss: 0.0261\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.0425 - val_accuracy: 0.9257 - val_loss: 0.0324\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.0403 - val_accuracy: 0.9413 - val_loss: 0.0226\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.0373 - val_accuracy: 0.9192 - val_loss: 0.0307\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8981 - loss: 0.0379 - val_accuracy: 0.9184 - val_loss: 0.0289\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9059 - loss: 0.0366 - val_accuracy: 0.9367 - val_loss: 0.0225\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9012 - loss: 0.0363 - val_accuracy: 0.9474 - val_loss: 0.0180\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9028 - loss: 0.0367 - val_accuracy: 0.9108 - val_loss: 0.0318\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.0382 - val_accuracy: 0.9241 - val_loss: 0.0248\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9082 - loss: 0.0333 - val_accuracy: 0.9535 - val_loss: 0.0170\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8903 - loss: 0.0420 - val_accuracy: 0.9409 - val_loss: 0.0187\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.0349 - val_accuracy: 0.9432 - val_loss: 0.0182\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.0343 - val_accuracy: 0.9283 - val_loss: 0.0244\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9121 - loss: 0.0321 - val_accuracy: 0.9112 - val_loss: 0.0291\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.0308 - val_accuracy: 0.9379 - val_loss: 0.0185\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.0332 - val_accuracy: 0.9543 - val_loss: 0.0161\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.0289 - val_accuracy: 0.9394 - val_loss: 0.0209\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.0294 - val_accuracy: 0.9543 - val_loss: 0.0150\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.0303 - val_accuracy: 0.9238 - val_loss: 0.0232\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8990 - loss: 0.0332 - val_accuracy: 0.9291 - val_loss: 0.0298\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.0316 - val_accuracy: 0.9325 - val_loss: 0.0196\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.0414 - val_accuracy: 0.9314 - val_loss: 0.0227\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9162 - loss: 0.0289 - val_accuracy: 0.9466 - val_loss: 0.0194\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.0306 - val_accuracy: 0.9428 - val_loss: 0.0198\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.0300 - val_accuracy: 0.9348 - val_loss: 0.0168\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.0283 - val_accuracy: 0.9268 - val_loss: 0.0206\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.0327 - val_accuracy: 0.9558 - val_loss: 0.0130\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 3: Using file /kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5923 - loss: 0.1475 - val_accuracy: 0.7693 - val_loss: 0.1060\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.0981 - val_accuracy: 0.8307 - val_loss: 0.0768\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.0749 - val_accuracy: 0.8547 - val_loss: 0.0654\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8324 - loss: 0.0750 - val_accuracy: 0.8677 - val_loss: 0.0600\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8466 - loss: 0.0696 - val_accuracy: 0.8689 - val_loss: 0.0579\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8622 - loss: 0.0618 - val_accuracy: 0.8700 - val_loss: 0.0533\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.0623 - val_accuracy: 0.8971 - val_loss: 0.0487\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8779 - loss: 0.0546 - val_accuracy: 0.8879 - val_loss: 0.0477\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8978 - loss: 0.0470 - val_accuracy: 0.9043 - val_loss: 0.0468\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8893 - loss: 0.0509 - val_accuracy: 0.8887 - val_loss: 0.0465\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8801 - loss: 0.0501 - val_accuracy: 0.9211 - val_loss: 0.0361\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8905 - loss: 0.0483 - val_accuracy: 0.9077 - val_loss: 0.0393\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.0462 - val_accuracy: 0.9272 - val_loss: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.0429 - val_accuracy: 0.9169 - val_loss: 0.0368\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.0375 - val_accuracy: 0.9116 - val_loss: 0.0355\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.0381 - val_accuracy: 0.9287 - val_loss: 0.0283\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9045 - loss: 0.0402 - val_accuracy: 0.9360 - val_loss: 0.0276\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.0342 - val_accuracy: 0.9405 - val_loss: 0.0243\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.0310 - val_accuracy: 0.9394 - val_loss: 0.0221\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.0283 - val_accuracy: 0.9371 - val_loss: 0.0214\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.0305 - val_accuracy: 0.9356 - val_loss: 0.0263\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.0275 - val_accuracy: 0.9501 - val_loss: 0.0179\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9220 - loss: 0.0293 - val_accuracy: 0.9279 - val_loss: 0.0266\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.0320 - val_accuracy: 0.9485 - val_loss: 0.0164\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.0296 - val_accuracy: 0.9489 - val_loss: 0.0185\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.0292 - val_accuracy: 0.9565 - val_loss: 0.0162\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9294 - loss: 0.0258 - val_accuracy: 0.9466 - val_loss: 0.0193\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.0278 - val_accuracy: 0.9340 - val_loss: 0.0242\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.0267 - val_accuracy: 0.9592 - val_loss: 0.0148\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.0271 - val_accuracy: 0.9630 - val_loss: 0.0151\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.0217 - val_accuracy: 0.9558 - val_loss: 0.0161\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.0262 - val_accuracy: 0.9596 - val_loss: 0.0155\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.0227 - val_accuracy: 0.9630 - val_loss: 0.0136\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.0243 - val_accuracy: 0.9177 - val_loss: 0.0374\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.0259 - val_accuracy: 0.9321 - val_loss: 0.0216\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.0276 - val_accuracy: 0.9447 - val_loss: 0.0162\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.0295 - val_accuracy: 0.9177 - val_loss: 0.0303\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9158 - loss: 0.0286 - val_accuracy: 0.9055 - val_loss: 0.0295\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.0274 - val_accuracy: 0.9619 - val_loss: 0.0145\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.0308 - val_accuracy: 0.9329 - val_loss: 0.0277\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.0237 - val_accuracy: 0.9462 - val_loss: 0.0199\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.0225 - val_accuracy: 0.9584 - val_loss: 0.0134\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 0.0228 - val_accuracy: 0.9485 - val_loss: 0.0167\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9306 - loss: 0.0228 - val_accuracy: 0.9485 - val_loss: 0.0185\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.0292 - val_accuracy: 0.9318 - val_loss: 0.0218\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.0301 - val_accuracy: 0.9367 - val_loss: 0.0180\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9218 - loss: 0.0295 - val_accuracy: 0.9276 - val_loss: 0.0197\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9278 - loss: 0.0259 - val_accuracy: 0.9421 - val_loss: 0.0179\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.0281 - val_accuracy: 0.9321 - val_loss: 0.0256\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.0330 - val_accuracy: 0.9485 - val_loss: 0.0160\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 4: Using file /kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6054 - loss: 0.1404 - val_accuracy: 0.7040 - val_loss: 0.1068\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7141 - loss: 0.1126 - val_accuracy: 0.8200 - val_loss: 0.0809\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.0840 - val_accuracy: 0.8330 - val_loss: 0.0704\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.0731 - val_accuracy: 0.8749 - val_loss: 0.0625\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 0.0685 - val_accuracy: 0.8799 - val_loss: 0.0529\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8644 - loss: 0.0620 - val_accuracy: 0.8944 - val_loss: 0.0460\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0551 - val_accuracy: 0.9138 - val_loss: 0.0391\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8864 - loss: 0.0507 - val_accuracy: 0.9001 - val_loss: 0.0464\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8836 - loss: 0.0545 - val_accuracy: 0.9077 - val_loss: 0.0432\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.0503 - val_accuracy: 0.9180 - val_loss: 0.0361\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8942 - loss: 0.0470 - val_accuracy: 0.9195 - val_loss: 0.0323\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.0450 - val_accuracy: 0.8974 - val_loss: 0.0409\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8923 - loss: 0.0461 - val_accuracy: 0.9081 - val_loss: 0.0356\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9059 - loss: 0.0402 - val_accuracy: 0.9211 - val_loss: 0.0289\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9012 - loss: 0.0430 - val_accuracy: 0.9233 - val_loss: 0.0316\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9057 - loss: 0.0394 - val_accuracy: 0.9211 - val_loss: 0.0290\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9059 - loss: 0.0410 - val_accuracy: 0.9325 - val_loss: 0.0291\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.0394 - val_accuracy: 0.9245 - val_loss: 0.0288\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.0420 - val_accuracy: 0.9203 - val_loss: 0.0354\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8975 - loss: 0.0432 - val_accuracy: 0.9130 - val_loss: 0.0421\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.0405 - val_accuracy: 0.9260 - val_loss: 0.0293\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9077 - loss: 0.0381 - val_accuracy: 0.9233 - val_loss: 0.0276\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.0385 - val_accuracy: 0.9241 - val_loss: 0.0268\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9084 - loss: 0.0383 - val_accuracy: 0.8776 - val_loss: 0.0499\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.0529 - val_accuracy: 0.9272 - val_loss: 0.0272\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.0387 - val_accuracy: 0.9294 - val_loss: 0.0267\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.0376 - val_accuracy: 0.9233 - val_loss: 0.0344\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.0381 - val_accuracy: 0.9157 - val_loss: 0.0297\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.0348 - val_accuracy: 0.9211 - val_loss: 0.0302\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9150 - loss: 0.0368 - val_accuracy: 0.9462 - val_loss: 0.0204\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.0335 - val_accuracy: 0.9428 - val_loss: 0.0218\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.0363 - val_accuracy: 0.9314 - val_loss: 0.0223\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9067 - loss: 0.0367 - val_accuracy: 0.9237 - val_loss: 0.0315\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.0312 - val_accuracy: 0.9466 - val_loss: 0.0195\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.0315 - val_accuracy: 0.9302 - val_loss: 0.0289\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.0343 - val_accuracy: 0.9477 - val_loss: 0.0173\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9191 - loss: 0.0324 - val_accuracy: 0.9516 - val_loss: 0.0180\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9316 - loss: 0.0282 - val_accuracy: 0.9455 - val_loss: 0.0190\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9302 - loss: 0.0275 - val_accuracy: 0.9207 - val_loss: 0.0295\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.0324 - val_accuracy: 0.9523 - val_loss: 0.0188\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9207 - loss: 0.0311 - val_accuracy: 0.9394 - val_loss: 0.0231\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.0302 - val_accuracy: 0.9546 - val_loss: 0.0156\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.0276 - val_accuracy: 0.9611 - val_loss: 0.0143\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.0273 - val_accuracy: 0.9420 - val_loss: 0.0209\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.0288 - val_accuracy: 0.9519 - val_loss: 0.0160\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.0287 - val_accuracy: 0.9062 - val_loss: 0.0339\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.0326 - val_accuracy: 0.9554 - val_loss: 0.0184\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9260 - loss: 0.0277 - val_accuracy: 0.9409 - val_loss: 0.0250\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.0340 - val_accuracy: 0.9531 - val_loss: 0.0171\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.0287 - val_accuracy: 0.9622 - val_loss: 0.0159\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 5: Using file /kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6205 - loss: 0.1392 - val_accuracy: 0.7265 - val_loss: 0.1045\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.0940 - val_accuracy: 0.8268 - val_loss: 0.0776\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8008 - loss: 0.0857 - val_accuracy: 0.8440 - val_loss: 0.0735\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8300 - loss: 0.0770 - val_accuracy: 0.8677 - val_loss: 0.0620\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8464 - loss: 0.0696 - val_accuracy: 0.8646 - val_loss: 0.0600\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.0643 - val_accuracy: 0.8928 - val_loss: 0.0510\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.0579 - val_accuracy: 0.8940 - val_loss: 0.0542\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.0589 - val_accuracy: 0.8947 - val_loss: 0.0536\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.0577 - val_accuracy: 0.8982 - val_loss: 0.0462\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8961 - loss: 0.0461 - val_accuracy: 0.8829 - val_loss: 0.0561\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.0559 - val_accuracy: 0.9077 - val_loss: 0.0509\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.0448 - val_accuracy: 0.9260 - val_loss: 0.0310\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.0449 - val_accuracy: 0.9024 - val_loss: 0.0422\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.0464 - val_accuracy: 0.9245 - val_loss: 0.0285\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.0395 - val_accuracy: 0.9127 - val_loss: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.0405 - val_accuracy: 0.9111 - val_loss: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.0415 - val_accuracy: 0.9252 - val_loss: 0.0293\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.0419 - val_accuracy: 0.9176 - val_loss: 0.0326\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.0364 - val_accuracy: 0.9218 - val_loss: 0.0284\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9054 - loss: 0.0389 - val_accuracy: 0.9237 - val_loss: 0.0304\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.0375 - val_accuracy: 0.9317 - val_loss: 0.0260\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.0377 - val_accuracy: 0.9268 - val_loss: 0.0307\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9178 - loss: 0.0332 - val_accuracy: 0.9306 - val_loss: 0.0249\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.0352 - val_accuracy: 0.9268 - val_loss: 0.0308\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9130 - loss: 0.0347 - val_accuracy: 0.9314 - val_loss: 0.0255\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9170 - loss: 0.0334 - val_accuracy: 0.9439 - val_loss: 0.0211\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9217 - loss: 0.0315 - val_accuracy: 0.9241 - val_loss: 0.0303\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.0299 - val_accuracy: 0.9169 - val_loss: 0.0343\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9121 - loss: 0.0329 - val_accuracy: 0.9348 - val_loss: 0.0258\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.0313 - val_accuracy: 0.9378 - val_loss: 0.0240\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9179 - loss: 0.0328 - val_accuracy: 0.9413 - val_loss: 0.0224\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 0.0334 - val_accuracy: 0.9481 - val_loss: 0.0187\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.0283 - val_accuracy: 0.9550 - val_loss: 0.0190\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9255 - loss: 0.0291 - val_accuracy: 0.9359 - val_loss: 0.0238\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.0307 - val_accuracy: 0.9451 - val_loss: 0.0211\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.0339 - val_accuracy: 0.9554 - val_loss: 0.0198\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.0312 - val_accuracy: 0.9466 - val_loss: 0.0234\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.0389 - val_accuracy: 0.9153 - val_loss: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.0288 - val_accuracy: 0.9535 - val_loss: 0.0167\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9352 - loss: 0.0270 - val_accuracy: 0.9458 - val_loss: 0.0238\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.0305 - val_accuracy: 0.9508 - val_loss: 0.0191\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.0277 - val_accuracy: 0.9577 - val_loss: 0.0174\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9294 - loss: 0.0281 - val_accuracy: 0.9558 - val_loss: 0.0174\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.0322 - val_accuracy: 0.9592 - val_loss: 0.0167\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9376 - loss: 0.0257 - val_accuracy: 0.9519 - val_loss: 0.0215\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.0265 - val_accuracy: 0.9287 - val_loss: 0.0234\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.0267 - val_accuracy: 0.9519 - val_loss: 0.0158\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.0255 - val_accuracy: 0.9127 - val_loss: 0.0292\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.0288 - val_accuracy: 0.9245 - val_loss: 0.0255\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.0299 - val_accuracy: 0.9302 - val_loss: 0.0238\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.9490\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.8894\n",
      "Macro Recall: 0.8359\n",
      "Macro F1-Score: 0.8412\n",
      "Macro AUC-ROC: 0.9909\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.9544\n",
      "Weighted Recall: 0.9490\n",
      "Weighted F1-Score: 0.9456\n",
      "Weighted AUC-ROC: 0.9960\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.986473        0.997000          0.991623     0.999522\n",
      "1      1           0.871637        0.832315          0.825179     0.994277\n",
      "2      2           0.814232        0.619283          0.689150     0.978714\n",
      "3      3           0.796884        0.737824          0.714849     0.984084\n",
      "4      4           0.977705        0.993140          0.985306     0.997837\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  598.2   0.2    1.2    0.4     0.0\n",
      "1    7.0  72.8    4.4    2.2     1.0\n",
      "2    0.8  12.2  101.8   33.0    16.6\n",
      "3    0.2   3.6   21.0  123.4    19.0\n",
      "4    0.4   2.2    3.4    5.0  1592.6\n",
      "\n",
      "Processing week4 with best parameters...\n",
      "best parameters for week4: {'units_1': 256, 'dropout_1': 0.4, 'learning_rate': 0.0007744958865587234}\n",
      "Fold 1: Using file /kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6190 - loss: 0.1422 - val_accuracy: 0.7713 - val_loss: 0.0989\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7638 - loss: 0.0990 - val_accuracy: 0.8750 - val_loss: 0.0631\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.0653 - val_accuracy: 0.8917 - val_loss: 0.0479\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.0480 - val_accuracy: 0.9173 - val_loss: 0.0337\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.0390 - val_accuracy: 0.9100 - val_loss: 0.0366\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9168 - loss: 0.0346 - val_accuracy: 0.9203 - val_loss: 0.0313\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.0309 - val_accuracy: 0.9291 - val_loss: 0.0299\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9277 - loss: 0.0286 - val_accuracy: 0.9485 - val_loss: 0.0194\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9299 - loss: 0.0276 - val_accuracy: 0.9413 - val_loss: 0.0184\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.0235 - val_accuracy: 0.9565 - val_loss: 0.0179\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.0257 - val_accuracy: 0.9405 - val_loss: 0.0197\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9446 - loss: 0.0215 - val_accuracy: 0.9539 - val_loss: 0.0152\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9420 - loss: 0.0198 - val_accuracy: 0.9680 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9500 - loss: 0.0187 - val_accuracy: 0.9581 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.0178 - val_accuracy: 0.9615 - val_loss: 0.0147\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.0177 - val_accuracy: 0.9661 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.0156 - val_accuracy: 0.9790 - val_loss: 0.0101\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.0148 - val_accuracy: 0.9729 - val_loss: 0.0098\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9592 - loss: 0.0146 - val_accuracy: 0.9703 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9527 - loss: 0.0169 - val_accuracy: 0.9691 - val_loss: 0.0097\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.0157 - val_accuracy: 0.9779 - val_loss: 0.0084\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9613 - loss: 0.0131 - val_accuracy: 0.9756 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9682 - loss: 0.0109 - val_accuracy: 0.9771 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.0114 - val_accuracy: 0.9695 - val_loss: 0.0073\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.0128 - val_accuracy: 0.9626 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9623 - loss: 0.0120 - val_accuracy: 0.9787 - val_loss: 0.0084\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.0118 - val_accuracy: 0.9676 - val_loss: 0.0084\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0089 - val_accuracy: 0.9748 - val_loss: 0.0064\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9601 - loss: 0.0125 - val_accuracy: 0.9832 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9651 - loss: 0.0102 - val_accuracy: 0.9794 - val_loss: 0.0062\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0089 - val_accuracy: 0.9836 - val_loss: 0.0066\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9676 - loss: 0.0099 - val_accuracy: 0.9848 - val_loss: 0.0068\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.0079 - val_accuracy: 0.9695 - val_loss: 0.0076\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9711 - loss: 0.0089 - val_accuracy: 0.9802 - val_loss: 0.0065\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9668 - loss: 0.0101 - val_accuracy: 0.9855 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9687 - loss: 0.0101 - val_accuracy: 0.9718 - val_loss: 0.0087\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.0109 - val_accuracy: 0.9638 - val_loss: 0.0088\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.0090 - val_accuracy: 0.9817 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.0078 - val_accuracy: 0.9882 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0087 - val_accuracy: 0.9889 - val_loss: 0.0040\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.0097 - val_accuracy: 0.9798 - val_loss: 0.0058\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0073 - val_accuracy: 0.9745 - val_loss: 0.0073\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0091 - val_accuracy: 0.9878 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9790 - loss: 0.0064 - val_accuracy: 0.9897 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9720 - loss: 0.0083 - val_accuracy: 0.9626 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0081 - val_accuracy: 0.9886 - val_loss: 0.0038\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0069 - val_accuracy: 0.9886 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9760 - loss: 0.0072 - val_accuracy: 0.9825 - val_loss: 0.0050\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.0093 - val_accuracy: 0.9909 - val_loss: 0.0035\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0072 - val_accuracy: 0.9897 - val_loss: 0.0037\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5986 - loss: 0.1471 - val_accuracy: 0.7606 - val_loss: 0.0968\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7670 - loss: 0.0950 - val_accuracy: 0.8936 - val_loss: 0.0597\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8686 - loss: 0.0607 - val_accuracy: 0.9226 - val_loss: 0.0392\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 0.0488 - val_accuracy: 0.9180 - val_loss: 0.0384\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9068 - loss: 0.0388 - val_accuracy: 0.9287 - val_loss: 0.0283\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9173 - loss: 0.0330 - val_accuracy: 0.9333 - val_loss: 0.0258\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.0315 - val_accuracy: 0.9329 - val_loss: 0.0214\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9322 - loss: 0.0265 - val_accuracy: 0.9565 - val_loss: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.0279 - val_accuracy: 0.9493 - val_loss: 0.0173\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.0251 - val_accuracy: 0.9344 - val_loss: 0.0214\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.0230 - val_accuracy: 0.9501 - val_loss: 0.0173\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9327 - loss: 0.0245 - val_accuracy: 0.9535 - val_loss: 0.0143\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.0220 - val_accuracy: 0.9588 - val_loss: 0.0145\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.0197 - val_accuracy: 0.9706 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.0175 - val_accuracy: 0.9501 - val_loss: 0.0140\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9520 - loss: 0.0167 - val_accuracy: 0.9550 - val_loss: 0.0165\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.0169 - val_accuracy: 0.9710 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9523 - loss: 0.0157 - val_accuracy: 0.9546 - val_loss: 0.0149\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9538 - loss: 0.0169 - val_accuracy: 0.9668 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9607 - loss: 0.0137 - val_accuracy: 0.9653 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.0133 - val_accuracy: 0.9729 - val_loss: 0.0074\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9607 - loss: 0.0135 - val_accuracy: 0.9748 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.0126 - val_accuracy: 0.9726 - val_loss: 0.0083\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9681 - loss: 0.0104 - val_accuracy: 0.9783 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.0124 - val_accuracy: 0.9813 - val_loss: 0.0054\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9678 - loss: 0.0108 - val_accuracy: 0.9699 - val_loss: 0.0085\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9686 - loss: 0.0110 - val_accuracy: 0.9825 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.0108 - val_accuracy: 0.9821 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9689 - loss: 0.0101 - val_accuracy: 0.9741 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9659 - loss: 0.0107 - val_accuracy: 0.9767 - val_loss: 0.0068\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.0116 - val_accuracy: 0.9836 - val_loss: 0.0048\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0085 - val_accuracy: 0.9817 - val_loss: 0.0048\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.0102 - val_accuracy: 0.9832 - val_loss: 0.0052\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0088 - val_accuracy: 0.9726 - val_loss: 0.0071\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0091 - val_accuracy: 0.9787 - val_loss: 0.0060\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0080 - val_accuracy: 0.9878 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9661 - loss: 0.0103 - val_accuracy: 0.9783 - val_loss: 0.0057\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.0077 - val_accuracy: 0.9729 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.0114 - val_accuracy: 0.9840 - val_loss: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9753 - loss: 0.0075 - val_accuracy: 0.9764 - val_loss: 0.0060\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.0080 - val_accuracy: 0.9783 - val_loss: 0.0056\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0081 - val_accuracy: 0.9859 - val_loss: 0.0042\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.0087 - val_accuracy: 0.9916 - val_loss: 0.0030\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0077 - val_accuracy: 0.9794 - val_loss: 0.0059\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0086 - val_accuracy: 0.9832 - val_loss: 0.0047\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9784 - loss: 0.0070 - val_accuracy: 0.9893 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.0078 - val_accuracy: 0.9874 - val_loss: 0.0037\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0073 - val_accuracy: 0.9779 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0078 - val_accuracy: 0.9752 - val_loss: 0.0081\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9724 - loss: 0.0079 - val_accuracy: 0.9737 - val_loss: 0.0082\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 3: Using file /kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6059 - loss: 0.1538 - val_accuracy: 0.7800 - val_loss: 0.0999\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7449 - loss: 0.1022 - val_accuracy: 0.8475 - val_loss: 0.0682\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8492 - loss: 0.0680 - val_accuracy: 0.8898 - val_loss: 0.0501\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8918 - loss: 0.0493 - val_accuracy: 0.9211 - val_loss: 0.0360\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.0425 - val_accuracy: 0.9215 - val_loss: 0.0308\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.0341 - val_accuracy: 0.9409 - val_loss: 0.0276\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.0323 - val_accuracy: 0.9508 - val_loss: 0.0231\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9296 - loss: 0.0264 - val_accuracy: 0.9443 - val_loss: 0.0222\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9275 - loss: 0.0274 - val_accuracy: 0.9440 - val_loss: 0.0207\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9367 - loss: 0.0250 - val_accuracy: 0.9550 - val_loss: 0.0183\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.0232 - val_accuracy: 0.9451 - val_loss: 0.0192\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9410 - loss: 0.0218 - val_accuracy: 0.9478 - val_loss: 0.0160\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.0199 - val_accuracy: 0.9649 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9465 - loss: 0.0193 - val_accuracy: 0.9558 - val_loss: 0.0181\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9443 - loss: 0.0195 - val_accuracy: 0.9695 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.0173 - val_accuracy: 0.9588 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.0173 - val_accuracy: 0.9691 - val_loss: 0.0106\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9560 - loss: 0.0152 - val_accuracy: 0.9710 - val_loss: 0.0105\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9583 - loss: 0.0150 - val_accuracy: 0.9600 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.0152 - val_accuracy: 0.9626 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.0123 - val_accuracy: 0.9748 - val_loss: 0.0083\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.0145 - val_accuracy: 0.9691 - val_loss: 0.0096\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0119 - val_accuracy: 0.9592 - val_loss: 0.0149\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9586 - loss: 0.0130 - val_accuracy: 0.9722 - val_loss: 0.0099\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.0137 - val_accuracy: 0.9790 - val_loss: 0.0074\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.0136 - val_accuracy: 0.9787 - val_loss: 0.0065\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.0111 - val_accuracy: 0.9821 - val_loss: 0.0053\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.0111 - val_accuracy: 0.9787 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9678 - loss: 0.0111 - val_accuracy: 0.9741 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.0103 - val_accuracy: 0.9760 - val_loss: 0.0062\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9675 - loss: 0.0108 - val_accuracy: 0.9825 - val_loss: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9691 - loss: 0.0102 - val_accuracy: 0.9577 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.0108 - val_accuracy: 0.9752 - val_loss: 0.0075\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9595 - loss: 0.0121 - val_accuracy: 0.9825 - val_loss: 0.0052\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.0097 - val_accuracy: 0.9569 - val_loss: 0.0126\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9597 - loss: 0.0127 - val_accuracy: 0.9634 - val_loss: 0.0112\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9694 - loss: 0.0093 - val_accuracy: 0.9855 - val_loss: 0.0047\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9712 - loss: 0.0084 - val_accuracy: 0.9821 - val_loss: 0.0055\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.0086 - val_accuracy: 0.9836 - val_loss: 0.0053\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9720 - loss: 0.0089 - val_accuracy: 0.9859 - val_loss: 0.0043\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.0082 - val_accuracy: 0.9638 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0081 - val_accuracy: 0.9874 - val_loss: 0.0041\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0077 - val_accuracy: 0.9825 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9731 - loss: 0.0088 - val_accuracy: 0.9790 - val_loss: 0.0070\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9718 - loss: 0.0083 - val_accuracy: 0.9844 - val_loss: 0.0047\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9694 - loss: 0.0096 - val_accuracy: 0.9806 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.0105 - val_accuracy: 0.9828 - val_loss: 0.0048\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9724 - loss: 0.0083 - val_accuracy: 0.9855 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0087 - val_accuracy: 0.9844 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 0.0075 - val_accuracy: 0.9764 - val_loss: 0.0065\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 4: Using file /kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6162 - loss: 0.1407 - val_accuracy: 0.7967 - val_loss: 0.0948\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7647 - loss: 0.0958 - val_accuracy: 0.8825 - val_loss: 0.0622\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8555 - loss: 0.0662 - val_accuracy: 0.8951 - val_loss: 0.0464\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.0492 - val_accuracy: 0.9298 - val_loss: 0.0325\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.0399 - val_accuracy: 0.9458 - val_loss: 0.0247\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.0346 - val_accuracy: 0.9436 - val_loss: 0.0231\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.0294 - val_accuracy: 0.9462 - val_loss: 0.0218\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.0281 - val_accuracy: 0.9375 - val_loss: 0.0206\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.0260 - val_accuracy: 0.9447 - val_loss: 0.0243\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.0254 - val_accuracy: 0.9424 - val_loss: 0.0175\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.0236 - val_accuracy: 0.9500 - val_loss: 0.0174\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.0212 - val_accuracy: 0.9580 - val_loss: 0.0163\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9380 - loss: 0.0232 - val_accuracy: 0.9504 - val_loss: 0.0151\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.0208 - val_accuracy: 0.9611 - val_loss: 0.0132\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.0185 - val_accuracy: 0.9641 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9506 - loss: 0.0173 - val_accuracy: 0.9638 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.0171 - val_accuracy: 0.9691 - val_loss: 0.0105\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.0166 - val_accuracy: 0.9741 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.0154 - val_accuracy: 0.9691 - val_loss: 0.0096\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9573 - loss: 0.0142 - val_accuracy: 0.9733 - val_loss: 0.0085\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.0147 - val_accuracy: 0.9569 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.0142 - val_accuracy: 0.9722 - val_loss: 0.0077\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.0146 - val_accuracy: 0.9695 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9608 - loss: 0.0124 - val_accuracy: 0.9783 - val_loss: 0.0068\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.0128 - val_accuracy: 0.9783 - val_loss: 0.0069\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.0117 - val_accuracy: 0.9783 - val_loss: 0.0073\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9608 - loss: 0.0148 - val_accuracy: 0.9783 - val_loss: 0.0067\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9663 - loss: 0.0102 - val_accuracy: 0.9809 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9661 - loss: 0.0109 - val_accuracy: 0.9626 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.0099 - val_accuracy: 0.9840 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9670 - loss: 0.0110 - val_accuracy: 0.9760 - val_loss: 0.0080\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.0080 - val_accuracy: 0.9714 - val_loss: 0.0086\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.0098 - val_accuracy: 0.9798 - val_loss: 0.0063\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9693 - loss: 0.0092 - val_accuracy: 0.9741 - val_loss: 0.0083\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0083 - val_accuracy: 0.9733 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.0089 - val_accuracy: 0.9703 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9666 - loss: 0.0110 - val_accuracy: 0.9798 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9746 - loss: 0.0072 - val_accuracy: 0.9874 - val_loss: 0.0042\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0084 - val_accuracy: 0.9901 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9737 - loss: 0.0080 - val_accuracy: 0.9863 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0089 - val_accuracy: 0.9886 - val_loss: 0.0036\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0080 - val_accuracy: 0.9817 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9706 - loss: 0.0089 - val_accuracy: 0.9889 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.0099 - val_accuracy: 0.9886 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0081 - val_accuracy: 0.9886 - val_loss: 0.0034\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.0086 - val_accuracy: 0.9737 - val_loss: 0.0056\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.0099 - val_accuracy: 0.9916 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.0091 - val_accuracy: 0.9767 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9705 - loss: 0.0079 - val_accuracy: 0.9878 - val_loss: 0.0033\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0071 - val_accuracy: 0.9851 - val_loss: 0.0039\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 5: Using file /kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6156 - loss: 0.1415 - val_accuracy: 0.7365 - val_loss: 0.1014\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.1028 - val_accuracy: 0.8780 - val_loss: 0.0639\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8539 - loss: 0.0655 - val_accuracy: 0.9119 - val_loss: 0.0426\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8897 - loss: 0.0480 - val_accuracy: 0.9142 - val_loss: 0.0336\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9138 - loss: 0.0375 - val_accuracy: 0.9329 - val_loss: 0.0282\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.0329 - val_accuracy: 0.9222 - val_loss: 0.0286\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.0312 - val_accuracy: 0.9439 - val_loss: 0.0223\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.0276 - val_accuracy: 0.9378 - val_loss: 0.0240\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.0282 - val_accuracy: 0.9367 - val_loss: 0.0198\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.0249 - val_accuracy: 0.9447 - val_loss: 0.0181\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9359 - loss: 0.0235 - val_accuracy: 0.9470 - val_loss: 0.0177\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.0217 - val_accuracy: 0.9622 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.0208 - val_accuracy: 0.9641 - val_loss: 0.0142\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9502 - loss: 0.0177 - val_accuracy: 0.9546 - val_loss: 0.0149\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.0178 - val_accuracy: 0.9622 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.0169 - val_accuracy: 0.9615 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.0155 - val_accuracy: 0.9603 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9599 - loss: 0.0142 - val_accuracy: 0.9676 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.0153 - val_accuracy: 0.9645 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9552 - loss: 0.0151 - val_accuracy: 0.9626 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.0145 - val_accuracy: 0.9783 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.0143 - val_accuracy: 0.9714 - val_loss: 0.0094\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0119 - val_accuracy: 0.9592 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.0126 - val_accuracy: 0.9744 - val_loss: 0.0083\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9655 - loss: 0.0115 - val_accuracy: 0.9706 - val_loss: 0.0089\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.0125 - val_accuracy: 0.9626 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9673 - loss: 0.0110 - val_accuracy: 0.9542 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.0144 - val_accuracy: 0.9607 - val_loss: 0.0141\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9594 - loss: 0.0126 - val_accuracy: 0.9683 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.0097 - val_accuracy: 0.9790 - val_loss: 0.0060\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0102 - val_accuracy: 0.9828 - val_loss: 0.0049\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9708 - loss: 0.0095 - val_accuracy: 0.9832 - val_loss: 0.0053\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9724 - loss: 0.0082 - val_accuracy: 0.9767 - val_loss: 0.0066\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0090 - val_accuracy: 0.9584 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.0117 - val_accuracy: 0.9844 - val_loss: 0.0051\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0082 - val_accuracy: 0.9840 - val_loss: 0.0049\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9693 - loss: 0.0089 - val_accuracy: 0.9821 - val_loss: 0.0045\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9701 - loss: 0.0095 - val_accuracy: 0.9603 - val_loss: 0.0196\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0106 - val_accuracy: 0.9783 - val_loss: 0.0058\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9743 - loss: 0.0086 - val_accuracy: 0.9771 - val_loss: 0.0063\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0096 - val_accuracy: 0.9851 - val_loss: 0.0045\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0067 - val_accuracy: 0.9783 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0077 - val_accuracy: 0.9771 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0096 - val_accuracy: 0.9851 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9731 - loss: 0.0080 - val_accuracy: 0.9836 - val_loss: 0.0041\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0072 - val_accuracy: 0.9844 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9757 - loss: 0.0081 - val_accuracy: 0.9817 - val_loss: 0.0046\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0078 - val_accuracy: 0.9756 - val_loss: 0.0075\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.0076 - val_accuracy: 0.9828 - val_loss: 0.0048\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0079 - val_accuracy: 0.9832 - val_loss: 0.0051\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.9816\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.9652\n",
      "Macro Recall: 0.9428\n",
      "Macro F1-Score: 0.9526\n",
      "Macro AUC-ROC: 0.9989\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.9817\n",
      "Weighted Recall: 0.9816\n",
      "Weighted F1-Score: 0.9812\n",
      "Weighted AUC-ROC: 0.9996\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.999001        0.999333          0.999167     1.000000\n",
      "1      1           0.973350        0.972414          0.971941     0.999968\n",
      "2      2           0.907794        0.861397          0.882632     0.996426\n",
      "3      3           0.960379        0.882685          0.917381     0.998407\n",
      "4      4           0.985539        0.998129          0.991774     0.999812\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  599.6   0.2    0.0    0.2     0.0\n",
      "1    0.0  85.0    2.0    0.0     0.4\n",
      "2    0.6   1.6  141.6    5.2    15.4\n",
      "3    0.0   0.2   11.6  147.6     7.8\n",
      "4    0.0   0.4    1.4    1.2  1600.6\n"
     ]
    }
   ],
   "source": [
    "# Biến lưu kết quả tổng quát\n",
    "overall_results_5folds = []\n",
    "\n",
    "# Lặp qua từng tuần\n",
    "for week, file_paths in five_fold_files.items():\n",
    "    print(f\"\\nProcessing {week} with best parameters...\")\n",
    "    params = best_params[week].values\n",
    "    print(f\"best parameters for {week}: {params}\")\n",
    "    \n",
    "    # Biến lưu kết quả cho từng tuần\n",
    "    week_results = {\n",
    "        \"week\": week,\n",
    "        \"accuracy_per_fold\": [],\n",
    "        \"precision_per_label\": [],\n",
    "        \"recall_per_label\": [],\n",
    "        \"f1_score_per_label\": [],\n",
    "        \"auc_roc_per_label\": [],    # AUC từng lớp\n",
    "        \"auc_roc_macro\": [],        # AUC macro\n",
    "        \"auc_roc_weighted\": [],     # AUC weighted (tự tính)\n",
    "        \"precision_macro\": [],\n",
    "        \"recall_macro\": [],\n",
    "        \"f1_macro\": [],\n",
    "        \"precision_weighted\": [],\n",
    "        \"recall_weighted\": [],\n",
    "        \"f1_weighted\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"train_times\": [],\n",
    "        \"test_times\": []\n",
    "    }\n",
    "\n",
    "    # Lặp qua từng fold\n",
    "    for i in range(len(file_paths)):\n",
    "        print(f\"Fold {i+1}: Using file {file_paths[i]} as test set\")\n",
    "        \n",
    "        # Tải dữ liệu\n",
    "        test_data = pd.read_csv(file_paths[i])\n",
    "        train_data = pd.concat([pd.read_csv(file_paths[j]) for j in range(len(file_paths)) if j != i])\n",
    "        \n",
    "        # Tách X và y\n",
    "        X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                           \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_train = to_categorical(train_data['classification_encoded'], num_classes=5)\n",
    "        \n",
    "        X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                         \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_test = to_categorical(test_data['classification_encoded'], num_classes=5)\n",
    "\n",
    "        # Reshape dữ liệu cho LSTM\n",
    "        X_train = X_train.to_numpy().reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        # Xây dựng mô hình với tham số tốt nhất\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        model = build_Bilstm_model(params, input_shape)\n",
    "        \n",
    "        # Bắt đầu tính thời gian huấn luyện\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)\n",
    "        end_train = time.time()\n",
    "        \n",
    "        # Bắt đầu tính thời gian kiểm thử\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        \n",
    "        # Tính thời gian và lưu lại\n",
    "        train_time = end_train - start_train\n",
    "        test_time = end_test - start_test\n",
    "        week_results[\"train_times\"].append(train_time)\n",
    "        week_results[\"test_times\"].append(test_time)\n",
    "\n",
    "        # Đánh giá mô hình trên tập kiểm thử của fold hiện tại\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        week_results[\"accuracy_per_fold\"].append(accuracy)\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_test_classes = y_test.argmax(axis=1)\n",
    "        \n",
    "        # Tính các chỉ số cho mỗi fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "        conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "        \n",
    "        # Tính AUC-ROC\n",
    "        try:\n",
    "            # Tính AUC macro và theo từng lớp với OvR\n",
    "            auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "            # Tính AUC weighted: tính trọng số theo số mẫu của từng lớp\n",
    "            supports = np.bincount(y_test_classes, minlength=5)\n",
    "            auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tính AUC: {e}\")\n",
    "            auc_macro = np.nan\n",
    "            auc_per_class = [np.nan] * 5\n",
    "            auc_weighted = np.nan\n",
    "            \n",
    "        # Lưu kết quả của fold hiện tại\n",
    "        week_results[\"precision_per_label\"].append(precision)\n",
    "        week_results[\"recall_per_label\"].append(recall)\n",
    "        week_results[\"f1_score_per_label\"].append(f1)\n",
    "        week_results[\"auc_roc_per_label\"].append(auc_per_class)  # AUC từng lớp\n",
    "        week_results[\"auc_roc_macro\"].append(auc_macro)          # AUC macro\n",
    "        week_results[\"auc_roc_weighted\"].append(auc_weighted)      # AUC weighted\n",
    "        week_results[\"confusion_matrices\"].append(conf_matrix)\n",
    "        week_results[\"precision_macro\"].append(precision_macro)\n",
    "        week_results[\"recall_macro\"].append(recall_macro)\n",
    "        week_results[\"f1_macro\"].append(f1_macro)\n",
    "        week_results[\"precision_weighted\"].append(precision_weighted)\n",
    "        week_results[\"recall_weighted\"].append(recall_weighted)\n",
    "        week_results[\"f1_weighted\"].append(f1_weighted)\n",
    "\n",
    "    # Tính trung bình cho từng nhãn\n",
    "    average_precision_per_label = np.mean(week_results[\"precision_per_label\"], axis=0)\n",
    "    average_recall_per_label = np.nanmean(week_results[\"recall_per_label\"], axis=0)\n",
    "    average_f1_per_label = np.nanmean(week_results[\"f1_score_per_label\"], axis=0)\n",
    "    average_auc_per_label = np.nanmean(week_results[\"auc_roc_per_label\"], axis=0)\n",
    "    average_confusion_matrix = np.nanmean(week_results[\"confusion_matrices\"], axis=0)\n",
    "    average_train_time = sum(week_results[\"train_times\"]) / len(week_results[\"train_times\"])\n",
    "    average_test_time = sum(week_results[\"test_times\"]) / len(week_results[\"test_times\"])\n",
    "    average_accuracy = np.nanmean(week_results[\"accuracy_per_fold\"])\n",
    "    average_precision_macro = np.nanmean(week_results[\"precision_macro\"])\n",
    "    average_recall_macro = np.nanmean(week_results[\"recall_macro\"])\n",
    "    average_f1_macro = np.nanmean(week_results[\"f1_macro\"])\n",
    "    average_auc_macro = np.nanmean(week_results[\"auc_roc_macro\"])\n",
    "    average_precision_weighted = np.nanmean(week_results[\"precision_weighted\"])\n",
    "    average_recall_weighted = np.nanmean(week_results[\"recall_weighted\"])\n",
    "    average_f1_weighted = np.nanmean(week_results[\"f1_weighted\"])\n",
    "    average_auc_weighted = np.nanmean(week_results[\"auc_roc_weighted\"])\n",
    "\n",
    "\n",
    "    # Tạo DataFrame cho precision, recall, f1-score\n",
    "    labels = np.unique(y_test_classes)  # Lấy nhãn từ y_test_classes\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Average Precision\": average_precision_per_label,\n",
    "        \"Average Recall\": average_recall_per_label,\n",
    "        \"Average F1-Score\": average_f1_per_label,\n",
    "        \"Average AUC\": average_auc_per_label\n",
    "    })\n",
    "    \n",
    "    # Tạo DataFrame cho confusion matrix\n",
    "    confusion_df = pd.DataFrame(average_confusion_matrix, index=labels, columns=labels)\n",
    "    # In kết quả Accuracy và Macro metrics\n",
    "    print(\"\\n=== Average Accuracy ===\")\n",
    "    print(f\"{average_accuracy:.4f}\")\n",
    "    print(\"\\n=== Average Macro Metrics ===\")\n",
    "    print(f\"Macro Precision: {average_precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {average_recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {average_f1_macro:.4f}\")\n",
    "    print(f\"Macro AUC-ROC: {average_auc_macro:.4f}\")\n",
    "    print(\"\\n=== Average Weighted Metrics ===\")\n",
    "    print(f\"Weighted Precision: {average_precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {average_recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {average_f1_weighted:.4f}\")\n",
    "    print(f\"Weighted AUC-ROC: {average_auc_weighted:.4f}\")\n",
    "    print(\"\\n=== Average Metrics per Label ===\")\n",
    "    print(metrics_df)\n",
    "    print(\"\\n=== Average Confusion Matrix ===\")\n",
    "    print(confusion_df)\n",
    "    \n",
    "    # Cập nhật kết quả cho tuần hiện tại\n",
    "    week_results.update({\n",
    "        \"average_accuracy\": average_accuracy,\n",
    "        \"average_precision_macro\": average_precision_macro,\n",
    "        \"average_recall_macro\": average_recall_macro,\n",
    "        \"average_f1_macro\": average_f1_macro,\n",
    "        \"average_auc_macro\": average_auc_macro,\n",
    "        \"average_precision_weighted\": average_precision_weighted,\n",
    "        \"average_recall_weighted\": average_recall_weighted,\n",
    "        \"average_f1_weighted\": average_f1_weighted,\n",
    "        \"average_auc_weighted\": average_auc_weighted,\n",
    "        \"average_metrics_df\": metrics_df,\n",
    "        \"average_confusion_matrix\": confusion_df,\n",
    "        \"average_train_times\": average_train_time,\n",
    "        \"average_test_times\": average_test_time,\n",
    "    })\n",
    "    overall_results_5folds.append(week_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a88d4",
   "metadata": {
    "papermill": {
     "duration": 1.920617,
     "end_time": "2025-04-05T07:41:02.189687",
     "exception": false,
     "start_time": "2025-04-05T07:41:00.269070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kết quả cross validation trên 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51687957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:41:05.791665Z",
     "iopub.status.busy": "2025-04-05T07:41:05.791312Z",
     "iopub.status.idle": "2025-04-05T07:41:05.821663Z",
     "shell.execute_reply": "2025-04-05T07:41:05.820942Z"
    },
    "papermill": {
     "duration": 1.822104,
     "end_time": "2025-04-05T07:41:05.823016",
     "exception": false,
     "start_time": "2025-04-05T07:41:04.000912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for week1 ===\n",
      "Average Accurancy: 0.9816216826438904\n",
      "Average Train Time: 98.6067 seconds\n",
      "Average Test Time: 0.5885 seconds\n",
      "Average AUC Macro: 0.9989225980105697\n",
      "Average AUC Weighted: 0.9995576306283234\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.685389        0.781333          0.728221     0.928917\n",
      "1      1           0.050000        0.002273          0.004348     0.868808\n",
      "2      2           0.757116        0.476918          0.578019     0.901484\n",
      "3      3           0.597322        0.672220          0.627065     0.927783\n",
      "4      4           0.902021        0.918187          0.909502     0.956321\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2      3       4\n",
      "0  468.8  0.4  11.2   26.8    92.8\n",
      "1   59.0  0.2   1.4   13.2    13.6\n",
      "2   40.2  0.2  78.4   16.6    29.0\n",
      "3   25.4  0.0   3.6  112.4    25.8\n",
      "4   95.8  0.2  11.2   24.0  1472.4\n",
      "\n",
      "=== Results for week2 ===\n",
      "Average Accurancy: 0.9816216826438904\n",
      "Average Train Time: 98.4602 seconds\n",
      "Average Test Time: 0.5756 seconds\n",
      "Average AUC Macro: 0.9989225980105697\n",
      "Average AUC Weighted: 0.9995576306283234\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.879232        0.866667          0.867808     0.975514\n",
      "1      1           0.683568        0.452090          0.521319     0.971996\n",
      "2      2           0.746275        0.598278          0.637489     0.942540\n",
      "3      3           0.688948        0.753564          0.708649     0.952946\n",
      "4      4           0.939846        0.959468          0.948850     0.983897\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2      3       4\n",
      "0  520.0   2.0   7.6   26.2    44.2\n",
      "1   14.4  39.6   7.6   11.0    14.8\n",
      "2   13.4   4.0  98.4   22.0    26.6\n",
      "3   14.6   1.2  10.2  126.0    15.2\n",
      "4   36.4   2.2  19.6    6.8  1538.6\n",
      "\n",
      "=== Results for week3 ===\n",
      "Average Accurancy: 0.9816216826438904\n",
      "Average Train Time: 97.8917 seconds\n",
      "Average Test Time: 0.5710 seconds\n",
      "Average AUC Macro: 0.9989225980105697\n",
      "Average AUC Weighted: 0.9995576306283234\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.986473        0.997000          0.991623     0.999522\n",
      "1      1           0.871637        0.832315          0.825179     0.994277\n",
      "2      2           0.814232        0.619283          0.689150     0.978714\n",
      "3      3           0.796884        0.737824          0.714849     0.984084\n",
      "4      4           0.977705        0.993140          0.985306     0.997837\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  598.2   0.2    1.2    0.4     0.0\n",
      "1    7.0  72.8    4.4    2.2     1.0\n",
      "2    0.8  12.2  101.8   33.0    16.6\n",
      "3    0.2   3.6   21.0  123.4    19.0\n",
      "4    0.4   2.2    3.4    5.0  1592.6\n",
      "\n",
      "=== Results for week4 ===\n",
      "Average Accurancy: 0.9816216826438904\n",
      "Average Train Time: 97.4634 seconds\n",
      "Average Test Time: 0.5563 seconds\n",
      "Average AUC Macro: 0.9989225980105697\n",
      "Average AUC Weighted: 0.9995576306283234\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.999001        0.999333          0.999167     1.000000\n",
      "1      1           0.973350        0.972414          0.971941     0.999968\n",
      "2      2           0.907794        0.861397          0.882632     0.996426\n",
      "3      3           0.960379        0.882685          0.917381     0.998407\n",
      "4      4           0.985539        0.998129          0.991774     0.999812\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  599.6   0.2    0.0    0.2     0.0\n",
      "1    0.0  85.0    2.0    0.0     0.4\n",
      "2    0.6   1.6  141.6    5.2    15.4\n",
      "3    0.0   0.2   11.6  147.6     7.8\n",
      "4    0.0   0.4    1.4    1.2  1600.6\n"
     ]
    }
   ],
   "source": [
    "# Duyệt qua các tuần trong overall_results\n",
    "for week_result in overall_results_5folds:\n",
    "    week = week_result[\"week\"]\n",
    "    average_train_time = np.mean(week_result[\"train_times\"])\n",
    "    average_test_time = np.mean(week_result[\"test_times\"])\n",
    "    average_metrics_df = week_result[\"average_metrics_df\"]\n",
    "    average_accuracy = np.mean(week_results[\"accuracy_per_fold\"])\n",
    "    average_confusion_matrix = week_result[\"average_confusion_matrix\"]\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n=== Results for {week} ===\")\n",
    "    print(f\"Average Accurancy: {average_accuracy}\")\n",
    "    print(f\"Average Train Time: {average_train_time:.4f} seconds\")\n",
    "    print(f\"Average Test Time: {average_test_time:.4f} seconds\")\n",
    "    print(f\"Average AUC Macro: {average_auc_macro}\")\n",
    "    print(f\"Average AUC Weighted: {average_auc_weighted}\")\n",
    "    print(\"\\nAverage Precision, Recall, F1-Score, AUC-ROC per Label:\")\n",
    "    print(average_metrics_df)\n",
    "    print(\"\\nAverage Confusion Matrix:\")\n",
    "    print(average_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2e798",
   "metadata": {
    "papermill": {
     "duration": 1.789032,
     "end_time": "2025-04-05T07:41:09.520037",
     "exception": false,
     "start_time": "2025-04-05T07:41:07.731005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kiểm tra trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e9c3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:41:13.290809Z",
     "iopub.status.busy": "2025-04-05T07:41:13.290471Z",
     "iopub.status.idle": "2025-04-05T07:41:13.305554Z",
     "shell.execute_reply": "2025-04-05T07:41:13.304809Z"
    },
    "papermill": {
     "duration": 1.89064,
     "end_time": "2025-04-05T07:41:13.306733",
     "exception": false,
     "start_time": "2025-04-05T07:41:11.416093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mảng lưu dữ liệu của các tuần\n",
    "results = []\n",
    "\n",
    "def process_week(week_num, best_params, results):\n",
    "    print(f\"\\n=== Processing Week {week_num} ===\")\n",
    "    params = best_params[f\"week{week_num}\"].values\n",
    "    # Đường dẫn tới dữ liệu tuần tương ứng\n",
    "    train_path = f\"{BASE_PATH}/clean_week{week_num}/train/clean_data_week{week_num}.csv\"\n",
    "    test_path = f\"{BASE_PATH}/clean_week{week_num}/test/test_week{week_num}.csv\"\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                       \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data['classification_encoded']\n",
    "    \n",
    "    X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                     \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_test = test_data['classification_encoded']\n",
    "\n",
    "    # Áp dụng SMOTE cho tập huấn luyện\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Chuyển đổi nhãn sang dạng one-hot\n",
    "    y_train_resampled = to_categorical(y_train_resampled, num_classes=5)\n",
    "    y_test = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "    # Reshape dữ liệu cho LSTM\n",
    "    X_train_resampled = X_train_resampled.to_numpy().reshape((X_train_resampled.shape[0], 1, X_train_resampled.shape[1]))\n",
    "    X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Xây dựng mô hình với tham số tốt nhất\n",
    "    input_shape = (X_train_resampled.shape[1], X_train_resampled.shape[2])\n",
    "    model = build_Bilstm_model(params, input_shape)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled, epochs=50, validation_split=0.1, batch_size=32)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Kiểm thử mô hình\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    # Tính thời gian huấn luyện và kiểm thử\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_test_classes = y_test.argmax(axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    # Tính AUC-ROC (với one-vs-rest)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "        auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "        # Tính AUC weighted tự tính theo trọng số mẫu của từng lớp\n",
    "        supports = np.bincount(y_test_classes, minlength=5)\n",
    "        auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tính AUC: {e}\")\n",
    "        auc_macro = np.nan\n",
    "        auc_per_class = [np.nan] * 5\n",
    "        auc_weighted = np.nan\n",
    "\n",
    "    # Lưu kết quả vào mảng\n",
    "    results.append({\n",
    "        \"week\": week_num,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_weighted\": precision_weighted,\n",
    "        \"recall_weighted\": recall_weighted,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"auc_weighted\": auc_weighted,\n",
    "        \"auc_per_class\": auc_per_class,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    })\n",
    "    \n",
    "    # In kết quả chi tiết\n",
    "    print(\"\\n=== Precision, Recall, F1-Score per Label ===\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Label\": np.unique(y_test_classes),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }))\n",
    "\n",
    "    print(\"\\n=== Macro Averages & Accuracy ===\")\n",
    "    print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Weighted Averages ===\")\n",
    "    print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")\n",
    "    \n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(pd.DataFrame(conf_matrix, index=np.unique(y_test_classes), columns=np.unique(y_test_classes)))\n",
    "    \n",
    "    print(f\"\\nTrain Time: {train_time:.2f} seconds\")\n",
    "    print(f\"Test Time: {test_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83023828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:41:16.977844Z",
     "iopub.status.busy": "2025-04-05T07:41:16.977248Z",
     "iopub.status.idle": "2025-04-05T07:46:18.314450Z",
     "shell.execute_reply": "2025-04-05T07:46:18.313548Z"
    },
    "papermill": {
     "duration": 303.283763,
     "end_time": "2025-04-05T07:46:18.315782",
     "exception": false,
     "start_time": "2025-04-05T07:41:15.032019",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4727 - loss: 0.1981 - val_accuracy: 0.4602 - val_loss: 0.3245\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5292 - loss: 0.1749 - val_accuracy: 0.3806 - val_loss: 0.2723\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5577 - loss: 0.1641 - val_accuracy: 0.3836 - val_loss: 0.2501\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5800 - loss: 0.1563 - val_accuracy: 0.3946 - val_loss: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 0.1549 - val_accuracy: 0.4353 - val_loss: 0.2228\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.1502 - val_accuracy: 0.4991 - val_loss: 0.2419\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6090 - loss: 0.1449 - val_accuracy: 0.5824 - val_loss: 0.1634\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6164 - loss: 0.1429 - val_accuracy: 0.5647 - val_loss: 0.1994\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6332 - loss: 0.1364 - val_accuracy: 0.4757 - val_loss: 0.2220\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6473 - loss: 0.1312 - val_accuracy: 0.5438 - val_loss: 0.1755\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6549 - loss: 0.1264 - val_accuracy: 0.6251 - val_loss: 0.1524\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6672 - loss: 0.1209 - val_accuracy: 0.5707 - val_loss: 0.2130\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6843 - loss: 0.1132 - val_accuracy: 0.6114 - val_loss: 0.1510\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6914 - loss: 0.1102 - val_accuracy: 0.5647 - val_loss: 0.1657\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6967 - loss: 0.1068 - val_accuracy: 0.6291 - val_loss: 0.1670\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7194 - loss: 0.0968 - val_accuracy: 0.6625 - val_loss: 0.1351\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.0906 - val_accuracy: 0.6580 - val_loss: 0.1438\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7314 - loss: 0.0911 - val_accuracy: 0.7456 - val_loss: 0.1014\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.0836 - val_accuracy: 0.6977 - val_loss: 0.1255\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.0805 - val_accuracy: 0.6540 - val_loss: 0.1278\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7597 - loss: 0.0786 - val_accuracy: 0.6393 - val_loss: 0.1079\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.0835 - val_accuracy: 0.5854 - val_loss: 0.1371\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7709 - loss: 0.0755 - val_accuracy: 0.4378 - val_loss: 0.1652\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.0723 - val_accuracy: 0.8261 - val_loss: 0.0469\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.0692 - val_accuracy: 0.6363 - val_loss: 0.1266\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7842 - loss: 0.0681 - val_accuracy: 0.6505 - val_loss: 0.0979\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.0690 - val_accuracy: 0.7276 - val_loss: 0.1041\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.0679 - val_accuracy: 0.7491 - val_loss: 0.0863\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.0690 - val_accuracy: 0.7885 - val_loss: 0.0977\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.0636 - val_accuracy: 0.5263 - val_loss: 0.1319\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.0600 - val_accuracy: 0.7583 - val_loss: 0.0703\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.0621 - val_accuracy: 0.7698 - val_loss: 0.1051\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8024 - loss: 0.0624 - val_accuracy: 0.6620 - val_loss: 0.1087\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.0624 - val_accuracy: 0.6847 - val_loss: 0.0836\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.0616 - val_accuracy: 0.6922 - val_loss: 0.0745\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.0620 - val_accuracy: 0.8381 - val_loss: 0.0626\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.0611 - val_accuracy: 0.7827 - val_loss: 0.0567\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8091 - loss: 0.0607 - val_accuracy: 0.8129 - val_loss: 0.0396\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.0563 - val_accuracy: 0.7730 - val_loss: 0.0453\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.0586 - val_accuracy: 0.6111 - val_loss: 0.1093\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.0579 - val_accuracy: 0.8122 - val_loss: 0.0475\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8214 - loss: 0.0559 - val_accuracy: 0.6899 - val_loss: 0.0906\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.0561 - val_accuracy: 0.8072 - val_loss: 0.0591\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.0547 - val_accuracy: 0.6909 - val_loss: 0.0879\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.0565 - val_accuracy: 0.8089 - val_loss: 0.0553\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.0540 - val_accuracy: 0.8114 - val_loss: 0.0525\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8193 - loss: 0.0570 - val_accuracy: 0.7548 - val_loss: 0.0711\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.0584 - val_accuracy: 0.7683 - val_loss: 0.0523\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.0552 - val_accuracy: 0.5974 - val_loss: 0.0848\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.0535 - val_accuracy: 0.8750 - val_loss: 0.0431\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.931034  0.864000  0.896266\n",
      "1      1   0.478723  0.818182  0.604027\n",
      "2      2   0.819277  0.660194  0.731183\n",
      "3      3   0.507937  0.615385  0.556522\n",
      "4      4   0.933198  0.920160  0.926633\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.7340\n",
      "Macro Recall: 0.7756\n",
      "Macro F1-Score: 0.7429\n",
      "Accuracy: 0.8682\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8833\n",
      "Weighted Recall: 0.8682\n",
      "Weighted F1-Score: 0.8731\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9670\n",
      "AUC Weighted: 0.9656\n",
      "AUC per Label: [0.98108861 0.96941001 0.983705   0.94061012 0.96035872]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  324  47   2   0    2\n",
      "1    9  45   1   0    0\n",
      "2    0   0  68   5   30\n",
      "3    0   0   6  64   34\n",
      "4   15   2   6  57  922\n",
      "\n",
      "Train Time: 300.61 seconds\n",
      "Test Time: 0.46 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(1, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80fdff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:46:22.407096Z",
     "iopub.status.busy": "2025-04-05T07:46:22.406777Z",
     "iopub.status.idle": "2025-04-05T07:51:26.469748Z",
     "shell.execute_reply": "2025-04-05T07:51:26.468811Z"
    },
    "papermill": {
     "duration": 306.102268,
     "end_time": "2025-04-05T07:51:26.471020",
     "exception": false,
     "start_time": "2025-04-05T07:46:20.368752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4646 - loss: 0.2010 - val_accuracy: 0.4103 - val_loss: 0.3213\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 0.1559 - val_accuracy: 0.3799 - val_loss: 0.2637\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6695 - loss: 0.1309 - val_accuracy: 0.6099 - val_loss: 0.1973\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7210 - loss: 0.1130 - val_accuracy: 0.6156 - val_loss: 0.1955\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7414 - loss: 0.1060 - val_accuracy: 0.6278 - val_loss: 0.1767\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.0959 - val_accuracy: 0.6313 - val_loss: 0.1043\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.0867 - val_accuracy: 0.3926 - val_loss: 0.2276\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 0.0769 - val_accuracy: 0.7955 - val_loss: 0.0710\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.0634 - val_accuracy: 0.9177 - val_loss: 0.0361\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0609 - val_accuracy: 0.8207 - val_loss: 0.0604\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8331 - loss: 0.0555 - val_accuracy: 0.3712 - val_loss: 0.1962\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.0599 - val_accuracy: 0.8860 - val_loss: 0.0481\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.0516 - val_accuracy: 0.9222 - val_loss: 0.0318\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.0526 - val_accuracy: 0.7975 - val_loss: 0.0504\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.0595 - val_accuracy: 0.8680 - val_loss: 0.0537\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.0574 - val_accuracy: 0.8533 - val_loss: 0.0522\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.0461 - val_accuracy: 0.9217 - val_loss: 0.0357\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8541 - loss: 0.0494 - val_accuracy: 0.8506 - val_loss: 0.0653\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.0468 - val_accuracy: 0.9381 - val_loss: 0.0341\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.0513 - val_accuracy: 0.8446 - val_loss: 0.0476\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8713 - loss: 0.0441 - val_accuracy: 0.7518 - val_loss: 0.1180\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.0454 - val_accuracy: 0.8224 - val_loss: 0.0683\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.0434 - val_accuracy: 0.8830 - val_loss: 0.0450\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.0440 - val_accuracy: 0.8102 - val_loss: 0.0558\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.0394 - val_accuracy: 0.9277 - val_loss: 0.0328\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.0407 - val_accuracy: 0.8124 - val_loss: 0.0530\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8864 - loss: 0.0391 - val_accuracy: 0.9302 - val_loss: 0.0283\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8843 - loss: 0.0406 - val_accuracy: 0.8880 - val_loss: 0.0508\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8938 - loss: 0.0383 - val_accuracy: 0.8516 - val_loss: 0.0530\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.0405 - val_accuracy: 0.8217 - val_loss: 0.0511\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.0386 - val_accuracy: 0.9299 - val_loss: 0.0301\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.0362 - val_accuracy: 0.7778 - val_loss: 0.0857\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.0404 - val_accuracy: 0.8062 - val_loss: 0.0642\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.0424 - val_accuracy: 0.9132 - val_loss: 0.0359\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8813 - loss: 0.0416 - val_accuracy: 0.9558 - val_loss: 0.0173\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.0360 - val_accuracy: 0.8084 - val_loss: 0.0650\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.0367 - val_accuracy: 0.8568 - val_loss: 0.0421\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 0.0346 - val_accuracy: 0.9596 - val_loss: 0.0147\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.0389 - val_accuracy: 0.8735 - val_loss: 0.0311\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8971 - loss: 0.0362 - val_accuracy: 0.7955 - val_loss: 0.0446\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.0438 - val_accuracy: 0.9556 - val_loss: 0.0197\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.0359 - val_accuracy: 0.8439 - val_loss: 0.0573\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9078 - loss: 0.0327 - val_accuracy: 0.9302 - val_loss: 0.0262\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.0331 - val_accuracy: 0.7119 - val_loss: 0.1165\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9113 - loss: 0.0317 - val_accuracy: 0.8892 - val_loss: 0.0485\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9022 - loss: 0.0351 - val_accuracy: 0.9067 - val_loss: 0.0325\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 0.0325 - val_accuracy: 0.8576 - val_loss: 0.0485\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.0336 - val_accuracy: 0.8680 - val_loss: 0.0470\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.0306 - val_accuracy: 0.8468 - val_loss: 0.0595\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.0362 - val_accuracy: 0.8304 - val_loss: 0.0517\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.926740  0.674667  0.780864\n",
      "1      1   0.704225  0.909091  0.793651\n",
      "2      2   0.538462  0.883495  0.669118\n",
      "3      3   0.523364  0.538462  0.530806\n",
      "4      4   0.893032  0.908184  0.900544\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.7172\n",
      "Macro Recall: 0.7828\n",
      "Macro F1-Score: 0.7350\n",
      "Accuracy: 0.8298\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8487\n",
      "Weighted Recall: 0.8298\n",
      "Weighted F1-Score: 0.8316\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9483\n",
      "AUC Weighted: 0.9525\n",
      "AUC per Label: [0.97259283 0.93304637 0.9501163  0.93770985 0.94789385]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  253  11  29   1   81\n",
      "1    2  50   1   0    2\n",
      "2    0   2  91   2    8\n",
      "3    1   1  28  56   18\n",
      "4   17   7  20  48  910\n",
      "\n",
      "Train Time: 303.33 seconds\n",
      "Test Time: 0.46 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(2, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a0122e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:51:31.329661Z",
     "iopub.status.busy": "2025-04-05T07:51:31.329299Z",
     "iopub.status.idle": "2025-04-05T07:56:46.864886Z",
     "shell.execute_reply": "2025-04-05T07:56:46.863661Z"
    },
    "papermill": {
     "duration": 317.954396,
     "end_time": "2025-04-05T07:56:46.866531",
     "exception": false,
     "start_time": "2025-04-05T07:51:28.912135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4797 - loss: 0.1963 - val_accuracy: 0.4380 - val_loss: 0.2577\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6566 - loss: 0.1270 - val_accuracy: 0.6049 - val_loss: 0.1796\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7783 - loss: 0.0774 - val_accuracy: 0.7144 - val_loss: 0.1003\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8448 - loss: 0.0520 - val_accuracy: 0.7171 - val_loss: 0.0455\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.0429 - val_accuracy: 0.7004 - val_loss: 0.0930\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.0367 - val_accuracy: 0.7204 - val_loss: 0.0554\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.0347 - val_accuracy: 0.8541 - val_loss: 0.0451\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.0337 - val_accuracy: 0.7595 - val_loss: 0.0788\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8970 - loss: 0.0311 - val_accuracy: 0.6822 - val_loss: 0.0765\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.0291 - val_accuracy: 0.8406 - val_loss: 0.0462\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.0270 - val_accuracy: 0.9159 - val_loss: 0.0218\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.0261 - val_accuracy: 0.9578 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.0238 - val_accuracy: 0.3053 - val_loss: 0.1104\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9085 - loss: 0.0277 - val_accuracy: 0.8014 - val_loss: 0.0357\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9123 - loss: 0.0260 - val_accuracy: 0.8705 - val_loss: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8957 - loss: 0.0309 - val_accuracy: 0.7962 - val_loss: 0.0562\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.0331 - val_accuracy: 0.7568 - val_loss: 0.0486\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.0285 - val_accuracy: 0.7920 - val_loss: 0.0395\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.0295 - val_accuracy: 0.9499 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9191 - loss: 0.0252 - val_accuracy: 0.9042 - val_loss: 0.0210\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.0252 - val_accuracy: 0.8481 - val_loss: 0.0261\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.0218 - val_accuracy: 0.8840 - val_loss: 0.0324\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.0231 - val_accuracy: 0.8197 - val_loss: 0.0392\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8939 - loss: 0.0336 - val_accuracy: 0.9379 - val_loss: 0.0187\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.0279 - val_accuracy: 0.8957 - val_loss: 0.0235\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.0268 - val_accuracy: 0.8523 - val_loss: 0.0467\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9123 - loss: 0.0288 - val_accuracy: 0.9531 - val_loss: 0.0097\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.0300 - val_accuracy: 0.7907 - val_loss: 0.0468\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.0353 - val_accuracy: 0.8770 - val_loss: 0.0257\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9116 - loss: 0.0282 - val_accuracy: 0.9154 - val_loss: 0.0250\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.0429 - val_accuracy: 0.9409 - val_loss: 0.0165\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.0287 - val_accuracy: 0.8137 - val_loss: 0.0335\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.0292 - val_accuracy: 0.9292 - val_loss: 0.0139\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.0309 - val_accuracy: 0.9219 - val_loss: 0.0190\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.0304 - val_accuracy: 0.9349 - val_loss: 0.0143\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.0270 - val_accuracy: 0.8556 - val_loss: 0.0342\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.0251 - val_accuracy: 0.8693 - val_loss: 0.0273\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.0256 - val_accuracy: 0.8062 - val_loss: 0.0382\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9100 - loss: 0.0243 - val_accuracy: 0.8421 - val_loss: 0.0345\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.0280 - val_accuracy: 0.9217 - val_loss: 0.0180\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.0315 - val_accuracy: 0.7900 - val_loss: 0.0550\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9038 - loss: 0.0303 - val_accuracy: 0.8868 - val_loss: 0.0253\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.0314 - val_accuracy: 0.8319 - val_loss: 0.0292\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.0244 - val_accuracy: 0.9481 - val_loss: 0.0109\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.0304 - val_accuracy: 0.8868 - val_loss: 0.0258\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9111 - loss: 0.0276 - val_accuracy: 0.9376 - val_loss: 0.0130\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8998 - loss: 0.0305 - val_accuracy: 0.9197 - val_loss: 0.0144\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.0274 - val_accuracy: 0.8379 - val_loss: 0.0495\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.0298 - val_accuracy: 0.9763 - val_loss: 0.0043\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.0255 - val_accuracy: 0.9593 - val_loss: 0.0108\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.991870  0.976000  0.983871\n",
      "1      1   0.785714  0.800000  0.792793\n",
      "2      2   0.782609  0.699029  0.738462\n",
      "3      3   0.495050  0.480769  0.487805\n",
      "4      4   0.925563  0.943114  0.934256\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.7962\n",
      "Macro Recall: 0.7798\n",
      "Macro F1-Score: 0.7874\n",
      "Accuracy: 0.9012\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8997\n",
      "Weighted Recall: 0.9012\n",
      "Weighted F1-Score: 0.9002\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9499\n",
      "AUC Weighted: 0.9676\n",
      "AUC per Label: [0.99675105 0.97110882 0.91578808 0.89680531 0.96922325]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  366   4   0   2    3\n",
      "1    1  44   1   0    9\n",
      "2    0   3  72   7   21\n",
      "3    0   0  11  50   43\n",
      "4    2   5   8  42  945\n",
      "\n",
      "Train Time: 314.65 seconds\n",
      "Test Time: 0.57 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(3, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4b9947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:56:52.375373Z",
     "iopub.status.busy": "2025-04-05T07:56:52.375023Z",
     "iopub.status.idle": "2025-04-05T08:02:09.084837Z",
     "shell.execute_reply": "2025-04-05T08:02:09.083913Z"
    },
    "papermill": {
     "duration": 319.468397,
     "end_time": "2025-04-05T08:02:09.086319",
     "exception": false,
     "start_time": "2025-04-05T07:56:49.617922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5240 - loss: 0.1839 - val_accuracy: 0.6495 - val_loss: 0.1909\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.0664 - val_accuracy: 0.7159 - val_loss: 0.0933\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.0293 - val_accuracy: 0.9102 - val_loss: 0.0200\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.0188 - val_accuracy: 0.8064 - val_loss: 0.0560\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.0172 - val_accuracy: 0.9738 - val_loss: 0.0068\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.0115 - val_accuracy: 0.9673 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9570 - loss: 0.0116 - val_accuracy: 0.8029 - val_loss: 0.0389\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.0104 - val_accuracy: 0.9414 - val_loss: 0.0135\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9568 - loss: 0.0122 - val_accuracy: 0.9631 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9721 - loss: 0.0077 - val_accuracy: 0.9294 - val_loss: 0.0240\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9607 - loss: 0.0108 - val_accuracy: 0.9728 - val_loss: 0.0069\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.0094 - val_accuracy: 0.9803 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9713 - loss: 0.0082 - val_accuracy: 0.9793 - val_loss: 0.0055\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0077 - val_accuracy: 0.9464 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 0.0068 - val_accuracy: 0.9691 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0071 - val_accuracy: 0.9638 - val_loss: 0.0085\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9709 - loss: 0.0077 - val_accuracy: 0.9643 - val_loss: 0.0086\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.0070 - val_accuracy: 0.9761 - val_loss: 0.0057\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.0078 - val_accuracy: 0.9678 - val_loss: 0.0062\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0066 - val_accuracy: 0.9681 - val_loss: 0.0087\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9776 - loss: 0.0057 - val_accuracy: 0.9776 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.0056 - val_accuracy: 0.9401 - val_loss: 0.0176\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0071 - val_accuracy: 0.9613 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0055 - val_accuracy: 0.9080 - val_loss: 0.0180\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9782 - loss: 0.0058 - val_accuracy: 0.9444 - val_loss: 0.0175\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9812 - loss: 0.0052 - val_accuracy: 0.9673 - val_loss: 0.0084\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0059 - val_accuracy: 0.9568 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0051 - val_accuracy: 0.9426 - val_loss: 0.0140\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.0057 - val_accuracy: 0.9950 - val_loss: 0.0021\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0049 - val_accuracy: 0.9691 - val_loss: 0.0068\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0048 - val_accuracy: 0.9499 - val_loss: 0.0125\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0055 - val_accuracy: 0.9718 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9845 - loss: 0.0044 - val_accuracy: 0.9913 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0068 - val_accuracy: 0.9895 - val_loss: 0.0030\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0039 - val_accuracy: 0.9935 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9783 - loss: 0.0057 - val_accuracy: 0.9469 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.0058 - val_accuracy: 0.9880 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9830 - loss: 0.0046 - val_accuracy: 0.9169 - val_loss: 0.0225\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0059 - val_accuracy: 0.9785 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0049 - val_accuracy: 0.9224 - val_loss: 0.0224\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0042 - val_accuracy: 0.9429 - val_loss: 0.0187\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0052 - val_accuracy: 0.9344 - val_loss: 0.0218\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9825 - loss: 0.0046 - val_accuracy: 0.9751 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0046 - val_accuracy: 0.9788 - val_loss: 0.0051\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9842 - loss: 0.0042 - val_accuracy: 0.9756 - val_loss: 0.0066\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0045 - val_accuracy: 0.9721 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0046 - val_accuracy: 0.9613 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0044 - val_accuracy: 0.9788 - val_loss: 0.0051\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0041 - val_accuracy: 0.9890 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0041 - val_accuracy: 0.9628 - val_loss: 0.0098\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   1.000000  0.984000  0.991935\n",
      "1      1   0.896552  0.945455  0.920354\n",
      "2      2   0.802083  0.747573  0.773869\n",
      "3      3   0.818182  0.432692  0.566038\n",
      "4      4   0.934025  0.989022  0.960737\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.8902\n",
      "Macro Recall: 0.8197\n",
      "Macro F1-Score: 0.8426\n",
      "Accuracy: 0.9359\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.9322\n",
      "Weighted Recall: 0.9359\n",
      "Weighted F1-Score: 0.9297\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9867\n",
      "AUC Weighted: 0.9926\n",
      "AUC per Label: [0.99990506 0.99816345 0.97939422 0.9621774  0.99402138]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  369   2   3   1    0\n",
      "1    0  52   1   0    2\n",
      "2    0   1  77   4   21\n",
      "3    0   2  10  45   47\n",
      "4    0   1   5   5  991\n",
      "\n",
      "Train Time: 315.84 seconds\n",
      "Test Time: 0.51 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(4, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a6b8c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T08:02:15.367592Z",
     "iopub.status.busy": "2025-04-05T08:02:15.367211Z",
     "iopub.status.idle": "2025-04-05T08:02:15.386661Z",
     "shell.execute_reply": "2025-04-05T08:02:15.385830Z"
    },
    "papermill": {
     "duration": 3.218374,
     "end_time": "2025-04-05T08:02:15.387907",
     "exception": false,
     "start_time": "2025-04-05T08:02:12.169533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Results for All Weeks ===\n",
      "Week 1:\n",
      "  Train Time: 300.61 seconds\n",
      "  Test Time: 0.46 seconds\n",
      "  Accurancy: 0.8682123245881636\n",
      "  Precision: [0.93103448 0.4787234  0.81927711 0.50793651 0.93319838]\n",
      "  Recall: [0.864      0.81818182 0.66019417 0.61538462 0.92015968]\n",
      "  F1-Score: [0.89626556 0.60402685 0.7311828  0.55652174 0.92663317]\n",
      "  Macro Precision: 0.7340339767901969\n",
      "  Macro Recall: 0.7755840577924876\n",
      "  Macro F1-Score: 0.7429260212924128\n",
      "  Confusion Matrix:\n",
      "[[324  47   2   0   2]\n",
      " [  9  45   1   0   0]\n",
      " [  0   0  68   5  30]\n",
      " [  0   0   6  64  34]\n",
      " [ 15   2   6  57 922]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9670\n",
      "AUC Weighted: 0.9656\n",
      "AUC per Label: [0.98108861 0.96941001 0.983705   0.94061012 0.96035872]\n",
      "Week 2:\n",
      "  Train Time: 303.33 seconds\n",
      "  Test Time: 0.46 seconds\n",
      "  Accurancy: 0.8297742525930445\n",
      "  Precision: [0.92673993 0.70422535 0.53846154 0.52336449 0.89303238]\n",
      "  Recall: [0.67466667 0.90909091 0.88349515 0.53846154 0.90818363]\n",
      "  F1-Score: [0.7808642  0.79365079 0.66911765 0.53080569 0.90054429]\n",
      "  Macro Precision: 0.7171647375972647\n",
      "  Macro Recall: 0.7827795785169427\n",
      "  Macro F1-Score: 0.734996522090339\n",
      "  Confusion Matrix:\n",
      "[[253  11  29   1  81]\n",
      " [  2  50   1   0   2]\n",
      " [  0   2  91   2   8]\n",
      " [  1   1  28  56  18]\n",
      " [ 17   7  20  48 910]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9483\n",
      "AUC Weighted: 0.9525\n",
      "AUC per Label: [0.97259283 0.93304637 0.9501163  0.93770985 0.94789385]\n",
      "Week 3:\n",
      "  Train Time: 314.65 seconds\n",
      "  Test Time: 0.57 seconds\n",
      "  Accurancy: 0.9011592434411226\n",
      "  Precision: [0.99186992 0.78571429 0.7826087  0.4950495  0.92556317]\n",
      "  Recall: [0.976      0.8        0.69902913 0.48076923 0.94311377]\n",
      "  F1-Score: [0.98387097 0.79279279 0.73846154 0.48780488 0.93425606]\n",
      "  Macro Precision: 0.7961611156751187\n",
      "  Macro Recall: 0.7797824258875826\n",
      "  Macro F1-Score: 0.7874372464816738\n",
      "  Confusion Matrix:\n",
      "[[366   4   0   2   3]\n",
      " [  1  44   1   0   9]\n",
      " [  0   3  72   7  21]\n",
      " [  0   0  11  50  43]\n",
      " [  2   5   8  42 945]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9499\n",
      "AUC Weighted: 0.9676\n",
      "AUC per Label: [0.99675105 0.97110882 0.91578808 0.89680531 0.96922325]\n",
      "Week 4:\n",
      "  Train Time: 315.84 seconds\n",
      "  Test Time: 0.51 seconds\n",
      "  Accurancy: 0.9359365466748018\n",
      "  Precision: [1.         0.89655172 0.80208333 0.81818182 0.93402451]\n",
      "  Recall: [0.984      0.94545455 0.74757282 0.43269231 0.98902196]\n",
      "  F1-Score: [0.99193548 0.92035398 0.77386935 0.56603774 0.96073679]\n",
      "  Macro Precision: 0.8901682761673744\n",
      "  Macro Recall: 0.8197483249537315\n",
      "  Macro F1-Score: 0.8425866679671057\n",
      "  Confusion Matrix:\n",
      "[[369   2   3   1   0]\n",
      " [  0  52   1   0   2]\n",
      " [  0   1  77   4  21]\n",
      " [  0   2  10  45  47]\n",
      " [  0   1   5   5 991]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9867\n",
      "AUC Weighted: 0.9926\n",
      "AUC per Label: [0.99990506 0.99816345 0.97939422 0.9621774  0.99402138]\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu của các tuần\n",
    "print(\"\\n=== Summary Results for All Weeks ===\")\n",
    "for result in results:\n",
    "    print(f\"Week {result['week']}:\")\n",
    "    print(f\"  Train Time: {result['train_time']:.2f} seconds\")\n",
    "    print(f\"  Test Time: {result['test_time']:.2f} seconds\")\n",
    "    print(f\"  Accurancy: {result['accuracy']}\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1-Score: {result['f1_score']}\")\n",
    "    print(f\"  Macro Precision: {result['precision_macro']}\")\n",
    "    print(f\"  Macro Recall: {result['recall_macro']}\")\n",
    "    print(f\"  Macro F1-Score: {result['f1_macro']}\")\n",
    "    print(f\"  Confusion Matrix:\\n{result['confusion_matrix']}\")\n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {result['auc_macro']:.4f}\")\n",
    "    print(f\"AUC Weighted: {result['auc_weighted']:.4f}\")\n",
    "    print(f\"AUC per Label: {result['auc_per_class']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21adddda",
   "metadata": {
    "papermill": {
     "duration": 3.0049,
     "end_time": "2025-04-05T08:02:21.582915",
     "exception": false,
     "start_time": "2025-04-05T08:02:18.578015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6328310,
     "sourceId": 11252263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9934.410631,
   "end_time": "2025-04-05T08:02:28.090988",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-05T05:16:53.680357",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
