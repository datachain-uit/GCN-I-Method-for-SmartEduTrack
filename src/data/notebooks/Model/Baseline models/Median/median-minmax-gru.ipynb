{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0706a02",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-04T17:30:54.598310Z",
     "iopub.status.busy": "2025-04-04T17:30:54.598088Z",
     "iopub.status.idle": "2025-04-04T17:30:56.748207Z",
     "shell.execute_reply": "2025-04-04T17:30:56.747209Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.156775,
     "end_time": "2025-04-04T17:30:56.749543",
     "exception": false,
     "start_time": "2025-04-04T17:30:54.592768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clean_raw_data.csv\n",
      "/kaggle/input/clean_data_mean.csv\n",
      "/kaggle/input/raw_data.csv\n",
      "/kaggle/input/clean_data_GCN.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_data_minmax_fill-zero.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_data_minmax_GCN_version4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_data_Fill-1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_data_minmax_Fill-1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_data_minmax_GCN_version3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_data_minmax_KNN.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_5.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9918e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T17:30:56.759953Z",
     "iopub.status.busy": "2025-04-04T17:30:56.759571Z",
     "iopub.status.idle": "2025-04-04T17:31:11.854309Z",
     "shell.execute_reply": "2025-04-04T17:31:11.853490Z"
    },
    "papermill": {
     "duration": 15.101465,
     "end_time": "2025-04-04T17:31:11.855983",
     "exception": false,
     "start_time": "2025-04-04T17:30:56.754518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b425e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T17:31:11.866889Z",
     "iopub.status.busy": "2025-04-04T17:31:11.866277Z",
     "iopub.status.idle": "2025-04-04T17:31:11.872650Z",
     "shell.execute_reply": "2025-04-04T17:31:11.871904Z"
    },
    "papermill": {
     "duration": 0.012987,
     "end_time": "2025-04-04T17:31:11.873959",
     "exception": false,
     "start_time": "2025-04-04T17:31:11.860972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Biến global cho base path\n",
    "BASE_PATH = \"/kaggle/input/Median_minmax_baseline_version2\"\n",
    "# Tuần và số phần fold\n",
    "weeks = ['week1', 'week2', 'week3', 'week4']\n",
    "fold_parts = 5\n",
    "\n",
    "# Tạo five_fold_files\n",
    "five_fold_files = {\n",
    "    week: [\n",
    "        f\"{BASE_PATH}/clean_{week}/train/5-folds/data_part_{i}.csv\"\n",
    "        for i in range(1, fold_parts + 1)\n",
    "    ]\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Tạo file_validation\n",
    "file_validation = {\n",
    "    'week1': [f\"{BASE_PATH}/clean_week1/val/val_week1.csv\"],\n",
    "    'week2': [f\"{BASE_PATH}/clean_week2/val/val_week1_2.csv\"],\n",
    "    'week3': [f\"{BASE_PATH}/clean_week3/val/val_week1_2_3.csv\"],\n",
    "    'week4': [f\"{BASE_PATH}/clean_week4/val/val_week1_2_3_4.csv\"]\n",
    "}\n",
    "\n",
    "# Tạo file_test\n",
    "file_test = {\n",
    "    week: [f\"{BASE_PATH}/clean_{week}/test/test_{week}.csv\"]\n",
    "    for week in weeks\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527139c",
   "metadata": {
    "papermill": {
     "duration": 0.004209,
     "end_time": "2025-04-04T17:31:11.882736",
     "exception": false,
     "start_time": "2025-04-04T17:31:11.878527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tìm siêu tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b097a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T17:31:11.892215Z",
     "iopub.status.busy": "2025-04-04T17:31:11.892003Z",
     "iopub.status.idle": "2025-04-04T17:31:11.902643Z",
     "shell.execute_reply": "2025-04-04T17:31:11.901934Z"
    },
    "papermill": {
     "duration": 0.016877,
     "end_time": "2025-04-04T17:31:11.903908",
     "exception": false,
     "start_time": "2025-04-04T17:31:11.887031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Tạo hàm train cho từng tuần\n",
    "def train_week_model(week_number, file_paths_train, file_validataion):\n",
    "    # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(file_paths_train)\n",
    "    val_data = pd.read_csv(file_validataion)\n",
    "    \n",
    "    # Tách đặc trưng và nhãn\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "    X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_val = val_data[\"classification_encoded\"]\n",
    "    \n",
    "    # Áp dụng Over-sampling cho dữ liệu huấn luyện bằng SMOTE\n",
    "    oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Reshape dữ liệu cho mô hình BiLSTM\n",
    "    X_train_res = X_train_res.values.reshape(X_train_res.shape[0], X_train_res.shape[1], 1)\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    \n",
    "    # One-hot encode nhãn\n",
    "    y_train_res = tf.keras.utils.to_categorical(y_train_res, num_classes=5)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "    \n",
    "    def build_model(hp):\n",
    "        inputs = tf.keras.Input(shape=(X_train_res.shape[1], 1))  # Khởi tạo đầu vào\n",
    "        \n",
    "        # GRU layer 1\n",
    "        x = layers.GRU(\n",
    "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=True\n",
    "        )(inputs)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # GRU layer 2\n",
    "        x = layers.GRU(\n",
    "            units=hp.Int('units_2', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=False\n",
    "        )(x)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # Lớp đầu ra\n",
    "        outputs = layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        # Khởi tạo mô hình\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile với Focal Loss\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                          learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                      loss=focal_loss(gamma=2., alpha=0.25),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    # Khởi tạo RandomSearch tuner\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='my_dir',\n",
    "        project_name=f'bilstm_tuning_week{week_number}'\n",
    "    )\n",
    "    \n",
    "    # Tìm kiếm siêu tham số tốt nhất\n",
    "    tuner.search(X_train_res, y_train_res,\n",
    "                 epochs=20,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 batch_size=32)\n",
    "    \n",
    "    # Trả về kết quả tối ưu cho tuần\n",
    "    best_params = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20d2e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T17:31:11.913670Z",
     "iopub.status.busy": "2025-04-04T17:31:11.913359Z",
     "iopub.status.idle": "2025-04-04T17:31:11.917897Z",
     "shell.execute_reply": "2025-04-04T17:31:11.917153Z"
    },
    "papermill": {
     "duration": 0.010806,
     "end_time": "2025-04-04T17:31:11.919158",
     "exception": false,
     "start_time": "2025-04-04T17:31:11.908352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa đường dẫn đến dữ liệu cho từng tuần\n",
    "file_paths_train = {\n",
    "    week: f\"{BASE_PATH}/clean_{week}/train/clean_data_{week}.csv\"\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Định nghĩa file_validation theo quy luật riêng\n",
    "file_validation = {\n",
    "    f\"week{idx + 1}\": f\"{BASE_PATH}/clean_week{idx + 1}/val/val_week{'_'.join(str(i) for i in range(1, idx + 2))}.csv\"\n",
    "    for idx in range(len(weeks))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d3fbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T17:31:11.929771Z",
     "iopub.status.busy": "2025-04-04T17:31:11.929490Z",
     "iopub.status.idle": "2025-04-04T19:05:51.628510Z",
     "shell.execute_reply": "2025-04-04T19:05:51.627689Z"
    },
    "papermill": {
     "duration": 5679.706054,
     "end_time": "2025-04-04T19:05:51.629849",
     "exception": false,
     "start_time": "2025-04-04T17:31:11.923795",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 33s]\n",
      "val_accuracy: 0.9896278381347656\n",
      "\n",
      "Best val_accuracy So Far: 0.9993898868560791\n",
      "Total elapsed time: 00h 25m 50s\n",
      "Best Parameters for Week 1:\n",
      "units_1: 128\n",
      "dropout_1: 0.1\n",
      "units_2: 224\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.0069108517839247645\n",
      "\n",
      "Best Parameters for Week 2:\n",
      "units_1: 224\n",
      "dropout_1: 0.4\n",
      "units_2: 32\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.0016017872820259641\n",
      "\n",
      "Best Parameters for Week 3:\n",
      "units_1: 64\n",
      "dropout_1: 0.2\n",
      "units_2: 96\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.0015027297638441546\n",
      "\n",
      "Best Parameters for Week 4:\n",
      "units_1: 224\n",
      "dropout_1: 0.1\n",
      "units_2: 64\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.001143448498353399\n"
     ]
    }
   ],
   "source": [
    "# Tìm tham số tốt nhất cho từng tuần\n",
    "best_params_week1 = train_week_model(1, file_paths_train[\"week1\"], file_validation[\"week1\"])\n",
    "best_params_week2 = train_week_model(2, file_paths_train[\"week2\"], file_validation[\"week2\"])\n",
    "best_params_week3 = train_week_model(3, file_paths_train[\"week3\"], file_validation[\"week3\"])\n",
    "best_params_week4 = train_week_model(4, file_paths_train[\"week4\"], file_validation[\"week4\"])\n",
    "\n",
    "# In thông tin chi tiết các tham số tối ưu\n",
    "print(\"Best Parameters for Week 1:\")\n",
    "for param_name in best_params_week1.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week1.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 2:\")\n",
    "for param_name in best_params_week2.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week2.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 3:\")\n",
    "for param_name in best_params_week3.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week3.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 4:\")\n",
    "for param_name in best_params_week4.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week4.get(param_name)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20bb69",
   "metadata": {
    "papermill": {
     "duration": 0.004418,
     "end_time": "2025-04-04T19:05:51.639601",
     "exception": false,
     "start_time": "2025-04-04T19:05:51.635183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Danh sách tham số tốt nhất của từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8dc493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:05:51.649272Z",
     "iopub.status.busy": "2025-04-04T19:05:51.649046Z",
     "iopub.status.idle": "2025-04-04T19:05:51.652093Z",
     "shell.execute_reply": "2025-04-04T19:05:51.651537Z"
    },
    "papermill": {
     "duration": 0.009225,
     "end_time": "2025-04-04T19:05:51.653253",
     "exception": false,
     "start_time": "2025-04-04T19:05:51.644028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Danh sách tham số tốt nhất\n",
    "best_params = {\n",
    "    \"week1\": best_params_week1,\n",
    "    \"week2\": best_params_week2,\n",
    "    \"week3\": best_params_week3,\n",
    "    \"week4\": best_params_week4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36901e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:05:51.663005Z",
     "iopub.status.busy": "2025-04-04T19:05:51.662793Z",
     "iopub.status.idle": "2025-04-04T19:05:51.669136Z",
     "shell.execute_reply": "2025-04-04T19:05:51.668566Z"
    },
    "papermill": {
     "duration": 0.012536,
     "end_time": "2025-04-04T19:05:51.670346",
     "exception": false,
     "start_time": "2025-04-04T19:05:51.657810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Xây dựng mô hình BiLSTM\n",
    "def build_GRU_model(params, input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "    # GRU layer 1\n",
    "    x = layers.GRU(\n",
    "        units=params.get('units_1'),\n",
    "        return_sequences=True\n",
    "    )(inputs)\n",
    "    x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "    # GRU layer 2\n",
    "    x = layers.GRU(\n",
    "        units=params.get('units_2', 32),\n",
    "        return_sequences=False\n",
    "    )(x)\n",
    "    x = layers.Dropout(rate=params.get('dropout_2', 0.2))(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile với Focal Loss\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                      learning_rate=params['learning_rate']),\n",
    "                  loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69149df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:05:51.680136Z",
     "iopub.status.busy": "2025-04-04T19:05:51.679932Z",
     "iopub.status.idle": "2025-04-04T19:34:40.891082Z",
     "shell.execute_reply": "2025-04-04T19:34:40.889350Z"
    },
    "papermill": {
     "duration": 1729.217912,
     "end_time": "2025-04-04T19:34:40.892725",
     "exception": false,
     "start_time": "2025-04-04T19:05:51.674813",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing week1 with best parameters...\n",
      "best parameters for week1: {'units_1': 128, 'dropout_1': 0.1, 'units_2': 224, 'dropout_2': 0.4, 'learning_rate': 0.0069108517839247645}\n",
      "Fold 1: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6105 - loss: 0.1452 - val_accuracy: 0.6477 - val_loss: 0.1260\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6253 - loss: 0.1314 - val_accuracy: 0.6561 - val_loss: 0.1248\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 0.1304 - val_accuracy: 0.6657 - val_loss: 0.1212\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6525 - loss: 0.1238 - val_accuracy: 0.6199 - val_loss: 0.1258\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6324 - loss: 0.1285 - val_accuracy: 0.6592 - val_loss: 0.1204\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 0.1267 - val_accuracy: 0.6172 - val_loss: 0.1281\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6315 - loss: 0.1256 - val_accuracy: 0.6191 - val_loss: 0.1257\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 0.1236 - val_accuracy: 0.6725 - val_loss: 0.1208\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6408 - loss: 0.1246 - val_accuracy: 0.6485 - val_loss: 0.1167\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6524 - loss: 0.1250 - val_accuracy: 0.6111 - val_loss: 0.1231\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.1274 - val_accuracy: 0.6146 - val_loss: 0.1217\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6333 - loss: 0.1278 - val_accuracy: 0.6169 - val_loss: 0.1218\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6218 - loss: 0.1281 - val_accuracy: 0.6218 - val_loss: 0.1176\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6286 - loss: 0.1291 - val_accuracy: 0.6245 - val_loss: 0.1212\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6279 - loss: 0.1266 - val_accuracy: 0.6218 - val_loss: 0.1221\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6292 - loss: 0.1266 - val_accuracy: 0.6645 - val_loss: 0.1162\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6462 - loss: 0.1218 - val_accuracy: 0.6794 - val_loss: 0.1115\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.1170 - val_accuracy: 0.6733 - val_loss: 0.1210\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6635 - loss: 0.1192 - val_accuracy: 0.6428 - val_loss: 0.1111\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6482 - loss: 0.1203 - val_accuracy: 0.6729 - val_loss: 0.1094\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6617 - loss: 0.1190 - val_accuracy: 0.6298 - val_loss: 0.1181\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6374 - loss: 0.1249 - val_accuracy: 0.6942 - val_loss: 0.1169\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6474 - loss: 0.1278 - val_accuracy: 0.6851 - val_loss: 0.1118\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 0.1218 - val_accuracy: 0.6897 - val_loss: 0.1119\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6675 - loss: 0.1200 - val_accuracy: 0.6878 - val_loss: 0.1108\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6614 - loss: 0.1209 - val_accuracy: 0.7034 - val_loss: 0.1087\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6637 - loss: 0.1182 - val_accuracy: 0.6630 - val_loss: 0.1197\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6391 - loss: 0.1272 - val_accuracy: 0.6130 - val_loss: 0.1197\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6438 - loss: 0.1285 - val_accuracy: 0.6237 - val_loss: 0.1158\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6431 - loss: 0.1268 - val_accuracy: 0.6676 - val_loss: 0.1252\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6454 - loss: 0.1300 - val_accuracy: 0.6535 - val_loss: 0.1232\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.1292 - val_accuracy: 0.6824 - val_loss: 0.1170\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 0.1284 - val_accuracy: 0.6157 - val_loss: 0.1197\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6487 - loss: 0.1245 - val_accuracy: 0.6313 - val_loss: 0.1233\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6362 - loss: 0.1254 - val_accuracy: 0.6881 - val_loss: 0.1132\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6484 - loss: 0.1219 - val_accuracy: 0.6862 - val_loss: 0.1164\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6495 - loss: 0.1250 - val_accuracy: 0.6847 - val_loss: 0.1139\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6537 - loss: 0.1244 - val_accuracy: 0.6912 - val_loss: 0.1210\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6393 - loss: 0.1281 - val_accuracy: 0.6474 - val_loss: 0.1179\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6578 - loss: 0.1243 - val_accuracy: 0.6759 - val_loss: 0.1204\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6397 - loss: 0.1288 - val_accuracy: 0.6946 - val_loss: 0.1144\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6488 - loss: 0.1244 - val_accuracy: 0.6367 - val_loss: 0.1251\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6264 - loss: 0.1312 - val_accuracy: 0.6210 - val_loss: 0.1210\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6426 - loss: 0.1265 - val_accuracy: 0.6668 - val_loss: 0.1194\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6521 - loss: 0.1238 - val_accuracy: 0.6115 - val_loss: 0.1196\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 0.1271 - val_accuracy: 0.6626 - val_loss: 0.1194\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6382 - loss: 0.1252 - val_accuracy: 0.6828 - val_loss: 0.1149\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6442 - loss: 0.1260 - val_accuracy: 0.6900 - val_loss: 0.1202\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6538 - loss: 0.1262 - val_accuracy: 0.6332 - val_loss: 0.1199\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.1252 - val_accuracy: 0.6973 - val_loss: 0.1154\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6124 - loss: 0.1448 - val_accuracy: 0.6062 - val_loss: 0.1315\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 0.1305 - val_accuracy: 0.6969 - val_loss: 0.1195\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6185 - loss: 0.1282 - val_accuracy: 0.5986 - val_loss: 0.1243\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6255 - loss: 0.1312 - val_accuracy: 0.6927 - val_loss: 0.1161\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6336 - loss: 0.1279 - val_accuracy: 0.6752 - val_loss: 0.1142\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6218 - loss: 0.1297 - val_accuracy: 0.6828 - val_loss: 0.1130\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6390 - loss: 0.1262 - val_accuracy: 0.6817 - val_loss: 0.1116\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.1242 - val_accuracy: 0.6214 - val_loss: 0.1200\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6177 - loss: 0.1307 - val_accuracy: 0.6843 - val_loss: 0.1175\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.1287 - val_accuracy: 0.6191 - val_loss: 0.1170\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6378 - loss: 0.1274 - val_accuracy: 0.6889 - val_loss: 0.1114\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6326 - loss: 0.1300 - val_accuracy: 0.6115 - val_loss: 0.1250\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6230 - loss: 0.1316 - val_accuracy: 0.6923 - val_loss: 0.1198\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6416 - loss: 0.1282 - val_accuracy: 0.6847 - val_loss: 0.1175\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6349 - loss: 0.1287 - val_accuracy: 0.6927 - val_loss: 0.1191\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6286 - loss: 0.1305 - val_accuracy: 0.6843 - val_loss: 0.1161\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6399 - loss: 0.1274 - val_accuracy: 0.6618 - val_loss: 0.1207\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6392 - loss: 0.1296 - val_accuracy: 0.6161 - val_loss: 0.1175\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 0.1252 - val_accuracy: 0.7080 - val_loss: 0.1055\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6511 - loss: 0.1246 - val_accuracy: 0.6702 - val_loss: 0.1113\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6594 - loss: 0.1238 - val_accuracy: 0.6321 - val_loss: 0.1222\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6629 - loss: 0.1206 - val_accuracy: 0.6931 - val_loss: 0.1114\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6822 - loss: 0.1170 - val_accuracy: 0.6878 - val_loss: 0.1114\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.1204 - val_accuracy: 0.6954 - val_loss: 0.1067\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.1230 - val_accuracy: 0.7064 - val_loss: 0.1107\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6806 - loss: 0.1219 - val_accuracy: 0.6912 - val_loss: 0.1099\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6863 - loss: 0.1148 - val_accuracy: 0.7190 - val_loss: 0.1111\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6723 - loss: 0.1185 - val_accuracy: 0.7217 - val_loss: 0.1088\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6771 - loss: 0.1208 - val_accuracy: 0.7160 - val_loss: 0.1060\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6493 - loss: 0.1272 - val_accuracy: 0.6203 - val_loss: 0.1216\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6276 - loss: 0.1302 - val_accuracy: 0.6256 - val_loss: 0.1172\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6338 - loss: 0.1289 - val_accuracy: 0.6596 - val_loss: 0.1193\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6208 - loss: 0.1294 - val_accuracy: 0.6759 - val_loss: 0.1153\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6469 - loss: 0.1251 - val_accuracy: 0.6260 - val_loss: 0.1219\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.1284 - val_accuracy: 0.6885 - val_loss: 0.1223\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6292 - loss: 0.1319 - val_accuracy: 0.6237 - val_loss: 0.1189\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6442 - loss: 0.1287 - val_accuracy: 0.6321 - val_loss: 0.1193\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6422 - loss: 0.1282 - val_accuracy: 0.6184 - val_loss: 0.1175\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6408 - loss: 0.1271 - val_accuracy: 0.6935 - val_loss: 0.1164\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6317 - loss: 0.1287 - val_accuracy: 0.6214 - val_loss: 0.1238\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6382 - loss: 0.1274 - val_accuracy: 0.6900 - val_loss: 0.1140\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6498 - loss: 0.1244 - val_accuracy: 0.6958 - val_loss: 0.1157\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6417 - loss: 0.1257 - val_accuracy: 0.7026 - val_loss: 0.1164\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6600 - loss: 0.1219 - val_accuracy: 0.6374 - val_loss: 0.1141\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.1210 - val_accuracy: 0.6908 - val_loss: 0.1117\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6411 - loss: 0.1228 - val_accuracy: 0.7095 - val_loss: 0.1133\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6554 - loss: 0.1221 - val_accuracy: 0.6233 - val_loss: 0.1133\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6615 - loss: 0.1200 - val_accuracy: 0.6199 - val_loss: 0.1211\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 0.1262 - val_accuracy: 0.6237 - val_loss: 0.1110\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 0.1216 - val_accuracy: 0.7057 - val_loss: 0.1090\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5908 - loss: 0.1472 - val_accuracy: 0.6180 - val_loss: 0.1246\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.1324 - val_accuracy: 0.6855 - val_loss: 0.1191\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6401 - loss: 0.1252 - val_accuracy: 0.6981 - val_loss: 0.1243\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 0.1271 - val_accuracy: 0.6710 - val_loss: 0.1213\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6522 - loss: 0.1219 - val_accuracy: 0.6775 - val_loss: 0.1197\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6561 - loss: 0.1198 - val_accuracy: 0.7183 - val_loss: 0.1083\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6846 - loss: 0.1140 - val_accuracy: 0.7274 - val_loss: 0.1084\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6748 - loss: 0.1170 - val_accuracy: 0.7156 - val_loss: 0.1089\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6738 - loss: 0.1170 - val_accuracy: 0.7278 - val_loss: 0.1087\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6681 - loss: 0.1222 - val_accuracy: 0.7381 - val_loss: 0.1041\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.1213 - val_accuracy: 0.7114 - val_loss: 0.1082\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6886 - loss: 0.1152 - val_accuracy: 0.7350 - val_loss: 0.1061\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7017 - loss: 0.1119 - val_accuracy: 0.7305 - val_loss: 0.1058\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6835 - loss: 0.1165 - val_accuracy: 0.6904 - val_loss: 0.1187\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6851 - loss: 0.1165 - val_accuracy: 0.7186 - val_loss: 0.1006\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.1131 - val_accuracy: 0.7042 - val_loss: 0.1138\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7036 - loss: 0.1152 - val_accuracy: 0.7160 - val_loss: 0.1102\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.1129 - val_accuracy: 0.7449 - val_loss: 0.1048\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.1063 - val_accuracy: 0.7594 - val_loss: 0.0970\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.1075 - val_accuracy: 0.7110 - val_loss: 0.1112\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.1054 - val_accuracy: 0.7781 - val_loss: 0.0918\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.1074 - val_accuracy: 0.7804 - val_loss: 0.0977\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7296 - loss: 0.1051 - val_accuracy: 0.7564 - val_loss: 0.0940\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.1058 - val_accuracy: 0.7842 - val_loss: 0.0945\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7406 - loss: 0.1025 - val_accuracy: 0.7735 - val_loss: 0.0954\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7355 - loss: 0.1022 - val_accuracy: 0.7591 - val_loss: 0.0944\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7370 - loss: 0.1014 - val_accuracy: 0.7888 - val_loss: 0.0892\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.1053 - val_accuracy: 0.7446 - val_loss: 0.0933\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.1050 - val_accuracy: 0.7835 - val_loss: 0.0879\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.1008 - val_accuracy: 0.7922 - val_loss: 0.0890\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.1029 - val_accuracy: 0.7541 - val_loss: 0.0999\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.1110 - val_accuracy: 0.7869 - val_loss: 0.0887\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7416 - loss: 0.1011 - val_accuracy: 0.7850 - val_loss: 0.0874\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7336 - loss: 0.1013 - val_accuracy: 0.7804 - val_loss: 0.0879\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7308 - loss: 0.1060 - val_accuracy: 0.7758 - val_loss: 0.0918\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.1042 - val_accuracy: 0.7747 - val_loss: 0.0951\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.1063 - val_accuracy: 0.7922 - val_loss: 0.0906\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.1002 - val_accuracy: 0.7907 - val_loss: 0.0889\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7374 - loss: 0.0997 - val_accuracy: 0.7846 - val_loss: 0.0864\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7394 - loss: 0.1018 - val_accuracy: 0.7785 - val_loss: 0.0930\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.1025 - val_accuracy: 0.7728 - val_loss: 0.0974\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.1022 - val_accuracy: 0.7659 - val_loss: 0.0899\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.1019 - val_accuracy: 0.7762 - val_loss: 0.0873\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.1020 - val_accuracy: 0.7751 - val_loss: 0.0928\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 0.0988 - val_accuracy: 0.7735 - val_loss: 0.0891\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 0.0967 - val_accuracy: 0.7507 - val_loss: 0.0993\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7559 - loss: 0.0992 - val_accuracy: 0.7621 - val_loss: 0.0994\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.1020 - val_accuracy: 0.7896 - val_loss: 0.0936\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.0988 - val_accuracy: 0.7739 - val_loss: 0.0984\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.0958 - val_accuracy: 0.7854 - val_loss: 0.0905\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 0.1503 - val_accuracy: 0.6247 - val_loss: 0.1190\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6325 - loss: 0.1299 - val_accuracy: 0.6342 - val_loss: 0.1216\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 0.1286 - val_accuracy: 0.6293 - val_loss: 0.1293\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 0.1341 - val_accuracy: 0.6587 - val_loss: 0.1189\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6416 - loss: 0.1267 - val_accuracy: 0.6838 - val_loss: 0.1185\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.1310 - val_accuracy: 0.6278 - val_loss: 0.1284\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6318 - loss: 0.1347 - val_accuracy: 0.6243 - val_loss: 0.1228\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6233 - loss: 0.1339 - val_accuracy: 0.6396 - val_loss: 0.1211\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6367 - loss: 0.1298 - val_accuracy: 0.6159 - val_loss: 0.1216\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6301 - loss: 0.1301 - val_accuracy: 0.6655 - val_loss: 0.1170\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6430 - loss: 0.1283 - val_accuracy: 0.6690 - val_loss: 0.1173\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6418 - loss: 0.1278 - val_accuracy: 0.6480 - val_loss: 0.1210\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6397 - loss: 0.1278 - val_accuracy: 0.6732 - val_loss: 0.1226\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6396 - loss: 0.1268 - val_accuracy: 0.6262 - val_loss: 0.1153\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6371 - loss: 0.1270 - val_accuracy: 0.6812 - val_loss: 0.1200\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6544 - loss: 0.1267 - val_accuracy: 0.6979 - val_loss: 0.1183\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.1279 - val_accuracy: 0.6281 - val_loss: 0.1141\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6433 - loss: 0.1255 - val_accuracy: 0.7052 - val_loss: 0.1118\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.1273 - val_accuracy: 0.6323 - val_loss: 0.1195\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6354 - loss: 0.1284 - val_accuracy: 0.6934 - val_loss: 0.1164\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6615 - loss: 0.1252 - val_accuracy: 0.6869 - val_loss: 0.1132\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.1251 - val_accuracy: 0.6884 - val_loss: 0.1233\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.1205 - val_accuracy: 0.6899 - val_loss: 0.1137\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6508 - loss: 0.1254 - val_accuracy: 0.6937 - val_loss: 0.1110\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6578 - loss: 0.1212 - val_accuracy: 0.6758 - val_loss: 0.1094\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6581 - loss: 0.1216 - val_accuracy: 0.6884 - val_loss: 0.1125\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6659 - loss: 0.1201 - val_accuracy: 0.7040 - val_loss: 0.1121\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6695 - loss: 0.1195 - val_accuracy: 0.7010 - val_loss: 0.1063\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.1235 - val_accuracy: 0.6922 - val_loss: 0.1109\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6556 - loss: 0.1207 - val_accuracy: 0.6426 - val_loss: 0.1234\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6343 - loss: 0.1303 - val_accuracy: 0.6312 - val_loss: 0.1118\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6456 - loss: 0.1244 - val_accuracy: 0.6934 - val_loss: 0.1125\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.1191 - val_accuracy: 0.7071 - val_loss: 0.1068\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6625 - loss: 0.1205 - val_accuracy: 0.7147 - val_loss: 0.1052\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 0.1168 - val_accuracy: 0.6491 - val_loss: 0.1149\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6666 - loss: 0.1189 - val_accuracy: 0.7006 - val_loss: 0.1077\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6689 - loss: 0.1197 - val_accuracy: 0.6739 - val_loss: 0.1101\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6664 - loss: 0.1263 - val_accuracy: 0.7040 - val_loss: 0.1066\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6717 - loss: 0.1204 - val_accuracy: 0.7067 - val_loss: 0.1057\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.1191 - val_accuracy: 0.6114 - val_loss: 0.1258\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6169 - loss: 0.1332 - val_accuracy: 0.6404 - val_loss: 0.1207\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6206 - loss: 0.1317 - val_accuracy: 0.6121 - val_loss: 0.1188\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6449 - loss: 0.1270 - val_accuracy: 0.7082 - val_loss: 0.1145\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6405 - loss: 0.1265 - val_accuracy: 0.6415 - val_loss: 0.1177\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6433 - loss: 0.1289 - val_accuracy: 0.6171 - val_loss: 0.1108\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6422 - loss: 0.1253 - val_accuracy: 0.6659 - val_loss: 0.1151\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6469 - loss: 0.1294 - val_accuracy: 0.7140 - val_loss: 0.1117\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6511 - loss: 0.1265 - val_accuracy: 0.6175 - val_loss: 0.1149\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6378 - loss: 0.1266 - val_accuracy: 0.6716 - val_loss: 0.1092\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6441 - loss: 0.1267 - val_accuracy: 0.6846 - val_loss: 0.1139\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6175 - loss: 0.1464 - val_accuracy: 0.6148 - val_loss: 0.1272\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6328 - loss: 0.1342 - val_accuracy: 0.6232 - val_loss: 0.1240\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6313 - loss: 0.1306 - val_accuracy: 0.6606 - val_loss: 0.1254\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.1258 - val_accuracy: 0.6861 - val_loss: 0.1219\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6289 - loss: 0.1311 - val_accuracy: 0.6274 - val_loss: 0.1206\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 0.1290 - val_accuracy: 0.6632 - val_loss: 0.1191\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6343 - loss: 0.1311 - val_accuracy: 0.6007 - val_loss: 0.1283\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6267 - loss: 0.1303 - val_accuracy: 0.6571 - val_loss: 0.1222\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6440 - loss: 0.1273 - val_accuracy: 0.6857 - val_loss: 0.1176\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6375 - loss: 0.1316 - val_accuracy: 0.6583 - val_loss: 0.1255\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6278 - loss: 0.1302 - val_accuracy: 0.6274 - val_loss: 0.1181\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6391 - loss: 0.1275 - val_accuracy: 0.6281 - val_loss: 0.1242\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6317 - loss: 0.1283 - val_accuracy: 0.6686 - val_loss: 0.1195\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6575 - loss: 0.1259 - val_accuracy: 0.6991 - val_loss: 0.1111\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6556 - loss: 0.1230 - val_accuracy: 0.6705 - val_loss: 0.1192\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6460 - loss: 0.1252 - val_accuracy: 0.6171 - val_loss: 0.1168\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6573 - loss: 0.1228 - val_accuracy: 0.6857 - val_loss: 0.1219\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6528 - loss: 0.1309 - val_accuracy: 0.6842 - val_loss: 0.1228\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6312 - loss: 0.1300 - val_accuracy: 0.6884 - val_loss: 0.1176\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6326 - loss: 0.1297 - val_accuracy: 0.6968 - val_loss: 0.1153\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6347 - loss: 0.1300 - val_accuracy: 0.6884 - val_loss: 0.1199\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6472 - loss: 0.1243 - val_accuracy: 0.7037 - val_loss: 0.1103\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6428 - loss: 0.1252 - val_accuracy: 0.6266 - val_loss: 0.1246\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6201 - loss: 0.1321 - val_accuracy: 0.6285 - val_loss: 0.1195\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.1307 - val_accuracy: 0.6236 - val_loss: 0.1266\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6332 - loss: 0.1282 - val_accuracy: 0.6732 - val_loss: 0.1153\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6433 - loss: 0.1244 - val_accuracy: 0.6945 - val_loss: 0.1132\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6501 - loss: 0.1237 - val_accuracy: 0.6781 - val_loss: 0.1214\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6518 - loss: 0.1225 - val_accuracy: 0.6842 - val_loss: 0.1162\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6661 - loss: 0.1207 - val_accuracy: 0.7040 - val_loss: 0.1148\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6442 - loss: 0.1239 - val_accuracy: 0.6945 - val_loss: 0.1138\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6584 - loss: 0.1233 - val_accuracy: 0.6930 - val_loss: 0.1129\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6617 - loss: 0.1192 - val_accuracy: 0.6789 - val_loss: 0.1133\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6656 - loss: 0.1203 - val_accuracy: 0.6987 - val_loss: 0.1103\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.1194 - val_accuracy: 0.6895 - val_loss: 0.1145\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6704 - loss: 0.1206 - val_accuracy: 0.6983 - val_loss: 0.1098\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.1232 - val_accuracy: 0.7056 - val_loss: 0.1103\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6700 - loss: 0.1217 - val_accuracy: 0.6930 - val_loss: 0.1124\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6718 - loss: 0.1213 - val_accuracy: 0.7033 - val_loss: 0.1082\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6809 - loss: 0.1215 - val_accuracy: 0.7155 - val_loss: 0.1080\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6656 - loss: 0.1221 - val_accuracy: 0.6827 - val_loss: 0.1147\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6702 - loss: 0.1219 - val_accuracy: 0.7006 - val_loss: 0.1112\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 0.1209 - val_accuracy: 0.7052 - val_loss: 0.1078\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6720 - loss: 0.1182 - val_accuracy: 0.6747 - val_loss: 0.1137\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6377 - loss: 0.1276 - val_accuracy: 0.6834 - val_loss: 0.1125\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6474 - loss: 0.1221 - val_accuracy: 0.6800 - val_loss: 0.1172\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.1226 - val_accuracy: 0.6976 - val_loss: 0.1107\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.1193 - val_accuracy: 0.6152 - val_loss: 0.1189\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6545 - loss: 0.1241 - val_accuracy: 0.6972 - val_loss: 0.1181\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6517 - loss: 0.1277 - val_accuracy: 0.6640 - val_loss: 0.1178\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average Accuracy ===\n",
      "0.7074\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.4170\n",
      "Macro Recall: 0.3670\n",
      "Macro F1-Score: 0.3702\n",
      "Macro AUC-ROC: 0.8132\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.6453\n",
      "Weighted Recall: 0.7074\n",
      "Weighted F1-Score: 0.6634\n",
      "Weighted AUC-ROC: 0.8289\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.590909        0.545667          0.558659     0.786498\n",
      "1      1           0.000000        0.000000          0.000000     0.740704\n",
      "2      2           0.439852        0.194375          0.267966     0.841316\n",
      "3      3           0.295846        0.180838          0.196671     0.851328\n",
      "4      4           0.758197        0.913935          0.827893     0.846035\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2     3       4\n",
      "0  327.4  0.0   4.8  16.6   251.2\n",
      "1   42.6  0.0   0.4   2.4    42.0\n",
      "2   40.2  0.0  32.0   5.4    86.8\n",
      "3   39.4  0.0   1.6  30.2    96.0\n",
      "4  115.2  0.0   5.4  17.4  1465.6\n",
      "\n",
      "Processing week2 with best parameters...\n",
      "best parameters for week2: {'units_1': 224, 'dropout_1': 0.4, 'units_2': 32, 'dropout_2': 0.2, 'learning_rate': 0.0016017872820259641}\n",
      "Fold 1: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6039 - loss: 0.1424 - val_accuracy: 0.6775 - val_loss: 0.1170\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6706 - loss: 0.1201 - val_accuracy: 0.7022 - val_loss: 0.1129\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6885 - loss: 0.1147 - val_accuracy: 0.7404 - val_loss: 0.1027\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.1125 - val_accuracy: 0.7613 - val_loss: 0.1020\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.1064 - val_accuracy: 0.7705 - val_loss: 0.0933\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.1041 - val_accuracy: 0.8105 - val_loss: 0.0862\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.0963 - val_accuracy: 0.8303 - val_loss: 0.0770\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.0964 - val_accuracy: 0.8338 - val_loss: 0.0766\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.0876 - val_accuracy: 0.8269 - val_loss: 0.0775\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7942 - loss: 0.0857 - val_accuracy: 0.8380 - val_loss: 0.0715\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.0852 - val_accuracy: 0.8239 - val_loss: 0.0800\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.0845 - val_accuracy: 0.8235 - val_loss: 0.0729\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.0844 - val_accuracy: 0.8323 - val_loss: 0.0729\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.0804 - val_accuracy: 0.8319 - val_loss: 0.0723\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8047 - loss: 0.0799 - val_accuracy: 0.8525 - val_loss: 0.0663\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.0801 - val_accuracy: 0.8521 - val_loss: 0.0767\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.0793 - val_accuracy: 0.8410 - val_loss: 0.0680\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.0765 - val_accuracy: 0.8445 - val_loss: 0.0657\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.0763 - val_accuracy: 0.8311 - val_loss: 0.0645\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.0743 - val_accuracy: 0.8513 - val_loss: 0.0650\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.0735 - val_accuracy: 0.8479 - val_loss: 0.0653\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.0758 - val_accuracy: 0.8498 - val_loss: 0.0642\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8207 - loss: 0.0745 - val_accuracy: 0.8475 - val_loss: 0.0612\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.0720 - val_accuracy: 0.8544 - val_loss: 0.0638\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.0713 - val_accuracy: 0.8490 - val_loss: 0.0614\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.0747 - val_accuracy: 0.8570 - val_loss: 0.0596\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.0717 - val_accuracy: 0.8532 - val_loss: 0.0622\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.0712 - val_accuracy: 0.8498 - val_loss: 0.0615\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.0713 - val_accuracy: 0.8559 - val_loss: 0.0587\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 0.0700 - val_accuracy: 0.8445 - val_loss: 0.0574\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 0.0689 - val_accuracy: 0.8574 - val_loss: 0.0573\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.0656 - val_accuracy: 0.8589 - val_loss: 0.0572\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.0686 - val_accuracy: 0.8643 - val_loss: 0.0550\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8350 - loss: 0.0680 - val_accuracy: 0.8608 - val_loss: 0.0582\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 0.0676 - val_accuracy: 0.8586 - val_loss: 0.0601\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8349 - loss: 0.0666 - val_accuracy: 0.8525 - val_loss: 0.0568\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8467 - loss: 0.0653 - val_accuracy: 0.8639 - val_loss: 0.0532\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8456 - loss: 0.0662 - val_accuracy: 0.8620 - val_loss: 0.0557\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.0629 - val_accuracy: 0.8647 - val_loss: 0.0524\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.0651 - val_accuracy: 0.8677 - val_loss: 0.0544\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8492 - loss: 0.0613 - val_accuracy: 0.8525 - val_loss: 0.0613\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.0634 - val_accuracy: 0.8719 - val_loss: 0.0537\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.0623 - val_accuracy: 0.8681 - val_loss: 0.0543\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 0.0613 - val_accuracy: 0.8849 - val_loss: 0.0505\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.0614 - val_accuracy: 0.8807 - val_loss: 0.0493\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.0620 - val_accuracy: 0.8624 - val_loss: 0.0600\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.0607 - val_accuracy: 0.8776 - val_loss: 0.0477\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8480 - loss: 0.0619 - val_accuracy: 0.8757 - val_loss: 0.0492\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.0598 - val_accuracy: 0.8807 - val_loss: 0.0468\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.0582 - val_accuracy: 0.8795 - val_loss: 0.0465\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6162 - loss: 0.1433 - val_accuracy: 0.6668 - val_loss: 0.1150\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.1219 - val_accuracy: 0.7000 - val_loss: 0.1083\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6803 - loss: 0.1161 - val_accuracy: 0.7358 - val_loss: 0.1018\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.1094 - val_accuracy: 0.7674 - val_loss: 0.0954\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7296 - loss: 0.1042 - val_accuracy: 0.7907 - val_loss: 0.0839\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.1023 - val_accuracy: 0.7766 - val_loss: 0.0882\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.0996 - val_accuracy: 0.8296 - val_loss: 0.0738\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.0929 - val_accuracy: 0.8223 - val_loss: 0.0752\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.0898 - val_accuracy: 0.8277 - val_loss: 0.0704\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.0847 - val_accuracy: 0.8223 - val_loss: 0.0741\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.0853 - val_accuracy: 0.8425 - val_loss: 0.0694\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.0844 - val_accuracy: 0.8345 - val_loss: 0.0690\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.0841 - val_accuracy: 0.8429 - val_loss: 0.0668\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.0808 - val_accuracy: 0.8391 - val_loss: 0.0633\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.0820 - val_accuracy: 0.8380 - val_loss: 0.0631\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.0763 - val_accuracy: 0.8441 - val_loss: 0.0637\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.0777 - val_accuracy: 0.8498 - val_loss: 0.0615\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0769 - val_accuracy: 0.8506 - val_loss: 0.0615\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8183 - loss: 0.0764 - val_accuracy: 0.8433 - val_loss: 0.0612\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.0737 - val_accuracy: 0.8612 - val_loss: 0.0598\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8186 - loss: 0.0762 - val_accuracy: 0.8555 - val_loss: 0.0602\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8218 - loss: 0.0737 - val_accuracy: 0.8742 - val_loss: 0.0585\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.0763 - val_accuracy: 0.8582 - val_loss: 0.0590\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.0712 - val_accuracy: 0.8605 - val_loss: 0.0577\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.0742 - val_accuracy: 0.8551 - val_loss: 0.0590\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0754 - val_accuracy: 0.8608 - val_loss: 0.0594\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.0705 - val_accuracy: 0.8612 - val_loss: 0.0588\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 0.0695 - val_accuracy: 0.8643 - val_loss: 0.0544\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.0702 - val_accuracy: 0.8658 - val_loss: 0.0560\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.0717 - val_accuracy: 0.8685 - val_loss: 0.0550\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8422 - loss: 0.0681 - val_accuracy: 0.8647 - val_loss: 0.0555\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.0701 - val_accuracy: 0.8669 - val_loss: 0.0590\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.0648 - val_accuracy: 0.8677 - val_loss: 0.0534\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.0643 - val_accuracy: 0.8715 - val_loss: 0.0538\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.0682 - val_accuracy: 0.8807 - val_loss: 0.0509\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8368 - loss: 0.0661 - val_accuracy: 0.8803 - val_loss: 0.0539\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 0.0639 - val_accuracy: 0.8738 - val_loss: 0.0567\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.0670 - val_accuracy: 0.8933 - val_loss: 0.0500\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.0618 - val_accuracy: 0.8841 - val_loss: 0.0495\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.0636 - val_accuracy: 0.8872 - val_loss: 0.0470\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.0638 - val_accuracy: 0.8898 - val_loss: 0.0462\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.0653 - val_accuracy: 0.8917 - val_loss: 0.0473\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8461 - loss: 0.0644 - val_accuracy: 0.8910 - val_loss: 0.0456\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0593 - val_accuracy: 0.8841 - val_loss: 0.0481\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.0611 - val_accuracy: 0.8994 - val_loss: 0.0447\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.0628 - val_accuracy: 0.8826 - val_loss: 0.0501\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.0625 - val_accuracy: 0.8948 - val_loss: 0.0451\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8453 - loss: 0.0631 - val_accuracy: 0.8639 - val_loss: 0.0579\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.0614 - val_accuracy: 0.8910 - val_loss: 0.0441\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8535 - loss: 0.0643 - val_accuracy: 0.8746 - val_loss: 0.0526\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6009 - loss: 0.1420 - val_accuracy: 0.6702 - val_loss: 0.1194\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.1207 - val_accuracy: 0.6737 - val_loss: 0.1157\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6727 - loss: 0.1174 - val_accuracy: 0.7114 - val_loss: 0.1085\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6882 - loss: 0.1168 - val_accuracy: 0.7469 - val_loss: 0.1027\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.1052 - val_accuracy: 0.8193 - val_loss: 0.0829\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.0980 - val_accuracy: 0.8212 - val_loss: 0.0785\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.0952 - val_accuracy: 0.8151 - val_loss: 0.0765\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.0906 - val_accuracy: 0.8151 - val_loss: 0.0787\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.0882 - val_accuracy: 0.8319 - val_loss: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7935 - loss: 0.0855 - val_accuracy: 0.8220 - val_loss: 0.0740\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.0878 - val_accuracy: 0.8323 - val_loss: 0.0718\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.0854 - val_accuracy: 0.8201 - val_loss: 0.0724\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.0822 - val_accuracy: 0.8292 - val_loss: 0.0682\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.0786 - val_accuracy: 0.8265 - val_loss: 0.0667\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.0817 - val_accuracy: 0.8345 - val_loss: 0.0694\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.0792 - val_accuracy: 0.8349 - val_loss: 0.0679\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.0790 - val_accuracy: 0.8273 - val_loss: 0.0689\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.0774 - val_accuracy: 0.8410 - val_loss: 0.0693\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8292 - loss: 0.0728 - val_accuracy: 0.8353 - val_loss: 0.0658\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.0775 - val_accuracy: 0.8300 - val_loss: 0.0676\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.0746 - val_accuracy: 0.8391 - val_loss: 0.0657\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.0767 - val_accuracy: 0.8384 - val_loss: 0.0647\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.0736 - val_accuracy: 0.8384 - val_loss: 0.0628\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.0748 - val_accuracy: 0.8490 - val_loss: 0.0616\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8298 - loss: 0.0725 - val_accuracy: 0.8395 - val_loss: 0.0624\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.0718 - val_accuracy: 0.8456 - val_loss: 0.0615\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8296 - loss: 0.0710 - val_accuracy: 0.8483 - val_loss: 0.0601\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 0.0682 - val_accuracy: 0.8551 - val_loss: 0.0626\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 0.0684 - val_accuracy: 0.8502 - val_loss: 0.0596\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.0694 - val_accuracy: 0.8532 - val_loss: 0.0591\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 0.0705 - val_accuracy: 0.8582 - val_loss: 0.0570\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.0683 - val_accuracy: 0.8616 - val_loss: 0.0592\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.0658 - val_accuracy: 0.8639 - val_loss: 0.0542\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.0647 - val_accuracy: 0.8445 - val_loss: 0.0560\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8442 - loss: 0.0664 - val_accuracy: 0.8471 - val_loss: 0.0536\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.0645 - val_accuracy: 0.8589 - val_loss: 0.0567\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.0680 - val_accuracy: 0.8506 - val_loss: 0.0622\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.0655 - val_accuracy: 0.8666 - val_loss: 0.0509\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 0.0648 - val_accuracy: 0.8685 - val_loss: 0.0498\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8497 - loss: 0.0628 - val_accuracy: 0.8711 - val_loss: 0.0515\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.0604 - val_accuracy: 0.8765 - val_loss: 0.0475\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.0607 - val_accuracy: 0.8738 - val_loss: 0.0499\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.0634 - val_accuracy: 0.8750 - val_loss: 0.0472\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 0.0582 - val_accuracy: 0.8730 - val_loss: 0.0487\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8455 - loss: 0.0627 - val_accuracy: 0.8791 - val_loss: 0.0482\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.0613 - val_accuracy: 0.8704 - val_loss: 0.0506\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.0603 - val_accuracy: 0.8788 - val_loss: 0.0486\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8535 - loss: 0.0597 - val_accuracy: 0.8723 - val_loss: 0.0481\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.0577 - val_accuracy: 0.8791 - val_loss: 0.0459\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8638 - loss: 0.0570 - val_accuracy: 0.8769 - val_loss: 0.0477\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6127 - loss: 0.1384 - val_accuracy: 0.6732 - val_loss: 0.1150\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6539 - loss: 0.1232 - val_accuracy: 0.6869 - val_loss: 0.1118\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6766 - loss: 0.1164 - val_accuracy: 0.7162 - val_loss: 0.1020\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6969 - loss: 0.1131 - val_accuracy: 0.7429 - val_loss: 0.0939\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7229 - loss: 0.1059 - val_accuracy: 0.7704 - val_loss: 0.0941\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.1033 - val_accuracy: 0.8074 - val_loss: 0.0881\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.0998 - val_accuracy: 0.8055 - val_loss: 0.0794\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 0.0971 - val_accuracy: 0.8215 - val_loss: 0.0767\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.0953 - val_accuracy: 0.8341 - val_loss: 0.0696\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.0860 - val_accuracy: 0.8253 - val_loss: 0.0732\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.0863 - val_accuracy: 0.8440 - val_loss: 0.0701\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.0843 - val_accuracy: 0.8421 - val_loss: 0.0681\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.0860 - val_accuracy: 0.8219 - val_loss: 0.0740\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.0827 - val_accuracy: 0.8463 - val_loss: 0.0666\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.0795 - val_accuracy: 0.8295 - val_loss: 0.0699\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.0782 - val_accuracy: 0.8429 - val_loss: 0.0642\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.0764 - val_accuracy: 0.8432 - val_loss: 0.0633\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.0741 - val_accuracy: 0.8497 - val_loss: 0.0637\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.0762 - val_accuracy: 0.8490 - val_loss: 0.0587\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.0750 - val_accuracy: 0.8501 - val_loss: 0.0575\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8214 - loss: 0.0751 - val_accuracy: 0.8551 - val_loss: 0.0563\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.0720 - val_accuracy: 0.8539 - val_loss: 0.0569\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.0736 - val_accuracy: 0.8577 - val_loss: 0.0613\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.0695 - val_accuracy: 0.8707 - val_loss: 0.0541\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.0708 - val_accuracy: 0.8577 - val_loss: 0.0556\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8320 - loss: 0.0708 - val_accuracy: 0.8589 - val_loss: 0.0573\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.0754 - val_accuracy: 0.8566 - val_loss: 0.0544\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.0703 - val_accuracy: 0.8581 - val_loss: 0.0574\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.0675 - val_accuracy: 0.8581 - val_loss: 0.0534\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.0661 - val_accuracy: 0.8677 - val_loss: 0.0519\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.0675 - val_accuracy: 0.8764 - val_loss: 0.0517\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.0672 - val_accuracy: 0.8677 - val_loss: 0.0514\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8456 - loss: 0.0636 - val_accuracy: 0.8688 - val_loss: 0.0517\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.0662 - val_accuracy: 0.8616 - val_loss: 0.0562\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.0660 - val_accuracy: 0.8654 - val_loss: 0.0500\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.0659 - val_accuracy: 0.8783 - val_loss: 0.0480\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.0641 - val_accuracy: 0.8776 - val_loss: 0.0498\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.0648 - val_accuracy: 0.8776 - val_loss: 0.0482\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.0652 - val_accuracy: 0.8863 - val_loss: 0.0466\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 0.0607 - val_accuracy: 0.8753 - val_loss: 0.0501\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8464 - loss: 0.0631 - val_accuracy: 0.8951 - val_loss: 0.0473\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.0642 - val_accuracy: 0.8715 - val_loss: 0.0525\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 0.0620 - val_accuracy: 0.8677 - val_loss: 0.0498\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8539 - loss: 0.0589 - val_accuracy: 0.8810 - val_loss: 0.0476\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.0609 - val_accuracy: 0.8795 - val_loss: 0.0476\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.0591 - val_accuracy: 0.8837 - val_loss: 0.0441\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 0.0603 - val_accuracy: 0.8867 - val_loss: 0.0452\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.0599 - val_accuracy: 0.8856 - val_loss: 0.0445\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 0.0599 - val_accuracy: 0.8829 - val_loss: 0.0469\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.0588 - val_accuracy: 0.8852 - val_loss: 0.0433\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 0.1397 - val_accuracy: 0.6884 - val_loss: 0.1141\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6639 - loss: 0.1202 - val_accuracy: 0.6793 - val_loss: 0.1121\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 0.1106 - val_accuracy: 0.7281 - val_loss: 0.1037\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7100 - loss: 0.1098 - val_accuracy: 0.7399 - val_loss: 0.1038\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7300 - loss: 0.1054 - val_accuracy: 0.8021 - val_loss: 0.0909\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.1007 - val_accuracy: 0.8089 - val_loss: 0.0832\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7589 - loss: 0.0960 - val_accuracy: 0.8162 - val_loss: 0.0812\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7762 - loss: 0.0911 - val_accuracy: 0.8207 - val_loss: 0.0770\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.0911 - val_accuracy: 0.7921 - val_loss: 0.0859\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.0904 - val_accuracy: 0.8387 - val_loss: 0.0748\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.0871 - val_accuracy: 0.8356 - val_loss: 0.0703\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.0852 - val_accuracy: 0.8375 - val_loss: 0.0701\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.0858 - val_accuracy: 0.8280 - val_loss: 0.0707\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.0810 - val_accuracy: 0.8471 - val_loss: 0.0645\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8126 - loss: 0.0778 - val_accuracy: 0.8444 - val_loss: 0.0655\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8186 - loss: 0.0763 - val_accuracy: 0.8459 - val_loss: 0.0675\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.0757 - val_accuracy: 0.8379 - val_loss: 0.0711\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.0755 - val_accuracy: 0.8524 - val_loss: 0.0643\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.0732 - val_accuracy: 0.8509 - val_loss: 0.0639\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.0774 - val_accuracy: 0.8494 - val_loss: 0.0615\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.0774 - val_accuracy: 0.8486 - val_loss: 0.0602\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.0749 - val_accuracy: 0.8566 - val_loss: 0.0612\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.0730 - val_accuracy: 0.8577 - val_loss: 0.0573\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.0720 - val_accuracy: 0.8513 - val_loss: 0.0644\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.0697 - val_accuracy: 0.8535 - val_loss: 0.0593\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.0695 - val_accuracy: 0.8589 - val_loss: 0.0575\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.0725 - val_accuracy: 0.8558 - val_loss: 0.0635\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8297 - loss: 0.0718 - val_accuracy: 0.8646 - val_loss: 0.0626\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.0699 - val_accuracy: 0.8616 - val_loss: 0.0565\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.0673 - val_accuracy: 0.8696 - val_loss: 0.0554\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.0633 - val_accuracy: 0.8616 - val_loss: 0.0555\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.0647 - val_accuracy: 0.8631 - val_loss: 0.0547\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.0655 - val_accuracy: 0.8654 - val_loss: 0.0542\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8394 - loss: 0.0674 - val_accuracy: 0.8764 - val_loss: 0.0526\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.0623 - val_accuracy: 0.8772 - val_loss: 0.0503\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.0627 - val_accuracy: 0.8726 - val_loss: 0.0530\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.0627 - val_accuracy: 0.8719 - val_loss: 0.0533\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8412 - loss: 0.0646 - val_accuracy: 0.8780 - val_loss: 0.0515\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8444 - loss: 0.0660 - val_accuracy: 0.8711 - val_loss: 0.0553\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.0626 - val_accuracy: 0.8791 - val_loss: 0.0482\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.0606 - val_accuracy: 0.8822 - val_loss: 0.0490\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.0629 - val_accuracy: 0.8719 - val_loss: 0.0496\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.0624 - val_accuracy: 0.8734 - val_loss: 0.0514\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0620 - val_accuracy: 0.8833 - val_loss: 0.0473\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 0.0594 - val_accuracy: 0.8879 - val_loss: 0.0468\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.0595 - val_accuracy: 0.8722 - val_loss: 0.0526\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.0616 - val_accuracy: 0.8886 - val_loss: 0.0467\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.0602 - val_accuracy: 0.8863 - val_loss: 0.0470\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.0596 - val_accuracy: 0.8810 - val_loss: 0.0477\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 0.0622 - val_accuracy: 0.8890 - val_loss: 0.0478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.8810\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7919\n",
      "Macro Recall: 0.6916\n",
      "Macro F1-Score: 0.7278\n",
      "Macro AUC-ROC: 0.9556\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.8780\n",
      "Weighted Recall: 0.8810\n",
      "Weighted F1-Score: 0.8749\n",
      "Weighted AUC-ROC: 0.9744\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.865478        0.879333          0.869421     0.977618\n",
      "1      1           0.610414        0.374843          0.463706     0.930450\n",
      "2      2           0.827147        0.534087          0.647312     0.935276\n",
      "3      3           0.739359        0.706900          0.719498     0.952928\n",
      "4      4           0.916874        0.962958          0.938888     0.981789\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2      3       4\n",
      "0  527.6   4.8   6.2    8.2    53.2\n",
      "1    9.8  32.8   4.4   11.8    28.6\n",
      "2   12.8   7.4  87.8   17.4    39.0\n",
      "3   19.4   5.4   3.0  118.2    21.2\n",
      "4   44.2   3.2   5.2    6.8  1544.2\n",
      "\n",
      "Processing week3 with best parameters...\n",
      "best parameters for week3: {'units_1': 64, 'dropout_1': 0.2, 'units_2': 96, 'dropout_2': 0.2, 'learning_rate': 0.0015027297638441546}\n",
      "Fold 1: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6106 - loss: 0.1401 - val_accuracy: 0.6878 - val_loss: 0.1122\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6988 - loss: 0.1099 - val_accuracy: 0.7175 - val_loss: 0.1062\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.1022 - val_accuracy: 0.8117 - val_loss: 0.0844\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.0865 - val_accuracy: 0.8113 - val_loss: 0.0777\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.0809 - val_accuracy: 0.8528 - val_loss: 0.0651\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.0746 - val_accuracy: 0.8666 - val_loss: 0.0622\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.0736 - val_accuracy: 0.8669 - val_loss: 0.0623\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.0699 - val_accuracy: 0.8711 - val_loss: 0.0582\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.0680 - val_accuracy: 0.8730 - val_loss: 0.0595\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.0659 - val_accuracy: 0.8696 - val_loss: 0.0622\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 0.0626 - val_accuracy: 0.8696 - val_loss: 0.0573\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.0656 - val_accuracy: 0.8719 - val_loss: 0.0521\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 0.0626 - val_accuracy: 0.8795 - val_loss: 0.0499\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.0588 - val_accuracy: 0.8833 - val_loss: 0.0484\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.0586 - val_accuracy: 0.8704 - val_loss: 0.0493\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.0574 - val_accuracy: 0.8772 - val_loss: 0.0503\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.0590 - val_accuracy: 0.8852 - val_loss: 0.0475\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.0577 - val_accuracy: 0.8826 - val_loss: 0.0469\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 0.0582 - val_accuracy: 0.8902 - val_loss: 0.0446\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.0561 - val_accuracy: 0.8849 - val_loss: 0.0541\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.0551 - val_accuracy: 0.8944 - val_loss: 0.0437\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.0514 - val_accuracy: 0.8921 - val_loss: 0.0430\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.0499 - val_accuracy: 0.8856 - val_loss: 0.0441\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.0501 - val_accuracy: 0.8894 - val_loss: 0.0455\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.0554 - val_accuracy: 0.8910 - val_loss: 0.0425\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8790 - loss: 0.0499 - val_accuracy: 0.8910 - val_loss: 0.0457\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 0.0514 - val_accuracy: 0.8826 - val_loss: 0.0467\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0518 - val_accuracy: 0.8990 - val_loss: 0.0411\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.0473 - val_accuracy: 0.8974 - val_loss: 0.0394\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.0475 - val_accuracy: 0.8898 - val_loss: 0.0418\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.0486 - val_accuracy: 0.9043 - val_loss: 0.0367\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8844 - loss: 0.0476 - val_accuracy: 0.8872 - val_loss: 0.0428\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.0452 - val_accuracy: 0.8780 - val_loss: 0.0454\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.0471 - val_accuracy: 0.8952 - val_loss: 0.0375\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.0472 - val_accuracy: 0.9001 - val_loss: 0.0349\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.0457 - val_accuracy: 0.8971 - val_loss: 0.0366\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8794 - loss: 0.0482 - val_accuracy: 0.8948 - val_loss: 0.0396\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.0460 - val_accuracy: 0.8936 - val_loss: 0.0373\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8839 - loss: 0.0474 - val_accuracy: 0.8868 - val_loss: 0.0434\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.0433 - val_accuracy: 0.9077 - val_loss: 0.0348\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.0444 - val_accuracy: 0.8917 - val_loss: 0.0416\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.0443 - val_accuracy: 0.8906 - val_loss: 0.0394\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.0451 - val_accuracy: 0.8948 - val_loss: 0.0369\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.0473 - val_accuracy: 0.8776 - val_loss: 0.0476\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.0496 - val_accuracy: 0.8955 - val_loss: 0.0373\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.0416 - val_accuracy: 0.9032 - val_loss: 0.0360\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.0427 - val_accuracy: 0.9081 - val_loss: 0.0324\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.0405 - val_accuracy: 0.9013 - val_loss: 0.0343\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.0395 - val_accuracy: 0.9150 - val_loss: 0.0301\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.0412 - val_accuracy: 0.8986 - val_loss: 0.0361\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6363 - loss: 0.1347 - val_accuracy: 0.7167 - val_loss: 0.1059\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.1104 - val_accuracy: 0.7899 - val_loss: 0.0896\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.0960 - val_accuracy: 0.8265 - val_loss: 0.0770\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.0910 - val_accuracy: 0.8387 - val_loss: 0.0701\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.0828 - val_accuracy: 0.8433 - val_loss: 0.0656\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.0814 - val_accuracy: 0.8551 - val_loss: 0.0638\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.0783 - val_accuracy: 0.8521 - val_loss: 0.0620\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.0731 - val_accuracy: 0.8662 - val_loss: 0.0588\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.0725 - val_accuracy: 0.8738 - val_loss: 0.0587\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.0711 - val_accuracy: 0.8658 - val_loss: 0.0596\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.0659 - val_accuracy: 0.8845 - val_loss: 0.0517\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.0658 - val_accuracy: 0.8807 - val_loss: 0.0506\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8469 - loss: 0.0667 - val_accuracy: 0.8742 - val_loss: 0.0546\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 0.0606 - val_accuracy: 0.8807 - val_loss: 0.0503\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8612 - loss: 0.0580 - val_accuracy: 0.8837 - val_loss: 0.0488\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0586 - val_accuracy: 0.8948 - val_loss: 0.0478\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.0560 - val_accuracy: 0.8887 - val_loss: 0.0483\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8630 - loss: 0.0587 - val_accuracy: 0.8902 - val_loss: 0.0504\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 0.0614 - val_accuracy: 0.8875 - val_loss: 0.0486\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.0575 - val_accuracy: 0.8982 - val_loss: 0.0437\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.0544 - val_accuracy: 0.8997 - val_loss: 0.0427\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.0548 - val_accuracy: 0.8990 - val_loss: 0.0429\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.0533 - val_accuracy: 0.8925 - val_loss: 0.0462\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.0534 - val_accuracy: 0.8902 - val_loss: 0.0445\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8689 - loss: 0.0538 - val_accuracy: 0.8974 - val_loss: 0.0451\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.0555 - val_accuracy: 0.8841 - val_loss: 0.0498\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.0589 - val_accuracy: 0.9081 - val_loss: 0.0401\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8807 - loss: 0.0483 - val_accuracy: 0.9016 - val_loss: 0.0406\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8762 - loss: 0.0507 - val_accuracy: 0.8967 - val_loss: 0.0429\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8788 - loss: 0.0481 - val_accuracy: 0.9062 - val_loss: 0.0399\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.0480 - val_accuracy: 0.9032 - val_loss: 0.0391\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.0476 - val_accuracy: 0.9058 - val_loss: 0.0376\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.0486 - val_accuracy: 0.8921 - val_loss: 0.0423\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.0492 - val_accuracy: 0.8952 - val_loss: 0.0413\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.0452 - val_accuracy: 0.8974 - val_loss: 0.0388\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.0498 - val_accuracy: 0.8933 - val_loss: 0.0413\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8855 - loss: 0.0462 - val_accuracy: 0.9055 - val_loss: 0.0378\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.0444 - val_accuracy: 0.9142 - val_loss: 0.0338\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.0431 - val_accuracy: 0.9093 - val_loss: 0.0366\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.0458 - val_accuracy: 0.8952 - val_loss: 0.0382\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.0435 - val_accuracy: 0.9089 - val_loss: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.0434 - val_accuracy: 0.9135 - val_loss: 0.0330\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.0499 - val_accuracy: 0.9119 - val_loss: 0.0323\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8878 - loss: 0.0433 - val_accuracy: 0.9070 - val_loss: 0.0324\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8875 - loss: 0.0423 - val_accuracy: 0.9116 - val_loss: 0.0342\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.0437 - val_accuracy: 0.9180 - val_loss: 0.0294\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.0416 - val_accuracy: 0.9146 - val_loss: 0.0319\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.0421 - val_accuracy: 0.8967 - val_loss: 0.0384\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.0399 - val_accuracy: 0.9142 - val_loss: 0.0314\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8938 - loss: 0.0414 - val_accuracy: 0.9062 - val_loss: 0.0353\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6117 - loss: 0.1396 - val_accuracy: 0.6698 - val_loss: 0.1134\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6838 - loss: 0.1151 - val_accuracy: 0.7507 - val_loss: 0.0947\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.1007 - val_accuracy: 0.7934 - val_loss: 0.0829\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.0876 - val_accuracy: 0.8330 - val_loss: 0.0733\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.0828 - val_accuracy: 0.8506 - val_loss: 0.0663\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.0737 - val_accuracy: 0.8502 - val_loss: 0.0662\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0765 - val_accuracy: 0.8559 - val_loss: 0.0613\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.0698 - val_accuracy: 0.8628 - val_loss: 0.0586\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.0681 - val_accuracy: 0.8307 - val_loss: 0.0767\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.0687 - val_accuracy: 0.8601 - val_loss: 0.0560\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.0616 - val_accuracy: 0.8708 - val_loss: 0.0565\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.0637 - val_accuracy: 0.8677 - val_loss: 0.0560\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.0624 - val_accuracy: 0.8673 - val_loss: 0.0539\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.0604 - val_accuracy: 0.8700 - val_loss: 0.0549\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.0628 - val_accuracy: 0.8791 - val_loss: 0.0519\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8613 - loss: 0.0591 - val_accuracy: 0.8753 - val_loss: 0.0508\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.0596 - val_accuracy: 0.8864 - val_loss: 0.0479\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.0551 - val_accuracy: 0.8791 - val_loss: 0.0489\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.0564 - val_accuracy: 0.8849 - val_loss: 0.0462\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.0559 - val_accuracy: 0.8894 - val_loss: 0.0466\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8698 - loss: 0.0546 - val_accuracy: 0.8902 - val_loss: 0.0447\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8765 - loss: 0.0523 - val_accuracy: 0.8807 - val_loss: 0.0483\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.0520 - val_accuracy: 0.8833 - val_loss: 0.0521\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8719 - loss: 0.0530 - val_accuracy: 0.8913 - val_loss: 0.0446\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8733 - loss: 0.0534 - val_accuracy: 0.8902 - val_loss: 0.0434\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8826 - loss: 0.0482 - val_accuracy: 0.8891 - val_loss: 0.0475\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.0490 - val_accuracy: 0.8978 - val_loss: 0.0396\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.0501 - val_accuracy: 0.8944 - val_loss: 0.0418\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.0499 - val_accuracy: 0.8978 - val_loss: 0.0401\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8783 - loss: 0.0503 - val_accuracy: 0.8894 - val_loss: 0.0445\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.0487 - val_accuracy: 0.8955 - val_loss: 0.0435\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.0473 - val_accuracy: 0.8948 - val_loss: 0.0428\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.0472 - val_accuracy: 0.8982 - val_loss: 0.0406\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.0472 - val_accuracy: 0.8864 - val_loss: 0.0462\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8821 - loss: 0.0459 - val_accuracy: 0.8986 - val_loss: 0.0385\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.0487 - val_accuracy: 0.8982 - val_loss: 0.0405\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.0435 - val_accuracy: 0.8902 - val_loss: 0.0431\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.0450 - val_accuracy: 0.9016 - val_loss: 0.0405\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8911 - loss: 0.0436 - val_accuracy: 0.9070 - val_loss: 0.0378\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8821 - loss: 0.0477 - val_accuracy: 0.9081 - val_loss: 0.0358\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8858 - loss: 0.0432 - val_accuracy: 0.8967 - val_loss: 0.0374\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.0436 - val_accuracy: 0.9058 - val_loss: 0.0366\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.0412 - val_accuracy: 0.9135 - val_loss: 0.0334\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.0395 - val_accuracy: 0.9074 - val_loss: 0.0378\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.0401 - val_accuracy: 0.9089 - val_loss: 0.0332\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.0412 - val_accuracy: 0.9081 - val_loss: 0.0341\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8982 - loss: 0.0394 - val_accuracy: 0.9089 - val_loss: 0.0338\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.0405 - val_accuracy: 0.9100 - val_loss: 0.0325\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.0384 - val_accuracy: 0.8990 - val_loss: 0.0381\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.0380 - val_accuracy: 0.9146 - val_loss: 0.0319\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6267 - loss: 0.1380 - val_accuracy: 0.6911 - val_loss: 0.1126\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6893 - loss: 0.1174 - val_accuracy: 0.7487 - val_loss: 0.0988\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.1000 - val_accuracy: 0.8093 - val_loss: 0.0809\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.0896 - val_accuracy: 0.8387 - val_loss: 0.0719\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.0818 - val_accuracy: 0.8490 - val_loss: 0.0658\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.0761 - val_accuracy: 0.8543 - val_loss: 0.0612\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.0707 - val_accuracy: 0.8532 - val_loss: 0.0615\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.0716 - val_accuracy: 0.8738 - val_loss: 0.0551\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.0728 - val_accuracy: 0.8669 - val_loss: 0.0555\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.0663 - val_accuracy: 0.8661 - val_loss: 0.0609\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.0654 - val_accuracy: 0.8722 - val_loss: 0.0532\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.0623 - val_accuracy: 0.8753 - val_loss: 0.0513\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.0624 - val_accuracy: 0.8699 - val_loss: 0.0528\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 0.0607 - val_accuracy: 0.8814 - val_loss: 0.0476\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.0589 - val_accuracy: 0.8833 - val_loss: 0.0512\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.0559 - val_accuracy: 0.8913 - val_loss: 0.0448\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.0556 - val_accuracy: 0.8764 - val_loss: 0.0472\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.0571 - val_accuracy: 0.8825 - val_loss: 0.0506\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.0580 - val_accuracy: 0.8936 - val_loss: 0.0447\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.0560 - val_accuracy: 0.8921 - val_loss: 0.0437\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.0535 - val_accuracy: 0.8890 - val_loss: 0.0456\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.0551 - val_accuracy: 0.8970 - val_loss: 0.0397\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8619 - loss: 0.0525 - val_accuracy: 0.9005 - val_loss: 0.0397\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.0516 - val_accuracy: 0.8913 - val_loss: 0.0429\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0586 - val_accuracy: 0.8852 - val_loss: 0.0454\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.0556 - val_accuracy: 0.9016 - val_loss: 0.0405\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.0484 - val_accuracy: 0.8978 - val_loss: 0.0417\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.0511 - val_accuracy: 0.8959 - val_loss: 0.0484\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8764 - loss: 0.0513 - val_accuracy: 0.9008 - val_loss: 0.0411\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.0511 - val_accuracy: 0.9012 - val_loss: 0.0401\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.0529 - val_accuracy: 0.8951 - val_loss: 0.0427\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.0497 - val_accuracy: 0.9016 - val_loss: 0.0401\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.0474 - val_accuracy: 0.9012 - val_loss: 0.0387\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.0448 - val_accuracy: 0.9085 - val_loss: 0.0374\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8762 - loss: 0.0479 - val_accuracy: 0.8810 - val_loss: 0.0454\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.0496 - val_accuracy: 0.8940 - val_loss: 0.0421\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8839 - loss: 0.0456 - val_accuracy: 0.9169 - val_loss: 0.0326\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.0451 - val_accuracy: 0.9069 - val_loss: 0.0341\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.0448 - val_accuracy: 0.8806 - val_loss: 0.0398\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.0434 - val_accuracy: 0.8982 - val_loss: 0.0429\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8825 - loss: 0.0492 - val_accuracy: 0.9035 - val_loss: 0.0366\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8832 - loss: 0.0444 - val_accuracy: 0.9035 - val_loss: 0.0377\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8923 - loss: 0.0426 - val_accuracy: 0.9115 - val_loss: 0.0340\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.0453 - val_accuracy: 0.9073 - val_loss: 0.0331\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.0448 - val_accuracy: 0.9108 - val_loss: 0.0325\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8820 - loss: 0.0462 - val_accuracy: 0.9123 - val_loss: 0.0326\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.0459 - val_accuracy: 0.9237 - val_loss: 0.0298\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.0410 - val_accuracy: 0.9050 - val_loss: 0.0328\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.0430 - val_accuracy: 0.9184 - val_loss: 0.0290\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.0414 - val_accuracy: 0.9214 - val_loss: 0.0291\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6392 - loss: 0.1328 - val_accuracy: 0.7021 - val_loss: 0.1074\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.1170 - val_accuracy: 0.7517 - val_loss: 0.0940\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.0983 - val_accuracy: 0.7956 - val_loss: 0.0850\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.0858 - val_accuracy: 0.8471 - val_loss: 0.0689\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.0795 - val_accuracy: 0.8375 - val_loss: 0.0714\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 0.0714 - val_accuracy: 0.8585 - val_loss: 0.0641\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.0721 - val_accuracy: 0.8650 - val_loss: 0.0610\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.0658 - val_accuracy: 0.8497 - val_loss: 0.0652\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.0684 - val_accuracy: 0.8619 - val_loss: 0.0632\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8496 - loss: 0.0630 - val_accuracy: 0.8722 - val_loss: 0.0534\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.0630 - val_accuracy: 0.8776 - val_loss: 0.0533\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8524 - loss: 0.0607 - val_accuracy: 0.8814 - val_loss: 0.0506\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.0585 - val_accuracy: 0.8719 - val_loss: 0.0564\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.0613 - val_accuracy: 0.8902 - val_loss: 0.0479\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.0566 - val_accuracy: 0.8852 - val_loss: 0.0468\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.0589 - val_accuracy: 0.8833 - val_loss: 0.0496\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8716 - loss: 0.0539 - val_accuracy: 0.8902 - val_loss: 0.0454\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.0506 - val_accuracy: 0.8776 - val_loss: 0.0501\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.0566 - val_accuracy: 0.8787 - val_loss: 0.0561\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.0529 - val_accuracy: 0.8917 - val_loss: 0.0453\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8731 - loss: 0.0523 - val_accuracy: 0.8886 - val_loss: 0.0490\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8745 - loss: 0.0517 - val_accuracy: 0.8959 - val_loss: 0.0448\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.0558 - val_accuracy: 0.8635 - val_loss: 0.0553\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8682 - loss: 0.0521 - val_accuracy: 0.8711 - val_loss: 0.0569\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8767 - loss: 0.0499 - val_accuracy: 0.9012 - val_loss: 0.0440\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.0516 - val_accuracy: 0.8947 - val_loss: 0.0414\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.0489 - val_accuracy: 0.8799 - val_loss: 0.0486\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.0511 - val_accuracy: 0.8963 - val_loss: 0.0407\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0499 - val_accuracy: 0.8696 - val_loss: 0.0518\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.0501 - val_accuracy: 0.9012 - val_loss: 0.0404\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.0454 - val_accuracy: 0.8928 - val_loss: 0.0410\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.0468 - val_accuracy: 0.9119 - val_loss: 0.0400\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8810 - loss: 0.0461 - val_accuracy: 0.8993 - val_loss: 0.0426\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.0474 - val_accuracy: 0.9092 - val_loss: 0.0374\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8882 - loss: 0.0432 - val_accuracy: 0.9020 - val_loss: 0.0439\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8811 - loss: 0.0465 - val_accuracy: 0.9069 - val_loss: 0.0375\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.0428 - val_accuracy: 0.9119 - val_loss: 0.0388\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.0438 - val_accuracy: 0.9062 - val_loss: 0.0391\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.0473 - val_accuracy: 0.8966 - val_loss: 0.0420\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.0431 - val_accuracy: 0.9111 - val_loss: 0.0358\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.0409 - val_accuracy: 0.9073 - val_loss: 0.0367\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8890 - loss: 0.0441 - val_accuracy: 0.8955 - val_loss: 0.0428\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8939 - loss: 0.0400 - val_accuracy: 0.9012 - val_loss: 0.0413\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8894 - loss: 0.0427 - val_accuracy: 0.9119 - val_loss: 0.0359\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8954 - loss: 0.0401 - val_accuracy: 0.9031 - val_loss: 0.0376\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.0400 - val_accuracy: 0.9104 - val_loss: 0.0339\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.0400 - val_accuracy: 0.9180 - val_loss: 0.0329\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8925 - loss: 0.0406 - val_accuracy: 0.9081 - val_loss: 0.0380\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.0427 - val_accuracy: 0.9142 - val_loss: 0.0337\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8957 - loss: 0.0395 - val_accuracy: 0.9214 - val_loss: 0.0322\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.9125\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.8400\n",
      "Macro Recall: 0.7731\n",
      "Macro F1-Score: 0.8009\n",
      "Macro AUC-ROC: 0.9736\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.9100\n",
      "Weighted Recall: 0.9125\n",
      "Weighted F1-Score: 0.9094\n",
      "Weighted AUC-ROC: 0.9866\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.925726        0.911000          0.917706     0.991024\n",
      "1      1           0.742984        0.599295          0.660525     0.949174\n",
      "2      2           0.796770        0.632565          0.700469     0.960344\n",
      "3      3           0.797918        0.746407          0.770165     0.976596\n",
      "4      4           0.936462        0.976055          0.955705     0.990731\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  546.6   2.0   10.4    5.0    36.0\n",
      "1    4.6  52.4    2.6    5.2    22.6\n",
      "2   12.8   2.8  104.0   15.8    29.0\n",
      "3    6.2   6.2   10.6  124.8    19.4\n",
      "4   20.8   7.4    4.4    5.8  1565.2\n",
      "\n",
      "Processing week4 with best parameters...\n",
      "best parameters for week4: {'units_1': 224, 'dropout_1': 0.1, 'units_2': 64, 'dropout_2': 0.4, 'learning_rate': 0.001143448498353399}\n",
      "Fold 1: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6336 - loss: 0.1332 - val_accuracy: 0.7266 - val_loss: 0.1050\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 0.0972 - val_accuracy: 0.8635 - val_loss: 0.0576\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.0625 - val_accuracy: 0.9028 - val_loss: 0.0390\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.0596 - val_accuracy: 0.9093 - val_loss: 0.0368\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.0424 - val_accuracy: 0.9177 - val_loss: 0.0366\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.0438 - val_accuracy: 0.9093 - val_loss: 0.0363\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9034 - loss: 0.0400 - val_accuracy: 0.9268 - val_loss: 0.0312\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.0342 - val_accuracy: 0.9226 - val_loss: 0.0288\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.0352 - val_accuracy: 0.9249 - val_loss: 0.0271\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9199 - loss: 0.0307 - val_accuracy: 0.9165 - val_loss: 0.0304\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.0327 - val_accuracy: 0.9302 - val_loss: 0.0247\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.0332 - val_accuracy: 0.9333 - val_loss: 0.0246\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.0319 - val_accuracy: 0.9329 - val_loss: 0.0286\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9210 - loss: 0.0299 - val_accuracy: 0.9325 - val_loss: 0.0232\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.0330 - val_accuracy: 0.9348 - val_loss: 0.0247\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9278 - loss: 0.0270 - val_accuracy: 0.9260 - val_loss: 0.0285\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.0276 - val_accuracy: 0.9409 - val_loss: 0.0252\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.0303 - val_accuracy: 0.9398 - val_loss: 0.0216\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.0297 - val_accuracy: 0.9188 - val_loss: 0.0314\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.0257 - val_accuracy: 0.9424 - val_loss: 0.0229\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.0282 - val_accuracy: 0.9443 - val_loss: 0.0215\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.0279 - val_accuracy: 0.9356 - val_loss: 0.0257\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.0255 - val_accuracy: 0.9272 - val_loss: 0.0304\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9327 - loss: 0.0253 - val_accuracy: 0.9493 - val_loss: 0.0206\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.0251 - val_accuracy: 0.9375 - val_loss: 0.0206\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.0272 - val_accuracy: 0.9375 - val_loss: 0.0205\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.0243 - val_accuracy: 0.9497 - val_loss: 0.0195\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9330 - loss: 0.0242 - val_accuracy: 0.9363 - val_loss: 0.0232\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9311 - loss: 0.0240 - val_accuracy: 0.9401 - val_loss: 0.0198\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.0229 - val_accuracy: 0.9440 - val_loss: 0.0216\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.0257 - val_accuracy: 0.9451 - val_loss: 0.0183\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.0245 - val_accuracy: 0.9482 - val_loss: 0.0171\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.0193 - val_accuracy: 0.9512 - val_loss: 0.0191\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.0215 - val_accuracy: 0.8742 - val_loss: 0.0684\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.0233 - val_accuracy: 0.9447 - val_loss: 0.0203\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.0188 - val_accuracy: 0.9588 - val_loss: 0.0153\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.0181 - val_accuracy: 0.9581 - val_loss: 0.0157\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.0186 - val_accuracy: 0.9493 - val_loss: 0.0160\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.0203 - val_accuracy: 0.9623 - val_loss: 0.0147\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.0196 - val_accuracy: 0.9523 - val_loss: 0.0158\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.0181 - val_accuracy: 0.9645 - val_loss: 0.0129\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9541 - loss: 0.0154 - val_accuracy: 0.9584 - val_loss: 0.0137\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.0167 - val_accuracy: 0.9340 - val_loss: 0.0257\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.0199 - val_accuracy: 0.9413 - val_loss: 0.0214\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.0190 - val_accuracy: 0.9565 - val_loss: 0.0144\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9526 - loss: 0.0166 - val_accuracy: 0.9569 - val_loss: 0.0130\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9579 - loss: 0.0144 - val_accuracy: 0.9573 - val_loss: 0.0162\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.0131 - val_accuracy: 0.9546 - val_loss: 0.0130\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9507 - loss: 0.0189 - val_accuracy: 0.9569 - val_loss: 0.0155\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9543 - loss: 0.0159 - val_accuracy: 0.9539 - val_loss: 0.0185\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6322 - loss: 0.1359 - val_accuracy: 0.7122 - val_loss: 0.1030\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.1019 - val_accuracy: 0.8799 - val_loss: 0.0528\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.0664 - val_accuracy: 0.9032 - val_loss: 0.0480\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.0549 - val_accuracy: 0.9207 - val_loss: 0.0355\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.0460 - val_accuracy: 0.8952 - val_loss: 0.0467\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8982 - loss: 0.0460 - val_accuracy: 0.9241 - val_loss: 0.0310\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.0413 - val_accuracy: 0.9177 - val_loss: 0.0331\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.0398 - val_accuracy: 0.9264 - val_loss: 0.0280\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.0362 - val_accuracy: 0.9035 - val_loss: 0.0399\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.0352 - val_accuracy: 0.9238 - val_loss: 0.0271\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.0322 - val_accuracy: 0.9291 - val_loss: 0.0236\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.0324 - val_accuracy: 0.9272 - val_loss: 0.0253\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.0315 - val_accuracy: 0.9398 - val_loss: 0.0221\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9175 - loss: 0.0331 - val_accuracy: 0.9329 - val_loss: 0.0225\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.0282 - val_accuracy: 0.9436 - val_loss: 0.0208\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.0281 - val_accuracy: 0.9283 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.0312 - val_accuracy: 0.9421 - val_loss: 0.0200\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.0256 - val_accuracy: 0.9443 - val_loss: 0.0196\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9301 - loss: 0.0278 - val_accuracy: 0.9409 - val_loss: 0.0210\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.0253 - val_accuracy: 0.9424 - val_loss: 0.0218\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.0275 - val_accuracy: 0.9382 - val_loss: 0.0226\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9294 - loss: 0.0261 - val_accuracy: 0.9523 - val_loss: 0.0172\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.0243 - val_accuracy: 0.9451 - val_loss: 0.0170\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.0304 - val_accuracy: 0.9485 - val_loss: 0.0170\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.0234 - val_accuracy: 0.9318 - val_loss: 0.0266\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.0265 - val_accuracy: 0.9489 - val_loss: 0.0174\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.0210 - val_accuracy: 0.9546 - val_loss: 0.0166\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.0200 - val_accuracy: 0.9485 - val_loss: 0.0173\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.0201 - val_accuracy: 0.9543 - val_loss: 0.0147\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9381 - loss: 0.0228 - val_accuracy: 0.9489 - val_loss: 0.0153\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.0189 - val_accuracy: 0.9619 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.0193 - val_accuracy: 0.9531 - val_loss: 0.0151\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.0187 - val_accuracy: 0.9573 - val_loss: 0.0138\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.0236 - val_accuracy: 0.9562 - val_loss: 0.0130\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.0187 - val_accuracy: 0.9630 - val_loss: 0.0132\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.0204 - val_accuracy: 0.9615 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.0177 - val_accuracy: 0.9619 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9435 - loss: 0.0203 - val_accuracy: 0.9504 - val_loss: 0.0157\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9441 - loss: 0.0199 - val_accuracy: 0.9672 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.0182 - val_accuracy: 0.9630 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.0180 - val_accuracy: 0.9672 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.0166 - val_accuracy: 0.9619 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9522 - loss: 0.0170 - val_accuracy: 0.9581 - val_loss: 0.0135\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.0178 - val_accuracy: 0.9600 - val_loss: 0.0112\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9544 - loss: 0.0160 - val_accuracy: 0.9634 - val_loss: 0.0144\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.0186 - val_accuracy: 0.9661 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.0181 - val_accuracy: 0.9577 - val_loss: 0.0155\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.0154 - val_accuracy: 0.9592 - val_loss: 0.0139\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.0182 - val_accuracy: 0.9546 - val_loss: 0.0141\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9549 - loss: 0.0140 - val_accuracy: 0.9607 - val_loss: 0.0109\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6341 - loss: 0.1404 - val_accuracy: 0.7571 - val_loss: 0.1037\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.1012 - val_accuracy: 0.8239 - val_loss: 0.0783\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.0697 - val_accuracy: 0.8971 - val_loss: 0.0453\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.0568 - val_accuracy: 0.8994 - val_loss: 0.0451\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8818 - loss: 0.0538 - val_accuracy: 0.9028 - val_loss: 0.0430\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.0490 - val_accuracy: 0.9016 - val_loss: 0.0424\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.0415 - val_accuracy: 0.9154 - val_loss: 0.0350\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.0384 - val_accuracy: 0.9264 - val_loss: 0.0308\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.0360 - val_accuracy: 0.9318 - val_loss: 0.0277\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9111 - loss: 0.0348 - val_accuracy: 0.9241 - val_loss: 0.0298\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.0355 - val_accuracy: 0.9257 - val_loss: 0.0254\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.0337 - val_accuracy: 0.9340 - val_loss: 0.0254\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.0309 - val_accuracy: 0.9295 - val_loss: 0.0255\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.0300 - val_accuracy: 0.9337 - val_loss: 0.0240\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.0280 - val_accuracy: 0.9401 - val_loss: 0.0227\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.0311 - val_accuracy: 0.9382 - val_loss: 0.0231\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.0274 - val_accuracy: 0.9363 - val_loss: 0.0224\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.0268 - val_accuracy: 0.9279 - val_loss: 0.0275\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.0278 - val_accuracy: 0.9394 - val_loss: 0.0212\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.0265 - val_accuracy: 0.9382 - val_loss: 0.0200\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.0319 - val_accuracy: 0.9344 - val_loss: 0.0253\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.0264 - val_accuracy: 0.9440 - val_loss: 0.0218\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9285 - loss: 0.0251 - val_accuracy: 0.9386 - val_loss: 0.0197\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.0280 - val_accuracy: 0.9447 - val_loss: 0.0193\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.0243 - val_accuracy: 0.9474 - val_loss: 0.0224\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9313 - loss: 0.0252 - val_accuracy: 0.9493 - val_loss: 0.0202\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.0241 - val_accuracy: 0.9413 - val_loss: 0.0215\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9300 - loss: 0.0255 - val_accuracy: 0.9352 - val_loss: 0.0214\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9330 - loss: 0.0246 - val_accuracy: 0.9550 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.0242 - val_accuracy: 0.9272 - val_loss: 0.0309\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.0234 - val_accuracy: 0.9470 - val_loss: 0.0173\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.0196 - val_accuracy: 0.9409 - val_loss: 0.0196\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9411 - loss: 0.0205 - val_accuracy: 0.9119 - val_loss: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.0246 - val_accuracy: 0.9577 - val_loss: 0.0142\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.0171 - val_accuracy: 0.9459 - val_loss: 0.0183\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.0209 - val_accuracy: 0.9497 - val_loss: 0.0151\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.0189 - val_accuracy: 0.9447 - val_loss: 0.0169\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.0197 - val_accuracy: 0.9516 - val_loss: 0.0158\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.0209 - val_accuracy: 0.9604 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0184 - val_accuracy: 0.9592 - val_loss: 0.0122\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.0159 - val_accuracy: 0.9497 - val_loss: 0.0185\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.0175 - val_accuracy: 0.9569 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9474 - loss: 0.0161 - val_accuracy: 0.9684 - val_loss: 0.0108\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.0198 - val_accuracy: 0.9512 - val_loss: 0.0175\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0182 - val_accuracy: 0.9623 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.0165 - val_accuracy: 0.9619 - val_loss: 0.0128\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.0156 - val_accuracy: 0.9699 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.0141 - val_accuracy: 0.9653 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9535 - loss: 0.0155 - val_accuracy: 0.9703 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.0155 - val_accuracy: 0.9604 - val_loss: 0.0116\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6231 - loss: 0.1406 - val_accuracy: 0.7357 - val_loss: 0.1055\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7238 - loss: 0.1069 - val_accuracy: 0.8608 - val_loss: 0.0641\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.0714 - val_accuracy: 0.8970 - val_loss: 0.0475\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.0624 - val_accuracy: 0.9047 - val_loss: 0.0445\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8848 - loss: 0.0531 - val_accuracy: 0.9069 - val_loss: 0.0431\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.0455 - val_accuracy: 0.9100 - val_loss: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.0408 - val_accuracy: 0.9165 - val_loss: 0.0310\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.0367 - val_accuracy: 0.9172 - val_loss: 0.0312\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.0350 - val_accuracy: 0.9371 - val_loss: 0.0246\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.0355 - val_accuracy: 0.9352 - val_loss: 0.0236\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.0316 - val_accuracy: 0.9397 - val_loss: 0.0238\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.0334 - val_accuracy: 0.9218 - val_loss: 0.0325\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.0296 - val_accuracy: 0.9397 - val_loss: 0.0215\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.0313 - val_accuracy: 0.9264 - val_loss: 0.0247\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.0290 - val_accuracy: 0.9432 - val_loss: 0.0199\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.0281 - val_accuracy: 0.9371 - val_loss: 0.0228\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.0321 - val_accuracy: 0.9348 - val_loss: 0.0214\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.0274 - val_accuracy: 0.9458 - val_loss: 0.0194\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.0270 - val_accuracy: 0.9336 - val_loss: 0.0221\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.0255 - val_accuracy: 0.9390 - val_loss: 0.0212\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9278 - loss: 0.0258 - val_accuracy: 0.9439 - val_loss: 0.0199\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.0246 - val_accuracy: 0.9451 - val_loss: 0.0180\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.0235 - val_accuracy: 0.9474 - val_loss: 0.0180\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9313 - loss: 0.0252 - val_accuracy: 0.9489 - val_loss: 0.0190\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9386 - loss: 0.0226 - val_accuracy: 0.9314 - val_loss: 0.0253\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.0288 - val_accuracy: 0.9523 - val_loss: 0.0155\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.0239 - val_accuracy: 0.9477 - val_loss: 0.0173\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9318 - loss: 0.0242 - val_accuracy: 0.9211 - val_loss: 0.0326\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.0251 - val_accuracy: 0.9527 - val_loss: 0.0160\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.0217 - val_accuracy: 0.9523 - val_loss: 0.0169\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.0243 - val_accuracy: 0.9584 - val_loss: 0.0163\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9438 - loss: 0.0196 - val_accuracy: 0.9565 - val_loss: 0.0162\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.0201 - val_accuracy: 0.9561 - val_loss: 0.0160\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.0212 - val_accuracy: 0.9611 - val_loss: 0.0134\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9464 - loss: 0.0193 - val_accuracy: 0.9603 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.0179 - val_accuracy: 0.9497 - val_loss: 0.0207\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.0202 - val_accuracy: 0.9451 - val_loss: 0.0193\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.0188 - val_accuracy: 0.9607 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.0217 - val_accuracy: 0.9592 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.0174 - val_accuracy: 0.9588 - val_loss: 0.0138\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.0167 - val_accuracy: 0.9615 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9488 - loss: 0.0179 - val_accuracy: 0.9649 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.0177 - val_accuracy: 0.9607 - val_loss: 0.0124\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.0177 - val_accuracy: 0.9455 - val_loss: 0.0180\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.0193 - val_accuracy: 0.9550 - val_loss: 0.0129\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.0151 - val_accuracy: 0.9680 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.0138 - val_accuracy: 0.9680 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.0166 - val_accuracy: 0.9680 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9557 - loss: 0.0144 - val_accuracy: 0.9600 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.0147 - val_accuracy: 0.9497 - val_loss: 0.0152\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6262 - loss: 0.1421 - val_accuracy: 0.7315 - val_loss: 0.1040\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.1006 - val_accuracy: 0.8322 - val_loss: 0.0765\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.0670 - val_accuracy: 0.8753 - val_loss: 0.0588\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.0535 - val_accuracy: 0.9127 - val_loss: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8960 - loss: 0.0440 - val_accuracy: 0.9115 - val_loss: 0.0389\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.0435 - val_accuracy: 0.9272 - val_loss: 0.0328\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.0378 - val_accuracy: 0.9237 - val_loss: 0.0318\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9113 - loss: 0.0350 - val_accuracy: 0.9100 - val_loss: 0.0356\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.0360 - val_accuracy: 0.9344 - val_loss: 0.0257\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.0303 - val_accuracy: 0.9157 - val_loss: 0.0330\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.0333 - val_accuracy: 0.9287 - val_loss: 0.0282\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.0309 - val_accuracy: 0.9321 - val_loss: 0.0246\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.0282 - val_accuracy: 0.9378 - val_loss: 0.0238\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.0305 - val_accuracy: 0.9298 - val_loss: 0.0275\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.0287 - val_accuracy: 0.9237 - val_loss: 0.0242\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.0267 - val_accuracy: 0.9367 - val_loss: 0.0233\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.0264 - val_accuracy: 0.9317 - val_loss: 0.0308\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.0292 - val_accuracy: 0.9211 - val_loss: 0.0313\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9286 - loss: 0.0279 - val_accuracy: 0.9123 - val_loss: 0.0365\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9233 - loss: 0.0284 - val_accuracy: 0.9382 - val_loss: 0.0230\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.0327 - val_accuracy: 0.8105 - val_loss: 0.0995\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.0354 - val_accuracy: 0.9371 - val_loss: 0.0229\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.0260 - val_accuracy: 0.9409 - val_loss: 0.0199\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.0281 - val_accuracy: 0.9340 - val_loss: 0.0270\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.0249 - val_accuracy: 0.9470 - val_loss: 0.0194\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.0217 - val_accuracy: 0.9470 - val_loss: 0.0171\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.0217 - val_accuracy: 0.9481 - val_loss: 0.0215\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.0241 - val_accuracy: 0.9474 - val_loss: 0.0209\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.0202 - val_accuracy: 0.9424 - val_loss: 0.0191\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.0223 - val_accuracy: 0.9512 - val_loss: 0.0161\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9409 - loss: 0.0206 - val_accuracy: 0.9344 - val_loss: 0.0219\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.0255 - val_accuracy: 0.9504 - val_loss: 0.0185\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.0226 - val_accuracy: 0.9523 - val_loss: 0.0166\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.0213 - val_accuracy: 0.9550 - val_loss: 0.0143\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.0178 - val_accuracy: 0.9592 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.0216 - val_accuracy: 0.9539 - val_loss: 0.0157\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.0189 - val_accuracy: 0.9615 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.0192 - val_accuracy: 0.9580 - val_loss: 0.0137\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0179 - val_accuracy: 0.9485 - val_loss: 0.0225\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.0198 - val_accuracy: 0.9596 - val_loss: 0.0134\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.0179 - val_accuracy: 0.9523 - val_loss: 0.0134\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.0170 - val_accuracy: 0.9569 - val_loss: 0.0156\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9522 - loss: 0.0172 - val_accuracy: 0.9619 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.0197 - val_accuracy: 0.9512 - val_loss: 0.0238\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.0180 - val_accuracy: 0.9508 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.0176 - val_accuracy: 0.9645 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 0.0152 - val_accuracy: 0.9546 - val_loss: 0.0153\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.0166 - val_accuracy: 0.9630 - val_loss: 0.0115\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.0149 - val_accuracy: 0.9634 - val_loss: 0.0114\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9501 - loss: 0.0170 - val_accuracy: 0.9645 - val_loss: 0.0108\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.9578\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.9275\n",
      "Macro Recall: 0.8660\n",
      "Macro F1-Score: 0.8902\n",
      "Macro AUC-ROC: 0.9947\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.9579\n",
      "Weighted Recall: 0.9578\n",
      "Weighted F1-Score: 0.9561\n",
      "Weighted AUC-ROC: 0.9972\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.999003        0.999000          0.999000     1.000000\n",
      "1      1           0.982862        0.810240          0.881454     0.999297\n",
      "2      2           0.840862        0.666726          0.741776     0.982156\n",
      "3      3           0.850506        0.863723          0.851942     0.994161\n",
      "4      4           0.964274        0.990148          0.976919     0.997953\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  599.4   0.2    0.0    0.4     0.0\n",
      "1    0.0  70.8    8.2    4.0     4.4\n",
      "2    0.4   0.6  109.6   14.6    39.2\n",
      "3    0.0   0.0    7.0  144.4    15.8\n",
      "4    0.2   0.6    6.0    9.0  1587.8\n"
     ]
    }
   ],
   "source": [
    "# Biến lưu kết quả tổng quát\n",
    "overall_results_5folds = []\n",
    "\n",
    "# Lặp qua từng tuần\n",
    "for week, file_paths in five_fold_files.items():\n",
    "    print(f\"\\nProcessing {week} with best parameters...\")\n",
    "    params = best_params[week].values\n",
    "    print(f\"best parameters for {week}: {params}\")\n",
    "    \n",
    "    # Biến lưu kết quả cho từng tuần\n",
    "    week_results = {\n",
    "        \"week\": week,\n",
    "        \"accuracy_per_fold\": [],\n",
    "        \"precision_per_label\": [],\n",
    "        \"recall_per_label\": [],\n",
    "        \"f1_score_per_label\": [],\n",
    "        \"auc_roc_per_label\": [],    # AUC từng lớp\n",
    "        \"auc_roc_macro\": [],        # AUC macro\n",
    "        \"auc_roc_weighted\": [],     # AUC weighted (tự tính)\n",
    "        \"precision_macro\": [],\n",
    "        \"recall_macro\": [],\n",
    "        \"f1_macro\": [],\n",
    "        \"precision_weighted\": [],\n",
    "        \"recall_weighted\": [],\n",
    "        \"f1_weighted\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"train_times\": [],\n",
    "        \"test_times\": []\n",
    "    }\n",
    "\n",
    "    # Lặp qua từng fold\n",
    "    for i in range(len(file_paths)):\n",
    "        print(f\"Fold {i+1}: Using file {file_paths[i]} as test set\")\n",
    "        \n",
    "        # Tải dữ liệu\n",
    "        test_data = pd.read_csv(file_paths[i])\n",
    "        train_data = pd.concat([pd.read_csv(file_paths[j]) for j in range(len(file_paths)) if j != i])\n",
    "        \n",
    "        # Tách X và y\n",
    "        X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                           \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_train = to_categorical(train_data['classification_encoded'], num_classes=5)\n",
    "        \n",
    "        X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                         \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_test = to_categorical(test_data['classification_encoded'], num_classes=5)\n",
    "\n",
    "        # Reshape dữ liệu cho LSTM\n",
    "        X_train = X_train.to_numpy().reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        # Xây dựng mô hình với tham số tốt nhất\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        model = build_GRU_model(params, input_shape)\n",
    "        \n",
    "        # Bắt đầu tính thời gian huấn luyện\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)\n",
    "        end_train = time.time()\n",
    "        \n",
    "        # Bắt đầu tính thời gian kiểm thử\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        \n",
    "        # Tính thời gian và lưu lại\n",
    "        train_time = end_train - start_train\n",
    "        test_time = end_test - start_test\n",
    "        week_results[\"train_times\"].append(train_time)\n",
    "        week_results[\"test_times\"].append(test_time)\n",
    "\n",
    "        # Đánh giá mô hình trên tập kiểm thử của fold hiện tại\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        week_results[\"accuracy_per_fold\"].append(accuracy)\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_test_classes = y_test.argmax(axis=1)\n",
    "        \n",
    "        # Tính các chỉ số cho mỗi fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "        conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "        \n",
    "        # Tính AUC-ROC\n",
    "        try:\n",
    "            # Tính AUC macro và theo từng lớp với OvR\n",
    "            auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "            # Tính AUC weighted: tính trọng số theo số mẫu của từng lớp\n",
    "            supports = np.bincount(y_test_classes, minlength=5)\n",
    "            auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tính AUC: {e}\")\n",
    "            auc_macro = np.nan\n",
    "            auc_per_class = [np.nan] * 5\n",
    "            auc_weighted = np.nan\n",
    "            \n",
    "        # Lưu kết quả của fold hiện tại\n",
    "        week_results[\"precision_per_label\"].append(precision)\n",
    "        week_results[\"recall_per_label\"].append(recall)\n",
    "        week_results[\"f1_score_per_label\"].append(f1)\n",
    "        week_results[\"auc_roc_per_label\"].append(auc_per_class)  # AUC từng lớp\n",
    "        week_results[\"auc_roc_macro\"].append(auc_macro)          # AUC macro\n",
    "        week_results[\"auc_roc_weighted\"].append(auc_weighted)      # AUC weighted\n",
    "        week_results[\"confusion_matrices\"].append(conf_matrix)\n",
    "        week_results[\"precision_macro\"].append(precision_macro)\n",
    "        week_results[\"recall_macro\"].append(recall_macro)\n",
    "        week_results[\"f1_macro\"].append(f1_macro)\n",
    "        week_results[\"precision_weighted\"].append(precision_weighted)\n",
    "        week_results[\"recall_weighted\"].append(recall_weighted)\n",
    "        week_results[\"f1_weighted\"].append(f1_weighted)\n",
    "\n",
    "    # Tính trung bình cho từng nhãn\n",
    "    average_precision_per_label = np.mean(week_results[\"precision_per_label\"], axis=0)\n",
    "    average_recall_per_label = np.nanmean(week_results[\"recall_per_label\"], axis=0)\n",
    "    average_f1_per_label = np.nanmean(week_results[\"f1_score_per_label\"], axis=0)\n",
    "    average_auc_per_label = np.nanmean(week_results[\"auc_roc_per_label\"], axis=0)\n",
    "    average_confusion_matrix = np.nanmean(week_results[\"confusion_matrices\"], axis=0)\n",
    "    average_train_time = sum(week_results[\"train_times\"]) / len(week_results[\"train_times\"])\n",
    "    average_test_time = sum(week_results[\"test_times\"]) / len(week_results[\"test_times\"])\n",
    "    average_accuracy = np.nanmean(week_results[\"accuracy_per_fold\"])\n",
    "    average_precision_macro = np.nanmean(week_results[\"precision_macro\"])\n",
    "    average_recall_macro = np.nanmean(week_results[\"recall_macro\"])\n",
    "    average_f1_macro = np.nanmean(week_results[\"f1_macro\"])\n",
    "    average_auc_macro = np.nanmean(week_results[\"auc_roc_macro\"])\n",
    "    average_precision_weighted = np.nanmean(week_results[\"precision_weighted\"])\n",
    "    average_recall_weighted = np.nanmean(week_results[\"recall_weighted\"])\n",
    "    average_f1_weighted = np.nanmean(week_results[\"f1_weighted\"])\n",
    "    average_auc_weighted = np.nanmean(week_results[\"auc_roc_weighted\"])\n",
    "\n",
    "\n",
    "    # Tạo DataFrame cho precision, recall, f1-score\n",
    "    labels = np.unique(y_test_classes)  # Lấy nhãn từ y_test_classes\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Average Precision\": average_precision_per_label,\n",
    "        \"Average Recall\": average_recall_per_label,\n",
    "        \"Average F1-Score\": average_f1_per_label,\n",
    "        \"Average AUC\": average_auc_per_label\n",
    "    })\n",
    "    \n",
    "    # Tạo DataFrame cho confusion matrix\n",
    "    confusion_df = pd.DataFrame(average_confusion_matrix, index=labels, columns=labels)\n",
    "    # In kết quả Accuracy và Macro metrics\n",
    "    print(\"\\n=== Average Accuracy ===\")\n",
    "    print(f\"{average_accuracy:.4f}\")\n",
    "    print(\"\\n=== Average Macro Metrics ===\")\n",
    "    print(f\"Macro Precision: {average_precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {average_recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {average_f1_macro:.4f}\")\n",
    "    print(f\"Macro AUC-ROC: {average_auc_macro:.4f}\")\n",
    "    print(\"\\n=== Average Weighted Metrics ===\")\n",
    "    print(f\"Weighted Precision: {average_precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {average_recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {average_f1_weighted:.4f}\")\n",
    "    print(f\"Weighted AUC-ROC: {average_auc_weighted:.4f}\")\n",
    "    print(\"\\n=== Average Metrics per Label ===\")\n",
    "    print(metrics_df)\n",
    "    print(\"\\n=== Average Confusion Matrix ===\")\n",
    "    print(confusion_df)\n",
    "    \n",
    "    # Cập nhật kết quả cho tuần hiện tại\n",
    "    week_results.update({\n",
    "        \"average_accuracy\": average_accuracy,\n",
    "        \"average_precision_macro\": average_precision_macro,\n",
    "        \"average_recall_macro\": average_recall_macro,\n",
    "        \"average_f1_macro\": average_f1_macro,\n",
    "        \"average_auc_macro\": average_auc_macro,\n",
    "        \"average_precision_weighted\": average_precision_weighted,\n",
    "        \"average_recall_weighted\": average_recall_weighted,\n",
    "        \"average_f1_weighted\": average_f1_weighted,\n",
    "        \"average_auc_weighted\": average_auc_weighted,\n",
    "        \"average_metrics_df\": metrics_df,\n",
    "        \"average_confusion_matrix\": confusion_df,\n",
    "        \"average_train_times\": average_train_time,\n",
    "        \"average_test_times\": average_test_time,\n",
    "    })\n",
    "    overall_results_5folds.append(week_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b301c18",
   "metadata": {
    "papermill": {
     "duration": 1.514205,
     "end_time": "2025-04-04T19:34:43.933447",
     "exception": false,
     "start_time": "2025-04-04T19:34:42.419242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kết quả cross validation trên 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea76232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:34:46.975239Z",
     "iopub.status.busy": "2025-04-04T19:34:46.974938Z",
     "iopub.status.idle": "2025-04-04T19:34:47.002075Z",
     "shell.execute_reply": "2025-04-04T19:34:47.001092Z"
    },
    "papermill": {
     "duration": 1.511036,
     "end_time": "2025-04-04T19:34:47.003222",
     "exception": false,
     "start_time": "2025-04-04T19:34:45.492186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for week1 ===\n",
      "Average Accurancy: 0.9578279972076416\n",
      "Average Train Time: 85.0733 seconds\n",
      "Average Test Time: 0.4292 seconds\n",
      "Average AUC Macro: 0.9947132314240156\n",
      "Average AUC Weighted: 0.9972342206040304\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.590909        0.545667          0.558659     0.786498\n",
      "1      1           0.000000        0.000000          0.000000     0.740704\n",
      "2      2           0.439852        0.194375          0.267966     0.841316\n",
      "3      3           0.295846        0.180838          0.196671     0.851328\n",
      "4      4           0.758197        0.913935          0.827893     0.846035\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2     3       4\n",
      "0  327.4  0.0   4.8  16.6   251.2\n",
      "1   42.6  0.0   0.4   2.4    42.0\n",
      "2   40.2  0.0  32.0   5.4    86.8\n",
      "3   39.4  0.0   1.6  30.2    96.0\n",
      "4  115.2  0.0   5.4  17.4  1465.6\n",
      "\n",
      "=== Results for week2 ===\n",
      "Average Accurancy: 0.9578279972076416\n",
      "Average Train Time: 85.5173 seconds\n",
      "Average Test Time: 0.4217 seconds\n",
      "Average AUC Macro: 0.9947132314240156\n",
      "Average AUC Weighted: 0.9972342206040304\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.865478        0.879333          0.869421     0.977618\n",
      "1      1           0.610414        0.374843          0.463706     0.930450\n",
      "2      2           0.827147        0.534087          0.647312     0.935276\n",
      "3      3           0.739359        0.706900          0.719498     0.952928\n",
      "4      4           0.916874        0.962958          0.938888     0.981789\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2      3       4\n",
      "0  527.6   4.8   6.2    8.2    53.2\n",
      "1    9.8  32.8   4.4   11.8    28.6\n",
      "2   12.8   7.4  87.8   17.4    39.0\n",
      "3   19.4   5.4   3.0  118.2    21.2\n",
      "4   44.2   3.2   5.2    6.8  1544.2\n",
      "\n",
      "=== Results for week3 ===\n",
      "Average Accurancy: 0.9578279972076416\n",
      "Average Train Time: 86.3002 seconds\n",
      "Average Test Time: 0.4275 seconds\n",
      "Average AUC Macro: 0.9947132314240156\n",
      "Average AUC Weighted: 0.9972342206040304\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.925726        0.911000          0.917706     0.991024\n",
      "1      1           0.742984        0.599295          0.660525     0.949174\n",
      "2      2           0.796770        0.632565          0.700469     0.960344\n",
      "3      3           0.797918        0.746407          0.770165     0.976596\n",
      "4      4           0.936462        0.976055          0.955705     0.990731\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  546.6   2.0   10.4    5.0    36.0\n",
      "1    4.6  52.4    2.6    5.2    22.6\n",
      "2   12.8   2.8  104.0   15.8    29.0\n",
      "3    6.2   6.2   10.6  124.8    19.4\n",
      "4   20.8   7.4    4.4    5.8  1565.2\n",
      "\n",
      "=== Results for week4 ===\n",
      "Average Accurancy: 0.9578279972076416\n",
      "Average Train Time: 85.6728 seconds\n",
      "Average Test Time: 0.4243 seconds\n",
      "Average AUC Macro: 0.9947132314240156\n",
      "Average AUC Weighted: 0.9972342206040304\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.999003        0.999000          0.999000     1.000000\n",
      "1      1           0.982862        0.810240          0.881454     0.999297\n",
      "2      2           0.840862        0.666726          0.741776     0.982156\n",
      "3      3           0.850506        0.863723          0.851942     0.994161\n",
      "4      4           0.964274        0.990148          0.976919     0.997953\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  599.4   0.2    0.0    0.4     0.0\n",
      "1    0.0  70.8    8.2    4.0     4.4\n",
      "2    0.4   0.6  109.6   14.6    39.2\n",
      "3    0.0   0.0    7.0  144.4    15.8\n",
      "4    0.2   0.6    6.0    9.0  1587.8\n"
     ]
    }
   ],
   "source": [
    "# Duyệt qua các tuần trong overall_results\n",
    "for week_result in overall_results_5folds:\n",
    "    week = week_result[\"week\"]\n",
    "    average_train_time = np.mean(week_result[\"train_times\"])\n",
    "    average_test_time = np.mean(week_result[\"test_times\"])\n",
    "    average_metrics_df = week_result[\"average_metrics_df\"]\n",
    "    average_accuracy = np.mean(week_results[\"accuracy_per_fold\"])\n",
    "    average_confusion_matrix = week_result[\"average_confusion_matrix\"]\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n=== Results for {week} ===\")\n",
    "    print(f\"Average Accurancy: {average_accuracy}\")\n",
    "    print(f\"Average Train Time: {average_train_time:.4f} seconds\")\n",
    "    print(f\"Average Test Time: {average_test_time:.4f} seconds\")\n",
    "    print(f\"Average AUC Macro: {average_auc_macro}\")\n",
    "    print(f\"Average AUC Weighted: {average_auc_weighted}\")\n",
    "    print(\"\\nAverage Precision, Recall, F1-Score, AUC-ROC per Label:\")\n",
    "    print(average_metrics_df)\n",
    "    print(\"\\nAverage Confusion Matrix:\")\n",
    "    print(average_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65510a16",
   "metadata": {
    "papermill": {
     "duration": 1.430252,
     "end_time": "2025-04-04T19:34:50.011185",
     "exception": false,
     "start_time": "2025-04-04T19:34:48.580933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kiểm tra trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e059f2c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:34:52.991307Z",
     "iopub.status.busy": "2025-04-04T19:34:52.990980Z",
     "iopub.status.idle": "2025-04-04T19:34:53.004546Z",
     "shell.execute_reply": "2025-04-04T19:34:53.003674Z"
    },
    "papermill": {
     "duration": 1.436821,
     "end_time": "2025-04-04T19:34:53.005900",
     "exception": false,
     "start_time": "2025-04-04T19:34:51.569079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mảng lưu dữ liệu của các tuần\n",
    "results = []\n",
    "\n",
    "def process_week(week_num, best_params, results):\n",
    "    print(f\"\\n=== Processing Week {week_num} ===\")\n",
    "    params = best_params[f\"week{week_num}\"].values\n",
    "    # Đường dẫn tới dữ liệu tuần tương ứng\n",
    "    train_path = f\"{BASE_PATH}/clean_week{week_num}/train/clean_data_week{week_num}.csv\"\n",
    "    test_path = f\"{BASE_PATH}/clean_week{week_num}/test/test_week{week_num}.csv\"\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                       \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data['classification_encoded']\n",
    "    \n",
    "    X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                     \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_test = test_data['classification_encoded']\n",
    "\n",
    "    # Áp dụng SMOTE cho tập huấn luyện\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Chuyển đổi nhãn sang dạng one-hot\n",
    "    y_train_resampled = to_categorical(y_train_resampled, num_classes=5)\n",
    "    y_test = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "    # Reshape dữ liệu cho LSTM\n",
    "    X_train_resampled = X_train_resampled.to_numpy().reshape((X_train_resampled.shape[0], 1, X_train_resampled.shape[1]))\n",
    "    X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Xây dựng mô hình với tham số tốt nhất\n",
    "    input_shape = (X_train_resampled.shape[1], X_train_resampled.shape[2])\n",
    "    model = build_GRU_model(params, input_shape)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled, epochs=50, validation_split=0.1, batch_size=32)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Kiểm thử mô hình\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    # Tính thời gian huấn luyện và kiểm thử\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_test_classes = y_test.argmax(axis=1)\n",
    "    \n",
    "    # Tính các chỉ số Precision, Recall, F1 cho từng lớp và macro\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    # Tính AUC-ROC (với one-vs-rest)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "        auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "        # Tính AUC weighted tự tính theo trọng số mẫu của từng lớp\n",
    "        supports = np.bincount(y_test_classes, minlength=5)\n",
    "        auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tính AUC: {e}\")\n",
    "        auc_macro = np.nan\n",
    "        auc_per_class = [np.nan] * 5\n",
    "        auc_weighted = np.nan\n",
    "\n",
    "    # Lưu kết quả vào mảng\n",
    "    results.append({\n",
    "        \"week\": week_num,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_weighted\": precision_weighted,\n",
    "        \"recall_weighted\": recall_weighted,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"auc_weighted\": auc_weighted,\n",
    "        \"auc_per_class\": auc_per_class,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    })\n",
    "    \n",
    "    # In kết quả chi tiết\n",
    "    print(\"\\n=== Precision, Recall, F1-Score per Label ===\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Label\": np.unique(y_test_classes),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }))\n",
    "\n",
    "    print(\"\\n=== Macro Averages & Accuracy ===\")\n",
    "    print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Weighted Averages ===\")\n",
    "    print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")\n",
    "    \n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(pd.DataFrame(conf_matrix, index=np.unique(y_test_classes), columns=np.unique(y_test_classes)))\n",
    "    \n",
    "    print(f\"\\nTrain Time: {train_time:.2f} seconds\")\n",
    "    print(f\"Test Time: {test_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84dc661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:34:56.104580Z",
     "iopub.status.busy": "2025-04-04T19:34:56.104211Z",
     "iopub.status.idle": "2025-04-04T19:39:27.553878Z",
     "shell.execute_reply": "2025-04-04T19:39:27.553101Z"
    },
    "papermill": {
     "duration": 273.058805,
     "end_time": "2025-04-04T19:39:27.555105",
     "exception": false,
     "start_time": "2025-04-04T19:34:54.496300",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4248 - loss: 0.2132 - val_accuracy: 0.4320 - val_loss: 0.2762\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4780 - loss: 0.1944 - val_accuracy: 0.6702 - val_loss: 0.1801\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4873 - loss: 0.1922 - val_accuracy: 0.5538 - val_loss: 0.2631\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4977 - loss: 0.1875 - val_accuracy: 0.4585 - val_loss: 0.3206\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4749 - loss: 0.1923 - val_accuracy: 0.4515 - val_loss: 0.2700\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4867 - loss: 0.1876 - val_accuracy: 0.6223 - val_loss: 0.2116\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4894 - loss: 0.1859 - val_accuracy: 0.4590 - val_loss: 0.2723\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4956 - loss: 0.1819 - val_accuracy: 0.6411 - val_loss: 0.1929\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4990 - loss: 0.1772 - val_accuracy: 0.6228 - val_loss: 0.2211\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4891 - loss: 0.1820 - val_accuracy: 0.5859 - val_loss: 0.1779\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4956 - loss: 0.1800 - val_accuracy: 0.3228 - val_loss: 0.3164\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4989 - loss: 0.1793 - val_accuracy: 0.4143 - val_loss: 0.2568\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4938 - loss: 0.1820 - val_accuracy: 0.4587 - val_loss: 0.2629\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5069 - loss: 0.1772 - val_accuracy: 0.4847 - val_loss: 0.2270\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4892 - loss: 0.1823 - val_accuracy: 0.3781 - val_loss: 0.3014\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5025 - loss: 0.1793 - val_accuracy: 0.4467 - val_loss: 0.2672\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5017 - loss: 0.1794 - val_accuracy: 0.3687 - val_loss: 0.2639\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5108 - loss: 0.1740 - val_accuracy: 0.4408 - val_loss: 0.2321\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5012 - loss: 0.1746 - val_accuracy: 0.4692 - val_loss: 0.2656\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5062 - loss: 0.1751 - val_accuracy: 0.4028 - val_loss: 0.2648\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5184 - loss: 0.1746 - val_accuracy: 0.4470 - val_loss: 0.3156\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5184 - loss: 0.1719 - val_accuracy: 0.4572 - val_loss: 0.2138\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5135 - loss: 0.1743 - val_accuracy: 0.4323 - val_loss: 0.3072\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5250 - loss: 0.1729 - val_accuracy: 0.4495 - val_loss: 0.2355\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5171 - loss: 0.1769 - val_accuracy: 0.3986 - val_loss: 0.2315\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5147 - loss: 0.1743 - val_accuracy: 0.4467 - val_loss: 0.2133\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5127 - loss: 0.1742 - val_accuracy: 0.3936 - val_loss: 0.2419\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5112 - loss: 0.1743 - val_accuracy: 0.4492 - val_loss: 0.2856\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5065 - loss: 0.1731 - val_accuracy: 0.4295 - val_loss: 0.2925\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5135 - loss: 0.1699 - val_accuracy: 0.0135 - val_loss: 0.3064\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5158 - loss: 0.1736 - val_accuracy: 0.5375 - val_loss: 0.2335\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5278 - loss: 0.1664 - val_accuracy: 0.5842 - val_loss: 0.1898\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5231 - loss: 0.1674 - val_accuracy: 0.5126 - val_loss: 0.2339\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5217 - loss: 0.1688 - val_accuracy: 0.5737 - val_loss: 0.2075\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 0.1647 - val_accuracy: 0.5914 - val_loss: 0.2029\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5283 - loss: 0.1650 - val_accuracy: 0.7099 - val_loss: 0.1937\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5148 - loss: 0.1682 - val_accuracy: 0.6179 - val_loss: 0.2152\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5225 - loss: 0.1682 - val_accuracy: 0.4615 - val_loss: 0.2486\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 0.1665 - val_accuracy: 0.7615 - val_loss: 0.1903\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5257 - loss: 0.1668 - val_accuracy: 0.6987 - val_loss: 0.1919\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 0.1660 - val_accuracy: 0.6303 - val_loss: 0.1965\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5290 - loss: 0.1668 - val_accuracy: 0.3213 - val_loss: 0.2595\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5430 - loss: 0.1642 - val_accuracy: 0.6927 - val_loss: 0.2265\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5432 - loss: 0.1619 - val_accuracy: 0.6944 - val_loss: 0.1917\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5227 - loss: 0.1695 - val_accuracy: 0.6134 - val_loss: 0.2282\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5431 - loss: 0.1660 - val_accuracy: 0.6281 - val_loss: 0.2226\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5228 - loss: 0.1684 - val_accuracy: 0.6286 - val_loss: 0.2126\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5158 - loss: 0.1675 - val_accuracy: 0.7249 - val_loss: 0.1836\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5394 - loss: 0.1649 - val_accuracy: 0.4430 - val_loss: 0.2413\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5048 - loss: 0.1734 - val_accuracy: 0.5453 - val_loss: 0.2074\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.817391  0.250667  0.383673\n",
      "1      1   0.063415  0.236364  0.100000\n",
      "2      2   0.371951  0.592233  0.456929\n",
      "3      3   0.523256  0.432692  0.473684\n",
      "4      4   0.754911  0.805389  0.779334\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.5062\n",
      "Macro Recall: 0.4635\n",
      "Macro F1-Score: 0.4387\n",
      "Accuracy: 0.6223\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.7072\n",
      "Weighted Recall: 0.6223\n",
      "Weighted F1-Score: 0.6264\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8310\n",
      "AUC Weighted: 0.8314\n",
      "AUC per Label: [0.80208228 0.76181703 0.86259228 0.89191932 0.83668926]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "    0    1   2   3    4\n",
      "0  94   43  32  16  190\n",
      "1   9   13   7   0   26\n",
      "2   6    8  61   8   20\n",
      "3   1    9  23  45   26\n",
      "4   5  132  41  17  807\n",
      "\n",
      "Train Time: 270.85 seconds\n",
      "Test Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(1, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd16d2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:39:31.094234Z",
     "iopub.status.busy": "2025-04-04T19:39:31.093933Z",
     "iopub.status.idle": "2025-04-04T19:44:03.978317Z",
     "shell.execute_reply": "2025-04-04T19:44:03.977362Z"
    },
    "papermill": {
     "duration": 274.731304,
     "end_time": "2025-04-04T19:44:03.979615",
     "exception": false,
     "start_time": "2025-04-04T19:39:29.248311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4536 - loss: 0.2030 - val_accuracy: 0.4470 - val_loss: 0.2737\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5315 - loss: 0.1750 - val_accuracy: 0.6034 - val_loss: 0.2540\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5686 - loss: 0.1609 - val_accuracy: 0.7136 - val_loss: 0.1764\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6040 - loss: 0.1490 - val_accuracy: 0.7019 - val_loss: 0.2054\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6401 - loss: 0.1357 - val_accuracy: 0.7156 - val_loss: 0.1882\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.1294 - val_accuracy: 0.6954 - val_loss: 0.1772\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6861 - loss: 0.1210 - val_accuracy: 0.7256 - val_loss: 0.1545\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6967 - loss: 0.1151 - val_accuracy: 0.6498 - val_loss: 0.1747\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7131 - loss: 0.1097 - val_accuracy: 0.6977 - val_loss: 0.1478\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.1052 - val_accuracy: 0.7144 - val_loss: 0.1192\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7316 - loss: 0.1009 - val_accuracy: 0.6949 - val_loss: 0.1227\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7469 - loss: 0.0955 - val_accuracy: 0.7713 - val_loss: 0.1068\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7457 - loss: 0.0951 - val_accuracy: 0.7032 - val_loss: 0.1071\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7640 - loss: 0.0898 - val_accuracy: 0.7695 - val_loss: 0.1015\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7601 - loss: 0.0902 - val_accuracy: 0.7578 - val_loss: 0.0921\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7776 - loss: 0.0849 - val_accuracy: 0.7620 - val_loss: 0.0990\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.0806 - val_accuracy: 0.7765 - val_loss: 0.0864\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.0804 - val_accuracy: 0.7358 - val_loss: 0.1223\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.0767 - val_accuracy: 0.7084 - val_loss: 0.0945\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.0815 - val_accuracy: 0.7678 - val_loss: 0.0818\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.0761 - val_accuracy: 0.7007 - val_loss: 0.0950\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.0724 - val_accuracy: 0.7822 - val_loss: 0.0826\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.0699 - val_accuracy: 0.7169 - val_loss: 0.0967\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.0732 - val_accuracy: 0.8177 - val_loss: 0.0641\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.0705 - val_accuracy: 0.7917 - val_loss: 0.0772\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.0667 - val_accuracy: 0.7760 - val_loss: 0.0834\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.0675 - val_accuracy: 0.6777 - val_loss: 0.1019\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.0674 - val_accuracy: 0.8586 - val_loss: 0.0572\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.0650 - val_accuracy: 0.7765 - val_loss: 0.0745\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8304 - loss: 0.0639 - val_accuracy: 0.8466 - val_loss: 0.0628\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8384 - loss: 0.0619 - val_accuracy: 0.8199 - val_loss: 0.0668\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.0637 - val_accuracy: 0.8224 - val_loss: 0.0645\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.0591 - val_accuracy: 0.8114 - val_loss: 0.0663\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.0635 - val_accuracy: 0.8481 - val_loss: 0.0647\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.0579 - val_accuracy: 0.8052 - val_loss: 0.0661\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.0583 - val_accuracy: 0.8177 - val_loss: 0.0702\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.0587 - val_accuracy: 0.8651 - val_loss: 0.0466\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.0569 - val_accuracy: 0.8359 - val_loss: 0.0568\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.0591 - val_accuracy: 0.8810 - val_loss: 0.0527\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.0556 - val_accuracy: 0.8189 - val_loss: 0.0600\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.0563 - val_accuracy: 0.8748 - val_loss: 0.0542\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.0568 - val_accuracy: 0.8202 - val_loss: 0.0569\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.0557 - val_accuracy: 0.8970 - val_loss: 0.0428\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.0561 - val_accuracy: 0.8850 - val_loss: 0.0443\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.0560 - val_accuracy: 0.7967 - val_loss: 0.0621\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 0.0539 - val_accuracy: 0.8453 - val_loss: 0.0487\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.0522 - val_accuracy: 0.8855 - val_loss: 0.0508\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.0522 - val_accuracy: 0.8803 - val_loss: 0.0594\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8617 - loss: 0.0534 - val_accuracy: 0.8251 - val_loss: 0.0563\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.0526 - val_accuracy: 0.9095 - val_loss: 0.0461\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.564202  0.386667  0.458861\n",
      "1      1   0.568182  0.909091  0.699301\n",
      "2      2   0.272300  0.563107  0.367089\n",
      "3      3   0.331081  0.471154  0.388889\n",
      "4      4   0.788853  0.734531  0.760724\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.5049\n",
      "Macro Recall: 0.6129\n",
      "Macro F1-Score: 0.5350\n",
      "Accuracy: 0.6333\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.6685\n",
      "Weighted Recall: 0.6333\n",
      "Weighted F1-Score: 0.6413\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8687\n",
      "AUC Weighted: 0.8436\n",
      "AUC per Label: [0.83338819 0.97217631 0.8460002  0.85259334 0.83916625]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  145  14  70  18  128\n",
      "1    1  50   2   0    2\n",
      "2   10   4  58   6   25\n",
      "3    4   2   7  49   42\n",
      "4   97  18  76  75  736\n",
      "\n",
      "Train Time: 272.26 seconds\n",
      "Test Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(2, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f256a82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:44:08.040573Z",
     "iopub.status.busy": "2025-04-04T19:44:08.040211Z",
     "iopub.status.idle": "2025-04-04T19:48:40.086420Z",
     "shell.execute_reply": "2025-04-04T19:48:40.085388Z"
    },
    "papermill": {
     "duration": 274.099509,
     "end_time": "2025-04-04T19:48:40.087939",
     "exception": false,
     "start_time": "2025-04-04T19:44:05.988430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4835 - loss: 0.1954 - val_accuracy: 0.5455 - val_loss: 0.2555\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6267 - loss: 0.1382 - val_accuracy: 0.6346 - val_loss: 0.1979\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6962 - loss: 0.1139 - val_accuracy: 0.6658 - val_loss: 0.1584\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.0940 - val_accuracy: 0.6059 - val_loss: 0.1412\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7721 - loss: 0.0834 - val_accuracy: 0.7346 - val_loss: 0.1122\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.0738 - val_accuracy: 0.7004 - val_loss: 0.0908\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.0702 - val_accuracy: 0.7892 - val_loss: 0.0571\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.0622 - val_accuracy: 0.7506 - val_loss: 0.1032\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.0558 - val_accuracy: 0.7900 - val_loss: 0.0786\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8532 - loss: 0.0521 - val_accuracy: 0.7797 - val_loss: 0.0603\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 0.0505 - val_accuracy: 0.8246 - val_loss: 0.0423\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.0450 - val_accuracy: 0.8087 - val_loss: 0.0624\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.0442 - val_accuracy: 0.7845 - val_loss: 0.0665\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.0408 - val_accuracy: 0.8688 - val_loss: 0.0372\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.0417 - val_accuracy: 0.9129 - val_loss: 0.0256\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.0393 - val_accuracy: 0.7960 - val_loss: 0.0719\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.0375 - val_accuracy: 0.8566 - val_loss: 0.0471\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.0358 - val_accuracy: 0.8174 - val_loss: 0.0674\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.0346 - val_accuracy: 0.9439 - val_loss: 0.0157\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.0353 - val_accuracy: 0.8356 - val_loss: 0.0471\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8947 - loss: 0.0343 - val_accuracy: 0.9119 - val_loss: 0.0263\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8971 - loss: 0.0332 - val_accuracy: 0.8441 - val_loss: 0.0413\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9006 - loss: 0.0328 - val_accuracy: 0.8675 - val_loss: 0.0378\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.0316 - val_accuracy: 0.8601 - val_loss: 0.0366\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.0318 - val_accuracy: 0.7795 - val_loss: 0.0632\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9054 - loss: 0.0316 - val_accuracy: 0.9172 - val_loss: 0.0254\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.0284 - val_accuracy: 0.8561 - val_loss: 0.0434\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9044 - loss: 0.0308 - val_accuracy: 0.8770 - val_loss: 0.0298\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.0291 - val_accuracy: 0.9576 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9127 - loss: 0.0277 - val_accuracy: 0.8488 - val_loss: 0.0435\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.0313 - val_accuracy: 0.9636 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.0290 - val_accuracy: 0.8708 - val_loss: 0.0347\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.0288 - val_accuracy: 0.8179 - val_loss: 0.0673\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9175 - loss: 0.0263 - val_accuracy: 0.8022 - val_loss: 0.0588\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.0275 - val_accuracy: 0.8720 - val_loss: 0.0441\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.0267 - val_accuracy: 0.9549 - val_loss: 0.0166\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.0255 - val_accuracy: 0.9022 - val_loss: 0.0317\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9124 - loss: 0.0282 - val_accuracy: 0.7990 - val_loss: 0.0593\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9171 - loss: 0.0267 - val_accuracy: 0.9581 - val_loss: 0.0161\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.0251 - val_accuracy: 0.9514 - val_loss: 0.0173\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.0249 - val_accuracy: 0.9429 - val_loss: 0.0216\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9210 - loss: 0.0258 - val_accuracy: 0.8758 - val_loss: 0.0413\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.0267 - val_accuracy: 0.8067 - val_loss: 0.0947\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.0224 - val_accuracy: 0.9431 - val_loss: 0.0212\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.0233 - val_accuracy: 0.9703 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.0263 - val_accuracy: 0.9097 - val_loss: 0.0296\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.0244 - val_accuracy: 0.8952 - val_loss: 0.0311\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.0225 - val_accuracy: 0.9000 - val_loss: 0.0292\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.0227 - val_accuracy: 0.9304 - val_loss: 0.0259\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9213 - loss: 0.0252 - val_accuracy: 0.8900 - val_loss: 0.0239\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.851282  0.442667  0.582456\n",
      "1      1   0.556818  0.890909  0.685315\n",
      "2      2   0.136106  0.699029  0.227848\n",
      "3      3   0.471014  0.625000  0.537190\n",
      "4      4   0.915820  0.629741  0.746304\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.5862\n",
      "Macro Recall: 0.6575\n",
      "Macro F1-Score: 0.5558\n",
      "Accuracy: 0.5998\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8118\n",
      "Weighted Recall: 0.5998\n",
      "Weighted F1-Score: 0.6609\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8973\n",
      "AUC Weighted: 0.8872\n",
      "AUC per Label: [0.90985443 0.97001837 0.81661484 0.91091205 0.87893131]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1    2   3    4\n",
      "0  166   5  167   5   32\n",
      "1    1  49    4   1    0\n",
      "2    9   4   72   7   11\n",
      "3    2   3   19  65   15\n",
      "4   17  27  267  60  631\n",
      "\n",
      "Train Time: 271.34 seconds\n",
      "Test Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(3, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4648e0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:48:44.647633Z",
     "iopub.status.busy": "2025-04-04T19:48:44.647273Z",
     "iopub.status.idle": "2025-04-04T19:53:28.123121Z",
     "shell.execute_reply": "2025-04-04T19:53:28.122453Z"
    },
    "papermill": {
     "duration": 285.742531,
     "end_time": "2025-04-04T19:53:28.124502",
     "exception": false,
     "start_time": "2025-04-04T19:48:42.381971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4985 - loss: 0.1890 - val_accuracy: 0.6969 - val_loss: 0.1393\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.0762 - val_accuracy: 0.6194 - val_loss: 0.1129\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.0464 - val_accuracy: 0.7553 - val_loss: 0.0486\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.0340 - val_accuracy: 0.8259 - val_loss: 0.0473\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.0299 - val_accuracy: 0.8401 - val_loss: 0.0319\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.0237 - val_accuracy: 0.8675 - val_loss: 0.0296\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.0233 - val_accuracy: 0.8755 - val_loss: 0.0277\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9240 - loss: 0.0208 - val_accuracy: 0.8758 - val_loss: 0.0363\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.0224 - val_accuracy: 0.9723 - val_loss: 0.0107\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.0193 - val_accuracy: 0.9182 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.0192 - val_accuracy: 0.9404 - val_loss: 0.0212\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.0208 - val_accuracy: 0.9414 - val_loss: 0.0215\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.0178 - val_accuracy: 0.9686 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.0158 - val_accuracy: 0.9676 - val_loss: 0.0102\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.0166 - val_accuracy: 0.5732 - val_loss: 0.1265\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.0187 - val_accuracy: 0.9309 - val_loss: 0.0211\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.0152 - val_accuracy: 0.9661 - val_loss: 0.0137\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.0151 - val_accuracy: 0.9419 - val_loss: 0.0182\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.0134 - val_accuracy: 0.9753 - val_loss: 0.0086\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.0136 - val_accuracy: 0.8336 - val_loss: 0.0508\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.0174 - val_accuracy: 0.9558 - val_loss: 0.0136\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.0130 - val_accuracy: 0.9341 - val_loss: 0.0254\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.0142 - val_accuracy: 0.9169 - val_loss: 0.0242\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.0147 - val_accuracy: 0.9573 - val_loss: 0.0148\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9506 - loss: 0.0132 - val_accuracy: 0.9853 - val_loss: 0.0056\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.0135 - val_accuracy: 0.9713 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9543 - loss: 0.0114 - val_accuracy: 0.9668 - val_loss: 0.0088\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.0120 - val_accuracy: 0.9910 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.0113 - val_accuracy: 0.8878 - val_loss: 0.0252\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9552 - loss: 0.0118 - val_accuracy: 0.9658 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.0128 - val_accuracy: 0.9541 - val_loss: 0.0166\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.0114 - val_accuracy: 0.8296 - val_loss: 0.0434\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.0132 - val_accuracy: 0.9002 - val_loss: 0.0344\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9598 - loss: 0.0109 - val_accuracy: 0.9416 - val_loss: 0.0151\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9561 - loss: 0.0116 - val_accuracy: 0.9658 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9585 - loss: 0.0106 - val_accuracy: 0.9930 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9612 - loss: 0.0107 - val_accuracy: 0.9242 - val_loss: 0.0264\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.0118 - val_accuracy: 0.9626 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9602 - loss: 0.0105 - val_accuracy: 0.9713 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9601 - loss: 0.0104 - val_accuracy: 0.9900 - val_loss: 0.0038\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 0.0135 - val_accuracy: 0.9840 - val_loss: 0.0060\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9602 - loss: 0.0108 - val_accuracy: 0.9626 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9595 - loss: 0.0104 - val_accuracy: 0.9668 - val_loss: 0.0091\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9601 - loss: 0.0103 - val_accuracy: 0.9501 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9621 - loss: 0.0107 - val_accuracy: 0.9738 - val_loss: 0.0082\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9621 - loss: 0.0100 - val_accuracy: 0.9534 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9654 - loss: 0.0091 - val_accuracy: 0.9928 - val_loss: 0.0032\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.0112 - val_accuracy: 0.8583 - val_loss: 0.0526\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.0123 - val_accuracy: 0.9651 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9627 - loss: 0.0098 - val_accuracy: 0.9746 - val_loss: 0.0075\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   1.000000  0.986667  0.993289\n",
      "1      1   0.909091  0.909091  0.909091\n",
      "2      2   0.330396  0.728155  0.454545\n",
      "3      3   0.585586  0.625000  0.604651\n",
      "4      4   0.945205  0.826347  0.881789\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.7541\n",
      "Macro Recall: 0.8151\n",
      "Macro F1-Score: 0.7687\n",
      "Accuracy: 0.8469\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8951\n",
      "Weighted Recall: 0.8469\n",
      "Weighted F1-Score: 0.8638\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9566\n",
      "AUC Weighted: 0.9676\n",
      "AUC per Label: [0.99931435 0.98667355 0.90880992 0.92269481 0.96544744]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1    2   3    4\n",
      "0  370   0    0   1    4\n",
      "1    0  50    4   1    0\n",
      "2    0   2   75   7   19\n",
      "3    0   2   12  65   25\n",
      "4    0   1  136  37  828\n",
      "\n",
      "Train Time: 282.78 seconds\n",
      "Test Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(4, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b80d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:53:33.275110Z",
     "iopub.status.busy": "2025-04-04T19:53:33.274771Z",
     "iopub.status.idle": "2025-04-04T19:53:33.290233Z",
     "shell.execute_reply": "2025-04-04T19:53:33.289270Z"
    },
    "papermill": {
     "duration": 2.567347,
     "end_time": "2025-04-04T19:53:33.291512",
     "exception": false,
     "start_time": "2025-04-04T19:53:30.724165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Results for All Weeks ===\n",
      "Week 1:\n",
      "  Train Time: 270.85 seconds\n",
      "  Test Time: 0.38 seconds\n",
      "  Accurancy: 0.6223306894447834\n",
      "  Precision: [0.8173913  0.06341463 0.37195122 0.52325581 0.75491113]\n",
      "  Recall: [0.25066667 0.23636364 0.59223301 0.43269231 0.80538922]\n",
      "  F1-Score: [0.38367347 0.1        0.45692884 0.47368421 0.77933366]\n",
      "  Macro Precision: 0.5061848207717643\n",
      "  Macro Recall: 0.463468968397647\n",
      "  Macro F1-Score: 0.43872403482087935\n",
      "  Confusion Matrix:\n",
      "[[ 94  43  32  16 190]\n",
      " [  9  13   7   0  26]\n",
      " [  6   8  61   8  20]\n",
      " [  1   9  23  45  26]\n",
      " [  5 132  41  17 807]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9957\n",
      "AUC Weighted: 0.9974\n",
      "AUC per Label: [1.         0.99972196 0.98574342 0.99525592 0.99768956]\n",
      "Week 2:\n",
      "  Train Time: 272.26 seconds\n",
      "  Test Time: 0.38 seconds\n",
      "  Accurancy: 0.6333129957291032\n",
      "  Precision: [0.56420233 0.56818182 0.27230047 0.33108108 0.78885316]\n",
      "  Recall: [0.38666667 0.90909091 0.5631068  0.47115385 0.73453094]\n",
      "  F1-Score: [0.45886076 0.6993007  0.36708861 0.38888889 0.76072351]\n",
      "  Macro Precision: 0.5049237730440665\n",
      "  Macro Recall: 0.6129098312303358\n",
      "  Macro F1-Score: 0.5349724938980165\n",
      "  Confusion Matrix:\n",
      "[[145  14  70  18 128]\n",
      " [  1  50   2   0   2]\n",
      " [ 10   4  58   6  25]\n",
      " [  4   2   7  49  42]\n",
      " [ 97  18  76  75 736]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9957\n",
      "AUC Weighted: 0.9974\n",
      "AUC per Label: [1.         0.99972196 0.98574342 0.99525592 0.99768956]\n",
      "Week 3:\n",
      "  Train Time: 271.34 seconds\n",
      "  Test Time: 0.38 seconds\n",
      "  Accurancy: 0.5997559487492373\n",
      "  Precision: [0.85128205 0.55681818 0.13610586 0.47101449 0.91582003]\n",
      "  Recall: [0.44266667 0.89090909 0.69902913 0.625      0.62974052]\n",
      "  F1-Score: [0.58245614 0.68531469 0.2278481  0.53719008 0.74630396]\n",
      "  Macro Precision: 0.5862081229989707\n",
      "  Macro Recall: 0.6574690805502852\n",
      "  Macro F1-Score: 0.5558225943457171\n",
      "  Confusion Matrix:\n",
      "[[166   5 167   5  32]\n",
      " [  1  49   4   1   0]\n",
      " [  9   4  72   7  11]\n",
      " [  2   3  19  65  15]\n",
      " [ 17  27 267  60 631]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9957\n",
      "AUC Weighted: 0.9974\n",
      "AUC per Label: [1.         0.99972196 0.98574342 0.99525592 0.99768956]\n",
      "Week 4:\n",
      "  Train Time: 282.78 seconds\n",
      "  Test Time: 0.38 seconds\n",
      "  Accurancy: 0.8468578401464307\n",
      "  Precision: [1.         0.90909091 0.33039648 0.58558559 0.94520548]\n",
      "  Recall: [0.98666667 0.90909091 0.72815534 0.625      0.82634731]\n",
      "  F1-Score: [0.99328859 0.90909091 0.45454545 0.60465116 0.88178914]\n",
      "  Macro Precision: 0.7540556899798949\n",
      "  Macro Recall: 0.8150520441905245\n",
      "  Macro F1-Score: 0.768673050882256\n",
      "  Confusion Matrix:\n",
      "[[370   0   0   1   4]\n",
      " [  0  50   4   1   0]\n",
      " [  0   2  75   7  19]\n",
      " [  0   2  12  65  25]\n",
      " [  0   1 136  37 828]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9957\n",
      "AUC Weighted: 0.9974\n",
      "AUC per Label: [1.         0.99972196 0.98574342 0.99525592 0.99768956]\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu của các tuần\n",
    "print(\"\\n=== Summary Results for All Weeks ===\")\n",
    "for result in results:\n",
    "    print(f\"Week {result['week']}:\")\n",
    "    print(f\"  Train Time: {result['train_time']:.2f} seconds\")\n",
    "    print(f\"  Test Time: {result['test_time']:.2f} seconds\")\n",
    "    print(f\"  Accurancy: {result['accuracy']}\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1-Score: {result['f1_score']}\")\n",
    "    print(f\"  Macro Precision: {result['precision_macro']}\")\n",
    "    print(f\"  Macro Recall: {result['recall_macro']}\")\n",
    "    print(f\"  Macro F1-Score: {result['f1_macro']}\")\n",
    "    print(f\"  Confusion Matrix:\\n{result['confusion_matrix']}\")\n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6328310,
     "sourceId": 11252263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8567.368524,
   "end_time": "2025-04-04T19:53:39.146821",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-04T17:30:51.778297",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
