{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff63d9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:12.000295Z",
     "iopub.status.busy": "2025-04-05T09:14:12.000100Z",
     "iopub.status.idle": "2025-04-05T09:14:15.137433Z",
     "shell.execute_reply": "2025-04-05T09:14:15.136550Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 3.143652,
     "end_time": "2025-04-05T09:14:15.138614",
     "exception": false,
     "start_time": "2025-04-05T09:14:11.994962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clean_raw_data.csv\n",
      "/kaggle/input/clean_data_mean.csv\n",
      "/kaggle/input/raw_data.csv\n",
      "/kaggle/input/clean_data_GCN.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_data_minmax_fill-zero.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_data_minmax_GCN_version4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_data_Fill-1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_data_minmax_Fill-1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_data_minmax_GCN_version3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_data_minmax_KNN.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_5.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed14148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:15.149611Z",
     "iopub.status.busy": "2025-04-05T09:14:15.149270Z",
     "iopub.status.idle": "2025-04-05T09:14:36.174658Z",
     "shell.execute_reply": "2025-04-05T09:14:36.173781Z"
    },
    "papermill": {
     "duration": 21.03218,
     "end_time": "2025-04-05T09:14:36.176141",
     "exception": false,
     "start_time": "2025-04-05T09:14:15.143961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e0d12a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:36.187261Z",
     "iopub.status.busy": "2025-04-05T09:14:36.186813Z",
     "iopub.status.idle": "2025-04-05T09:14:36.191275Z",
     "shell.execute_reply": "2025-04-05T09:14:36.190659Z"
    },
    "papermill": {
     "duration": 0.011163,
     "end_time": "2025-04-05T09:14:36.192473",
     "exception": false,
     "start_time": "2025-04-05T09:14:36.181310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Biến global cho base path\n",
    "BASE_PATH = \"/kaggle/input/KNN_minmax_baseline\"\n",
    "# Tuần và số phần fold\n",
    "weeks = ['week1', 'week2', 'week3', 'week4']\n",
    "fold_parts = 5\n",
    "\n",
    "# Tạo five_fold_files\n",
    "five_fold_files = {\n",
    "    week: [\n",
    "        f\"{BASE_PATH}/clean_{week}/train/5-folds/data_part_{i}.csv\"\n",
    "        for i in range(1, fold_parts + 1)\n",
    "    ]\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Tạo file_validation\n",
    "file_validation = {\n",
    "    'week1': [f\"{BASE_PATH}/clean_week1/val/val_week1.csv\"],\n",
    "    'week2': [f\"{BASE_PATH}/clean_week2/val/val_week1_2.csv\"],\n",
    "    'week3': [f\"{BASE_PATH}/clean_week3/val/val_week1_2_3.csv\"],\n",
    "    'week4': [f\"{BASE_PATH}/clean_week4/val/val_week1_2_3_4.csv\"]\n",
    "}\n",
    "\n",
    "# Tạo file_test\n",
    "file_test = {\n",
    "    week: [f\"{BASE_PATH}/clean_{week}/test/test_{week}.csv\"]\n",
    "    for week in weeks\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692710c",
   "metadata": {
    "papermill": {
     "duration": 0.004493,
     "end_time": "2025-04-05T09:14:36.201859",
     "exception": false,
     "start_time": "2025-04-05T09:14:36.197366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tìm siêu tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e9b6b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:36.212048Z",
     "iopub.status.busy": "2025-04-05T09:14:36.211803Z",
     "iopub.status.idle": "2025-04-05T09:14:36.221226Z",
     "shell.execute_reply": "2025-04-05T09:14:36.220453Z"
    },
    "papermill": {
     "duration": 0.015953,
     "end_time": "2025-04-05T09:14:36.222445",
     "exception": false,
     "start_time": "2025-04-05T09:14:36.206492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Tạo hàm train cho từng tuần\n",
    "def train_week_model(week_number, file_paths_train, file_validataion):\n",
    "    # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(file_paths_train)\n",
    "    val_data = pd.read_csv(file_validataion)\n",
    "    \n",
    "    # Tách đặc trưng và nhãn\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "    X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_val = val_data[\"classification_encoded\"]\n",
    "    \n",
    "    # Áp dụng Over-sampling cho dữ liệu huấn luyện bằng SMOTE\n",
    "    oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Reshape dữ liệu cho mô hình BiLSTM\n",
    "    X_train_res = X_train_res.values.reshape(X_train_res.shape[0], X_train_res.shape[1], 1)\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    \n",
    "    # One-hot encode nhãn\n",
    "    y_train_res = tf.keras.utils.to_categorical(y_train_res, num_classes=5)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "    \n",
    "    def build_model(hp):\n",
    "        inputs = tf.keras.Input(shape=(X_train_res.shape[1], 1))  # Khởi tạo đầu vào\n",
    "        \n",
    "        # Chỉ sử dụng một lớp Bidirectional LSTM\n",
    "        x = layers.Bidirectional(layers.LSTM(\n",
    "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=False  # Thay đổi thành False vì đây là lớp LSTM duy nhất\n",
    "        ))(inputs)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # Lớp đầu ra\n",
    "        outputs = layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        # Khởi tạo mô hình\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile với Focal Loss\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                          learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                      loss=focal_loss(gamma=2., alpha=0.25),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    # Khởi tạo RandomSearch tuner\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='my_dir',\n",
    "        project_name=f'bilstm_tuning_week{week_number}'\n",
    "    )\n",
    "    \n",
    "    # Tìm kiếm siêu tham số tốt nhất\n",
    "    tuner.search(X_train_res, y_train_res,\n",
    "                 epochs=20,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 batch_size=32)\n",
    "    \n",
    "    # Trả về kết quả tối ưu cho tuần\n",
    "    best_params = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67568d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:36.232404Z",
     "iopub.status.busy": "2025-04-05T09:14:36.232206Z",
     "iopub.status.idle": "2025-04-05T09:14:36.235470Z",
     "shell.execute_reply": "2025-04-05T09:14:36.234914Z"
    },
    "papermill": {
     "duration": 0.009702,
     "end_time": "2025-04-05T09:14:36.236777",
     "exception": false,
     "start_time": "2025-04-05T09:14:36.227075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa đường dẫn đến dữ liệu cho từng tuần\n",
    "file_paths_train = {\n",
    "    week: f\"{BASE_PATH}/clean_{week}/train/clean_data_{week}.csv\"\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Định nghĩa file_validation theo quy luật riêng\n",
    "file_validation = {\n",
    "    f\"week{idx + 1}\": f\"{BASE_PATH}/clean_week{idx + 1}/val/val_week{'_'.join(str(i) for i in range(1, idx + 2))}.csv\"\n",
    "    for idx in range(len(weeks))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d191aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:36.247265Z",
     "iopub.status.busy": "2025-04-05T09:14:36.247067Z",
     "iopub.status.idle": "2025-04-05T10:47:37.325058Z",
     "shell.execute_reply": "2025-04-05T10:47:37.324305Z"
    },
    "papermill": {
     "duration": 5581.084744,
     "end_time": "2025-04-05T10:47:37.326412",
     "exception": false,
     "start_time": "2025-04-05T09:14:36.241668",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 34s]\n",
      "val_accuracy: 0.8669920563697815\n",
      "\n",
      "Best val_accuracy So Far: 0.9280048608779907\n",
      "Total elapsed time: 00h 25m 10s\n",
      "Best Parameters for Week 1:\n",
      "units_1: 192\n",
      "dropout_1: 0.5\n",
      "learning_rate: 0.0020894688241366384\n",
      "\n",
      "Best Parameters for Week 2:\n",
      "units_1: 160\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.0013917854917016644\n",
      "\n",
      "Best Parameters for Week 3:\n",
      "units_1: 256\n",
      "dropout_1: 0.5\n",
      "learning_rate: 0.0009123863082217119\n",
      "\n",
      "Best Parameters for Week 4:\n",
      "units_1: 224\n",
      "dropout_1: 0.2\n",
      "learning_rate: 0.0005818542202431094\n"
     ]
    }
   ],
   "source": [
    "# Tìm tham số tốt nhất cho từng tuần\n",
    "best_params_week1 = train_week_model(1, file_paths_train[\"week1\"], file_validation[\"week1\"])\n",
    "best_params_week2 = train_week_model(2, file_paths_train[\"week2\"], file_validation[\"week2\"])\n",
    "best_params_week3 = train_week_model(3, file_paths_train[\"week3\"], file_validation[\"week3\"])\n",
    "best_params_week4 = train_week_model(4, file_paths_train[\"week4\"], file_validation[\"week4\"])\n",
    "\n",
    "# In thông tin chi tiết các tham số tối ưu\n",
    "print(\"Best Parameters for Week 1:\")\n",
    "for param_name in best_params_week1.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week1.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 2:\")\n",
    "for param_name in best_params_week2.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week2.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 3:\")\n",
    "for param_name in best_params_week3.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week3.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 4:\")\n",
    "for param_name in best_params_week4.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week4.get(param_name)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e463b",
   "metadata": {
    "papermill": {
     "duration": 0.004772,
     "end_time": "2025-04-05T10:47:37.336739",
     "exception": false,
     "start_time": "2025-04-05T10:47:37.331967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Danh sách tham số tốt nhất của từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a886911c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T10:47:37.347071Z",
     "iopub.status.busy": "2025-04-05T10:47:37.346827Z",
     "iopub.status.idle": "2025-04-05T10:47:37.350181Z",
     "shell.execute_reply": "2025-04-05T10:47:37.349523Z"
    },
    "papermill": {
     "duration": 0.009854,
     "end_time": "2025-04-05T10:47:37.351312",
     "exception": false,
     "start_time": "2025-04-05T10:47:37.341458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Danh sách tham số tốt nhất\n",
    "best_params = {\n",
    "    \"week1\": best_params_week1,\n",
    "    \"week2\": best_params_week2,\n",
    "    \"week3\": best_params_week3,\n",
    "    \"week4\": best_params_week4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c21d8c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T10:47:37.361888Z",
     "iopub.status.busy": "2025-04-05T10:47:37.361658Z",
     "iopub.status.idle": "2025-04-05T10:47:37.368167Z",
     "shell.execute_reply": "2025-04-05T10:47:37.367517Z"
    },
    "papermill": {
     "duration": 0.012965,
     "end_time": "2025-04-05T10:47:37.369336",
     "exception": false,
     "start_time": "2025-04-05T10:47:37.356371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "# # Xây dựng mô hình BiLSTM\n",
    "# def build_Bilstm_model(params, input_shape):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "#     # Bidirectional LSTM layer 1\n",
    "#     x = layers.Bidirectional(layers.LSTM(\n",
    "#         units=params.get('units_1'),\n",
    "#         return_sequences=True\n",
    "#     ))(inputs)\n",
    "#     x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "#     # Bidirectional LSTM layer 2\n",
    "#     x = layers.Bidirectional(layers.LSTM(\n",
    "#         units=params.get('units_2', 32),\n",
    "#         return_sequences=False\n",
    "#     ))(x)\n",
    "#     x = layers.Dropout(rate=params.get('dropout_2', 0.2))(x)\n",
    "    \n",
    "#     # Lớp đầu ra\n",
    "#     outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "#     # Khởi tạo mô hình\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     # Compile với Focal Loss\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "#                       learning_rate=params['learning_rate']),\n",
    "#                   loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "def build_Bilstm_model(params, input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "    # Chỉ sử dụng một lớp Bidirectional LSTM\n",
    "    x = layers.Bidirectional(layers.LSTM(\n",
    "        units=params.get('units_1', 64),\n",
    "        return_sequences=False  # Đặt thành False vì đây là lớp LSTM cuối cùng\n",
    "    ))(inputs)\n",
    "    x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile với Focal Loss\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7928960f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T10:47:37.379515Z",
     "iopub.status.busy": "2025-04-05T10:47:37.379316Z",
     "iopub.status.idle": "2025-04-05T11:16:23.308699Z",
     "shell.execute_reply": "2025-04-05T11:16:23.307983Z"
    },
    "papermill": {
     "duration": 1725.935992,
     "end_time": "2025-04-05T11:16:23.310019",
     "exception": false,
     "start_time": "2025-04-05T10:47:37.374027",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing week1 with best parameters...\n",
      "best parameters for week1: {'units_1': 192, 'dropout_1': 0.5, 'learning_rate': 0.0020894688241366384}\n",
      "Fold 1: Using file /kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 0.1486 - val_accuracy: 0.6988 - val_loss: 0.1130\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 0.1251 - val_accuracy: 0.6317 - val_loss: 0.1179\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6496 - loss: 0.1262 - val_accuracy: 0.7057 - val_loss: 0.1138\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6490 - loss: 0.1268 - val_accuracy: 0.7022 - val_loss: 0.1116\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6548 - loss: 0.1242 - val_accuracy: 0.7106 - val_loss: 0.1088\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.1204 - val_accuracy: 0.7308 - val_loss: 0.1073\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6764 - loss: 0.1214 - val_accuracy: 0.7205 - val_loss: 0.1062\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6771 - loss: 0.1223 - val_accuracy: 0.6645 - val_loss: 0.1086\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.1212 - val_accuracy: 0.7286 - val_loss: 0.1065\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.1145 - val_accuracy: 0.7347 - val_loss: 0.1020\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6878 - loss: 0.1160 - val_accuracy: 0.7385 - val_loss: 0.1007\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6986 - loss: 0.1146 - val_accuracy: 0.7335 - val_loss: 0.1016\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6977 - loss: 0.1132 - val_accuracy: 0.7388 - val_loss: 0.1003\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7033 - loss: 0.1130 - val_accuracy: 0.7434 - val_loss: 0.1025\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6985 - loss: 0.1139 - val_accuracy: 0.7312 - val_loss: 0.1002\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6991 - loss: 0.1137 - val_accuracy: 0.7381 - val_loss: 0.0992\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7062 - loss: 0.1147 - val_accuracy: 0.7503 - val_loss: 0.0970\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7087 - loss: 0.1122 - val_accuracy: 0.7442 - val_loss: 0.0982\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7027 - loss: 0.1136 - val_accuracy: 0.7430 - val_loss: 0.0974\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7181 - loss: 0.1055 - val_accuracy: 0.7632 - val_loss: 0.0978\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7056 - loss: 0.1126 - val_accuracy: 0.7571 - val_loss: 0.0940\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7065 - loss: 0.1122 - val_accuracy: 0.7583 - val_loss: 0.0947\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7156 - loss: 0.1095 - val_accuracy: 0.7469 - val_loss: 0.0980\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7065 - loss: 0.1106 - val_accuracy: 0.7533 - val_loss: 0.0953\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.1056 - val_accuracy: 0.7530 - val_loss: 0.0970\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7027 - loss: 0.1132 - val_accuracy: 0.7632 - val_loss: 0.0935\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.1144 - val_accuracy: 0.7491 - val_loss: 0.0952\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.1074 - val_accuracy: 0.7770 - val_loss: 0.0919\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7270 - loss: 0.1075 - val_accuracy: 0.7693 - val_loss: 0.0923\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.1095 - val_accuracy: 0.7621 - val_loss: 0.0927\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.1109 - val_accuracy: 0.7598 - val_loss: 0.0943\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7315 - loss: 0.1056 - val_accuracy: 0.7655 - val_loss: 0.0934\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.1110 - val_accuracy: 0.7652 - val_loss: 0.0941\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7218 - loss: 0.1070 - val_accuracy: 0.7663 - val_loss: 0.0943\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.1052 - val_accuracy: 0.7735 - val_loss: 0.0925\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.1080 - val_accuracy: 0.7812 - val_loss: 0.0931\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.1065 - val_accuracy: 0.7793 - val_loss: 0.0929\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.1095 - val_accuracy: 0.7705 - val_loss: 0.0894\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.1117 - val_accuracy: 0.7789 - val_loss: 0.0897\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7157 - loss: 0.1099 - val_accuracy: 0.7667 - val_loss: 0.0915\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.1032 - val_accuracy: 0.7526 - val_loss: 0.0968\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.1106 - val_accuracy: 0.7690 - val_loss: 0.0898\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.1047 - val_accuracy: 0.7732 - val_loss: 0.0882\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.1071 - val_accuracy: 0.7644 - val_loss: 0.0926\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.1078 - val_accuracy: 0.7819 - val_loss: 0.0906\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.1036 - val_accuracy: 0.7743 - val_loss: 0.0899\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.1064 - val_accuracy: 0.7880 - val_loss: 0.0901\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.1082 - val_accuracy: 0.7430 - val_loss: 0.0958\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7157 - loss: 0.1088 - val_accuracy: 0.7720 - val_loss: 0.0922\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7214 - loss: 0.1072 - val_accuracy: 0.7716 - val_loss: 0.0926\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5882 - loss: 0.1510 - val_accuracy: 0.6900 - val_loss: 0.1166\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6492 - loss: 0.1265 - val_accuracy: 0.7064 - val_loss: 0.1146\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6629 - loss: 0.1186 - val_accuracy: 0.7015 - val_loss: 0.1153\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6567 - loss: 0.1232 - val_accuracy: 0.6348 - val_loss: 0.1191\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.1228 - val_accuracy: 0.6939 - val_loss: 0.1145\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6767 - loss: 0.1221 - val_accuracy: 0.7068 - val_loss: 0.1100\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6730 - loss: 0.1202 - val_accuracy: 0.6931 - val_loss: 0.1178\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6793 - loss: 0.1205 - val_accuracy: 0.7286 - val_loss: 0.1076\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.1133 - val_accuracy: 0.7308 - val_loss: 0.1050\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7027 - loss: 0.1110 - val_accuracy: 0.7449 - val_loss: 0.1051\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6969 - loss: 0.1109 - val_accuracy: 0.7293 - val_loss: 0.1071\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6836 - loss: 0.1148 - val_accuracy: 0.7419 - val_loss: 0.1032\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7121 - loss: 0.1115 - val_accuracy: 0.7533 - val_loss: 0.1003\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6959 - loss: 0.1121 - val_accuracy: 0.7571 - val_loss: 0.1005\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6905 - loss: 0.1171 - val_accuracy: 0.7446 - val_loss: 0.1052\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.1066 - val_accuracy: 0.7232 - val_loss: 0.1077\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.1124 - val_accuracy: 0.7320 - val_loss: 0.1070\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7037 - loss: 0.1133 - val_accuracy: 0.7339 - val_loss: 0.1044\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.1074 - val_accuracy: 0.7442 - val_loss: 0.1009\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.1114 - val_accuracy: 0.7644 - val_loss: 0.1006\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.1097 - val_accuracy: 0.7629 - val_loss: 0.0995\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7172 - loss: 0.1095 - val_accuracy: 0.7560 - val_loss: 0.1013\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.1084 - val_accuracy: 0.7674 - val_loss: 0.0964\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.1120 - val_accuracy: 0.7484 - val_loss: 0.1007\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.1093 - val_accuracy: 0.7598 - val_loss: 0.1007\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.1062 - val_accuracy: 0.7530 - val_loss: 0.0980\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.1067 - val_accuracy: 0.7571 - val_loss: 0.0969\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.1069 - val_accuracy: 0.7347 - val_loss: 0.1005\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.1074 - val_accuracy: 0.7469 - val_loss: 0.0999\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.1073 - val_accuracy: 0.7644 - val_loss: 0.0966\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 0.1047 - val_accuracy: 0.7533 - val_loss: 0.0965\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.1067 - val_accuracy: 0.7701 - val_loss: 0.0958\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7243 - loss: 0.1069 - val_accuracy: 0.7335 - val_loss: 0.1014\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.1062 - val_accuracy: 0.7556 - val_loss: 0.0965\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7217 - loss: 0.1055 - val_accuracy: 0.7617 - val_loss: 0.0960\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.1059 - val_accuracy: 0.7598 - val_loss: 0.0996\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7140 - loss: 0.1095 - val_accuracy: 0.7526 - val_loss: 0.0956\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.1058 - val_accuracy: 0.7568 - val_loss: 0.0937\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7240 - loss: 0.1047 - val_accuracy: 0.7709 - val_loss: 0.0937\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7245 - loss: 0.1035 - val_accuracy: 0.7480 - val_loss: 0.1011\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7094 - loss: 0.1146 - val_accuracy: 0.7823 - val_loss: 0.0965\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.1070 - val_accuracy: 0.7716 - val_loss: 0.0963\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.1041 - val_accuracy: 0.7762 - val_loss: 0.0975\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7330 - loss: 0.1032 - val_accuracy: 0.7636 - val_loss: 0.0931\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7342 - loss: 0.1025 - val_accuracy: 0.7735 - val_loss: 0.0946\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.1050 - val_accuracy: 0.7610 - val_loss: 0.0941\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.1016 - val_accuracy: 0.7301 - val_loss: 0.1009\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7330 - loss: 0.1022 - val_accuracy: 0.7693 - val_loss: 0.0929\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.1066 - val_accuracy: 0.7724 - val_loss: 0.0957\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.1049 - val_accuracy: 0.7556 - val_loss: 0.0952\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6015 - loss: 0.1419 - val_accuracy: 0.6663 - val_loss: 0.1219\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6557 - loss: 0.1247 - val_accuracy: 0.6213 - val_loss: 0.1203\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6627 - loss: 0.1233 - val_accuracy: 0.6308 - val_loss: 0.1184\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6465 - loss: 0.1256 - val_accuracy: 0.6773 - val_loss: 0.1161\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6787 - loss: 0.1189 - val_accuracy: 0.6777 - val_loss: 0.1108\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.1191 - val_accuracy: 0.6998 - val_loss: 0.1082\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6902 - loss: 0.1165 - val_accuracy: 0.7094 - val_loss: 0.1091\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6938 - loss: 0.1135 - val_accuracy: 0.7265 - val_loss: 0.1096\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.1150 - val_accuracy: 0.7246 - val_loss: 0.1051\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6953 - loss: 0.1142 - val_accuracy: 0.7002 - val_loss: 0.1096\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6981 - loss: 0.1135 - val_accuracy: 0.7326 - val_loss: 0.1019\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7068 - loss: 0.1149 - val_accuracy: 0.7346 - val_loss: 0.1024\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7093 - loss: 0.1125 - val_accuracy: 0.7326 - val_loss: 0.1045\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7163 - loss: 0.1083 - val_accuracy: 0.7277 - val_loss: 0.1062\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7019 - loss: 0.1127 - val_accuracy: 0.7403 - val_loss: 0.1014\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7103 - loss: 0.1115 - val_accuracy: 0.7204 - val_loss: 0.1058\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7038 - loss: 0.1117 - val_accuracy: 0.7380 - val_loss: 0.0998\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7132 - loss: 0.1096 - val_accuracy: 0.7433 - val_loss: 0.0995\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.1069 - val_accuracy: 0.7365 - val_loss: 0.0998\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7094 - loss: 0.1128 - val_accuracy: 0.7456 - val_loss: 0.1022\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.1091 - val_accuracy: 0.7502 - val_loss: 0.1013\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 0.1104 - val_accuracy: 0.7407 - val_loss: 0.1012\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.1093 - val_accuracy: 0.7609 - val_loss: 0.0982\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7215 - loss: 0.1066 - val_accuracy: 0.7300 - val_loss: 0.1027\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.1074 - val_accuracy: 0.7326 - val_loss: 0.1014\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.1083 - val_accuracy: 0.7437 - val_loss: 0.0968\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.1062 - val_accuracy: 0.7548 - val_loss: 0.0986\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7254 - loss: 0.1058 - val_accuracy: 0.7483 - val_loss: 0.0982\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.1077 - val_accuracy: 0.7445 - val_loss: 0.0996\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7145 - loss: 0.1067 - val_accuracy: 0.7445 - val_loss: 0.1018\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.1101 - val_accuracy: 0.7616 - val_loss: 0.0976\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.1088 - val_accuracy: 0.7605 - val_loss: 0.0961\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.1063 - val_accuracy: 0.7490 - val_loss: 0.0990\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 0.1056 - val_accuracy: 0.7536 - val_loss: 0.0981\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.1047 - val_accuracy: 0.7395 - val_loss: 0.0975\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7231 - loss: 0.1074 - val_accuracy: 0.7326 - val_loss: 0.1014\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.1042 - val_accuracy: 0.7464 - val_loss: 0.0981\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7346 - loss: 0.1030 - val_accuracy: 0.7487 - val_loss: 0.0977\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7393 - loss: 0.1017 - val_accuracy: 0.7624 - val_loss: 0.0968\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7326 - loss: 0.1054 - val_accuracy: 0.7590 - val_loss: 0.0951\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.1077 - val_accuracy: 0.7452 - val_loss: 0.0994\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.1038 - val_accuracy: 0.7559 - val_loss: 0.0964\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.1033 - val_accuracy: 0.7662 - val_loss: 0.0933\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7299 - loss: 0.1062 - val_accuracy: 0.7647 - val_loss: 0.0974\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7306 - loss: 0.1018 - val_accuracy: 0.7666 - val_loss: 0.0939\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.1056 - val_accuracy: 0.7544 - val_loss: 0.0980\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7280 - loss: 0.1050 - val_accuracy: 0.7590 - val_loss: 0.0964\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.1007 - val_accuracy: 0.7815 - val_loss: 0.0936\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 0.1050 - val_accuracy: 0.7727 - val_loss: 0.0926\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7374 - loss: 0.1030 - val_accuracy: 0.7654 - val_loss: 0.0939\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 0.1444 - val_accuracy: 0.7021 - val_loss: 0.1164\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6579 - loss: 0.1249 - val_accuracy: 0.6819 - val_loss: 0.1151\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6650 - loss: 0.1242 - val_accuracy: 0.6415 - val_loss: 0.1147\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6696 - loss: 0.1232 - val_accuracy: 0.7243 - val_loss: 0.1110\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6837 - loss: 0.1205 - val_accuracy: 0.7155 - val_loss: 0.1053\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6722 - loss: 0.1183 - val_accuracy: 0.6873 - val_loss: 0.1115\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6811 - loss: 0.1188 - val_accuracy: 0.7147 - val_loss: 0.1046\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6888 - loss: 0.1165 - val_accuracy: 0.7063 - val_loss: 0.1053\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6927 - loss: 0.1141 - val_accuracy: 0.7422 - val_loss: 0.0996\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6848 - loss: 0.1185 - val_accuracy: 0.7342 - val_loss: 0.0992\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7021 - loss: 0.1129 - val_accuracy: 0.7407 - val_loss: 0.1005\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.1160 - val_accuracy: 0.7319 - val_loss: 0.0993\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7010 - loss: 0.1121 - val_accuracy: 0.7456 - val_loss: 0.0977\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7117 - loss: 0.1116 - val_accuracy: 0.7517 - val_loss: 0.1002\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.1126 - val_accuracy: 0.7372 - val_loss: 0.0995\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7148 - loss: 0.1114 - val_accuracy: 0.7410 - val_loss: 0.1056\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7023 - loss: 0.1117 - val_accuracy: 0.7540 - val_loss: 0.0965\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7200 - loss: 0.1086 - val_accuracy: 0.7422 - val_loss: 0.0984\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7049 - loss: 0.1095 - val_accuracy: 0.7468 - val_loss: 0.1005\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.1095 - val_accuracy: 0.7410 - val_loss: 0.1024\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7100 - loss: 0.1118 - val_accuracy: 0.7494 - val_loss: 0.0974\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7168 - loss: 0.1088 - val_accuracy: 0.7757 - val_loss: 0.0986\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7184 - loss: 0.1091 - val_accuracy: 0.7532 - val_loss: 0.0983\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7106 - loss: 0.1129 - val_accuracy: 0.7376 - val_loss: 0.0978\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7185 - loss: 0.1048 - val_accuracy: 0.7346 - val_loss: 0.1038\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7113 - loss: 0.1095 - val_accuracy: 0.7323 - val_loss: 0.1012\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7276 - loss: 0.1071 - val_accuracy: 0.7513 - val_loss: 0.0979\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7241 - loss: 0.1071 - val_accuracy: 0.7422 - val_loss: 0.0987\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7158 - loss: 0.1094 - val_accuracy: 0.7597 - val_loss: 0.0963\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 0.1057 - val_accuracy: 0.7571 - val_loss: 0.0985\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7190 - loss: 0.1070 - val_accuracy: 0.7696 - val_loss: 0.0950\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.1075 - val_accuracy: 0.7590 - val_loss: 0.0946\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.1052 - val_accuracy: 0.7616 - val_loss: 0.0955\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.1066 - val_accuracy: 0.7620 - val_loss: 0.0951\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.1050 - val_accuracy: 0.7525 - val_loss: 0.0987\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.1100 - val_accuracy: 0.7639 - val_loss: 0.0945\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.1095 - val_accuracy: 0.7624 - val_loss: 0.0948\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.1068 - val_accuracy: 0.7586 - val_loss: 0.0970\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.1060 - val_accuracy: 0.7609 - val_loss: 0.0965\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.1040 - val_accuracy: 0.7632 - val_loss: 0.0929\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7200 - loss: 0.1063 - val_accuracy: 0.7769 - val_loss: 0.0934\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7184 - loss: 0.1082 - val_accuracy: 0.7654 - val_loss: 0.0937\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.1040 - val_accuracy: 0.7525 - val_loss: 0.0965\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.1012 - val_accuracy: 0.7593 - val_loss: 0.0942\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.1049 - val_accuracy: 0.7460 - val_loss: 0.0964\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7232 - loss: 0.1059 - val_accuracy: 0.7708 - val_loss: 0.0950\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.1013 - val_accuracy: 0.7723 - val_loss: 0.0913\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7251 - loss: 0.1053 - val_accuracy: 0.7689 - val_loss: 0.0960\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.1036 - val_accuracy: 0.7643 - val_loss: 0.0961\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7334 - loss: 0.1039 - val_accuracy: 0.7613 - val_loss: 0.0946\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5975 - loss: 0.1505 - val_accuracy: 0.6926 - val_loss: 0.1154\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 0.1254 - val_accuracy: 0.7037 - val_loss: 0.1122\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6656 - loss: 0.1237 - val_accuracy: 0.7151 - val_loss: 0.1118\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.1216 - val_accuracy: 0.7147 - val_loss: 0.1100\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6721 - loss: 0.1199 - val_accuracy: 0.7262 - val_loss: 0.1061\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6858 - loss: 0.1185 - val_accuracy: 0.7140 - val_loss: 0.1071\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6816 - loss: 0.1184 - val_accuracy: 0.7365 - val_loss: 0.1028\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.1150 - val_accuracy: 0.7239 - val_loss: 0.1030\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.1134 - val_accuracy: 0.7372 - val_loss: 0.1002\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7076 - loss: 0.1121 - val_accuracy: 0.7052 - val_loss: 0.1088\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 0.1113 - val_accuracy: 0.7391 - val_loss: 0.1010\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 0.1103 - val_accuracy: 0.7330 - val_loss: 0.1014\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6952 - loss: 0.1157 - val_accuracy: 0.7296 - val_loss: 0.1067\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7071 - loss: 0.1103 - val_accuracy: 0.7452 - val_loss: 0.0987\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6996 - loss: 0.1131 - val_accuracy: 0.7521 - val_loss: 0.0997\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6962 - loss: 0.1155 - val_accuracy: 0.7407 - val_loss: 0.1004\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6952 - loss: 0.1130 - val_accuracy: 0.7452 - val_loss: 0.0971\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7013 - loss: 0.1114 - val_accuracy: 0.7490 - val_loss: 0.1029\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.1148 - val_accuracy: 0.7418 - val_loss: 0.1011\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7062 - loss: 0.1128 - val_accuracy: 0.7418 - val_loss: 0.1013\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6955 - loss: 0.1115 - val_accuracy: 0.7437 - val_loss: 0.0956\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.1106 - val_accuracy: 0.7357 - val_loss: 0.1019\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 0.1129 - val_accuracy: 0.7403 - val_loss: 0.0945\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7019 - loss: 0.1121 - val_accuracy: 0.7471 - val_loss: 0.1000\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7185 - loss: 0.1079 - val_accuracy: 0.7384 - val_loss: 0.1004\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.1120 - val_accuracy: 0.7574 - val_loss: 0.0958\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.1094 - val_accuracy: 0.7529 - val_loss: 0.0961\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.1098 - val_accuracy: 0.7555 - val_loss: 0.0966\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7137 - loss: 0.1134 - val_accuracy: 0.7517 - val_loss: 0.0978\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7147 - loss: 0.1080 - val_accuracy: 0.7647 - val_loss: 0.0967\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.1070 - val_accuracy: 0.7666 - val_loss: 0.0945\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7123 - loss: 0.1127 - val_accuracy: 0.7517 - val_loss: 0.0976\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.1079 - val_accuracy: 0.7605 - val_loss: 0.0935\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.1084 - val_accuracy: 0.7628 - val_loss: 0.0932\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.1094 - val_accuracy: 0.7551 - val_loss: 0.0958\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7210 - loss: 0.1092 - val_accuracy: 0.7632 - val_loss: 0.0947\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.1065 - val_accuracy: 0.7319 - val_loss: 0.1009\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.1085 - val_accuracy: 0.7410 - val_loss: 0.0975\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7337 - loss: 0.1013 - val_accuracy: 0.7445 - val_loss: 0.0967\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7264 - loss: 0.1061 - val_accuracy: 0.7372 - val_loss: 0.0953\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.1083 - val_accuracy: 0.7674 - val_loss: 0.0944\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.1039 - val_accuracy: 0.7712 - val_loss: 0.0909\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.1070 - val_accuracy: 0.7586 - val_loss: 0.0977\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.1092 - val_accuracy: 0.7628 - val_loss: 0.0927\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7264 - loss: 0.1047 - val_accuracy: 0.7605 - val_loss: 0.0993\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7184 - loss: 0.1079 - val_accuracy: 0.7182 - val_loss: 0.1010\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.1042 - val_accuracy: 0.7597 - val_loss: 0.0915\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.1025 - val_accuracy: 0.7521 - val_loss: 0.0951\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.1068 - val_accuracy: 0.7479 - val_loss: 0.0981\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7186 - loss: 0.1062 - val_accuracy: 0.7540 - val_loss: 0.0964\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average Accuracy ===\n",
      "0.7616\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.5888\n",
      "Macro Recall: 0.4444\n",
      "Macro F1-Score: 0.4800\n",
      "Macro AUC-ROC: 0.8536\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7322\n",
      "Weighted Recall: 0.7616\n",
      "Weighted F1-Score: 0.7279\n",
      "Weighted AUC-ROC: 0.8884\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.715229        0.566000          0.629308     0.867114\n",
      "1      1           0.000000        0.000000          0.000000     0.778681\n",
      "2      2           0.714760        0.424405          0.520309     0.847547\n",
      "3      3           0.733997        0.269461          0.389351     0.865818\n",
      "4      4           0.780164        0.962202          0.861121     0.908830\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2     3       4\n",
      "0  339.6  0.0  13.2   6.8   240.4\n",
      "1   32.2  0.0   1.4   2.4    51.6\n",
      "2   25.8  0.0  69.8   2.4    66.4\n",
      "3   40.6  0.0   2.4  45.0    79.0\n",
      "4   40.8  0.0  14.2   5.6  1542.8\n",
      "\n",
      "Processing week2 with best parameters...\n",
      "best parameters for week2: {'units_1': 160, 'dropout_1': 0.1, 'learning_rate': 0.0013917854917016644}\n",
      "Fold 1: Using file /kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6682 - loss: 0.1261 - val_accuracy: 0.7297 - val_loss: 0.1076\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.1083 - val_accuracy: 0.7751 - val_loss: 0.0920\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7593 - loss: 0.0989 - val_accuracy: 0.8006 - val_loss: 0.0873\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.0922 - val_accuracy: 0.8124 - val_loss: 0.0822\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.0893 - val_accuracy: 0.8063 - val_loss: 0.0841\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.0874 - val_accuracy: 0.7800 - val_loss: 0.0857\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.0881 - val_accuracy: 0.8101 - val_loss: 0.0767\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.0836 - val_accuracy: 0.8303 - val_loss: 0.0738\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.0814 - val_accuracy: 0.8258 - val_loss: 0.0757\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.0815 - val_accuracy: 0.8227 - val_loss: 0.0771\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.0811 - val_accuracy: 0.8262 - val_loss: 0.0781\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.0833 - val_accuracy: 0.8239 - val_loss: 0.0739\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.0815 - val_accuracy: 0.8345 - val_loss: 0.0703\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.0805 - val_accuracy: 0.8364 - val_loss: 0.0700\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 0.0774 - val_accuracy: 0.8242 - val_loss: 0.0730\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.0765 - val_accuracy: 0.8281 - val_loss: 0.0695\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.0769 - val_accuracy: 0.8307 - val_loss: 0.0723\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8157 - loss: 0.0748 - val_accuracy: 0.8334 - val_loss: 0.0695\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.0741 - val_accuracy: 0.8330 - val_loss: 0.0685\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8219 - loss: 0.0766 - val_accuracy: 0.8486 - val_loss: 0.0655\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.0757 - val_accuracy: 0.8342 - val_loss: 0.0705\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.0768 - val_accuracy: 0.8467 - val_loss: 0.0656\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.0708 - val_accuracy: 0.8502 - val_loss: 0.0661\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.0733 - val_accuracy: 0.8311 - val_loss: 0.0723\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.0734 - val_accuracy: 0.8391 - val_loss: 0.0679\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8186 - loss: 0.0739 - val_accuracy: 0.8044 - val_loss: 0.0738\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.0740 - val_accuracy: 0.8483 - val_loss: 0.0630\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.0708 - val_accuracy: 0.8437 - val_loss: 0.0637\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.0711 - val_accuracy: 0.8494 - val_loss: 0.0629\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.0705 - val_accuracy: 0.8292 - val_loss: 0.0669\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8220 - loss: 0.0712 - val_accuracy: 0.8460 - val_loss: 0.0648\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.0687 - val_accuracy: 0.8395 - val_loss: 0.0648\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.0719 - val_accuracy: 0.8517 - val_loss: 0.0623\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.0684 - val_accuracy: 0.8452 - val_loss: 0.0658\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.0711 - val_accuracy: 0.8448 - val_loss: 0.0627\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.0693 - val_accuracy: 0.8551 - val_loss: 0.0593\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.0703 - val_accuracy: 0.8486 - val_loss: 0.0632\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.0721 - val_accuracy: 0.8326 - val_loss: 0.0682\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.0711 - val_accuracy: 0.8120 - val_loss: 0.0729\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.0720 - val_accuracy: 0.8525 - val_loss: 0.0588\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8242 - loss: 0.0702 - val_accuracy: 0.8460 - val_loss: 0.0663\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.0702 - val_accuracy: 0.8334 - val_loss: 0.0620\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.0667 - val_accuracy: 0.8586 - val_loss: 0.0587\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 0.0693 - val_accuracy: 0.8471 - val_loss: 0.0609\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.0688 - val_accuracy: 0.8506 - val_loss: 0.0625\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0692 - val_accuracy: 0.8551 - val_loss: 0.0582\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.0653 - val_accuracy: 0.8593 - val_loss: 0.0573\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.0699 - val_accuracy: 0.8479 - val_loss: 0.0598\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.0658 - val_accuracy: 0.8547 - val_loss: 0.0611\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.0665 - val_accuracy: 0.8479 - val_loss: 0.0603\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6535 - loss: 0.1247 - val_accuracy: 0.7228 - val_loss: 0.1097\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.1047 - val_accuracy: 0.7636 - val_loss: 0.0968\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7597 - loss: 0.0978 - val_accuracy: 0.7911 - val_loss: 0.0920\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7747 - loss: 0.0925 - val_accuracy: 0.7125 - val_loss: 0.1037\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7716 - loss: 0.0921 - val_accuracy: 0.7884 - val_loss: 0.0879\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.0897 - val_accuracy: 0.8101 - val_loss: 0.0877\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 0.0883 - val_accuracy: 0.8025 - val_loss: 0.0852\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 0.0858 - val_accuracy: 0.8140 - val_loss: 0.0850\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.0820 - val_accuracy: 0.8277 - val_loss: 0.0828\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.0857 - val_accuracy: 0.8025 - val_loss: 0.0828\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.0818 - val_accuracy: 0.8075 - val_loss: 0.0811\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.0820 - val_accuracy: 0.8208 - val_loss: 0.0780\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.0782 - val_accuracy: 0.8204 - val_loss: 0.0774\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.0775 - val_accuracy: 0.8166 - val_loss: 0.0790\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.0793 - val_accuracy: 0.8273 - val_loss: 0.0757\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.0785 - val_accuracy: 0.8254 - val_loss: 0.0758\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.0777 - val_accuracy: 0.8220 - val_loss: 0.0762\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.0765 - val_accuracy: 0.8162 - val_loss: 0.0786\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.0770 - val_accuracy: 0.7995 - val_loss: 0.0826\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.0779 - val_accuracy: 0.8323 - val_loss: 0.0717\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.0728 - val_accuracy: 0.8166 - val_loss: 0.0739\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.0742 - val_accuracy: 0.8368 - val_loss: 0.0712\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.0745 - val_accuracy: 0.8319 - val_loss: 0.0727\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.0732 - val_accuracy: 0.8193 - val_loss: 0.0744\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0740 - val_accuracy: 0.8387 - val_loss: 0.0699\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.0737 - val_accuracy: 0.8262 - val_loss: 0.0709\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.0718 - val_accuracy: 0.8239 - val_loss: 0.0741\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.0729 - val_accuracy: 0.8242 - val_loss: 0.0722\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.0699 - val_accuracy: 0.8334 - val_loss: 0.0684\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.0715 - val_accuracy: 0.8288 - val_loss: 0.0712\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.0685 - val_accuracy: 0.8460 - val_loss: 0.0686\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.0686 - val_accuracy: 0.8151 - val_loss: 0.0752\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8304 - loss: 0.0690 - val_accuracy: 0.8345 - val_loss: 0.0670\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.0675 - val_accuracy: 0.8330 - val_loss: 0.0684\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8220 - loss: 0.0716 - val_accuracy: 0.8429 - val_loss: 0.0690\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8326 - loss: 0.0687 - val_accuracy: 0.8296 - val_loss: 0.0708\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.0709 - val_accuracy: 0.8384 - val_loss: 0.0677\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.0700 - val_accuracy: 0.8292 - val_loss: 0.0677\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.0709 - val_accuracy: 0.8387 - val_loss: 0.0661\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.0672 - val_accuracy: 0.8486 - val_loss: 0.0665\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8314 - loss: 0.0671 - val_accuracy: 0.8433 - val_loss: 0.0644\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.0696 - val_accuracy: 0.8452 - val_loss: 0.0647\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8298 - loss: 0.0676 - val_accuracy: 0.8239 - val_loss: 0.0717\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.0673 - val_accuracy: 0.8422 - val_loss: 0.0688\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.0669 - val_accuracy: 0.8502 - val_loss: 0.0642\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 0.0648 - val_accuracy: 0.8338 - val_loss: 0.0681\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.0711 - val_accuracy: 0.8391 - val_loss: 0.0692\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.0686 - val_accuracy: 0.8334 - val_loss: 0.0660\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.0658 - val_accuracy: 0.8277 - val_loss: 0.0671\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 0.0680 - val_accuracy: 0.8349 - val_loss: 0.0679\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6575 - loss: 0.1263 - val_accuracy: 0.7166 - val_loss: 0.1106\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.1062 - val_accuracy: 0.7601 - val_loss: 0.0980\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.0977 - val_accuracy: 0.7735 - val_loss: 0.0900\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 0.0943 - val_accuracy: 0.7899 - val_loss: 0.0877\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7806 - loss: 0.0909 - val_accuracy: 0.7990 - val_loss: 0.0838\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.0865 - val_accuracy: 0.7632 - val_loss: 0.0909\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.0887 - val_accuracy: 0.8021 - val_loss: 0.0869\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 0.0845 - val_accuracy: 0.8089 - val_loss: 0.0819\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 0.0846 - val_accuracy: 0.7876 - val_loss: 0.0850\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.0813 - val_accuracy: 0.8066 - val_loss: 0.0798\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.0804 - val_accuracy: 0.8200 - val_loss: 0.0783\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.0793 - val_accuracy: 0.7365 - val_loss: 0.0925\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.0811 - val_accuracy: 0.8196 - val_loss: 0.0747\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.0776 - val_accuracy: 0.8318 - val_loss: 0.0741\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8174 - loss: 0.0749 - val_accuracy: 0.8257 - val_loss: 0.0749\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.0768 - val_accuracy: 0.8410 - val_loss: 0.0719\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.0750 - val_accuracy: 0.8120 - val_loss: 0.0769\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.0774 - val_accuracy: 0.8169 - val_loss: 0.0735\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.0765 - val_accuracy: 0.8307 - val_loss: 0.0728\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.0719 - val_accuracy: 0.8291 - val_loss: 0.0691\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.0756 - val_accuracy: 0.8230 - val_loss: 0.0695\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.0740 - val_accuracy: 0.8322 - val_loss: 0.0695\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.0737 - val_accuracy: 0.8162 - val_loss: 0.0713\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.0729 - val_accuracy: 0.8268 - val_loss: 0.0689\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.0699 - val_accuracy: 0.8318 - val_loss: 0.0678\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8302 - loss: 0.0695 - val_accuracy: 0.8398 - val_loss: 0.0666\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.0721 - val_accuracy: 0.8089 - val_loss: 0.0743\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.0732 - val_accuracy: 0.8188 - val_loss: 0.0717\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.0738 - val_accuracy: 0.8345 - val_loss: 0.0675\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.0708 - val_accuracy: 0.8192 - val_loss: 0.0728\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.0698 - val_accuracy: 0.8326 - val_loss: 0.0701\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0706 - val_accuracy: 0.8459 - val_loss: 0.0645\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 0.0695 - val_accuracy: 0.8337 - val_loss: 0.0671\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.0704 - val_accuracy: 0.8326 - val_loss: 0.0662\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.0692 - val_accuracy: 0.8135 - val_loss: 0.0696\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.0713 - val_accuracy: 0.8494 - val_loss: 0.0641\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.0666 - val_accuracy: 0.8272 - val_loss: 0.0682\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.0745 - val_accuracy: 0.8375 - val_loss: 0.0630\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.0700 - val_accuracy: 0.8436 - val_loss: 0.0633\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.0659 - val_accuracy: 0.8368 - val_loss: 0.0683\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.0694 - val_accuracy: 0.8166 - val_loss: 0.0694\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.0702 - val_accuracy: 0.8421 - val_loss: 0.0629\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.0660 - val_accuracy: 0.8429 - val_loss: 0.0617\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8427 - loss: 0.0627 - val_accuracy: 0.8341 - val_loss: 0.0676\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.0690 - val_accuracy: 0.8410 - val_loss: 0.0636\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8350 - loss: 0.0648 - val_accuracy: 0.8242 - val_loss: 0.0678\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.0699 - val_accuracy: 0.8448 - val_loss: 0.0620\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.0659 - val_accuracy: 0.8455 - val_loss: 0.0631\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.0663 - val_accuracy: 0.8524 - val_loss: 0.0621\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.0641 - val_accuracy: 0.8391 - val_loss: 0.0669\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6489 - loss: 0.1297 - val_accuracy: 0.7243 - val_loss: 0.1057\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.1036 - val_accuracy: 0.7700 - val_loss: 0.0941\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.0977 - val_accuracy: 0.7788 - val_loss: 0.0905\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7695 - loss: 0.0935 - val_accuracy: 0.7937 - val_loss: 0.0862\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.0905 - val_accuracy: 0.7937 - val_loss: 0.0865\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7924 - loss: 0.0871 - val_accuracy: 0.8021 - val_loss: 0.0876\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.0860 - val_accuracy: 0.7921 - val_loss: 0.0900\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7988 - loss: 0.0848 - val_accuracy: 0.8066 - val_loss: 0.0835\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.0864 - val_accuracy: 0.8009 - val_loss: 0.0803\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.0842 - val_accuracy: 0.8200 - val_loss: 0.0784\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.0815 - val_accuracy: 0.8177 - val_loss: 0.0806\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.0792 - val_accuracy: 0.8146 - val_loss: 0.0758\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.0798 - val_accuracy: 0.8196 - val_loss: 0.0782\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.0788 - val_accuracy: 0.8162 - val_loss: 0.0791\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.0795 - val_accuracy: 0.8063 - val_loss: 0.0782\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.0774 - val_accuracy: 0.8291 - val_loss: 0.0772\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.0761 - val_accuracy: 0.8238 - val_loss: 0.0759\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.0750 - val_accuracy: 0.8192 - val_loss: 0.0759\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.0747 - val_accuracy: 0.8055 - val_loss: 0.0760\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8191 - loss: 0.0749 - val_accuracy: 0.8310 - val_loss: 0.0719\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.0744 - val_accuracy: 0.8356 - val_loss: 0.0715\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.0723 - val_accuracy: 0.8249 - val_loss: 0.0695\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.0738 - val_accuracy: 0.8284 - val_loss: 0.0710\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.0719 - val_accuracy: 0.8207 - val_loss: 0.0767\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.0739 - val_accuracy: 0.8356 - val_loss: 0.0692\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.0723 - val_accuracy: 0.8337 - val_loss: 0.0681\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.0684 - val_accuracy: 0.8238 - val_loss: 0.0755\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.0684 - val_accuracy: 0.8432 - val_loss: 0.0670\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.0706 - val_accuracy: 0.8360 - val_loss: 0.0679\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.0706 - val_accuracy: 0.8291 - val_loss: 0.0680\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.0696 - val_accuracy: 0.8356 - val_loss: 0.0673\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8297 - loss: 0.0683 - val_accuracy: 0.8280 - val_loss: 0.0707\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0690 - val_accuracy: 0.8280 - val_loss: 0.0737\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.0706 - val_accuracy: 0.8295 - val_loss: 0.0681\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0710 - val_accuracy: 0.8330 - val_loss: 0.0678\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.0720 - val_accuracy: 0.8413 - val_loss: 0.0642\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.0670 - val_accuracy: 0.8337 - val_loss: 0.0712\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.0693 - val_accuracy: 0.8272 - val_loss: 0.0668\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.0716 - val_accuracy: 0.8375 - val_loss: 0.0725\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.0705 - val_accuracy: 0.8352 - val_loss: 0.0639\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.0656 - val_accuracy: 0.8452 - val_loss: 0.0644\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.0643 - val_accuracy: 0.8490 - val_loss: 0.0646\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.0672 - val_accuracy: 0.8284 - val_loss: 0.0682\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.0659 - val_accuracy: 0.8272 - val_loss: 0.0725\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8314 - loss: 0.0695 - val_accuracy: 0.8417 - val_loss: 0.0640\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 0.0652 - val_accuracy: 0.8391 - val_loss: 0.0654\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.0645 - val_accuracy: 0.8322 - val_loss: 0.0647\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.0647 - val_accuracy: 0.8478 - val_loss: 0.0622\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.0649 - val_accuracy: 0.8440 - val_loss: 0.0630\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.0664 - val_accuracy: 0.8452 - val_loss: 0.0621\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6217 - loss: 0.1411 - val_accuracy: 0.7155 - val_loss: 0.1096\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.1069 - val_accuracy: 0.7201 - val_loss: 0.1009\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7506 - loss: 0.0997 - val_accuracy: 0.7853 - val_loss: 0.0876\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.0943 - val_accuracy: 0.7948 - val_loss: 0.0868\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7853 - loss: 0.0912 - val_accuracy: 0.7891 - val_loss: 0.0855\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.0867 - val_accuracy: 0.8070 - val_loss: 0.0810\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.0878 - val_accuracy: 0.8089 - val_loss: 0.0810\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.0884 - val_accuracy: 0.8139 - val_loss: 0.0781\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.0830 - val_accuracy: 0.7956 - val_loss: 0.0857\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.0799 - val_accuracy: 0.8185 - val_loss: 0.0781\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.0796 - val_accuracy: 0.8215 - val_loss: 0.0746\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.0776 - val_accuracy: 0.8265 - val_loss: 0.0767\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.0785 - val_accuracy: 0.8242 - val_loss: 0.0737\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.0791 - val_accuracy: 0.8181 - val_loss: 0.0752\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.0794 - val_accuracy: 0.8169 - val_loss: 0.0766\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.0738 - val_accuracy: 0.7895 - val_loss: 0.0862\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.0771 - val_accuracy: 0.8234 - val_loss: 0.0735\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.0758 - val_accuracy: 0.8249 - val_loss: 0.0729\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.0746 - val_accuracy: 0.8364 - val_loss: 0.0711\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.0739 - val_accuracy: 0.8204 - val_loss: 0.0723\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.0764 - val_accuracy: 0.8257 - val_loss: 0.0721\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.0750 - val_accuracy: 0.8345 - val_loss: 0.0678\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.0763 - val_accuracy: 0.8421 - val_loss: 0.0671\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.0701 - val_accuracy: 0.8257 - val_loss: 0.0707\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.0696 - val_accuracy: 0.8349 - val_loss: 0.0687\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.0714 - val_accuracy: 0.8406 - val_loss: 0.0678\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.0710 - val_accuracy: 0.8383 - val_loss: 0.0670\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8303 - loss: 0.0701 - val_accuracy: 0.8207 - val_loss: 0.0708\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.0731 - val_accuracy: 0.8368 - val_loss: 0.0661\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.0678 - val_accuracy: 0.8383 - val_loss: 0.0683\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.0664 - val_accuracy: 0.8337 - val_loss: 0.0671\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.0692 - val_accuracy: 0.8394 - val_loss: 0.0647\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.0699 - val_accuracy: 0.8467 - val_loss: 0.0618\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.0671 - val_accuracy: 0.8307 - val_loss: 0.0657\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.0706 - val_accuracy: 0.8455 - val_loss: 0.0636\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.0704 - val_accuracy: 0.8406 - val_loss: 0.0637\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.0693 - val_accuracy: 0.8314 - val_loss: 0.0674\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8350 - loss: 0.0645 - val_accuracy: 0.8417 - val_loss: 0.0645\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.0651 - val_accuracy: 0.8394 - val_loss: 0.0653\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.0668 - val_accuracy: 0.8368 - val_loss: 0.0686\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.0669 - val_accuracy: 0.8398 - val_loss: 0.0685\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.0666 - val_accuracy: 0.8429 - val_loss: 0.0653\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.0694 - val_accuracy: 0.8383 - val_loss: 0.0648\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 0.0661 - val_accuracy: 0.8394 - val_loss: 0.0640\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.0684 - val_accuracy: 0.8249 - val_loss: 0.0723\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.0676 - val_accuracy: 0.8505 - val_loss: 0.0621\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.0672 - val_accuracy: 0.8417 - val_loss: 0.0648\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.0659 - val_accuracy: 0.8551 - val_loss: 0.0624\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 0.0646 - val_accuracy: 0.8471 - val_loss: 0.0617\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.0676 - val_accuracy: 0.8577 - val_loss: 0.0628\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.8450\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7981\n",
      "Macro Recall: 0.5911\n",
      "Macro F1-Score: 0.6298\n",
      "Macro AUC-ROC: 0.9252\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.8437\n",
      "Weighted Recall: 0.8450\n",
      "Weighted F1-Score: 0.8290\n",
      "Weighted AUC-ROC: 0.9492\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.790471        0.808000          0.794173     0.951816\n",
      "1      1           0.742895        0.112173          0.181328     0.893192\n",
      "2      2           0.844415        0.440421          0.575823     0.906485\n",
      "3      3           0.732128        0.632335          0.678386     0.915382\n",
      "4      4           0.880731        0.962457          0.919063     0.959114\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2      3       4\n",
      "0  484.8  2.4   4.8    4.2   103.8\n",
      "1   51.8  9.8   1.4    3.8    20.8\n",
      "2   32.4  1.6  72.4   12.0    46.0\n",
      "3   15.6  1.6   2.2  105.6    42.0\n",
      "4   36.4  0.2   5.0   18.6  1543.2\n",
      "\n",
      "Processing week3 with best parameters...\n",
      "best parameters for week3: {'units_1': 256, 'dropout_1': 0.5, 'learning_rate': 0.0009123863082217119}\n",
      "Fold 1: Using file /kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6099 - loss: 0.1460 - val_accuracy: 0.7320 - val_loss: 0.1062\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6942 - loss: 0.1187 - val_accuracy: 0.7457 - val_loss: 0.0958\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.1078 - val_accuracy: 0.7842 - val_loss: 0.0903\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.1025 - val_accuracy: 0.7888 - val_loss: 0.0873\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 0.0979 - val_accuracy: 0.7854 - val_loss: 0.0861\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7703 - loss: 0.0951 - val_accuracy: 0.8147 - val_loss: 0.0797\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.0908 - val_accuracy: 0.8136 - val_loss: 0.0807\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.0863 - val_accuracy: 0.8059 - val_loss: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7841 - loss: 0.0903 - val_accuracy: 0.8242 - val_loss: 0.0761\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.0860 - val_accuracy: 0.8399 - val_loss: 0.0750\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.0851 - val_accuracy: 0.8300 - val_loss: 0.0745\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.0840 - val_accuracy: 0.8239 - val_loss: 0.0728\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.0839 - val_accuracy: 0.8391 - val_loss: 0.0704\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.0844 - val_accuracy: 0.8486 - val_loss: 0.0695\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.0840 - val_accuracy: 0.8414 - val_loss: 0.0699\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.0813 - val_accuracy: 0.8460 - val_loss: 0.0709\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.0818 - val_accuracy: 0.8399 - val_loss: 0.0683\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.0796 - val_accuracy: 0.8208 - val_loss: 0.0714\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.0791 - val_accuracy: 0.8300 - val_loss: 0.0708\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.0783 - val_accuracy: 0.8212 - val_loss: 0.0728\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.0808 - val_accuracy: 0.8494 - val_loss: 0.0666\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.0798 - val_accuracy: 0.8547 - val_loss: 0.0662\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.0790 - val_accuracy: 0.8460 - val_loss: 0.0670\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.0769 - val_accuracy: 0.8506 - val_loss: 0.0651\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.0749 - val_accuracy: 0.8517 - val_loss: 0.0660\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8191 - loss: 0.0763 - val_accuracy: 0.8498 - val_loss: 0.0646\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.0796 - val_accuracy: 0.8494 - val_loss: 0.0651\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.0745 - val_accuracy: 0.8494 - val_loss: 0.0635\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.0746 - val_accuracy: 0.8536 - val_loss: 0.0632\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.0783 - val_accuracy: 0.8567 - val_loss: 0.0629\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.0780 - val_accuracy: 0.8498 - val_loss: 0.0638\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8203 - loss: 0.0753 - val_accuracy: 0.8517 - val_loss: 0.0621\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.0744 - val_accuracy: 0.8311 - val_loss: 0.0672\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.0763 - val_accuracy: 0.8528 - val_loss: 0.0625\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8183 - loss: 0.0739 - val_accuracy: 0.8559 - val_loss: 0.0630\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.0761 - val_accuracy: 0.8475 - val_loss: 0.0630\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8278 - loss: 0.0719 - val_accuracy: 0.8567 - val_loss: 0.0615\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.0761 - val_accuracy: 0.8532 - val_loss: 0.0615\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.0736 - val_accuracy: 0.8578 - val_loss: 0.0610\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.0749 - val_accuracy: 0.8441 - val_loss: 0.0644\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.0741 - val_accuracy: 0.8597 - val_loss: 0.0619\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.0708 - val_accuracy: 0.8506 - val_loss: 0.0612\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.0726 - val_accuracy: 0.8578 - val_loss: 0.0594\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.0705 - val_accuracy: 0.8559 - val_loss: 0.0606\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.0708 - val_accuracy: 0.8574 - val_loss: 0.0588\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.0699 - val_accuracy: 0.8570 - val_loss: 0.0591\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.0737 - val_accuracy: 0.8551 - val_loss: 0.0606\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.0716 - val_accuracy: 0.8547 - val_loss: 0.0591\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.0702 - val_accuracy: 0.8639 - val_loss: 0.0574\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.0725 - val_accuracy: 0.8563 - val_loss: 0.0582\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.1430 - val_accuracy: 0.7282 - val_loss: 0.1079\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.1144 - val_accuracy: 0.7610 - val_loss: 0.0997\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7394 - loss: 0.1029 - val_accuracy: 0.7819 - val_loss: 0.0918\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7460 - loss: 0.0998 - val_accuracy: 0.7583 - val_loss: 0.0987\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7624 - loss: 0.0993 - val_accuracy: 0.8071 - val_loss: 0.0851\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.0938 - val_accuracy: 0.8132 - val_loss: 0.0844\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.0911 - val_accuracy: 0.7861 - val_loss: 0.0877\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7902 - loss: 0.0894 - val_accuracy: 0.8155 - val_loss: 0.0815\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.0874 - val_accuracy: 0.8120 - val_loss: 0.0801\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.0886 - val_accuracy: 0.8170 - val_loss: 0.0822\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.0870 - val_accuracy: 0.8242 - val_loss: 0.0800\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.0829 - val_accuracy: 0.8170 - val_loss: 0.0798\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.0825 - val_accuracy: 0.8323 - val_loss: 0.0771\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.0828 - val_accuracy: 0.8345 - val_loss: 0.0771\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8047 - loss: 0.0808 - val_accuracy: 0.8288 - val_loss: 0.0748\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.0795 - val_accuracy: 0.8338 - val_loss: 0.0754\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.0825 - val_accuracy: 0.8364 - val_loss: 0.0742\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8128 - loss: 0.0786 - val_accuracy: 0.8311 - val_loss: 0.0745\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.0775 - val_accuracy: 0.8445 - val_loss: 0.0715\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.0822 - val_accuracy: 0.8319 - val_loss: 0.0732\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.0782 - val_accuracy: 0.8387 - val_loss: 0.0719\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.0773 - val_accuracy: 0.8433 - val_loss: 0.0703\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 0.0738 - val_accuracy: 0.8345 - val_loss: 0.0713\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.0776 - val_accuracy: 0.8326 - val_loss: 0.0715\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.0771 - val_accuracy: 0.8460 - val_loss: 0.0704\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.0757 - val_accuracy: 0.8498 - val_loss: 0.0723\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.0783 - val_accuracy: 0.8353 - val_loss: 0.0729\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.0770 - val_accuracy: 0.8391 - val_loss: 0.0711\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.0773 - val_accuracy: 0.8418 - val_loss: 0.0684\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.0734 - val_accuracy: 0.8384 - val_loss: 0.0714\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.0738 - val_accuracy: 0.8395 - val_loss: 0.0691\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.0764 - val_accuracy: 0.8418 - val_loss: 0.0691\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.0733 - val_accuracy: 0.8437 - val_loss: 0.0686\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.0758 - val_accuracy: 0.8406 - val_loss: 0.0671\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.0722 - val_accuracy: 0.8486 - val_loss: 0.0685\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.0725 - val_accuracy: 0.8498 - val_loss: 0.0671\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8269 - loss: 0.0702 - val_accuracy: 0.8357 - val_loss: 0.0682\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0741 - val_accuracy: 0.8384 - val_loss: 0.0685\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0715 - val_accuracy: 0.8467 - val_loss: 0.0659\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0714 - val_accuracy: 0.8483 - val_loss: 0.0652\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8331 - loss: 0.0704 - val_accuracy: 0.8559 - val_loss: 0.0646\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.0707 - val_accuracy: 0.8479 - val_loss: 0.0651\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0720 - val_accuracy: 0.8540 - val_loss: 0.0649\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.0704 - val_accuracy: 0.8486 - val_loss: 0.0652\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.0715 - val_accuracy: 0.8456 - val_loss: 0.0668\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0706 - val_accuracy: 0.8525 - val_loss: 0.0642\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.0698 - val_accuracy: 0.8464 - val_loss: 0.0652\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.0714 - val_accuracy: 0.8403 - val_loss: 0.0663\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.0708 - val_accuracy: 0.8422 - val_loss: 0.0679\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.0693 - val_accuracy: 0.8384 - val_loss: 0.0676\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5969 - loss: 0.1532 - val_accuracy: 0.6995 - val_loss: 0.1087\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7053 - loss: 0.1142 - val_accuracy: 0.7372 - val_loss: 0.1043\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7360 - loss: 0.1053 - val_accuracy: 0.7670 - val_loss: 0.0932\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7546 - loss: 0.1002 - val_accuracy: 0.7670 - val_loss: 0.0941\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 0.0938 - val_accuracy: 0.8078 - val_loss: 0.0857\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 0.0912 - val_accuracy: 0.8124 - val_loss: 0.0839\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.0913 - val_accuracy: 0.8166 - val_loss: 0.0833\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.0887 - val_accuracy: 0.8070 - val_loss: 0.0802\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7910 - loss: 0.0896 - val_accuracy: 0.8200 - val_loss: 0.0776\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.0854 - val_accuracy: 0.8192 - val_loss: 0.0775\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7953 - loss: 0.0869 - val_accuracy: 0.8215 - val_loss: 0.0776\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.0895 - val_accuracy: 0.8257 - val_loss: 0.0755\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.0858 - val_accuracy: 0.8322 - val_loss: 0.0750\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.0829 - val_accuracy: 0.8253 - val_loss: 0.0754\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.0840 - val_accuracy: 0.8135 - val_loss: 0.0761\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.0813 - val_accuracy: 0.8307 - val_loss: 0.0730\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.0802 - val_accuracy: 0.8280 - val_loss: 0.0726\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.0803 - val_accuracy: 0.8177 - val_loss: 0.0739\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.0800 - val_accuracy: 0.8391 - val_loss: 0.0721\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.0806 - val_accuracy: 0.8402 - val_loss: 0.0697\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.0794 - val_accuracy: 0.8520 - val_loss: 0.0705\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 0.0770 - val_accuracy: 0.8379 - val_loss: 0.0709\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.0792 - val_accuracy: 0.8417 - val_loss: 0.0705\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.0778 - val_accuracy: 0.8345 - val_loss: 0.0710\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.0774 - val_accuracy: 0.8494 - val_loss: 0.0683\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8157 - loss: 0.0772 - val_accuracy: 0.8432 - val_loss: 0.0701\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.0750 - val_accuracy: 0.8467 - val_loss: 0.0658\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.0756 - val_accuracy: 0.8474 - val_loss: 0.0680\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.0765 - val_accuracy: 0.8383 - val_loss: 0.0685\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.0747 - val_accuracy: 0.8337 - val_loss: 0.0688\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.0733 - val_accuracy: 0.8261 - val_loss: 0.0717\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.0734 - val_accuracy: 0.8444 - val_loss: 0.0656\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.0742 - val_accuracy: 0.8413 - val_loss: 0.0660\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8238 - loss: 0.0736 - val_accuracy: 0.8501 - val_loss: 0.0659\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.0747 - val_accuracy: 0.8436 - val_loss: 0.0671\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.0744 - val_accuracy: 0.8459 - val_loss: 0.0660\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.0726 - val_accuracy: 0.8463 - val_loss: 0.0650\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.0746 - val_accuracy: 0.8494 - val_loss: 0.0660\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.0736 - val_accuracy: 0.8410 - val_loss: 0.0663\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.0714 - val_accuracy: 0.8410 - val_loss: 0.0644\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8158 - loss: 0.0770 - val_accuracy: 0.8543 - val_loss: 0.0646\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.0722 - val_accuracy: 0.8516 - val_loss: 0.0634\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.0719 - val_accuracy: 0.8448 - val_loss: 0.0639\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.0728 - val_accuracy: 0.8497 - val_loss: 0.0636\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.0696 - val_accuracy: 0.8539 - val_loss: 0.0662\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.0718 - val_accuracy: 0.8310 - val_loss: 0.0670\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0726 - val_accuracy: 0.8509 - val_loss: 0.0640\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.0705 - val_accuracy: 0.8368 - val_loss: 0.0659\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.0687 - val_accuracy: 0.8463 - val_loss: 0.0631\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.0745 - val_accuracy: 0.8604 - val_loss: 0.0622\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5959 - loss: 0.1497 - val_accuracy: 0.7590 - val_loss: 0.1036\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7019 - loss: 0.1142 - val_accuracy: 0.7685 - val_loss: 0.0994\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.1012 - val_accuracy: 0.7853 - val_loss: 0.0884\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.0960 - val_accuracy: 0.8009 - val_loss: 0.0842\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.1016 - val_accuracy: 0.7944 - val_loss: 0.0863\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.0938 - val_accuracy: 0.8169 - val_loss: 0.0815\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.0935 - val_accuracy: 0.8173 - val_loss: 0.0783\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7827 - loss: 0.0889 - val_accuracy: 0.8105 - val_loss: 0.0811\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7794 - loss: 0.0893 - val_accuracy: 0.8082 - val_loss: 0.0824\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.0854 - val_accuracy: 0.8139 - val_loss: 0.0781\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.0835 - val_accuracy: 0.8200 - val_loss: 0.0768\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.0836 - val_accuracy: 0.8330 - val_loss: 0.0769\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.0842 - val_accuracy: 0.8135 - val_loss: 0.0778\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 0.0838 - val_accuracy: 0.8204 - val_loss: 0.0737\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 0.0817 - val_accuracy: 0.8310 - val_loss: 0.0731\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.0800 - val_accuracy: 0.8341 - val_loss: 0.0713\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.0778 - val_accuracy: 0.8368 - val_loss: 0.0716\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.0802 - val_accuracy: 0.8185 - val_loss: 0.0768\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.0813 - val_accuracy: 0.8307 - val_loss: 0.0735\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.0794 - val_accuracy: 0.8429 - val_loss: 0.0696\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.0787 - val_accuracy: 0.8318 - val_loss: 0.0703\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.0778 - val_accuracy: 0.8246 - val_loss: 0.0741\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.0752 - val_accuracy: 0.8417 - val_loss: 0.0692\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.0755 - val_accuracy: 0.8421 - val_loss: 0.0685\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.0723 - val_accuracy: 0.8391 - val_loss: 0.0696\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.0785 - val_accuracy: 0.8429 - val_loss: 0.0675\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.0741 - val_accuracy: 0.8082 - val_loss: 0.0775\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8116 - loss: 0.0772 - val_accuracy: 0.8383 - val_loss: 0.0704\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0754 - val_accuracy: 0.8394 - val_loss: 0.0680\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.0718 - val_accuracy: 0.8398 - val_loss: 0.0672\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8154 - loss: 0.0758 - val_accuracy: 0.8486 - val_loss: 0.0659\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.0754 - val_accuracy: 0.8509 - val_loss: 0.0661\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.0734 - val_accuracy: 0.8497 - val_loss: 0.0667\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.0733 - val_accuracy: 0.8490 - val_loss: 0.0662\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.0726 - val_accuracy: 0.8524 - val_loss: 0.0641\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.0710 - val_accuracy: 0.8459 - val_loss: 0.0654\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.0771 - val_accuracy: 0.8524 - val_loss: 0.0640\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.0729 - val_accuracy: 0.8486 - val_loss: 0.0669\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.0770 - val_accuracy: 0.8490 - val_loss: 0.0647\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.0726 - val_accuracy: 0.8486 - val_loss: 0.0651\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.0717 - val_accuracy: 0.8509 - val_loss: 0.0662\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.0694 - val_accuracy: 0.8360 - val_loss: 0.0689\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.0723 - val_accuracy: 0.8421 - val_loss: 0.0652\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.0722 - val_accuracy: 0.8497 - val_loss: 0.0641\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.0728 - val_accuracy: 0.8524 - val_loss: 0.0659\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8303 - loss: 0.0719 - val_accuracy: 0.8322 - val_loss: 0.0689\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8354 - loss: 0.0679 - val_accuracy: 0.8432 - val_loss: 0.0662\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 0.0699 - val_accuracy: 0.8436 - val_loss: 0.0653\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.0702 - val_accuracy: 0.8486 - val_loss: 0.0647\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.0694 - val_accuracy: 0.8566 - val_loss: 0.0623\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6294 - loss: 0.1416 - val_accuracy: 0.7315 - val_loss: 0.1067\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.1121 - val_accuracy: 0.7639 - val_loss: 0.0967\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.1039 - val_accuracy: 0.7788 - val_loss: 0.0901\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.1012 - val_accuracy: 0.7975 - val_loss: 0.0852\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7720 - loss: 0.0959 - val_accuracy: 0.8097 - val_loss: 0.0838\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7743 - loss: 0.0933 - val_accuracy: 0.7952 - val_loss: 0.0856\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.0916 - val_accuracy: 0.8024 - val_loss: 0.0784\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.0911 - val_accuracy: 0.8139 - val_loss: 0.0777\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.0886 - val_accuracy: 0.8242 - val_loss: 0.0775\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.0855 - val_accuracy: 0.8116 - val_loss: 0.0778\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.0859 - val_accuracy: 0.8242 - val_loss: 0.0742\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.0858 - val_accuracy: 0.8093 - val_loss: 0.0784\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.0849 - val_accuracy: 0.8272 - val_loss: 0.0762\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8066 - loss: 0.0834 - val_accuracy: 0.8383 - val_loss: 0.0726\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.0846 - val_accuracy: 0.8291 - val_loss: 0.0723\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.0807 - val_accuracy: 0.8341 - val_loss: 0.0722\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.0802 - val_accuracy: 0.8177 - val_loss: 0.0763\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.0798 - val_accuracy: 0.8330 - val_loss: 0.0699\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.0794 - val_accuracy: 0.8413 - val_loss: 0.0685\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8157 - loss: 0.0774 - val_accuracy: 0.8349 - val_loss: 0.0696\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.0780 - val_accuracy: 0.8406 - val_loss: 0.0694\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.0784 - val_accuracy: 0.8406 - val_loss: 0.0689\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.0787 - val_accuracy: 0.8402 - val_loss: 0.0696\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.0773 - val_accuracy: 0.8406 - val_loss: 0.0668\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.0762 - val_accuracy: 0.8398 - val_loss: 0.0673\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.0769 - val_accuracy: 0.8455 - val_loss: 0.0668\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.0768 - val_accuracy: 0.8421 - val_loss: 0.0685\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.0779 - val_accuracy: 0.8471 - val_loss: 0.0673\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.0762 - val_accuracy: 0.8459 - val_loss: 0.0652\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.0745 - val_accuracy: 0.8432 - val_loss: 0.0673\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.0791 - val_accuracy: 0.8402 - val_loss: 0.0656\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.0772 - val_accuracy: 0.8440 - val_loss: 0.0656\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8234 - loss: 0.0751 - val_accuracy: 0.8432 - val_loss: 0.0649\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.0730 - val_accuracy: 0.8455 - val_loss: 0.0666\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8292 - loss: 0.0722 - val_accuracy: 0.8448 - val_loss: 0.0641\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.0714 - val_accuracy: 0.8413 - val_loss: 0.0637\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.0735 - val_accuracy: 0.8505 - val_loss: 0.0645\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.0731 - val_accuracy: 0.8509 - val_loss: 0.0632\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.0720 - val_accuracy: 0.8379 - val_loss: 0.0662\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.0744 - val_accuracy: 0.8509 - val_loss: 0.0647\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.0716 - val_accuracy: 0.8478 - val_loss: 0.0639\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8193 - loss: 0.0756 - val_accuracy: 0.8463 - val_loss: 0.0635\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.0748 - val_accuracy: 0.8513 - val_loss: 0.0645\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.0716 - val_accuracy: 0.8562 - val_loss: 0.0627\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0714 - val_accuracy: 0.8532 - val_loss: 0.0618\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.0704 - val_accuracy: 0.8463 - val_loss: 0.0634\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.0720 - val_accuracy: 0.8535 - val_loss: 0.0623\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.0680 - val_accuracy: 0.8494 - val_loss: 0.0635\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.0707 - val_accuracy: 0.8402 - val_loss: 0.0654\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 0.0690 - val_accuracy: 0.8547 - val_loss: 0.0610\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.8533\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7256\n",
      "Macro Recall: 0.5809\n",
      "Macro F1-Score: 0.6141\n",
      "Macro AUC-ROC: 0.9212\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.8350\n",
      "Weighted Recall: 0.8533\n",
      "Weighted F1-Score: 0.8340\n",
      "Weighted AUC-ROC: 0.9501\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.792956        0.823667          0.807053     0.956155\n",
      "1      1           0.330087        0.029598          0.052563     0.879962\n",
      "2      2           0.818016        0.473193          0.596202     0.902252\n",
      "3      3           0.803839        0.603593          0.688052     0.906590\n",
      "4      4           0.883306        0.974304          0.926381     0.961113\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2      3       4\n",
      "0  494.2  0.6   6.0    2.8    96.4\n",
      "1   53.0  2.6   2.0    5.4    24.6\n",
      "2   33.8  0.8  77.8    8.8    43.2\n",
      "3   18.2  2.0   2.6  100.8    43.4\n",
      "4   25.0  0.6   7.4    8.2  1562.2\n",
      "\n",
      "Processing week4 with best parameters...\n",
      "best parameters for week4: {'units_1': 224, 'dropout_1': 0.2, 'learning_rate': 0.0005818542202431094}\n",
      "Fold 1: Using file /kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6211 - loss: 0.1390 - val_accuracy: 0.7453 - val_loss: 0.0993\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7352 - loss: 0.1047 - val_accuracy: 0.7979 - val_loss: 0.0853\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.0889 - val_accuracy: 0.7922 - val_loss: 0.0851\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.0873 - val_accuracy: 0.8300 - val_loss: 0.0760\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.0800 - val_accuracy: 0.8273 - val_loss: 0.0726\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0753 - val_accuracy: 0.7899 - val_loss: 0.0806\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.0766 - val_accuracy: 0.8490 - val_loss: 0.0681\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.0724 - val_accuracy: 0.8517 - val_loss: 0.0668\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.0731 - val_accuracy: 0.8490 - val_loss: 0.0642\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.0676 - val_accuracy: 0.8368 - val_loss: 0.0682\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.0677 - val_accuracy: 0.8220 - val_loss: 0.0772\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.0696 - val_accuracy: 0.8578 - val_loss: 0.0598\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.0700 - val_accuracy: 0.8540 - val_loss: 0.0607\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.0683 - val_accuracy: 0.8586 - val_loss: 0.0583\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.0656 - val_accuracy: 0.8521 - val_loss: 0.0589\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.0638 - val_accuracy: 0.8563 - val_loss: 0.0572\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.0634 - val_accuracy: 0.8605 - val_loss: 0.0580\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 0.0646 - val_accuracy: 0.8616 - val_loss: 0.0557\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.0649 - val_accuracy: 0.8639 - val_loss: 0.0552\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 0.0638 - val_accuracy: 0.8601 - val_loss: 0.0581\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.0622 - val_accuracy: 0.8689 - val_loss: 0.0540\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8480 - loss: 0.0627 - val_accuracy: 0.8685 - val_loss: 0.0550\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8452 - loss: 0.0609 - val_accuracy: 0.8700 - val_loss: 0.0528\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8496 - loss: 0.0597 - val_accuracy: 0.8708 - val_loss: 0.0513\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.0585 - val_accuracy: 0.8795 - val_loss: 0.0528\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.0598 - val_accuracy: 0.8715 - val_loss: 0.0517\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.0604 - val_accuracy: 0.8738 - val_loss: 0.0502\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.0560 - val_accuracy: 0.8700 - val_loss: 0.0517\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.0565 - val_accuracy: 0.8757 - val_loss: 0.0496\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.0572 - val_accuracy: 0.8582 - val_loss: 0.0532\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.0591 - val_accuracy: 0.8715 - val_loss: 0.0510\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 0.0579 - val_accuracy: 0.8658 - val_loss: 0.0540\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.0593 - val_accuracy: 0.8776 - val_loss: 0.0492\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8626 - loss: 0.0559 - val_accuracy: 0.8677 - val_loss: 0.0500\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.0576 - val_accuracy: 0.8700 - val_loss: 0.0516\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 0.0525 - val_accuracy: 0.8711 - val_loss: 0.0508\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.0549 - val_accuracy: 0.8734 - val_loss: 0.0485\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.0554 - val_accuracy: 0.8765 - val_loss: 0.0492\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8688 - loss: 0.0528 - val_accuracy: 0.8753 - val_loss: 0.0490\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.0534 - val_accuracy: 0.8772 - val_loss: 0.0472\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 0.0563 - val_accuracy: 0.8765 - val_loss: 0.0468\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.0536 - val_accuracy: 0.8738 - val_loss: 0.0471\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.0524 - val_accuracy: 0.8727 - val_loss: 0.0483\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.0530 - val_accuracy: 0.8822 - val_loss: 0.0459\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8675 - loss: 0.0529 - val_accuracy: 0.8750 - val_loss: 0.0465\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 0.0516 - val_accuracy: 0.8833 - val_loss: 0.0466\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.0521 - val_accuracy: 0.8841 - val_loss: 0.0449\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.0517 - val_accuracy: 0.8730 - val_loss: 0.0475\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.0509 - val_accuracy: 0.8750 - val_loss: 0.0485\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8713 - loss: 0.0511 - val_accuracy: 0.8864 - val_loss: 0.0458\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6341 - loss: 0.1357 - val_accuracy: 0.7362 - val_loss: 0.1023\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7280 - loss: 0.1040 - val_accuracy: 0.8025 - val_loss: 0.0910\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7688 - loss: 0.0932 - val_accuracy: 0.8090 - val_loss: 0.0836\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.0882 - val_accuracy: 0.8281 - val_loss: 0.0780\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.0818 - val_accuracy: 0.7934 - val_loss: 0.0842\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8032 - loss: 0.0786 - val_accuracy: 0.8349 - val_loss: 0.0773\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8278 - loss: 0.0746 - val_accuracy: 0.8361 - val_loss: 0.0724\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.0747 - val_accuracy: 0.8262 - val_loss: 0.0713\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 0.0696 - val_accuracy: 0.8265 - val_loss: 0.0714\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.0688 - val_accuracy: 0.8273 - val_loss: 0.0713\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.0693 - val_accuracy: 0.8342 - val_loss: 0.0682\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.0701 - val_accuracy: 0.8490 - val_loss: 0.0655\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.0637 - val_accuracy: 0.8467 - val_loss: 0.0652\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.0635 - val_accuracy: 0.8483 - val_loss: 0.0633\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 0.0674 - val_accuracy: 0.8513 - val_loss: 0.0630\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8467 - loss: 0.0651 - val_accuracy: 0.8536 - val_loss: 0.0623\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.0628 - val_accuracy: 0.8498 - val_loss: 0.0636\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.0577 - val_accuracy: 0.8506 - val_loss: 0.0609\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.0593 - val_accuracy: 0.8483 - val_loss: 0.0662\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.0643 - val_accuracy: 0.8536 - val_loss: 0.0608\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.0623 - val_accuracy: 0.8555 - val_loss: 0.0589\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.0614 - val_accuracy: 0.8418 - val_loss: 0.0617\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8539 - loss: 0.0598 - val_accuracy: 0.8528 - val_loss: 0.0593\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.0589 - val_accuracy: 0.8578 - val_loss: 0.0579\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 0.0579 - val_accuracy: 0.8582 - val_loss: 0.0587\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8558 - loss: 0.0589 - val_accuracy: 0.8544 - val_loss: 0.0588\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.0591 - val_accuracy: 0.8551 - val_loss: 0.0564\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8556 - loss: 0.0578 - val_accuracy: 0.8467 - val_loss: 0.0592\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.0585 - val_accuracy: 0.8559 - val_loss: 0.0569\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0593 - val_accuracy: 0.8582 - val_loss: 0.0575\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.0568 - val_accuracy: 0.8628 - val_loss: 0.0554\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8630 - loss: 0.0552 - val_accuracy: 0.8643 - val_loss: 0.0560\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.0561 - val_accuracy: 0.8605 - val_loss: 0.0559\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0558 - val_accuracy: 0.8631 - val_loss: 0.0533\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.0543 - val_accuracy: 0.8677 - val_loss: 0.0548\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.0542 - val_accuracy: 0.8639 - val_loss: 0.0547\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.0555 - val_accuracy: 0.8692 - val_loss: 0.0553\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.0544 - val_accuracy: 0.8708 - val_loss: 0.0523\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.0528 - val_accuracy: 0.8677 - val_loss: 0.0526\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.0527 - val_accuracy: 0.8681 - val_loss: 0.0536\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.0529 - val_accuracy: 0.8601 - val_loss: 0.0544\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.0549 - val_accuracy: 0.8620 - val_loss: 0.0533\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8641 - loss: 0.0537 - val_accuracy: 0.8448 - val_loss: 0.0594\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8639 - loss: 0.0550 - val_accuracy: 0.8719 - val_loss: 0.0524\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8656 - loss: 0.0531 - val_accuracy: 0.8662 - val_loss: 0.0550\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.0529 - val_accuracy: 0.8708 - val_loss: 0.0517\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8790 - loss: 0.0483 - val_accuracy: 0.8620 - val_loss: 0.0522\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8694 - loss: 0.0520 - val_accuracy: 0.8692 - val_loss: 0.0516\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.0522 - val_accuracy: 0.8708 - val_loss: 0.0511\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.0524 - val_accuracy: 0.8681 - val_loss: 0.0498\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6310 - loss: 0.1372 - val_accuracy: 0.7380 - val_loss: 0.1017\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 0.1027 - val_accuracy: 0.7788 - val_loss: 0.0911\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.0855 - val_accuracy: 0.8089 - val_loss: 0.0829\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.0853 - val_accuracy: 0.8356 - val_loss: 0.0763\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.0811 - val_accuracy: 0.8291 - val_loss: 0.0729\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.0763 - val_accuracy: 0.8200 - val_loss: 0.0740\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.0740 - val_accuracy: 0.8219 - val_loss: 0.0759\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.0735 - val_accuracy: 0.8391 - val_loss: 0.0678\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 0.0727 - val_accuracy: 0.8410 - val_loss: 0.0675\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8342 - loss: 0.0696 - val_accuracy: 0.8474 - val_loss: 0.0670\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.0687 - val_accuracy: 0.8516 - val_loss: 0.0648\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8381 - loss: 0.0691 - val_accuracy: 0.8383 - val_loss: 0.0645\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8441 - loss: 0.0660 - val_accuracy: 0.8555 - val_loss: 0.0613\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.0698 - val_accuracy: 0.8558 - val_loss: 0.0623\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.0657 - val_accuracy: 0.8520 - val_loss: 0.0602\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.0637 - val_accuracy: 0.8543 - val_loss: 0.0612\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.0644 - val_accuracy: 0.8547 - val_loss: 0.0607\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.0657 - val_accuracy: 0.8555 - val_loss: 0.0601\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.0614 - val_accuracy: 0.8566 - val_loss: 0.0582\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.0635 - val_accuracy: 0.8593 - val_loss: 0.0574\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.0650 - val_accuracy: 0.8127 - val_loss: 0.0724\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.0642 - val_accuracy: 0.8715 - val_loss: 0.0555\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.0608 - val_accuracy: 0.8673 - val_loss: 0.0553\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.0623 - val_accuracy: 0.8558 - val_loss: 0.0583\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.0589 - val_accuracy: 0.8623 - val_loss: 0.0553\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.0582 - val_accuracy: 0.8604 - val_loss: 0.0540\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.0574 - val_accuracy: 0.8417 - val_loss: 0.0595\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 0.0584 - val_accuracy: 0.8566 - val_loss: 0.0565\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.0562 - val_accuracy: 0.8616 - val_loss: 0.0528\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8591 - loss: 0.0546 - val_accuracy: 0.8692 - val_loss: 0.0532\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.0588 - val_accuracy: 0.8333 - val_loss: 0.0603\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8567 - loss: 0.0561 - val_accuracy: 0.8654 - val_loss: 0.0545\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.0540 - val_accuracy: 0.8677 - val_loss: 0.0511\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.0538 - val_accuracy: 0.8734 - val_loss: 0.0525\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.0556 - val_accuracy: 0.8688 - val_loss: 0.0508\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.0544 - val_accuracy: 0.8604 - val_loss: 0.0541\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.0536 - val_accuracy: 0.8730 - val_loss: 0.0500\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.0539 - val_accuracy: 0.8738 - val_loss: 0.0489\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.0533 - val_accuracy: 0.8619 - val_loss: 0.0532\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.0539 - val_accuracy: 0.8631 - val_loss: 0.0536\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.0523 - val_accuracy: 0.8730 - val_loss: 0.0516\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.0546 - val_accuracy: 0.8768 - val_loss: 0.0495\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8664 - loss: 0.0528 - val_accuracy: 0.8738 - val_loss: 0.0486\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.0508 - val_accuracy: 0.8696 - val_loss: 0.0500\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8705 - loss: 0.0512 - val_accuracy: 0.8726 - val_loss: 0.0499\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.0499 - val_accuracy: 0.8757 - val_loss: 0.0502\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.0512 - val_accuracy: 0.8799 - val_loss: 0.0480\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.0537 - val_accuracy: 0.8593 - val_loss: 0.0544\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8626 - loss: 0.0528 - val_accuracy: 0.8593 - val_loss: 0.0541\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8687 - loss: 0.0507 - val_accuracy: 0.8741 - val_loss: 0.0515\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 4: Using file /kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6558 - loss: 0.1303 - val_accuracy: 0.7429 - val_loss: 0.0994\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7499 - loss: 0.1018 - val_accuracy: 0.7792 - val_loss: 0.0916\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7845 - loss: 0.0921 - val_accuracy: 0.8139 - val_loss: 0.0794\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.0847 - val_accuracy: 0.8158 - val_loss: 0.0773\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.0834 - val_accuracy: 0.8211 - val_loss: 0.0758\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.0755 - val_accuracy: 0.8207 - val_loss: 0.0751\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.0733 - val_accuracy: 0.8463 - val_loss: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8331 - loss: 0.0721 - val_accuracy: 0.8429 - val_loss: 0.0699\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 0.0725 - val_accuracy: 0.8402 - val_loss: 0.0715\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.0685 - val_accuracy: 0.8486 - val_loss: 0.0677\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.0715 - val_accuracy: 0.8463 - val_loss: 0.0686\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8384 - loss: 0.0687 - val_accuracy: 0.8604 - val_loss: 0.0664\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.0670 - val_accuracy: 0.8574 - val_loss: 0.0628\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8492 - loss: 0.0629 - val_accuracy: 0.8410 - val_loss: 0.0695\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 0.0649 - val_accuracy: 0.8421 - val_loss: 0.0663\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.0624 - val_accuracy: 0.8291 - val_loss: 0.0698\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.0646 - val_accuracy: 0.8543 - val_loss: 0.0630\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.0650 - val_accuracy: 0.8654 - val_loss: 0.0587\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.0613 - val_accuracy: 0.8524 - val_loss: 0.0609\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.0606 - val_accuracy: 0.8547 - val_loss: 0.0582\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.0608 - val_accuracy: 0.8619 - val_loss: 0.0606\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 0.0596 - val_accuracy: 0.8600 - val_loss: 0.0586\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8453 - loss: 0.0613 - val_accuracy: 0.8455 - val_loss: 0.0643\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.0585 - val_accuracy: 0.8455 - val_loss: 0.0632\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.0605 - val_accuracy: 0.8596 - val_loss: 0.0599\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.0564 - val_accuracy: 0.8673 - val_loss: 0.0558\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8524 - loss: 0.0598 - val_accuracy: 0.8715 - val_loss: 0.0555\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 0.0567 - val_accuracy: 0.8486 - val_loss: 0.0579\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.0562 - val_accuracy: 0.8661 - val_loss: 0.0569\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.0565 - val_accuracy: 0.8711 - val_loss: 0.0539\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.0577 - val_accuracy: 0.8574 - val_loss: 0.0617\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8539 - loss: 0.0584 - val_accuracy: 0.8722 - val_loss: 0.0552\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.0560 - val_accuracy: 0.8684 - val_loss: 0.0560\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.0567 - val_accuracy: 0.8726 - val_loss: 0.0552\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.0560 - val_accuracy: 0.8654 - val_loss: 0.0581\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.0546 - val_accuracy: 0.8654 - val_loss: 0.0557\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8564 - loss: 0.0556 - val_accuracy: 0.8730 - val_loss: 0.0534\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.0522 - val_accuracy: 0.8741 - val_loss: 0.0526\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.0556 - val_accuracy: 0.8604 - val_loss: 0.0531\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.0537 - val_accuracy: 0.8631 - val_loss: 0.0548\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.0542 - val_accuracy: 0.8730 - val_loss: 0.0555\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8611 - loss: 0.0546 - val_accuracy: 0.8516 - val_loss: 0.0567\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.0537 - val_accuracy: 0.8749 - val_loss: 0.0545\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.0514 - val_accuracy: 0.8650 - val_loss: 0.0555\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.0536 - val_accuracy: 0.8791 - val_loss: 0.0521\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8711 - loss: 0.0511 - val_accuracy: 0.8738 - val_loss: 0.0515\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.0530 - val_accuracy: 0.8768 - val_loss: 0.0543\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.0502 - val_accuracy: 0.8844 - val_loss: 0.0502\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.0507 - val_accuracy: 0.8787 - val_loss: 0.0516\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.0494 - val_accuracy: 0.8814 - val_loss: 0.0486\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6466 - loss: 0.1321 - val_accuracy: 0.7193 - val_loss: 0.1047\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.1036 - val_accuracy: 0.7818 - val_loss: 0.0893\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.0930 - val_accuracy: 0.8085 - val_loss: 0.0837\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7936 - loss: 0.0885 - val_accuracy: 0.8154 - val_loss: 0.0780\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8019 - loss: 0.0821 - val_accuracy: 0.8303 - val_loss: 0.0734\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.0791 - val_accuracy: 0.8452 - val_loss: 0.0700\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.0766 - val_accuracy: 0.8486 - val_loss: 0.0686\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.0741 - val_accuracy: 0.8028 - val_loss: 0.0776\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.0747 - val_accuracy: 0.8482 - val_loss: 0.0664\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.0745 - val_accuracy: 0.8543 - val_loss: 0.0647\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.0690 - val_accuracy: 0.8486 - val_loss: 0.0659\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.0684 - val_accuracy: 0.8432 - val_loss: 0.0649\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.0651 - val_accuracy: 0.8532 - val_loss: 0.0632\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.0682 - val_accuracy: 0.8398 - val_loss: 0.0639\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.0682 - val_accuracy: 0.8516 - val_loss: 0.0602\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.0671 - val_accuracy: 0.8535 - val_loss: 0.0589\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.0660 - val_accuracy: 0.8513 - val_loss: 0.0604\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.0616 - val_accuracy: 0.8642 - val_loss: 0.0572\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.0627 - val_accuracy: 0.8535 - val_loss: 0.0616\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.0654 - val_accuracy: 0.8589 - val_loss: 0.0594\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.0641 - val_accuracy: 0.8482 - val_loss: 0.0596\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.0612 - val_accuracy: 0.8623 - val_loss: 0.0590\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.0604 - val_accuracy: 0.8650 - val_loss: 0.0573\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8575 - loss: 0.0594 - val_accuracy: 0.8627 - val_loss: 0.0556\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.0598 - val_accuracy: 0.8665 - val_loss: 0.0553\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 0.0573 - val_accuracy: 0.8604 - val_loss: 0.0556\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.0596 - val_accuracy: 0.8631 - val_loss: 0.0560\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 0.0581 - val_accuracy: 0.8654 - val_loss: 0.0550\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0578 - val_accuracy: 0.8631 - val_loss: 0.0533\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.0564 - val_accuracy: 0.8562 - val_loss: 0.0568\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 0.0577 - val_accuracy: 0.8516 - val_loss: 0.0610\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.0563 - val_accuracy: 0.8680 - val_loss: 0.0530\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 0.0582 - val_accuracy: 0.8635 - val_loss: 0.0544\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 0.0570 - val_accuracy: 0.8612 - val_loss: 0.0551\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.0544 - val_accuracy: 0.8757 - val_loss: 0.0512\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8538 - loss: 0.0570 - val_accuracy: 0.8688 - val_loss: 0.0530\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.0529 - val_accuracy: 0.8673 - val_loss: 0.0544\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.0558 - val_accuracy: 0.8696 - val_loss: 0.0510\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.0529 - val_accuracy: 0.8673 - val_loss: 0.0510\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.0544 - val_accuracy: 0.8627 - val_loss: 0.0521\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.0537 - val_accuracy: 0.8692 - val_loss: 0.0508\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.0523 - val_accuracy: 0.8638 - val_loss: 0.0527\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 0.0554 - val_accuracy: 0.8677 - val_loss: 0.0506\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8642 - loss: 0.0538 - val_accuracy: 0.8867 - val_loss: 0.0485\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.0509 - val_accuracy: 0.8699 - val_loss: 0.0519\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.0533 - val_accuracy: 0.8776 - val_loss: 0.0490\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.0528 - val_accuracy: 0.8764 - val_loss: 0.0500\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.0516 - val_accuracy: 0.8745 - val_loss: 0.0493\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.0529 - val_accuracy: 0.8802 - val_loss: 0.0474\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.0546 - val_accuracy: 0.8806 - val_loss: 0.0461\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.8781\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7967\n",
      "Macro Recall: 0.6626\n",
      "Macro F1-Score: 0.7007\n",
      "Macro AUC-ROC: 0.9499\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.8726\n",
      "Weighted Recall: 0.8781\n",
      "Weighted F1-Score: 0.8688\n",
      "Weighted AUC-ROC: 0.9680\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.822843        0.874667          0.847813     0.972721\n",
      "1      1           0.668419        0.251149          0.353038     0.931244\n",
      "2      2           0.793911        0.526785          0.631372     0.935575\n",
      "3      3           0.778056        0.691018          0.727298     0.934850\n",
      "4      4           0.920219        0.969191          0.943991     0.975081\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2      3       4\n",
      "0  524.8   6.8   7.0    3.6    57.8\n",
      "1   45.8  22.0   3.6    3.0    13.2\n",
      "2   34.0   1.4  86.6   12.8    29.6\n",
      "3   12.4   2.0   2.8  115.4    34.4\n",
      "4   21.0   2.4  10.0   16.0  1554.0\n"
     ]
    }
   ],
   "source": [
    "# Biến lưu kết quả tổng quát\n",
    "overall_results_5folds = []\n",
    "\n",
    "# Lặp qua từng tuần\n",
    "for week, file_paths in five_fold_files.items():\n",
    "    print(f\"\\nProcessing {week} with best parameters...\")\n",
    "    params = best_params[week].values\n",
    "    print(f\"best parameters for {week}: {params}\")\n",
    "    \n",
    "    # Biến lưu kết quả cho từng tuần\n",
    "    week_results = {\n",
    "        \"week\": week,\n",
    "        \"accuracy_per_fold\": [],\n",
    "        \"precision_per_label\": [],\n",
    "        \"recall_per_label\": [],\n",
    "        \"f1_score_per_label\": [],\n",
    "        \"auc_roc_per_label\": [],    # AUC từng lớp\n",
    "        \"auc_roc_macro\": [],        # AUC macro\n",
    "        \"auc_roc_weighted\": [],     # AUC weighted (tự tính)\n",
    "        \"precision_macro\": [],\n",
    "        \"recall_macro\": [],\n",
    "        \"f1_macro\": [],\n",
    "        \"precision_weighted\": [],\n",
    "        \"recall_weighted\": [],\n",
    "        \"f1_weighted\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"train_times\": [],\n",
    "        \"test_times\": []\n",
    "    }\n",
    "\n",
    "    # Lặp qua từng fold\n",
    "    for i in range(len(file_paths)):\n",
    "        print(f\"Fold {i+1}: Using file {file_paths[i]} as test set\")\n",
    "        \n",
    "        # Tải dữ liệu\n",
    "        test_data = pd.read_csv(file_paths[i])\n",
    "        train_data = pd.concat([pd.read_csv(file_paths[j]) for j in range(len(file_paths)) if j != i])\n",
    "        \n",
    "        # Tách X và y\n",
    "        X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                           \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_train = to_categorical(train_data['classification_encoded'], num_classes=5)\n",
    "        \n",
    "        X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                         \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_test = to_categorical(test_data['classification_encoded'], num_classes=5)\n",
    "\n",
    "        # Reshape dữ liệu cho LSTM\n",
    "        X_train = X_train.to_numpy().reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        # Xây dựng mô hình với tham số tốt nhất\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        model = build_Bilstm_model(params, input_shape)\n",
    "        \n",
    "        # Bắt đầu tính thời gian huấn luyện\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)\n",
    "        end_train = time.time()\n",
    "        \n",
    "        # Bắt đầu tính thời gian kiểm thử\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        \n",
    "        # Tính thời gian và lưu lại\n",
    "        train_time = end_train - start_train\n",
    "        test_time = end_test - start_test\n",
    "        week_results[\"train_times\"].append(train_time)\n",
    "        week_results[\"test_times\"].append(test_time)\n",
    "\n",
    "        # Đánh giá mô hình trên tập kiểm thử của fold hiện tại\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        week_results[\"accuracy_per_fold\"].append(accuracy)\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_test_classes = y_test.argmax(axis=1)\n",
    "        \n",
    "        # Tính các chỉ số cho mỗi fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "        conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "        \n",
    "        # Tính AUC-ROC\n",
    "        try:\n",
    "            # Tính AUC macro và theo từng lớp với OvR\n",
    "            auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "            # Tính AUC weighted: tính trọng số theo số mẫu của từng lớp\n",
    "            supports = np.bincount(y_test_classes, minlength=5)\n",
    "            auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tính AUC: {e}\")\n",
    "            auc_macro = np.nan\n",
    "            auc_per_class = [np.nan] * 5\n",
    "            auc_weighted = np.nan\n",
    "            \n",
    "        # Lưu kết quả của fold hiện tại\n",
    "        week_results[\"precision_per_label\"].append(precision)\n",
    "        week_results[\"recall_per_label\"].append(recall)\n",
    "        week_results[\"f1_score_per_label\"].append(f1)\n",
    "        week_results[\"auc_roc_per_label\"].append(auc_per_class)  # AUC từng lớp\n",
    "        week_results[\"auc_roc_macro\"].append(auc_macro)          # AUC macro\n",
    "        week_results[\"auc_roc_weighted\"].append(auc_weighted)      # AUC weighted\n",
    "        week_results[\"confusion_matrices\"].append(conf_matrix)\n",
    "        week_results[\"precision_macro\"].append(precision_macro)\n",
    "        week_results[\"recall_macro\"].append(recall_macro)\n",
    "        week_results[\"f1_macro\"].append(f1_macro)\n",
    "        week_results[\"precision_weighted\"].append(precision_weighted)\n",
    "        week_results[\"recall_weighted\"].append(recall_weighted)\n",
    "        week_results[\"f1_weighted\"].append(f1_weighted)\n",
    "\n",
    "    # Tính trung bình cho từng nhãn\n",
    "    average_precision_per_label = np.mean(week_results[\"precision_per_label\"], axis=0)\n",
    "    average_recall_per_label = np.nanmean(week_results[\"recall_per_label\"], axis=0)\n",
    "    average_f1_per_label = np.nanmean(week_results[\"f1_score_per_label\"], axis=0)\n",
    "    average_auc_per_label = np.nanmean(week_results[\"auc_roc_per_label\"], axis=0)\n",
    "    average_confusion_matrix = np.nanmean(week_results[\"confusion_matrices\"], axis=0)\n",
    "    average_train_time = sum(week_results[\"train_times\"]) / len(week_results[\"train_times\"])\n",
    "    average_test_time = sum(week_results[\"test_times\"]) / len(week_results[\"test_times\"])\n",
    "    average_accuracy = np.nanmean(week_results[\"accuracy_per_fold\"])\n",
    "    average_precision_macro = np.nanmean(week_results[\"precision_macro\"])\n",
    "    average_recall_macro = np.nanmean(week_results[\"recall_macro\"])\n",
    "    average_f1_macro = np.nanmean(week_results[\"f1_macro\"])\n",
    "    average_auc_macro = np.nanmean(week_results[\"auc_roc_macro\"])\n",
    "    average_precision_weighted = np.nanmean(week_results[\"precision_weighted\"])\n",
    "    average_recall_weighted = np.nanmean(week_results[\"recall_weighted\"])\n",
    "    average_f1_weighted = np.nanmean(week_results[\"f1_weighted\"])\n",
    "    average_auc_weighted = np.nanmean(week_results[\"auc_roc_weighted\"])\n",
    "\n",
    "\n",
    "    # Tạo DataFrame cho precision, recall, f1-score\n",
    "    labels = np.unique(y_test_classes)  # Lấy nhãn từ y_test_classes\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Average Precision\": average_precision_per_label,\n",
    "        \"Average Recall\": average_recall_per_label,\n",
    "        \"Average F1-Score\": average_f1_per_label,\n",
    "        \"Average AUC\": average_auc_per_label\n",
    "    })\n",
    "    \n",
    "    # Tạo DataFrame cho confusion matrix\n",
    "    confusion_df = pd.DataFrame(average_confusion_matrix, index=labels, columns=labels)\n",
    "    # In kết quả Accuracy và Macro metrics\n",
    "    print(\"\\n=== Average Accuracy ===\")\n",
    "    print(f\"{average_accuracy:.4f}\")\n",
    "    print(\"\\n=== Average Macro Metrics ===\")\n",
    "    print(f\"Macro Precision: {average_precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {average_recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {average_f1_macro:.4f}\")\n",
    "    print(f\"Macro AUC-ROC: {average_auc_macro:.4f}\")\n",
    "    print(\"\\n=== Average Weighted Metrics ===\")\n",
    "    print(f\"Weighted Precision: {average_precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {average_recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {average_f1_weighted:.4f}\")\n",
    "    print(f\"Weighted AUC-ROC: {average_auc_weighted:.4f}\")\n",
    "    print(\"\\n=== Average Metrics per Label ===\")\n",
    "    print(metrics_df)\n",
    "    print(\"\\n=== Average Confusion Matrix ===\")\n",
    "    print(confusion_df)\n",
    "    \n",
    "    # Cập nhật kết quả cho tuần hiện tại\n",
    "    week_results.update({\n",
    "        \"average_accuracy\": average_accuracy,\n",
    "        \"average_precision_macro\": average_precision_macro,\n",
    "        \"average_recall_macro\": average_recall_macro,\n",
    "        \"average_f1_macro\": average_f1_macro,\n",
    "        \"average_auc_macro\": average_auc_macro,\n",
    "        \"average_precision_weighted\": average_precision_weighted,\n",
    "        \"average_recall_weighted\": average_recall_weighted,\n",
    "        \"average_f1_weighted\": average_f1_weighted,\n",
    "        \"average_auc_weighted\": average_auc_weighted,\n",
    "        \"average_metrics_df\": metrics_df,\n",
    "        \"average_confusion_matrix\": confusion_df,\n",
    "        \"average_train_times\": average_train_time,\n",
    "        \"average_test_times\": average_test_time,\n",
    "    })\n",
    "    overall_results_5folds.append(week_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5d799",
   "metadata": {
    "papermill": {
     "duration": 1.502381,
     "end_time": "2025-04-05T11:16:26.336724",
     "exception": false,
     "start_time": "2025-04-05T11:16:24.834343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kết quả cross validation trên 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a24ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:16:29.336563Z",
     "iopub.status.busy": "2025-04-05T11:16:29.336219Z",
     "iopub.status.idle": "2025-04-05T11:16:29.365556Z",
     "shell.execute_reply": "2025-04-05T11:16:29.364907Z"
    },
    "papermill": {
     "duration": 1.462765,
     "end_time": "2025-04-05T11:16:29.367134",
     "exception": false,
     "start_time": "2025-04-05T11:16:27.904369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for week1 ===\n",
      "Average Accurancy: 0.8781270384788513\n",
      "Average Train Time: 85.4354 seconds\n",
      "Average Test Time: 0.5008 seconds\n",
      "Average AUC Macro: 0.9498943122515197\n",
      "Average AUC Weighted: 0.9680365002600959\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.715229        0.566000          0.629308     0.867114\n",
      "1      1           0.000000        0.000000          0.000000     0.778681\n",
      "2      2           0.714760        0.424405          0.520309     0.847547\n",
      "3      3           0.733997        0.269461          0.389351     0.865818\n",
      "4      4           0.780164        0.962202          0.861121     0.908830\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2     3       4\n",
      "0  339.6  0.0  13.2   6.8   240.4\n",
      "1   32.2  0.0   1.4   2.4    51.6\n",
      "2   25.8  0.0  69.8   2.4    66.4\n",
      "3   40.6  0.0   2.4  45.0    79.0\n",
      "4   40.8  0.0  14.2   5.6  1542.8\n",
      "\n",
      "=== Results for week2 ===\n",
      "Average Accurancy: 0.8781270384788513\n",
      "Average Train Time: 84.9007 seconds\n",
      "Average Test Time: 0.6794 seconds\n",
      "Average AUC Macro: 0.9498943122515197\n",
      "Average AUC Weighted: 0.9680365002600959\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.790471        0.808000          0.794173     0.951816\n",
      "1      1           0.742895        0.112173          0.181328     0.893192\n",
      "2      2           0.844415        0.440421          0.575823     0.906485\n",
      "3      3           0.732128        0.632335          0.678386     0.915382\n",
      "4      4           0.880731        0.962457          0.919063     0.959114\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2      3       4\n",
      "0  484.8  2.4   4.8    4.2   103.8\n",
      "1   51.8  9.8   1.4    3.8    20.8\n",
      "2   32.4  1.6  72.4   12.0    46.0\n",
      "3   15.6  1.6   2.2  105.6    42.0\n",
      "4   36.4  0.2   5.0   18.6  1543.2\n",
      "\n",
      "=== Results for week3 ===\n",
      "Average Accurancy: 0.8781270384788513\n",
      "Average Train Time: 85.5143 seconds\n",
      "Average Test Time: 0.5047 seconds\n",
      "Average AUC Macro: 0.9498943122515197\n",
      "Average AUC Weighted: 0.9680365002600959\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.792956        0.823667          0.807053     0.956155\n",
      "1      1           0.330087        0.029598          0.052563     0.879962\n",
      "2      2           0.818016        0.473193          0.596202     0.902252\n",
      "3      3           0.803839        0.603593          0.688052     0.906590\n",
      "4      4           0.883306        0.974304          0.926381     0.961113\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2      3       4\n",
      "0  494.2  0.6   6.0    2.8    96.4\n",
      "1   53.0  2.6   2.0    5.4    24.6\n",
      "2   33.8  0.8  77.8    8.8    43.2\n",
      "3   18.2  2.0   2.6  100.8    43.4\n",
      "4   25.0  0.6   7.4    8.2  1562.2\n",
      "\n",
      "=== Results for week4 ===\n",
      "Average Accurancy: 0.8781270384788513\n",
      "Average Train Time: 85.4390 seconds\n",
      "Average Test Time: 0.4997 seconds\n",
      "Average AUC Macro: 0.9498943122515197\n",
      "Average AUC Weighted: 0.9680365002600959\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.822843        0.874667          0.847813     0.972721\n",
      "1      1           0.668419        0.251149          0.353038     0.931244\n",
      "2      2           0.793911        0.526785          0.631372     0.935575\n",
      "3      3           0.778056        0.691018          0.727298     0.934850\n",
      "4      4           0.920219        0.969191          0.943991     0.975081\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2      3       4\n",
      "0  524.8   6.8   7.0    3.6    57.8\n",
      "1   45.8  22.0   3.6    3.0    13.2\n",
      "2   34.0   1.4  86.6   12.8    29.6\n",
      "3   12.4   2.0   2.8  115.4    34.4\n",
      "4   21.0   2.4  10.0   16.0  1554.0\n"
     ]
    }
   ],
   "source": [
    "# Duyệt qua các tuần trong overall_results\n",
    "for week_result in overall_results_5folds:\n",
    "    week = week_result[\"week\"]\n",
    "    average_train_time = np.mean(week_result[\"train_times\"])\n",
    "    average_test_time = np.mean(week_result[\"test_times\"])\n",
    "    average_metrics_df = week_result[\"average_metrics_df\"]\n",
    "    average_accuracy = np.mean(week_results[\"accuracy_per_fold\"])\n",
    "    average_confusion_matrix = week_result[\"average_confusion_matrix\"]\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n=== Results for {week} ===\")\n",
    "    print(f\"Average Accurancy: {average_accuracy}\")\n",
    "    print(f\"Average Train Time: {average_train_time:.4f} seconds\")\n",
    "    print(f\"Average Test Time: {average_test_time:.4f} seconds\")\n",
    "    print(f\"Average AUC Macro: {average_auc_macro}\")\n",
    "    print(f\"Average AUC Weighted: {average_auc_weighted}\")\n",
    "    print(\"\\nAverage Precision, Recall, F1-Score, AUC-ROC per Label:\")\n",
    "    print(average_metrics_df)\n",
    "    print(\"\\nAverage Confusion Matrix:\")\n",
    "    print(average_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578877f",
   "metadata": {
    "papermill": {
     "duration": 1.563712,
     "end_time": "2025-04-05T11:16:32.472716",
     "exception": false,
     "start_time": "2025-04-05T11:16:30.909004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kiểm tra trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f9efbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:16:35.485151Z",
     "iopub.status.busy": "2025-04-05T11:16:35.484587Z",
     "iopub.status.idle": "2025-04-05T11:16:35.498132Z",
     "shell.execute_reply": "2025-04-05T11:16:35.497442Z"
    },
    "papermill": {
     "duration": 1.595423,
     "end_time": "2025-04-05T11:16:35.499333",
     "exception": false,
     "start_time": "2025-04-05T11:16:33.903910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mảng lưu dữ liệu của các tuần\n",
    "results = []\n",
    "\n",
    "def process_week(week_num, best_params, results):\n",
    "    print(f\"\\n=== Processing Week {week_num} ===\")\n",
    "    params = best_params[f\"week{week_num}\"].values\n",
    "    # Đường dẫn tới dữ liệu tuần tương ứng\n",
    "    train_path = f\"{BASE_PATH}/clean_week{week_num}/train/clean_data_week{week_num}.csv\"\n",
    "    test_path = f\"{BASE_PATH}/clean_week{week_num}/test/test_week{week_num}.csv\"\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                       \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data['classification_encoded']\n",
    "    \n",
    "    X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                     \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_test = test_data['classification_encoded']\n",
    "\n",
    "    # Áp dụng SMOTE cho tập huấn luyện\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Chuyển đổi nhãn sang dạng one-hot\n",
    "    y_train_resampled = to_categorical(y_train_resampled, num_classes=5)\n",
    "    y_test = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "    # Reshape dữ liệu cho LSTM\n",
    "    X_train_resampled = X_train_resampled.to_numpy().reshape((X_train_resampled.shape[0], 1, X_train_resampled.shape[1]))\n",
    "    X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Xây dựng mô hình với tham số tốt nhất\n",
    "    input_shape = (X_train_resampled.shape[1], X_train_resampled.shape[2])\n",
    "    model = build_Bilstm_model(params, input_shape)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled, epochs=50, validation_split=0.1, batch_size=32)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Kiểm thử mô hình\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    # Tính thời gian huấn luyện và kiểm thử\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_test_classes = y_test.argmax(axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    # Tính AUC-ROC (với one-vs-rest)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "        auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "        # Tính AUC weighted tự tính theo trọng số mẫu của từng lớp\n",
    "        supports = np.bincount(y_test_classes, minlength=5)\n",
    "        auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tính AUC: {e}\")\n",
    "        auc_macro = np.nan\n",
    "        auc_per_class = [np.nan] * 5\n",
    "        auc_weighted = np.nan\n",
    "\n",
    "    # Lưu kết quả vào mảng\n",
    "    results.append({\n",
    "        \"week\": week_num,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_weighted\": precision_weighted,\n",
    "        \"recall_weighted\": recall_weighted,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"auc_weighted\": auc_weighted,\n",
    "        \"auc_per_class\": auc_per_class,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    })\n",
    "    \n",
    "    # In kết quả chi tiết\n",
    "    print(\"\\n=== Precision, Recall, F1-Score per Label ===\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Label\": np.unique(y_test_classes),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }))\n",
    "\n",
    "    print(\"\\n=== Macro Averages & Accuracy ===\")\n",
    "    print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Weighted Averages ===\")\n",
    "    print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")\n",
    "    \n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(pd.DataFrame(conf_matrix, index=np.unique(y_test_classes), columns=np.unique(y_test_classes)))\n",
    "    \n",
    "    print(f\"\\nTrain Time: {train_time:.2f} seconds\")\n",
    "    print(f\"Test Time: {test_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3bfad5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:16:38.436968Z",
     "iopub.status.busy": "2025-04-05T11:16:38.436466Z",
     "iopub.status.idle": "2025-04-05T11:21:06.275188Z",
     "shell.execute_reply": "2025-04-05T11:21:06.274221Z"
    },
    "papermill": {
     "duration": 269.32914,
     "end_time": "2025-04-05T11:21:06.276458",
     "exception": false,
     "start_time": "2025-04-05T11:16:36.947318",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4450 - loss: 0.2101 - val_accuracy: 0.4665 - val_loss: 0.2768\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4747 - loss: 0.1957 - val_accuracy: 0.4388 - val_loss: 0.2981\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 0.1878 - val_accuracy: 0.4183 - val_loss: 0.2830\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5125 - loss: 0.1820 - val_accuracy: 0.5657 - val_loss: 0.2098\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5263 - loss: 0.1792 - val_accuracy: 0.4652 - val_loss: 0.2739\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5238 - loss: 0.1797 - val_accuracy: 0.5173 - val_loss: 0.2718\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 0.1774 - val_accuracy: 0.4253 - val_loss: 0.2735\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5397 - loss: 0.1728 - val_accuracy: 0.3684 - val_loss: 0.3012\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5397 - loss: 0.1718 - val_accuracy: 0.5844 - val_loss: 0.2112\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5481 - loss: 0.1710 - val_accuracy: 0.5922 - val_loss: 0.2178\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5564 - loss: 0.1685 - val_accuracy: 0.3764 - val_loss: 0.2866\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5551 - loss: 0.1683 - val_accuracy: 0.4036 - val_loss: 0.2745\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5603 - loss: 0.1674 - val_accuracy: 0.4894 - val_loss: 0.2550\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5637 - loss: 0.1671 - val_accuracy: 0.5755 - val_loss: 0.2122\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5536 - loss: 0.1669 - val_accuracy: 0.3819 - val_loss: 0.2869\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5641 - loss: 0.1664 - val_accuracy: 0.4275 - val_loss: 0.2442\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.1639 - val_accuracy: 0.6044 - val_loss: 0.2034\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5677 - loss: 0.1648 - val_accuracy: 0.4996 - val_loss: 0.2409\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5743 - loss: 0.1609 - val_accuracy: 0.4777 - val_loss: 0.2341\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5727 - loss: 0.1636 - val_accuracy: 0.5884 - val_loss: 0.2028\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5751 - loss: 0.1615 - val_accuracy: 0.4694 - val_loss: 0.2415\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5659 - loss: 0.1636 - val_accuracy: 0.6041 - val_loss: 0.2024\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5748 - loss: 0.1601 - val_accuracy: 0.4802 - val_loss: 0.2333\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5689 - loss: 0.1614 - val_accuracy: 0.4849 - val_loss: 0.2473\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 0.1624 - val_accuracy: 0.4944 - val_loss: 0.2563\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5714 - loss: 0.1612 - val_accuracy: 0.5353 - val_loss: 0.2219\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5710 - loss: 0.1617 - val_accuracy: 0.4916 - val_loss: 0.2422\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5758 - loss: 0.1602 - val_accuracy: 0.5036 - val_loss: 0.2243\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5735 - loss: 0.1576 - val_accuracy: 0.6174 - val_loss: 0.1718\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5735 - loss: 0.1604 - val_accuracy: 0.5410 - val_loss: 0.2313\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5767 - loss: 0.1579 - val_accuracy: 0.6049 - val_loss: 0.2037\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5804 - loss: 0.1575 - val_accuracy: 0.5972 - val_loss: 0.2128\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.1533 - val_accuracy: 0.6393 - val_loss: 0.1986\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5897 - loss: 0.1531 - val_accuracy: 0.4530 - val_loss: 0.2311\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.1553 - val_accuracy: 0.6515 - val_loss: 0.1745\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5815 - loss: 0.1552 - val_accuracy: 0.5914 - val_loss: 0.2261\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 0.1555 - val_accuracy: 0.6478 - val_loss: 0.1831\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5872 - loss: 0.1544 - val_accuracy: 0.5553 - val_loss: 0.2082\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5835 - loss: 0.1567 - val_accuracy: 0.6528 - val_loss: 0.1553\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5816 - loss: 0.1586 - val_accuracy: 0.6288 - val_loss: 0.1967\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5823 - loss: 0.1558 - val_accuracy: 0.6725 - val_loss: 0.1605\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5871 - loss: 0.1540 - val_accuracy: 0.6056 - val_loss: 0.2074\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5832 - loss: 0.1564 - val_accuracy: 0.6807 - val_loss: 0.1574\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5886 - loss: 0.1553 - val_accuracy: 0.5924 - val_loss: 0.2071\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5861 - loss: 0.1549 - val_accuracy: 0.6630 - val_loss: 0.1683\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5824 - loss: 0.1563 - val_accuracy: 0.5473 - val_loss: 0.2331\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5733 - loss: 0.1590 - val_accuracy: 0.6505 - val_loss: 0.1858\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.1536 - val_accuracy: 0.6418 - val_loss: 0.1912\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.1521 - val_accuracy: 0.6465 - val_loss: 0.1681\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.1514 - val_accuracy: 0.5879 - val_loss: 0.1991\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.774892  0.477333  0.590759\n",
      "1      1   0.133803  0.703704  0.224852\n",
      "2      2   0.444444  0.582524  0.504202\n",
      "3      3   0.475410  0.552381  0.511013\n",
      "4      4   0.908986  0.786640  0.843399\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.5475\n",
      "Macro Recall: 0.6205\n",
      "Macro F1-Score: 0.5348\n",
      "Accuracy: 0.6854\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.7959\n",
      "Weighted Recall: 0.6854\n",
      "Weighted F1-Score: 0.7227\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8643\n",
      "AUC Weighted: 0.8943\n",
      "AUC per Label: [0.87365692 0.85900939 0.80212367 0.87065612 0.91593195]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0    1   2   3    4\n",
      "0  179  111  30   5   50\n",
      "1    5   38   1   2    8\n",
      "2   10   19  60   5    9\n",
      "3    3   25   7  58   12\n",
      "4   34   91  37  52  789\n",
      "\n",
      "Train Time: 267.16 seconds\n",
      "Test Time: 0.43 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(1, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a316d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:21:09.777552Z",
     "iopub.status.busy": "2025-04-05T11:21:09.777248Z",
     "iopub.status.idle": "2025-04-05T11:25:43.793151Z",
     "shell.execute_reply": "2025-04-05T11:25:43.792370Z"
    },
    "papermill": {
     "duration": 275.763386,
     "end_time": "2025-04-05T11:25:43.794375",
     "exception": false,
     "start_time": "2025-04-05T11:21:08.030989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5018 - loss: 0.1885 - val_accuracy: 0.5084 - val_loss: 0.2220\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5905 - loss: 0.1539 - val_accuracy: 0.6263 - val_loss: 0.1927\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6316 - loss: 0.1411 - val_accuracy: 0.4143 - val_loss: 0.2930\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6495 - loss: 0.1313 - val_accuracy: 0.6840 - val_loss: 0.1679\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6565 - loss: 0.1277 - val_accuracy: 0.5131 - val_loss: 0.2619\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6728 - loss: 0.1226 - val_accuracy: 0.7047 - val_loss: 0.1608\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.1217 - val_accuracy: 0.5303 - val_loss: 0.2290\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6786 - loss: 0.1164 - val_accuracy: 0.7294 - val_loss: 0.1396\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6902 - loss: 0.1137 - val_accuracy: 0.6927 - val_loss: 0.1128\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6904 - loss: 0.1093 - val_accuracy: 0.6712 - val_loss: 0.1663\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6989 - loss: 0.1080 - val_accuracy: 0.6308 - val_loss: 0.1757\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7015 - loss: 0.1064 - val_accuracy: 0.7478 - val_loss: 0.1168\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.1037 - val_accuracy: 0.6383 - val_loss: 0.1656\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7053 - loss: 0.1040 - val_accuracy: 0.6974 - val_loss: 0.1424\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7130 - loss: 0.1016 - val_accuracy: 0.5962 - val_loss: 0.1731\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.0998 - val_accuracy: 0.7498 - val_loss: 0.0921\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.1011 - val_accuracy: 0.7463 - val_loss: 0.1107\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.0996 - val_accuracy: 0.6445 - val_loss: 0.1451\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.0985 - val_accuracy: 0.6341 - val_loss: 0.1438\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.0967 - val_accuracy: 0.5797 - val_loss: 0.1970\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7291 - loss: 0.0950 - val_accuracy: 0.7438 - val_loss: 0.1175\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.0997 - val_accuracy: 0.7241 - val_loss: 0.1225\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.0965 - val_accuracy: 0.6460 - val_loss: 0.1701\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.0955 - val_accuracy: 0.6949 - val_loss: 0.1294\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.0937 - val_accuracy: 0.6959 - val_loss: 0.1135\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.0909 - val_accuracy: 0.7590 - val_loss: 0.1054\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.0920 - val_accuracy: 0.6500 - val_loss: 0.1497\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.0909 - val_accuracy: 0.6460 - val_loss: 0.1623\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.0916 - val_accuracy: 0.6423 - val_loss: 0.1908\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7415 - loss: 0.0902 - val_accuracy: 0.7264 - val_loss: 0.1240\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.0893 - val_accuracy: 0.6613 - val_loss: 0.1448\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7378 - loss: 0.0914 - val_accuracy: 0.5942 - val_loss: 0.1894\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7419 - loss: 0.0894 - val_accuracy: 0.6880 - val_loss: 0.1471\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7465 - loss: 0.0890 - val_accuracy: 0.7506 - val_loss: 0.1004\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7459 - loss: 0.0883 - val_accuracy: 0.6860 - val_loss: 0.1403\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7494 - loss: 0.0882 - val_accuracy: 0.7493 - val_loss: 0.1122\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.0874 - val_accuracy: 0.7029 - val_loss: 0.1267\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.0878 - val_accuracy: 0.6984 - val_loss: 0.1482\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7468 - loss: 0.0900 - val_accuracy: 0.7341 - val_loss: 0.1188\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7456 - loss: 0.0871 - val_accuracy: 0.7062 - val_loss: 0.1017\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.0858 - val_accuracy: 0.7301 - val_loss: 0.1038\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7514 - loss: 0.0869 - val_accuracy: 0.7057 - val_loss: 0.0993\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.0855 - val_accuracy: 0.7321 - val_loss: 0.1039\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.0850 - val_accuracy: 0.6635 - val_loss: 0.1486\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7482 - loss: 0.0872 - val_accuracy: 0.6795 - val_loss: 0.1199\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.0860 - val_accuracy: 0.6585 - val_loss: 0.1460\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.0847 - val_accuracy: 0.7136 - val_loss: 0.1178\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0859 - val_accuracy: 0.6942 - val_loss: 0.1285\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.0858 - val_accuracy: 0.6994 - val_loss: 0.1436\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.0864 - val_accuracy: 0.6605 - val_loss: 0.1529\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.862500  0.736000  0.794245\n",
      "1      1   0.291339  0.685185  0.408840\n",
      "2      2   0.553719  0.650485  0.598214\n",
      "3      3   0.782051  0.580952  0.666667\n",
      "4      4   0.925553  0.917248  0.921382\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.6830\n",
      "Macro Recall: 0.7140\n",
      "Macro F1-Score: 0.6779\n",
      "Accuracy: 0.8299\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8577\n",
      "Weighted Recall: 0.8299\n",
      "Weighted F1-Score: 0.8388\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9390\n",
      "AUC Weighted: 0.9544\n",
      "AUC per Label: [0.95424506 0.91279015 0.93734485 0.92985264 0.96097735]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  276  53   8   0   38\n",
      "1    6  37   6   0    5\n",
      "2   11  15  67   4    6\n",
      "3    2   2  15  61   25\n",
      "4   25  20  25  13  920\n",
      "\n",
      "Train Time: 273.33 seconds\n",
      "Test Time: 0.43 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(2, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bae56f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:25:47.862231Z",
     "iopub.status.busy": "2025-04-05T11:25:47.861755Z",
     "iopub.status.idle": "2025-04-05T11:30:30.322438Z",
     "shell.execute_reply": "2025-04-05T11:30:30.321536Z"
    },
    "papermill": {
     "duration": 284.449223,
     "end_time": "2025-04-05T11:30:30.323763",
     "exception": false,
     "start_time": "2025-04-05T11:25:45.874540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4620 - loss: 0.2052 - val_accuracy: 0.6149 - val_loss: 0.2113\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5594 - loss: 0.1651 - val_accuracy: 0.5495 - val_loss: 0.2708\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5958 - loss: 0.1513 - val_accuracy: 0.6361 - val_loss: 0.2216\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 0.1423 - val_accuracy: 0.5161 - val_loss: 0.2210\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6295 - loss: 0.1349 - val_accuracy: 0.6603 - val_loss: 0.1842\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6419 - loss: 0.1296 - val_accuracy: 0.4455 - val_loss: 0.2624\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6613 - loss: 0.1245 - val_accuracy: 0.6341 - val_loss: 0.1979\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 0.1269 - val_accuracy: 0.6503 - val_loss: 0.1725\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6622 - loss: 0.1217 - val_accuracy: 0.6752 - val_loss: 0.1760\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6786 - loss: 0.1162 - val_accuracy: 0.6625 - val_loss: 0.1713\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6724 - loss: 0.1173 - val_accuracy: 0.6702 - val_loss: 0.1695\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6862 - loss: 0.1127 - val_accuracy: 0.6296 - val_loss: 0.1812\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6826 - loss: 0.1123 - val_accuracy: 0.6346 - val_loss: 0.1922\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.1110 - val_accuracy: 0.7343 - val_loss: 0.1363\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6918 - loss: 0.1100 - val_accuracy: 0.6630 - val_loss: 0.1635\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6943 - loss: 0.1082 - val_accuracy: 0.6416 - val_loss: 0.1778\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6997 - loss: 0.1066 - val_accuracy: 0.6997 - val_loss: 0.1585\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6939 - loss: 0.1085 - val_accuracy: 0.7206 - val_loss: 0.1254\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 0.1057 - val_accuracy: 0.7521 - val_loss: 0.1224\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7056 - loss: 0.1035 - val_accuracy: 0.6181 - val_loss: 0.1748\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.1024 - val_accuracy: 0.6862 - val_loss: 0.1493\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.1011 - val_accuracy: 0.7613 - val_loss: 0.1037\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7101 - loss: 0.1023 - val_accuracy: 0.7331 - val_loss: 0.1387\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7200 - loss: 0.0983 - val_accuracy: 0.7087 - val_loss: 0.1185\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.0992 - val_accuracy: 0.7301 - val_loss: 0.1161\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.0991 - val_accuracy: 0.6755 - val_loss: 0.1464\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7182 - loss: 0.1004 - val_accuracy: 0.6558 - val_loss: 0.1502\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.0967 - val_accuracy: 0.6827 - val_loss: 0.1350\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.0959 - val_accuracy: 0.7004 - val_loss: 0.1519\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7251 - loss: 0.0958 - val_accuracy: 0.6356 - val_loss: 0.1561\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7204 - loss: 0.0972 - val_accuracy: 0.6555 - val_loss: 0.1411\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.0966 - val_accuracy: 0.7708 - val_loss: 0.1046\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.0965 - val_accuracy: 0.6924 - val_loss: 0.1302\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.0962 - val_accuracy: 0.6812 - val_loss: 0.1499\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.0932 - val_accuracy: 0.6573 - val_loss: 0.1650\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7317 - loss: 0.0941 - val_accuracy: 0.7144 - val_loss: 0.1241\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7317 - loss: 0.0934 - val_accuracy: 0.6885 - val_loss: 0.1147\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.0950 - val_accuracy: 0.6942 - val_loss: 0.1382\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.0931 - val_accuracy: 0.7239 - val_loss: 0.1210\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7321 - loss: 0.0927 - val_accuracy: 0.7042 - val_loss: 0.1449\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.0927 - val_accuracy: 0.7236 - val_loss: 0.1194\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.0927 - val_accuracy: 0.7326 - val_loss: 0.1026\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.0934 - val_accuracy: 0.6962 - val_loss: 0.1474\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.0920 - val_accuracy: 0.6837 - val_loss: 0.1520\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7318 - loss: 0.0918 - val_accuracy: 0.6847 - val_loss: 0.1277\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.0902 - val_accuracy: 0.6702 - val_loss: 0.1500\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.0916 - val_accuracy: 0.7413 - val_loss: 0.1075\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7393 - loss: 0.0896 - val_accuracy: 0.7441 - val_loss: 0.1122\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.0906 - val_accuracy: 0.6947 - val_loss: 0.1261\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.0916 - val_accuracy: 0.7231 - val_loss: 0.1174\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.859060  0.682667  0.760773\n",
      "1      1   0.234043  0.814815  0.363636\n",
      "2      2   0.537190  0.631068  0.580357\n",
      "3      3   0.821429  0.657143  0.730159\n",
      "4      4   0.934668  0.884347  0.908811\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.6773\n",
      "Macro Recall: 0.7340\n",
      "Macro F1-Score: 0.6687\n",
      "Accuracy: 0.8055\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8621\n",
      "Weighted Recall: 0.8055\n",
      "Weighted F1-Score: 0.8249\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9418\n",
      "AUC Weighted: 0.9569\n",
      "AUC per Label: [0.96248116 0.9160595  0.94411633 0.92458508 0.96175524]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  256  80  11   1   27\n",
      "1    5  44   0   0    5\n",
      "2    9  18  65   2    9\n",
      "3    0   4  11  69   21\n",
      "4   28  42  34  12  887\n",
      "\n",
      "Train Time: 281.72 seconds\n",
      "Test Time: 0.44 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(3, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad2c72ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:30:34.856590Z",
     "iopub.status.busy": "2025-04-05T11:30:34.856268Z",
     "iopub.status.idle": "2025-04-05T11:35:13.288526Z",
     "shell.execute_reply": "2025-04-05T11:35:13.287748Z"
    },
    "papermill": {
     "duration": 280.693749,
     "end_time": "2025-04-05T11:35:13.289887",
     "exception": false,
     "start_time": "2025-04-05T11:30:32.596138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5095 - loss: 0.1867 - val_accuracy: 0.6802 - val_loss: 0.1746\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6359 - loss: 0.1372 - val_accuracy: 0.6041 - val_loss: 0.2081\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6720 - loss: 0.1213 - val_accuracy: 0.6273 - val_loss: 0.1917\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6910 - loss: 0.1125 - val_accuracy: 0.6166 - val_loss: 0.1981\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7121 - loss: 0.1043 - val_accuracy: 0.7219 - val_loss: 0.1294\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.0997 - val_accuracy: 0.6039 - val_loss: 0.1691\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7262 - loss: 0.0967 - val_accuracy: 0.7585 - val_loss: 0.1174\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.0940 - val_accuracy: 0.6603 - val_loss: 0.1684\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7352 - loss: 0.0928 - val_accuracy: 0.5842 - val_loss: 0.1683\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7459 - loss: 0.0880 - val_accuracy: 0.7341 - val_loss: 0.1310\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.0844 - val_accuracy: 0.7301 - val_loss: 0.0911\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 0.0822 - val_accuracy: 0.6780 - val_loss: 0.1431\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7598 - loss: 0.0831 - val_accuracy: 0.6523 - val_loss: 0.1184\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7621 - loss: 0.0806 - val_accuracy: 0.7104 - val_loss: 0.1074\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.0770 - val_accuracy: 0.6939 - val_loss: 0.1053\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7675 - loss: 0.0786 - val_accuracy: 0.7615 - val_loss: 0.1104\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7696 - loss: 0.0768 - val_accuracy: 0.7274 - val_loss: 0.0953\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.0749 - val_accuracy: 0.6520 - val_loss: 0.1433\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.0745 - val_accuracy: 0.7850 - val_loss: 0.0719\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.0724 - val_accuracy: 0.7443 - val_loss: 0.1112\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7832 - loss: 0.0714 - val_accuracy: 0.7353 - val_loss: 0.1051\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.0698 - val_accuracy: 0.7226 - val_loss: 0.0881\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.0690 - val_accuracy: 0.7363 - val_loss: 0.0902\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 0.0706 - val_accuracy: 0.7590 - val_loss: 0.1007\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.0671 - val_accuracy: 0.7645 - val_loss: 0.0896\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.0662 - val_accuracy: 0.7628 - val_loss: 0.0695\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.0662 - val_accuracy: 0.7144 - val_loss: 0.0943\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.0654 - val_accuracy: 0.7493 - val_loss: 0.0945\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7997 - loss: 0.0657 - val_accuracy: 0.7199 - val_loss: 0.1051\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.0636 - val_accuracy: 0.7538 - val_loss: 0.0775\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.0635 - val_accuracy: 0.6882 - val_loss: 0.1237\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.0625 - val_accuracy: 0.7897 - val_loss: 0.0634\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.0610 - val_accuracy: 0.7301 - val_loss: 0.1069\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.0628 - val_accuracy: 0.7493 - val_loss: 0.0683\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.0610 - val_accuracy: 0.7331 - val_loss: 0.0840\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.0589 - val_accuracy: 0.7655 - val_loss: 0.0757\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8203 - loss: 0.0586 - val_accuracy: 0.7837 - val_loss: 0.0745\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.0584 - val_accuracy: 0.7543 - val_loss: 0.0762\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.0582 - val_accuracy: 0.7625 - val_loss: 0.0722\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.0571 - val_accuracy: 0.7603 - val_loss: 0.0774\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8186 - loss: 0.0575 - val_accuracy: 0.7067 - val_loss: 0.1093\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.0552 - val_accuracy: 0.7663 - val_loss: 0.0652\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.0536 - val_accuracy: 0.7488 - val_loss: 0.0898\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.0559 - val_accuracy: 0.7792 - val_loss: 0.0673\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.0553 - val_accuracy: 0.7743 - val_loss: 0.0792\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.0533 - val_accuracy: 0.7633 - val_loss: 0.0807\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.0541 - val_accuracy: 0.7797 - val_loss: 0.0805\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.0532 - val_accuracy: 0.8144 - val_loss: 0.0527\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 0.0527 - val_accuracy: 0.8112 - val_loss: 0.0626\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 0.0514 - val_accuracy: 0.7810 - val_loss: 0.0727\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.909366  0.802667  0.852691\n",
      "1      1   0.371429  0.722222  0.490566\n",
      "2      2   0.608108  0.873786  0.717131\n",
      "3      3   0.712963  0.733333  0.723005\n",
      "4      4   0.957806  0.905284  0.930805\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.7119\n",
      "Macro Recall: 0.8075\n",
      "Macro F1-Score: 0.7428\n",
      "Accuracy: 0.8628\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8898\n",
      "Weighted Recall: 0.8628\n",
      "Weighted F1-Score: 0.8717\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9657\n",
      "AUC Weighted: 0.9780\n",
      "AUC per Label: [0.98603215 0.94033441 0.96903563 0.95252986 0.98066084]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  301  48   7   0   19\n",
      "1    7  39   4   0    4\n",
      "2    4   3  90   3    3\n",
      "3    3   1  10  77   14\n",
      "4   16  14  37  28  908\n",
      "\n",
      "Train Time: 277.65 seconds\n",
      "Test Time: 0.45 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(4, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a992e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:35:18.518838Z",
     "iopub.status.busy": "2025-04-05T11:35:18.518495Z",
     "iopub.status.idle": "2025-04-05T11:35:18.533583Z",
     "shell.execute_reply": "2025-04-05T11:35:18.532783Z"
    },
    "papermill": {
     "duration": 2.617573,
     "end_time": "2025-04-05T11:35:18.534817",
     "exception": false,
     "start_time": "2025-04-05T11:35:15.917244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Results for All Weeks ===\n",
      "Week 1:\n",
      "  Train Time: 267.16 seconds\n",
      "  Test Time: 0.43 seconds\n",
      "  Accurancy: 0.6853658536585366\n",
      "  Precision: [0.77489177 0.13380282 0.44444444 0.47540984 0.90898618]\n",
      "  Recall: [0.47733333 0.7037037  0.58252427 0.55238095 0.78664008]\n",
      "  F1-Score: [0.59075908 0.22485207 0.50420168 0.51101322 0.84339925]\n",
      "  Macro Precision: 0.5475070094836817\n",
      "  Macro Recall: 0.6205164682046734\n",
      "  Macro F1-Score: 0.5348450590363693\n",
      "  Confusion Matrix:\n",
      "[[179 111  30   5  50]\n",
      " [  5  38   1   2   8]\n",
      " [ 10  19  60   5   9]\n",
      " [  3  25   7  58  12]\n",
      " [ 34  91  37  52 789]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8643\n",
      "AUC Weighted: 0.8943\n",
      "AUC per Label: [0.87365692 0.85900939 0.80212367 0.87065612 0.91593195]\n",
      "Week 2:\n",
      "  Train Time: 273.33 seconds\n",
      "  Test Time: 0.43 seconds\n",
      "  Accurancy: 0.8298780487804878\n",
      "  Precision: [0.8625     0.29133858 0.55371901 0.78205128 0.92555332]\n",
      "  Recall: [0.736      0.68518519 0.65048544 0.58095238 0.91724826]\n",
      "  F1-Score: [0.7942446  0.40883978 0.59821429 0.66666667 0.92138207]\n",
      "  Macro Precision: 0.6830324385824854\n",
      "  Macro Recall: 0.7139742516530135\n",
      "  Macro F1-Score: 0.6778694817625377\n",
      "  Confusion Matrix:\n",
      "[[276  53   8   0  38]\n",
      " [  6  37   6   0   5]\n",
      " [ 11  15  67   4   6]\n",
      " [  2   2  15  61  25]\n",
      " [ 25  20  25  13 920]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9390\n",
      "AUC Weighted: 0.9544\n",
      "AUC per Label: [0.95424506 0.91279015 0.93734485 0.92985264 0.96097735]\n",
      "Week 3:\n",
      "  Train Time: 281.72 seconds\n",
      "  Test Time: 0.44 seconds\n",
      "  Accurancy: 0.8054878048780488\n",
      "  Precision: [0.8590604  0.23404255 0.53719008 0.82142857 0.93466807]\n",
      "  Recall: [0.68266667 0.81481481 0.63106796 0.65714286 0.88434696]\n",
      "  F1-Score: [0.76077266 0.36363636 0.58035714 0.73015873 0.90881148]\n",
      "  Macro Precision: 0.6772779363207251\n",
      "  Macro Recall: 0.7340078517824038\n",
      "  Macro F1-Score: 0.6687472743589227\n",
      "  Confusion Matrix:\n",
      "[[256  80  11   1  27]\n",
      " [  5  44   0   0   5]\n",
      " [  9  18  65   2   9]\n",
      " [  0   4  11  69  21]\n",
      " [ 28  42  34  12 887]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9418\n",
      "AUC Weighted: 0.9569\n",
      "AUC per Label: [0.96248116 0.9160595  0.94411633 0.92458508 0.96175524]\n",
      "Week 4:\n",
      "  Train Time: 277.65 seconds\n",
      "  Test Time: 0.45 seconds\n",
      "  Accurancy: 0.8628048780487805\n",
      "  Precision: [0.90936556 0.37142857 0.60810811 0.71296296 0.95780591]\n",
      "  Recall: [0.80266667 0.72222222 0.87378641 0.73333333 0.90528415]\n",
      "  F1-Score: [0.85269122 0.49056604 0.71713147 0.72300469 0.93080472]\n",
      "  Macro Precision: 0.711934221717005\n",
      "  Macro Recall: 0.8074585555093081\n",
      "  Macro F1-Score: 0.742839628067185\n",
      "  Confusion Matrix:\n",
      "[[301  48   7   0  19]\n",
      " [  7  39   4   0   4]\n",
      " [  4   3  90   3   3]\n",
      " [  3   1  10  77  14]\n",
      " [ 16  14  37  28 908]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9657\n",
      "AUC Weighted: 0.9780\n",
      "AUC per Label: [0.98603215 0.94033441 0.96903563 0.95252986 0.98066084]\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu của các tuần\n",
    "print(\"\\n=== Summary Results for All Weeks ===\")\n",
    "for result in results:\n",
    "    print(f\"Week {result['week']}:\")\n",
    "    print(f\"  Train Time: {result['train_time']:.2f} seconds\")\n",
    "    print(f\"  Test Time: {result['test_time']:.2f} seconds\")\n",
    "    print(f\"  Accurancy: {result['accuracy']}\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1-Score: {result['f1_score']}\")\n",
    "    print(f\"  Macro Precision: {result['precision_macro']}\")\n",
    "    print(f\"  Macro Recall: {result['recall_macro']}\")\n",
    "    print(f\"  Macro F1-Score: {result['f1_macro']}\")\n",
    "    print(f\"  Confusion Matrix:\\n{result['confusion_matrix']}\")\n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {result['auc_macro']:.4f}\")\n",
    "    print(f\"AUC Weighted: {result['auc_weighted']:.4f}\")\n",
    "    print(f\"AUC per Label: {result['auc_per_class']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ec6c9",
   "metadata": {
    "papermill": {
     "duration": 2.500593,
     "end_time": "2025-04-05T11:35:23.579994",
     "exception": false,
     "start_time": "2025-04-05T11:35:21.079401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6328310,
     "sourceId": 11252263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8480.465818,
   "end_time": "2025-04-05T11:35:28.910738",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-05T09:14:08.444920",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
