{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84a8342",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-30T10:35:49.001946Z",
     "iopub.status.busy": "2025-06-30T10:35:49.001698Z",
     "iopub.status.idle": "2025-06-30T10:35:51.573803Z",
     "shell.execute_reply": "2025-06-30T10:35:51.572934Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.578714,
     "end_time": "2025-06-30T10:35:51.575138",
     "exception": false,
     "start_time": "2025-06-30T10:35:48.996424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clean_raw_data.csv\n",
      "/kaggle/input/clean_data_mean.csv\n",
      "/kaggle/input/raw_data.csv\n",
      "/kaggle/input/clean_data_GCN.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_data_minmax_fill-zero.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_data_minmax_GCN_version4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_data_Fill-1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_data_minmax_Fill-1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_data_minmax_KI.csv\n",
      "/kaggle/input/KI_minmax_baseline/KI.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_data_minmax_GCN_version3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/Listwise-deletion.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_data_minmax_KNN.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_5.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2b6da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T10:35:51.586846Z",
     "iopub.status.busy": "2025-06-30T10:35:51.586461Z",
     "iopub.status.idle": "2025-06-30T10:36:04.182145Z",
     "shell.execute_reply": "2025-06-30T10:36:04.181479Z"
    },
    "papermill": {
     "duration": 12.602977,
     "end_time": "2025-06-30T10:36:04.183613",
     "exception": false,
     "start_time": "2025-06-30T10:35:51.580636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe555e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T10:36:04.194982Z",
     "iopub.status.busy": "2025-06-30T10:36:04.194514Z",
     "iopub.status.idle": "2025-06-30T10:36:04.199326Z",
     "shell.execute_reply": "2025-06-30T10:36:04.198518Z"
    },
    "papermill": {
     "duration": 0.011516,
     "end_time": "2025-06-30T10:36:04.200619",
     "exception": false,
     "start_time": "2025-06-30T10:36:04.189103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Biến global cho base path\n",
    "BASE_PATH = \"/kaggle/input/KI_minmax_baseline\"\n",
    "# Tuần và số phần fold\n",
    "weeks = ['week1', 'week2', 'week3', 'week4']\n",
    "fold_parts = 5\n",
    "\n",
    "# Tạo five_fold_files\n",
    "five_fold_files = {\n",
    "    week: [\n",
    "        f\"{BASE_PATH}/clean_{week}/train/5-folds/data_part_{i}.csv\"\n",
    "        for i in range(1, fold_parts + 1)\n",
    "    ]\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Tạo file_validation\n",
    "file_validation = {\n",
    "    'week1': [f\"{BASE_PATH}/clean_week1/val/val_week1.csv\"],\n",
    "    'week2': [f\"{BASE_PATH}/clean_week2/val/val_week1_2.csv\"],\n",
    "    'week3': [f\"{BASE_PATH}/clean_week3/val/val_week1_2_3.csv\"],\n",
    "    'week4': [f\"{BASE_PATH}/clean_week4/val/val_week1_2_3_4.csv\"]\n",
    "}\n",
    "\n",
    "# Tạo file_test\n",
    "file_test = {\n",
    "    week: [f\"{BASE_PATH}/clean_{week}/test/test_{week}.csv\"]\n",
    "    for week in weeks\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b090b9",
   "metadata": {
    "papermill": {
     "duration": 0.004611,
     "end_time": "2025-06-30T10:36:04.210234",
     "exception": false,
     "start_time": "2025-06-30T10:36:04.205623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tìm siêu tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbeba76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T10:36:04.221110Z",
     "iopub.status.busy": "2025-06-30T10:36:04.220890Z",
     "iopub.status.idle": "2025-06-30T10:36:04.231082Z",
     "shell.execute_reply": "2025-06-30T10:36:04.230491Z"
    },
    "papermill": {
     "duration": 0.016992,
     "end_time": "2025-06-30T10:36:04.232266",
     "exception": false,
     "start_time": "2025-06-30T10:36:04.215274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Tạo hàm train cho từng tuần\n",
    "def train_week_model(week_number, file_paths_train, file_validataion):\n",
    "    # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(file_paths_train)\n",
    "    val_data = pd.read_csv(file_validataion)\n",
    "    \n",
    "    # Tách đặc trưng và nhãn\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "    X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_val = val_data[\"classification_encoded\"]\n",
    "    \n",
    "    # Áp dụng Over-sampling cho dữ liệu huấn luyện bằng SMOTE\n",
    "    oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Reshape dữ liệu cho mô hình BiLSTM\n",
    "    X_train_res = X_train_res.values.reshape(X_train_res.shape[0], X_train_res.shape[1], 1)\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    \n",
    "    # One-hot encode nhãn\n",
    "    y_train_res = tf.keras.utils.to_categorical(y_train_res, num_classes=5)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "    \n",
    "    def build_model(hp):\n",
    "        inputs = tf.keras.Input(shape=(X_train_res.shape[1], 1))  # Khởi tạo đầu vào\n",
    "        \n",
    "        # GRU layer 1\n",
    "        x = layers.GRU(\n",
    "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=True\n",
    "        )(inputs)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # GRU layer 2\n",
    "        x = layers.GRU(\n",
    "            units=hp.Int('units_2', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=False\n",
    "        )(x)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # Lớp đầu ra\n",
    "        outputs = layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        # Khởi tạo mô hình\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile với Focal Loss\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                          learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                      loss=focal_loss(gamma=2., alpha=0.25),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    # Khởi tạo RandomSearch tuner\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='my_dir',\n",
    "        project_name=f'bilstm_tuning_week{week_number}'\n",
    "    )\n",
    "    \n",
    "    # Tìm kiếm siêu tham số tốt nhất\n",
    "    tuner.search(X_train_res, y_train_res,\n",
    "                 epochs=20,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 batch_size=32)\n",
    "    \n",
    "    # Trả về kết quả tối ưu cho tuần\n",
    "    best_params = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce5d632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T10:36:04.242564Z",
     "iopub.status.busy": "2025-06-30T10:36:04.242365Z",
     "iopub.status.idle": "2025-06-30T10:36:04.245652Z",
     "shell.execute_reply": "2025-06-30T10:36:04.245094Z"
    },
    "papermill": {
     "duration": 0.009583,
     "end_time": "2025-06-30T10:36:04.246701",
     "exception": false,
     "start_time": "2025-06-30T10:36:04.237118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa đường dẫn đến dữ liệu cho từng tuần\n",
    "file_paths_train = {\n",
    "    week: f\"{BASE_PATH}/clean_{week}/train/clean_data_{week}.csv\"\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Định nghĩa file_validation theo quy luật riêng\n",
    "file_validation = {\n",
    "    f\"week{idx + 1}\": f\"{BASE_PATH}/clean_week{idx + 1}/val/val_week{'_'.join(str(i) for i in range(1, idx + 2))}.csv\"\n",
    "    for idx in range(len(weeks))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0df26ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T10:36:04.257191Z",
     "iopub.status.busy": "2025-06-30T10:36:04.256989Z",
     "iopub.status.idle": "2025-06-30T12:12:06.968254Z",
     "shell.execute_reply": "2025-06-30T12:12:06.966712Z"
    },
    "papermill": {
     "duration": 5762.718367,
     "end_time": "2025-06-30T12:12:06.969965",
     "exception": false,
     "start_time": "2025-06-30T10:36:04.251598",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 49s]\n",
      "val_accuracy: 0.7968273162841797\n",
      "\n",
      "Best val_accuracy So Far: 0.7968273162841797\n",
      "Total elapsed time: 00h 27m 12s\n",
      "Best Parameters for Week 1:\n",
      "units_1: 256\n",
      "dropout_1: 0.2\n",
      "units_2: 192\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.0019513235178244249\n",
      "\n",
      "Best Parameters for Week 2:\n",
      "units_1: 96\n",
      "dropout_1: 0.1\n",
      "units_2: 96\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.0007634521198846196\n",
      "\n",
      "Best Parameters for Week 3:\n",
      "units_1: 96\n",
      "dropout_1: 0.2\n",
      "units_2: 160\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.0019833455634702653\n",
      "\n",
      "Best Parameters for Week 4:\n",
      "units_1: 128\n",
      "dropout_1: 0.5\n",
      "units_2: 256\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.0010692731625104286\n"
     ]
    }
   ],
   "source": [
    "# Tìm tham số tốt nhất cho từng tuần\n",
    "best_params_week1 = train_week_model(1, file_paths_train[\"week1\"], file_validation[\"week1\"])\n",
    "best_params_week2 = train_week_model(2, file_paths_train[\"week2\"], file_validation[\"week2\"])\n",
    "best_params_week3 = train_week_model(3, file_paths_train[\"week3\"], file_validation[\"week3\"])\n",
    "best_params_week4 = train_week_model(4, file_paths_train[\"week4\"], file_validation[\"week4\"])\n",
    "\n",
    "# In thông tin chi tiết các tham số tối ưu\n",
    "print(\"Best Parameters for Week 1:\")\n",
    "for param_name in best_params_week1.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week1.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 2:\")\n",
    "for param_name in best_params_week2.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week2.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 3:\")\n",
    "for param_name in best_params_week3.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week3.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 4:\")\n",
    "for param_name in best_params_week4.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week4.get(param_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6104796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:12:06.986735Z",
     "iopub.status.busy": "2025-06-30T12:12:06.986483Z",
     "iopub.status.idle": "2025-06-30T12:14:33.973531Z",
     "shell.execute_reply": "2025-06-30T12:14:33.972572Z"
    },
    "papermill": {
     "duration": 146.994585,
     "end_time": "2025-06-30T12:14:33.975017",
     "exception": false,
     "start_time": "2025-06-30T12:12:06.980432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3624 - loss: 0.2249 - val_accuracy: 0.6565 - val_loss: 0.1440\n",
      "Epoch 2/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6084 - loss: 0.1559 - val_accuracy: 0.7023 - val_loss: 0.1225\n",
      "Epoch 3/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6487 - loss: 0.1381 - val_accuracy: 0.6595 - val_loss: 0.1333\n",
      "Epoch 4/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6680 - loss: 0.1277 - val_accuracy: 0.7419 - val_loss: 0.1066\n",
      "Epoch 5/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6937 - loss: 0.1146 - val_accuracy: 0.7425 - val_loss: 0.1039\n",
      "Epoch 6/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7142 - loss: 0.1039 - val_accuracy: 0.7535 - val_loss: 0.1009\n",
      "Epoch 7/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7361 - loss: 0.0953 - val_accuracy: 0.7718 - val_loss: 0.0985\n",
      "Epoch 8/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7519 - loss: 0.0883 - val_accuracy: 0.7315 - val_loss: 0.1088\n",
      "Epoch 9/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7576 - loss: 0.0826 - val_accuracy: 0.7541 - val_loss: 0.0967\n",
      "Epoch 10/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7729 - loss: 0.0770 - val_accuracy: 0.7291 - val_loss: 0.1003\n",
      "Epoch 11/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.0717 - val_accuracy: 0.7706 - val_loss: 0.0888\n",
      "Epoch 12/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.0690 - val_accuracy: 0.7395 - val_loss: 0.1006\n",
      "Epoch 13/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7954 - loss: 0.0668 - val_accuracy: 0.7559 - val_loss: 0.0962\n",
      "Epoch 14/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.0636 - val_accuracy: 0.7566 - val_loss: 0.0899\n",
      "Epoch 15/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.0623 - val_accuracy: 0.7370 - val_loss: 0.1045\n",
      "Epoch 16/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.0584 - val_accuracy: 0.7315 - val_loss: 0.0990\n",
      "Epoch 17/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.0603 - val_accuracy: 0.7724 - val_loss: 0.0914\n",
      "Epoch 18/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8198 - loss: 0.0564 - val_accuracy: 0.7755 - val_loss: 0.0912\n",
      "Epoch 19/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.0527 - val_accuracy: 0.7657 - val_loss: 0.0914\n",
      "Epoch 20/20\n",
      "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8320 - loss: 0.0516 - val_accuracy: 0.7566 - val_loss: 0.0989\n",
      "✅ Đã lưu mô hình GRU tuần 3 dưới dạng gru_week3_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Sau khi tìm ra best_params_week3, tiến hành build và train mô hình với tham số tối ưu\n",
    "def build_best_gru_model(best_params, input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.GRU(units=best_params.get('units_1'), return_sequences=True)(inputs)\n",
    "    x = layers.Dropout(rate=best_params.get('dropout_1'))(x)\n",
    "    \n",
    "    x = layers.GRU(units=best_params.get('units_2'), return_sequences=False)(x)\n",
    "    x = layers.Dropout(rate=best_params.get('dropout_2'))(x)\n",
    "    \n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params.get('learning_rate')),\n",
    "                  loss=focal_loss(gamma=2., alpha=0.25),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Chuẩn bị dữ liệu giống như trước cho tuần 3\n",
    "train_data = pd.read_csv(file_paths_train[\"week3\"])\n",
    "val_data = pd.read_csv(file_validation[\"week3\"])\n",
    "\n",
    "X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "y_val = val_data[\"classification_encoded\"]\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_res = X_train_res.values.reshape(X_train_res.shape[0], X_train_res.shape[1], 1)\n",
    "X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "\n",
    "y_train_res = tf.keras.utils.to_categorical(y_train_res, num_classes=5)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "\n",
    "# Xây dựng mô hình với tham số tốt nhất\n",
    "model_week3 = build_best_gru_model(best_params_week3, input_shape=(X_train_res.shape[1], 1))\n",
    "\n",
    "# Train mô hình\n",
    "model_week3.fit(X_train_res, y_train_res,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=20,\n",
    "                batch_size=32)\n",
    "\n",
    "# ✅ Lưu mô hình dưới dạng .h5\n",
    "model_week3.save(\"gru_week3_model.h5\")\n",
    "\n",
    "print(\"✅ Đã lưu mô hình GRU tuần 3 dưới dạng gru_week3_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8f710",
   "metadata": {
    "papermill": {
     "duration": 0.13182,
     "end_time": "2025-06-30T12:14:34.240067",
     "exception": false,
     "start_time": "2025-06-30T12:14:34.108247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Danh sách tham số tốt nhất của từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60984f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:14:34.517133Z",
     "iopub.status.busy": "2025-06-30T12:14:34.516776Z",
     "iopub.status.idle": "2025-06-30T12:14:34.520598Z",
     "shell.execute_reply": "2025-06-30T12:14:34.519888Z"
    },
    "papermill": {
     "duration": 0.146204,
     "end_time": "2025-06-30T12:14:34.521956",
     "exception": false,
     "start_time": "2025-06-30T12:14:34.375752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Danh sách tham số tốt nhất\n",
    "best_params = {\n",
    "    \"week1\": best_params_week1,\n",
    "    \"week2\": best_params_week2,\n",
    "    \"week3\": best_params_week3,\n",
    "    \"week4\": best_params_week4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddd5e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:14:34.787946Z",
     "iopub.status.busy": "2025-06-30T12:14:34.787611Z",
     "iopub.status.idle": "2025-06-30T12:14:34.794740Z",
     "shell.execute_reply": "2025-06-30T12:14:34.794012Z"
    },
    "papermill": {
     "duration": 0.14044,
     "end_time": "2025-06-30T12:14:34.796071",
     "exception": false,
     "start_time": "2025-06-30T12:14:34.655631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Xây dựng mô hình BiLSTM\n",
    "def build_GRU_model(params, input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "    # GRU layer 1\n",
    "    x = layers.GRU(\n",
    "        units=params.get('units_1'),\n",
    "        return_sequences=True\n",
    "    )(inputs)\n",
    "    x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "    # GRU layer 2\n",
    "    x = layers.GRU(\n",
    "        units=params.get('units_2', 32),\n",
    "        return_sequences=False\n",
    "    )(x)\n",
    "    x = layers.Dropout(rate=params.get('dropout_2', 0.2))(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile với Focal Loss\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                      learning_rate=params['learning_rate']),\n",
    "                  loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b0e213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:14:35.065752Z",
     "iopub.status.busy": "2025-06-30T12:14:35.065429Z",
     "iopub.status.idle": "2025-06-30T12:43:18.685645Z",
     "shell.execute_reply": "2025-06-30T12:43:18.684579Z"
    },
    "papermill": {
     "duration": 1723.756983,
     "end_time": "2025-06-30T12:43:18.686998",
     "exception": false,
     "start_time": "2025-06-30T12:14:34.930015",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing week1 with best parameters...\n",
      "best parameters for week1: {'units_1': 256, 'dropout_1': 0.2, 'units_2': 192, 'dropout_2': 0.1, 'learning_rate': 0.0019513235178244249}\n",
      "Fold 1: Using file /kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6300 - loss: 0.1357 - val_accuracy: 0.6763 - val_loss: 0.1145\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6712 - loss: 0.1191 - val_accuracy: 0.7064 - val_loss: 0.1110\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6849 - loss: 0.1149 - val_accuracy: 0.6778 - val_loss: 0.1098\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6756 - loss: 0.1142 - val_accuracy: 0.6984 - val_loss: 0.1075\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6880 - loss: 0.1120 - val_accuracy: 0.7259 - val_loss: 0.1048\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6923 - loss: 0.1102 - val_accuracy: 0.6973 - val_loss: 0.1088\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6985 - loss: 0.1115 - val_accuracy: 0.7362 - val_loss: 0.1013\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7004 - loss: 0.1086 - val_accuracy: 0.7339 - val_loss: 0.1026\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.1089 - val_accuracy: 0.7316 - val_loss: 0.1039\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7082 - loss: 0.1090 - val_accuracy: 0.7247 - val_loss: 0.1027\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7163 - loss: 0.1061 - val_accuracy: 0.7312 - val_loss: 0.0981\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.1068 - val_accuracy: 0.7461 - val_loss: 0.0973\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7130 - loss: 0.1067 - val_accuracy: 0.7293 - val_loss: 0.1027\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7090 - loss: 0.1076 - val_accuracy: 0.7503 - val_loss: 0.0955\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7177 - loss: 0.1034 - val_accuracy: 0.7366 - val_loss: 0.0990\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.1051 - val_accuracy: 0.7373 - val_loss: 0.0960\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.1036 - val_accuracy: 0.7507 - val_loss: 0.0964\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7153 - loss: 0.1055 - val_accuracy: 0.7408 - val_loss: 0.0953\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.1036 - val_accuracy: 0.7575 - val_loss: 0.0931\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7203 - loss: 0.1047 - val_accuracy: 0.7510 - val_loss: 0.0927\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.1018 - val_accuracy: 0.7621 - val_loss: 0.0915\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7307 - loss: 0.1000 - val_accuracy: 0.7480 - val_loss: 0.0919\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.0964 - val_accuracy: 0.7423 - val_loss: 0.0946\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7459 - loss: 0.0994 - val_accuracy: 0.7613 - val_loss: 0.0905\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7317 - loss: 0.0983 - val_accuracy: 0.7419 - val_loss: 0.0951\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7351 - loss: 0.0998 - val_accuracy: 0.7369 - val_loss: 0.0945\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7311 - loss: 0.1000 - val_accuracy: 0.7686 - val_loss: 0.0935\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7352 - loss: 0.0999 - val_accuracy: 0.7270 - val_loss: 0.1046\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.0977 - val_accuracy: 0.7510 - val_loss: 0.0908\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.0995 - val_accuracy: 0.7480 - val_loss: 0.0902\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7428 - loss: 0.0975 - val_accuracy: 0.7518 - val_loss: 0.0915\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.0964 - val_accuracy: 0.7495 - val_loss: 0.0912\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.0992 - val_accuracy: 0.7430 - val_loss: 0.0918\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7378 - loss: 0.0969 - val_accuracy: 0.7507 - val_loss: 0.0900\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.0992 - val_accuracy: 0.7701 - val_loss: 0.0878\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.0964 - val_accuracy: 0.7549 - val_loss: 0.0886\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.0986 - val_accuracy: 0.7697 - val_loss: 0.0888\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.0945 - val_accuracy: 0.7583 - val_loss: 0.0895\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7391 - loss: 0.0999 - val_accuracy: 0.7495 - val_loss: 0.0880\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.0944 - val_accuracy: 0.7632 - val_loss: 0.0869\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.0959 - val_accuracy: 0.7575 - val_loss: 0.0887\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.0964 - val_accuracy: 0.7541 - val_loss: 0.0917\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7367 - loss: 0.0968 - val_accuracy: 0.7705 - val_loss: 0.0848\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7473 - loss: 0.0929 - val_accuracy: 0.7602 - val_loss: 0.0888\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 0.0954 - val_accuracy: 0.7549 - val_loss: 0.0901\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.0939 - val_accuracy: 0.7709 - val_loss: 0.0875\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.0954 - val_accuracy: 0.7659 - val_loss: 0.0854\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7452 - loss: 0.0954 - val_accuracy: 0.7613 - val_loss: 0.0870\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.0927 - val_accuracy: 0.7648 - val_loss: 0.0877\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.0966 - val_accuracy: 0.7789 - val_loss: 0.0833\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6501 - loss: 0.1282 - val_accuracy: 0.6264 - val_loss: 0.1199\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6662 - loss: 0.1184 - val_accuracy: 0.6786 - val_loss: 0.1147\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6802 - loss: 0.1147 - val_accuracy: 0.6885 - val_loss: 0.1162\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.1147 - val_accuracy: 0.6958 - val_loss: 0.1087\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6870 - loss: 0.1110 - val_accuracy: 0.7129 - val_loss: 0.1069\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 0.1118 - val_accuracy: 0.7270 - val_loss: 0.1066\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6925 - loss: 0.1092 - val_accuracy: 0.7301 - val_loss: 0.1035\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.1094 - val_accuracy: 0.7465 - val_loss: 0.1051\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.1090 - val_accuracy: 0.7282 - val_loss: 0.1055\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7083 - loss: 0.1073 - val_accuracy: 0.7526 - val_loss: 0.1008\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7091 - loss: 0.1084 - val_accuracy: 0.7358 - val_loss: 0.1028\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7103 - loss: 0.1057 - val_accuracy: 0.7404 - val_loss: 0.1009\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.1055 - val_accuracy: 0.7552 - val_loss: 0.0987\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7089 - loss: 0.1063 - val_accuracy: 0.7423 - val_loss: 0.1021\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.1077 - val_accuracy: 0.7457 - val_loss: 0.0978\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.1043 - val_accuracy: 0.7552 - val_loss: 0.0987\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.1032 - val_accuracy: 0.7476 - val_loss: 0.1002\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.1008 - val_accuracy: 0.7568 - val_loss: 0.0991\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.1043 - val_accuracy: 0.7373 - val_loss: 0.1000\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7123 - loss: 0.1068 - val_accuracy: 0.7514 - val_loss: 0.0989\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.0998 - val_accuracy: 0.7587 - val_loss: 0.0949\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.1001 - val_accuracy: 0.7556 - val_loss: 0.0957\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.0996 - val_accuracy: 0.7571 - val_loss: 0.0947\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.1022 - val_accuracy: 0.7518 - val_loss: 0.0967\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.1040 - val_accuracy: 0.7453 - val_loss: 0.0983\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.0987 - val_accuracy: 0.7320 - val_loss: 0.0951\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7238 - loss: 0.1009 - val_accuracy: 0.7583 - val_loss: 0.0946\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 0.1014 - val_accuracy: 0.7629 - val_loss: 0.0936\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7288 - loss: 0.0992 - val_accuracy: 0.7613 - val_loss: 0.0930\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.0936 - val_accuracy: 0.7625 - val_loss: 0.0928\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.1014 - val_accuracy: 0.7564 - val_loss: 0.0922\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7394 - loss: 0.0966 - val_accuracy: 0.7537 - val_loss: 0.0935\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.0967 - val_accuracy: 0.7549 - val_loss: 0.0931\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.0952 - val_accuracy: 0.7602 - val_loss: 0.0915\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7373 - loss: 0.0955 - val_accuracy: 0.7743 - val_loss: 0.0910\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.0956 - val_accuracy: 0.7693 - val_loss: 0.0903\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.0979 - val_accuracy: 0.7716 - val_loss: 0.0934\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.0976 - val_accuracy: 0.7743 - val_loss: 0.0890\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7401 - loss: 0.0953 - val_accuracy: 0.7690 - val_loss: 0.0887\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7454 - loss: 0.0931 - val_accuracy: 0.7621 - val_loss: 0.0893\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.0950 - val_accuracy: 0.7743 - val_loss: 0.0898\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.0915 - val_accuracy: 0.7625 - val_loss: 0.0895\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.0949 - val_accuracy: 0.7697 - val_loss: 0.0897\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.0939 - val_accuracy: 0.7686 - val_loss: 0.0876\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.0934 - val_accuracy: 0.7747 - val_loss: 0.0876\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.0936 - val_accuracy: 0.7732 - val_loss: 0.0881\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.0925 - val_accuracy: 0.7648 - val_loss: 0.0881\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7469 - loss: 0.0950 - val_accuracy: 0.7815 - val_loss: 0.0873\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.0905 - val_accuracy: 0.7613 - val_loss: 0.0872\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.0955 - val_accuracy: 0.7587 - val_loss: 0.0878\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6482 - loss: 0.1316 - val_accuracy: 0.6686 - val_loss: 0.1176\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6753 - loss: 0.1173 - val_accuracy: 0.6857 - val_loss: 0.1137\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6872 - loss: 0.1159 - val_accuracy: 0.6831 - val_loss: 0.1169\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6815 - loss: 0.1133 - val_accuracy: 0.6934 - val_loss: 0.1113\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6848 - loss: 0.1143 - val_accuracy: 0.6922 - val_loss: 0.1106\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6969 - loss: 0.1120 - val_accuracy: 0.6972 - val_loss: 0.1095\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7043 - loss: 0.1104 - val_accuracy: 0.7098 - val_loss: 0.1085\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7020 - loss: 0.1075 - val_accuracy: 0.7143 - val_loss: 0.1050\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7061 - loss: 0.1063 - val_accuracy: 0.7018 - val_loss: 0.1081\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 0.1076 - val_accuracy: 0.7208 - val_loss: 0.1070\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7161 - loss: 0.1065 - val_accuracy: 0.7201 - val_loss: 0.1050\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.1047 - val_accuracy: 0.7239 - val_loss: 0.1030\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.1058 - val_accuracy: 0.7353 - val_loss: 0.1012\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.1044 - val_accuracy: 0.7082 - val_loss: 0.1028\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7138 - loss: 0.1040 - val_accuracy: 0.7277 - val_loss: 0.1000\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7176 - loss: 0.1054 - val_accuracy: 0.7330 - val_loss: 0.1001\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 0.0988 - val_accuracy: 0.7243 - val_loss: 0.1023\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7360 - loss: 0.1018 - val_accuracy: 0.7387 - val_loss: 0.0994\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.1017 - val_accuracy: 0.7498 - val_loss: 0.0963\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 0.0964 - val_accuracy: 0.7353 - val_loss: 0.0971\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.1000 - val_accuracy: 0.7483 - val_loss: 0.0929\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 0.0979 - val_accuracy: 0.7368 - val_loss: 0.0960\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.1014 - val_accuracy: 0.7323 - val_loss: 0.0937\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.0959 - val_accuracy: 0.7601 - val_loss: 0.0912\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.0952 - val_accuracy: 0.7590 - val_loss: 0.0925\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.1005 - val_accuracy: 0.7586 - val_loss: 0.0924\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.1010 - val_accuracy: 0.7429 - val_loss: 0.0925\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7404 - loss: 0.0921 - val_accuracy: 0.7433 - val_loss: 0.0925\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7491 - loss: 0.0958 - val_accuracy: 0.7639 - val_loss: 0.0886\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.0932 - val_accuracy: 0.7422 - val_loss: 0.0941\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.0936 - val_accuracy: 0.7632 - val_loss: 0.0906\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.0914 - val_accuracy: 0.7613 - val_loss: 0.0895\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.0913 - val_accuracy: 0.7494 - val_loss: 0.0908\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7424 - loss: 0.0921 - val_accuracy: 0.7460 - val_loss: 0.0888\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7519 - loss: 0.0906 - val_accuracy: 0.7365 - val_loss: 0.0955\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.0916 - val_accuracy: 0.7605 - val_loss: 0.0896\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.0943 - val_accuracy: 0.7551 - val_loss: 0.0890\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.0924 - val_accuracy: 0.7613 - val_loss: 0.0870\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7499 - loss: 0.0913 - val_accuracy: 0.7639 - val_loss: 0.0886\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.0918 - val_accuracy: 0.7422 - val_loss: 0.0935\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7480 - loss: 0.0922 - val_accuracy: 0.7525 - val_loss: 0.0912\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.0898 - val_accuracy: 0.7551 - val_loss: 0.0884\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.0923 - val_accuracy: 0.7651 - val_loss: 0.0875\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7447 - loss: 0.0940 - val_accuracy: 0.7586 - val_loss: 0.0870\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.0887 - val_accuracy: 0.7647 - val_loss: 0.0871\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7535 - loss: 0.0890 - val_accuracy: 0.7460 - val_loss: 0.0915\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.0909 - val_accuracy: 0.7624 - val_loss: 0.0900\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7524 - loss: 0.0932 - val_accuracy: 0.7662 - val_loss: 0.0869\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.0935 - val_accuracy: 0.7551 - val_loss: 0.0844\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.0897 - val_accuracy: 0.7593 - val_loss: 0.0852\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6553 - loss: 0.1283 - val_accuracy: 0.6876 - val_loss: 0.1137\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6624 - loss: 0.1216 - val_accuracy: 0.6983 - val_loss: 0.1105\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.1146 - val_accuracy: 0.6880 - val_loss: 0.1108\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6867 - loss: 0.1121 - val_accuracy: 0.7056 - val_loss: 0.1149\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6812 - loss: 0.1175 - val_accuracy: 0.7113 - val_loss: 0.1084\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6966 - loss: 0.1136 - val_accuracy: 0.7147 - val_loss: 0.1042\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6940 - loss: 0.1106 - val_accuracy: 0.7025 - val_loss: 0.1092\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6985 - loss: 0.1094 - val_accuracy: 0.7246 - val_loss: 0.1075\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.1135 - val_accuracy: 0.7246 - val_loss: 0.1011\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.1091 - val_accuracy: 0.7250 - val_loss: 0.1004\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 0.1053 - val_accuracy: 0.7182 - val_loss: 0.1025\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7060 - loss: 0.1084 - val_accuracy: 0.7353 - val_loss: 0.1032\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7136 - loss: 0.1056 - val_accuracy: 0.7296 - val_loss: 0.1011\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.1049 - val_accuracy: 0.7403 - val_loss: 0.0977\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.1035 - val_accuracy: 0.7414 - val_loss: 0.0977\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6962 - loss: 0.1090 - val_accuracy: 0.7376 - val_loss: 0.0964\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 0.1059 - val_accuracy: 0.7407 - val_loss: 0.0975\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.1022 - val_accuracy: 0.7021 - val_loss: 0.1031\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7103 - loss: 0.1047 - val_accuracy: 0.7422 - val_loss: 0.0950\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.0984 - val_accuracy: 0.7433 - val_loss: 0.0963\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.1025 - val_accuracy: 0.7361 - val_loss: 0.0985\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7334 - loss: 0.0999 - val_accuracy: 0.7414 - val_loss: 0.0950\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.1035 - val_accuracy: 0.7460 - val_loss: 0.0920\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.0980 - val_accuracy: 0.7464 - val_loss: 0.0923\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7254 - loss: 0.1023 - val_accuracy: 0.7490 - val_loss: 0.0926\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.0977 - val_accuracy: 0.7490 - val_loss: 0.0926\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.0968 - val_accuracy: 0.7475 - val_loss: 0.0923\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.0960 - val_accuracy: 0.7544 - val_loss: 0.0913\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7365 - loss: 0.0994 - val_accuracy: 0.7494 - val_loss: 0.0927\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.0976 - val_accuracy: 0.7517 - val_loss: 0.0932\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.0951 - val_accuracy: 0.7551 - val_loss: 0.0926\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.0966 - val_accuracy: 0.7613 - val_loss: 0.0908\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.0990 - val_accuracy: 0.7502 - val_loss: 0.0920\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7348 - loss: 0.0989 - val_accuracy: 0.7517 - val_loss: 0.0884\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7473 - loss: 0.0962 - val_accuracy: 0.7555 - val_loss: 0.0913\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7472 - loss: 0.0929 - val_accuracy: 0.7513 - val_loss: 0.0889\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.0980 - val_accuracy: 0.7426 - val_loss: 0.0928\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.0962 - val_accuracy: 0.7460 - val_loss: 0.0934\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.0950 - val_accuracy: 0.7601 - val_loss: 0.0889\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7440 - loss: 0.0968 - val_accuracy: 0.7643 - val_loss: 0.0873\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7472 - loss: 0.0925 - val_accuracy: 0.7540 - val_loss: 0.0898\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7424 - loss: 0.0941 - val_accuracy: 0.7551 - val_loss: 0.0881\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.0988 - val_accuracy: 0.7582 - val_loss: 0.0891\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.0937 - val_accuracy: 0.7700 - val_loss: 0.0874\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.0938 - val_accuracy: 0.7590 - val_loss: 0.0859\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7438 - loss: 0.0956 - val_accuracy: 0.7715 - val_loss: 0.0862\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.0925 - val_accuracy: 0.7719 - val_loss: 0.0887\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.0927 - val_accuracy: 0.7540 - val_loss: 0.0864\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.0929 - val_accuracy: 0.7624 - val_loss: 0.0870\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.0933 - val_accuracy: 0.7662 - val_loss: 0.0868\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KI_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6374 - loss: 0.1344 - val_accuracy: 0.6861 - val_loss: 0.1143\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6723 - loss: 0.1166 - val_accuracy: 0.6827 - val_loss: 0.1158\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6749 - loss: 0.1166 - val_accuracy: 0.6865 - val_loss: 0.1105\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6835 - loss: 0.1143 - val_accuracy: 0.7059 - val_loss: 0.1102\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6957 - loss: 0.1152 - val_accuracy: 0.7063 - val_loss: 0.1063\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6898 - loss: 0.1126 - val_accuracy: 0.7258 - val_loss: 0.1075\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6996 - loss: 0.1106 - val_accuracy: 0.7109 - val_loss: 0.1066\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7001 - loss: 0.1103 - val_accuracy: 0.7117 - val_loss: 0.1048\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7113 - loss: 0.1081 - val_accuracy: 0.7185 - val_loss: 0.1056\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.1039 - val_accuracy: 0.7273 - val_loss: 0.1066\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7090 - loss: 0.1078 - val_accuracy: 0.7109 - val_loss: 0.1036\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7271 - loss: 0.1037 - val_accuracy: 0.7296 - val_loss: 0.1003\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7355 - loss: 0.1021 - val_accuracy: 0.7220 - val_loss: 0.1042\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.1027 - val_accuracy: 0.7151 - val_loss: 0.1068\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.1024 - val_accuracy: 0.7258 - val_loss: 0.0991\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7248 - loss: 0.1006 - val_accuracy: 0.7418 - val_loss: 0.0960\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.0985 - val_accuracy: 0.7265 - val_loss: 0.1000\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.1012 - val_accuracy: 0.7300 - val_loss: 0.1004\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.1022 - val_accuracy: 0.7368 - val_loss: 0.0966\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.1001 - val_accuracy: 0.7307 - val_loss: 0.0950\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7370 - loss: 0.0980 - val_accuracy: 0.7468 - val_loss: 0.0956\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7359 - loss: 0.0974 - val_accuracy: 0.7418 - val_loss: 0.0957\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.0986 - val_accuracy: 0.7380 - val_loss: 0.0939\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.0961 - val_accuracy: 0.7315 - val_loss: 0.0946\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.0951 - val_accuracy: 0.7365 - val_loss: 0.0919\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.0963 - val_accuracy: 0.7449 - val_loss: 0.0931\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.0944 - val_accuracy: 0.7452 - val_loss: 0.0931\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7432 - loss: 0.0955 - val_accuracy: 0.7590 - val_loss: 0.0897\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.0944 - val_accuracy: 0.7498 - val_loss: 0.0927\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7439 - loss: 0.0943 - val_accuracy: 0.7658 - val_loss: 0.0881\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7537 - loss: 0.0927 - val_accuracy: 0.7502 - val_loss: 0.0884\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.0956 - val_accuracy: 0.7586 - val_loss: 0.0902\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.0942 - val_accuracy: 0.7445 - val_loss: 0.0902\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7409 - loss: 0.0943 - val_accuracy: 0.7639 - val_loss: 0.0904\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7405 - loss: 0.0965 - val_accuracy: 0.7605 - val_loss: 0.0883\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.0956 - val_accuracy: 0.7475 - val_loss: 0.0893\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7524 - loss: 0.0893 - val_accuracy: 0.7601 - val_loss: 0.0874\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.0915 - val_accuracy: 0.7715 - val_loss: 0.0862\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 0.0928 - val_accuracy: 0.7761 - val_loss: 0.0878\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 0.0919 - val_accuracy: 0.7551 - val_loss: 0.0901\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.0905 - val_accuracy: 0.7380 - val_loss: 0.0927\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.0923 - val_accuracy: 0.7590 - val_loss: 0.0872\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7535 - loss: 0.0920 - val_accuracy: 0.7735 - val_loss: 0.0846\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.0892 - val_accuracy: 0.7582 - val_loss: 0.0873\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.0927 - val_accuracy: 0.7624 - val_loss: 0.0859\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7513 - loss: 0.0909 - val_accuracy: 0.7708 - val_loss: 0.0849\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7584 - loss: 0.0910 - val_accuracy: 0.7750 - val_loss: 0.0853\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.0906 - val_accuracy: 0.7605 - val_loss: 0.0853\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0913 - val_accuracy: 0.7613 - val_loss: 0.0889\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 0.0897 - val_accuracy: 0.7693 - val_loss: 0.0850\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.7665\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7274\n",
      "Macro Recall: 0.5355\n",
      "Macro F1-Score: 0.5635\n",
      "Macro AUC-ROC: 0.8748\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7706\n",
      "Weighted Recall: 0.7665\n",
      "Weighted F1-Score: 0.7549\n",
      "Weighted AUC-ROC: 0.8861\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.629935        0.716333          0.669509     0.877962\n",
      "1      1           0.871448        0.116536          0.199598     0.872404\n",
      "2      2           0.660003        0.468426          0.544475     0.862229\n",
      "3      3           0.632116        0.497006          0.543288     0.867065\n",
      "4      4           0.843558        0.879377          0.860779     0.894302\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2     3       4\n",
      "0  429.8   0.4  11.8   8.4   149.6\n",
      "1   52.2  10.2   2.0   2.8    20.4\n",
      "2   49.0   0.2  77.0   3.6    34.6\n",
      "3   23.6   0.0   2.2  83.0    58.2\n",
      "4  129.0   1.6  24.6  38.2  1410.0\n",
      "\n",
      "Processing week2 with best parameters...\n",
      "best parameters for week2: {'units_1': 96, 'dropout_1': 0.1, 'units_2': 96, 'dropout_2': 0.1, 'learning_rate': 0.0007634521198846196}\n",
      "Fold 1: Using file /kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6052 - loss: 0.1435 - val_accuracy: 0.6916 - val_loss: 0.1078\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.1124 - val_accuracy: 0.7125 - val_loss: 0.1051\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7027 - loss: 0.1092 - val_accuracy: 0.7110 - val_loss: 0.1013\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 0.1073 - val_accuracy: 0.7133 - val_loss: 0.1002\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.1046 - val_accuracy: 0.7499 - val_loss: 0.0965\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.1013 - val_accuracy: 0.7381 - val_loss: 0.0981\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7308 - loss: 0.1019 - val_accuracy: 0.7385 - val_loss: 0.0942\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.1017 - val_accuracy: 0.7423 - val_loss: 0.0946\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.0991 - val_accuracy: 0.7335 - val_loss: 0.0953\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7365 - loss: 0.0996 - val_accuracy: 0.7621 - val_loss: 0.0922\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7308 - loss: 0.0995 - val_accuracy: 0.7514 - val_loss: 0.0912\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.0958 - val_accuracy: 0.7552 - val_loss: 0.0885\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 0.0931 - val_accuracy: 0.7655 - val_loss: 0.0888\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.0922 - val_accuracy: 0.7430 - val_loss: 0.0931\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7488 - loss: 0.0950 - val_accuracy: 0.7632 - val_loss: 0.0872\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7537 - loss: 0.0900 - val_accuracy: 0.7663 - val_loss: 0.0870\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.0881 - val_accuracy: 0.7587 - val_loss: 0.0876\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.0914 - val_accuracy: 0.7751 - val_loss: 0.0844\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7639 - loss: 0.0887 - val_accuracy: 0.7644 - val_loss: 0.0867\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.0916 - val_accuracy: 0.7613 - val_loss: 0.0853\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.0894 - val_accuracy: 0.7632 - val_loss: 0.0856\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7539 - loss: 0.0924 - val_accuracy: 0.7690 - val_loss: 0.0825\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.0911 - val_accuracy: 0.7560 - val_loss: 0.0887\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.0887 - val_accuracy: 0.7735 - val_loss: 0.0830\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.0877 - val_accuracy: 0.7648 - val_loss: 0.0846\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7619 - loss: 0.0879 - val_accuracy: 0.7610 - val_loss: 0.0846\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7578 - loss: 0.0863 - val_accuracy: 0.7632 - val_loss: 0.0823\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7674 - loss: 0.0846 - val_accuracy: 0.7648 - val_loss: 0.0862\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.0893 - val_accuracy: 0.7793 - val_loss: 0.0785\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.0852 - val_accuracy: 0.7819 - val_loss: 0.0803\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.0862 - val_accuracy: 0.7800 - val_loss: 0.0830\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.0863 - val_accuracy: 0.7808 - val_loss: 0.0784\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7629 - loss: 0.0863 - val_accuracy: 0.7682 - val_loss: 0.0815\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.0840 - val_accuracy: 0.7823 - val_loss: 0.0801\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7568 - loss: 0.0876 - val_accuracy: 0.7728 - val_loss: 0.0815\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7683 - loss: 0.0843 - val_accuracy: 0.7857 - val_loss: 0.0779\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.0818 - val_accuracy: 0.7762 - val_loss: 0.0786\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.0803 - val_accuracy: 0.7945 - val_loss: 0.0779\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.0821 - val_accuracy: 0.7998 - val_loss: 0.0769\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.0845 - val_accuracy: 0.7823 - val_loss: 0.0779\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.0822 - val_accuracy: 0.7819 - val_loss: 0.0775\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7706 - loss: 0.0823 - val_accuracy: 0.7812 - val_loss: 0.0769\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7752 - loss: 0.0806 - val_accuracy: 0.7857 - val_loss: 0.0772\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.0808 - val_accuracy: 0.7911 - val_loss: 0.0761\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.0832 - val_accuracy: 0.7949 - val_loss: 0.0769\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.0839 - val_accuracy: 0.7804 - val_loss: 0.0793\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.0802 - val_accuracy: 0.7915 - val_loss: 0.0745\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.0796 - val_accuracy: 0.7949 - val_loss: 0.0752\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.0771 - val_accuracy: 0.7976 - val_loss: 0.0756\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.0781 - val_accuracy: 0.7922 - val_loss: 0.0748\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6356 - loss: 0.1337 - val_accuracy: 0.7022 - val_loss: 0.1146\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6870 - loss: 0.1136 - val_accuracy: 0.7087 - val_loss: 0.1095\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7017 - loss: 0.1061 - val_accuracy: 0.7194 - val_loss: 0.1047\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7005 - loss: 0.1084 - val_accuracy: 0.7396 - val_loss: 0.1003\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.1038 - val_accuracy: 0.7480 - val_loss: 0.0995\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7300 - loss: 0.0983 - val_accuracy: 0.7240 - val_loss: 0.1018\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.1003 - val_accuracy: 0.7617 - val_loss: 0.0965\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.0991 - val_accuracy: 0.7537 - val_loss: 0.0953\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7456 - loss: 0.0933 - val_accuracy: 0.7545 - val_loss: 0.0961\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.0972 - val_accuracy: 0.7560 - val_loss: 0.0932\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7396 - loss: 0.0952 - val_accuracy: 0.7713 - val_loss: 0.0920\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 0.0916 - val_accuracy: 0.7652 - val_loss: 0.0939\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.0919 - val_accuracy: 0.7613 - val_loss: 0.0918\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7482 - loss: 0.0915 - val_accuracy: 0.7636 - val_loss: 0.0906\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.0924 - val_accuracy: 0.7522 - val_loss: 0.0906\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7545 - loss: 0.0903 - val_accuracy: 0.7762 - val_loss: 0.0898\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.0907 - val_accuracy: 0.7655 - val_loss: 0.0905\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.0886 - val_accuracy: 0.7716 - val_loss: 0.0888\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.0915 - val_accuracy: 0.7724 - val_loss: 0.0872\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.0884 - val_accuracy: 0.7583 - val_loss: 0.0914\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.0894 - val_accuracy: 0.7735 - val_loss: 0.0889\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7606 - loss: 0.0859 - val_accuracy: 0.7812 - val_loss: 0.0890\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.0857 - val_accuracy: 0.7842 - val_loss: 0.0853\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7612 - loss: 0.0875 - val_accuracy: 0.7812 - val_loss: 0.0873\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.0851 - val_accuracy: 0.7758 - val_loss: 0.0872\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7635 - loss: 0.0868 - val_accuracy: 0.7655 - val_loss: 0.0871\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7646 - loss: 0.0840 - val_accuracy: 0.7591 - val_loss: 0.0886\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7522 - loss: 0.0869 - val_accuracy: 0.7617 - val_loss: 0.0887\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.0856 - val_accuracy: 0.7735 - val_loss: 0.0855\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.0846 - val_accuracy: 0.7762 - val_loss: 0.0851\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.0830 - val_accuracy: 0.7857 - val_loss: 0.0846\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7710 - loss: 0.0840 - val_accuracy: 0.7857 - val_loss: 0.0847\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 0.0850 - val_accuracy: 0.7793 - val_loss: 0.0830\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.0853 - val_accuracy: 0.7831 - val_loss: 0.0818\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7604 - loss: 0.0859 - val_accuracy: 0.7823 - val_loss: 0.0837\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.0845 - val_accuracy: 0.7812 - val_loss: 0.0827\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.0841 - val_accuracy: 0.7922 - val_loss: 0.0814\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.0806 - val_accuracy: 0.7632 - val_loss: 0.0867\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.0847 - val_accuracy: 0.7876 - val_loss: 0.0818\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.0814 - val_accuracy: 0.7838 - val_loss: 0.0824\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7776 - loss: 0.0823 - val_accuracy: 0.7766 - val_loss: 0.0849\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.0809 - val_accuracy: 0.7865 - val_loss: 0.0841\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 0.0814 - val_accuracy: 0.7907 - val_loss: 0.0813\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7799 - loss: 0.0811 - val_accuracy: 0.7911 - val_loss: 0.0812\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.0799 - val_accuracy: 0.7861 - val_loss: 0.0803\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 0.0796 - val_accuracy: 0.7861 - val_loss: 0.0839\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.0791 - val_accuracy: 0.7827 - val_loss: 0.0824\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7750 - loss: 0.0809 - val_accuracy: 0.7884 - val_loss: 0.0801\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.0792 - val_accuracy: 0.7972 - val_loss: 0.0799\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7823 - loss: 0.0778 - val_accuracy: 0.7941 - val_loss: 0.0806\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6482 - loss: 0.1314 - val_accuracy: 0.6918 - val_loss: 0.1148\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6957 - loss: 0.1129 - val_accuracy: 0.6743 - val_loss: 0.1136\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 0.1079 - val_accuracy: 0.6880 - val_loss: 0.1074\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7158 - loss: 0.1058 - val_accuracy: 0.7227 - val_loss: 0.1023\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.1060 - val_accuracy: 0.7258 - val_loss: 0.1024\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7138 - loss: 0.1073 - val_accuracy: 0.7262 - val_loss: 0.1008\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7346 - loss: 0.1007 - val_accuracy: 0.7159 - val_loss: 0.1026\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 0.1016 - val_accuracy: 0.7460 - val_loss: 0.0979\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.0947 - val_accuracy: 0.7277 - val_loss: 0.1007\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.0978 - val_accuracy: 0.7372 - val_loss: 0.0971\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.0959 - val_accuracy: 0.7414 - val_loss: 0.0965\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.0948 - val_accuracy: 0.7578 - val_loss: 0.0920\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7419 - loss: 0.0955 - val_accuracy: 0.7590 - val_loss: 0.0919\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7488 - loss: 0.0921 - val_accuracy: 0.7437 - val_loss: 0.0942\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0919 - val_accuracy: 0.7433 - val_loss: 0.0934\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.0941 - val_accuracy: 0.7582 - val_loss: 0.0929\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.0926 - val_accuracy: 0.7429 - val_loss: 0.0988\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7499 - loss: 0.0920 - val_accuracy: 0.7609 - val_loss: 0.0923\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7598 - loss: 0.0894 - val_accuracy: 0.7334 - val_loss: 0.0962\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.0920 - val_accuracy: 0.7632 - val_loss: 0.0916\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0905 - val_accuracy: 0.7529 - val_loss: 0.0891\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.0898 - val_accuracy: 0.7525 - val_loss: 0.0898\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7613 - loss: 0.0897 - val_accuracy: 0.7639 - val_loss: 0.0872\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.0884 - val_accuracy: 0.7544 - val_loss: 0.0911\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.0896 - val_accuracy: 0.7708 - val_loss: 0.0868\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7655 - loss: 0.0881 - val_accuracy: 0.7727 - val_loss: 0.0857\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7646 - loss: 0.0875 - val_accuracy: 0.7555 - val_loss: 0.0876\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7669 - loss: 0.0879 - val_accuracy: 0.7590 - val_loss: 0.0863\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.0865 - val_accuracy: 0.7654 - val_loss: 0.0846\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7662 - loss: 0.0862 - val_accuracy: 0.7555 - val_loss: 0.0848\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7606 - loss: 0.0878 - val_accuracy: 0.7590 - val_loss: 0.0872\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7604 - loss: 0.0870 - val_accuracy: 0.7586 - val_loss: 0.0849\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7693 - loss: 0.0855 - val_accuracy: 0.7677 - val_loss: 0.0819\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.0836 - val_accuracy: 0.7689 - val_loss: 0.0813\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7662 - loss: 0.0849 - val_accuracy: 0.7628 - val_loss: 0.0843\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7692 - loss: 0.0824 - val_accuracy: 0.7658 - val_loss: 0.0820\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 0.0822 - val_accuracy: 0.7754 - val_loss: 0.0809\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.0812 - val_accuracy: 0.7696 - val_loss: 0.0845\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.0837 - val_accuracy: 0.7662 - val_loss: 0.0834\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7705 - loss: 0.0834 - val_accuracy: 0.7757 - val_loss: 0.0825\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.0799 - val_accuracy: 0.7792 - val_loss: 0.0814\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 0.0804 - val_accuracy: 0.7784 - val_loss: 0.0823\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.0842 - val_accuracy: 0.7841 - val_loss: 0.0796\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.0853 - val_accuracy: 0.7860 - val_loss: 0.0806\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.0814 - val_accuracy: 0.7799 - val_loss: 0.0805\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.0812 - val_accuracy: 0.7742 - val_loss: 0.0823\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.0821 - val_accuracy: 0.7735 - val_loss: 0.0825\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 0.0798 - val_accuracy: 0.7685 - val_loss: 0.0802\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7725 - loss: 0.0820 - val_accuracy: 0.7761 - val_loss: 0.0797\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.0782 - val_accuracy: 0.7727 - val_loss: 0.0811\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6477 - loss: 0.1322 - val_accuracy: 0.6850 - val_loss: 0.1098\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 0.1138 - val_accuracy: 0.7075 - val_loss: 0.1082\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7023 - loss: 0.1108 - val_accuracy: 0.7273 - val_loss: 0.1021\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.1061 - val_accuracy: 0.7140 - val_loss: 0.1011\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7172 - loss: 0.1027 - val_accuracy: 0.7189 - val_loss: 0.1021\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7133 - loss: 0.1049 - val_accuracy: 0.7422 - val_loss: 0.1000\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.1015 - val_accuracy: 0.7395 - val_loss: 0.0987\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.1007 - val_accuracy: 0.7555 - val_loss: 0.0946\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.0975 - val_accuracy: 0.7441 - val_loss: 0.0938\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.0974 - val_accuracy: 0.7449 - val_loss: 0.0948\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7297 - loss: 0.0963 - val_accuracy: 0.7567 - val_loss: 0.0928\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.0959 - val_accuracy: 0.7567 - val_loss: 0.0920\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7447 - loss: 0.0969 - val_accuracy: 0.7532 - val_loss: 0.0909\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.0924 - val_accuracy: 0.7525 - val_loss: 0.0930\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7402 - loss: 0.0956 - val_accuracy: 0.7624 - val_loss: 0.0907\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7529 - loss: 0.0911 - val_accuracy: 0.7574 - val_loss: 0.0905\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7481 - loss: 0.0928 - val_accuracy: 0.7635 - val_loss: 0.0900\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.0926 - val_accuracy: 0.7731 - val_loss: 0.0886\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.0921 - val_accuracy: 0.7693 - val_loss: 0.0873\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.0917 - val_accuracy: 0.7582 - val_loss: 0.0860\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7543 - loss: 0.0914 - val_accuracy: 0.7605 - val_loss: 0.0861\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.0924 - val_accuracy: 0.7662 - val_loss: 0.0858\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 0.0882 - val_accuracy: 0.7681 - val_loss: 0.0880\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7523 - loss: 0.0900 - val_accuracy: 0.7628 - val_loss: 0.0861\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7563 - loss: 0.0888 - val_accuracy: 0.7723 - val_loss: 0.0848\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.0870 - val_accuracy: 0.7651 - val_loss: 0.0899\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7612 - loss: 0.0875 - val_accuracy: 0.7662 - val_loss: 0.0868\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7649 - loss: 0.0860 - val_accuracy: 0.7643 - val_loss: 0.0853\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 0.0863 - val_accuracy: 0.7735 - val_loss: 0.0834\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 0.0843 - val_accuracy: 0.7723 - val_loss: 0.0832\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.0804 - val_accuracy: 0.7735 - val_loss: 0.0832\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.0848 - val_accuracy: 0.7777 - val_loss: 0.0813\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.0838 - val_accuracy: 0.7803 - val_loss: 0.0810\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7659 - loss: 0.0857 - val_accuracy: 0.7845 - val_loss: 0.0808\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.0814 - val_accuracy: 0.7796 - val_loss: 0.0839\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7677 - loss: 0.0850 - val_accuracy: 0.7765 - val_loss: 0.0812\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.0823 - val_accuracy: 0.7807 - val_loss: 0.0812\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7712 - loss: 0.0820 - val_accuracy: 0.7914 - val_loss: 0.0818\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.0809 - val_accuracy: 0.7773 - val_loss: 0.0808\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.0838 - val_accuracy: 0.7799 - val_loss: 0.0808\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 0.0810 - val_accuracy: 0.7765 - val_loss: 0.0807\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.0813 - val_accuracy: 0.7815 - val_loss: 0.0815\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.0804 - val_accuracy: 0.7857 - val_loss: 0.0791\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7725 - loss: 0.0814 - val_accuracy: 0.7803 - val_loss: 0.0832\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.0810 - val_accuracy: 0.7811 - val_loss: 0.0799\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.0796 - val_accuracy: 0.7845 - val_loss: 0.0784\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7752 - loss: 0.0801 - val_accuracy: 0.7979 - val_loss: 0.0786\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7700 - loss: 0.0823 - val_accuracy: 0.7838 - val_loss: 0.0787\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7799 - loss: 0.0804 - val_accuracy: 0.7914 - val_loss: 0.0786\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7783 - loss: 0.0806 - val_accuracy: 0.7868 - val_loss: 0.0785\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KI_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6121 - loss: 0.1452 - val_accuracy: 0.6876 - val_loss: 0.1130\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6986 - loss: 0.1118 - val_accuracy: 0.6953 - val_loss: 0.1081\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 0.1091 - val_accuracy: 0.7090 - val_loss: 0.1042\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7137 - loss: 0.1051 - val_accuracy: 0.7109 - val_loss: 0.1016\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.1045 - val_accuracy: 0.7147 - val_loss: 0.1027\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.1009 - val_accuracy: 0.7319 - val_loss: 0.0994\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.1049 - val_accuracy: 0.7326 - val_loss: 0.0993\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.1000 - val_accuracy: 0.7285 - val_loss: 0.0987\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7442 - loss: 0.0967 - val_accuracy: 0.7372 - val_loss: 0.0943\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7415 - loss: 0.0968 - val_accuracy: 0.7437 - val_loss: 0.0939\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7415 - loss: 0.0953 - val_accuracy: 0.7490 - val_loss: 0.0949\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.0935 - val_accuracy: 0.7574 - val_loss: 0.0932\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.0926 - val_accuracy: 0.7571 - val_loss: 0.0903\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.0909 - val_accuracy: 0.7582 - val_loss: 0.0894\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.0911 - val_accuracy: 0.7494 - val_loss: 0.0909\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.0921 - val_accuracy: 0.7597 - val_loss: 0.0904\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7535 - loss: 0.0910 - val_accuracy: 0.7483 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7589 - loss: 0.0897 - val_accuracy: 0.7593 - val_loss: 0.0872\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.0892 - val_accuracy: 0.7704 - val_loss: 0.0852\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7626 - loss: 0.0875 - val_accuracy: 0.7521 - val_loss: 0.0872\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7645 - loss: 0.0870 - val_accuracy: 0.7582 - val_loss: 0.0871\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.0858 - val_accuracy: 0.7647 - val_loss: 0.0853\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7636 - loss: 0.0860 - val_accuracy: 0.7613 - val_loss: 0.0873\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7621 - loss: 0.0887 - val_accuracy: 0.7754 - val_loss: 0.0833\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.0873 - val_accuracy: 0.7635 - val_loss: 0.0840\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.0874 - val_accuracy: 0.7536 - val_loss: 0.0842\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.0838 - val_accuracy: 0.7651 - val_loss: 0.0843\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.0826 - val_accuracy: 0.7803 - val_loss: 0.0833\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.0832 - val_accuracy: 0.7780 - val_loss: 0.0822\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7674 - loss: 0.0831 - val_accuracy: 0.7696 - val_loss: 0.0830\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.0858 - val_accuracy: 0.7571 - val_loss: 0.0863\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.0835 - val_accuracy: 0.7750 - val_loss: 0.0821\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.0820 - val_accuracy: 0.7792 - val_loss: 0.0826\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.0805 - val_accuracy: 0.7700 - val_loss: 0.0824\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.0835 - val_accuracy: 0.7750 - val_loss: 0.0821\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.0827 - val_accuracy: 0.7750 - val_loss: 0.0820\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.0827 - val_accuracy: 0.7735 - val_loss: 0.0817\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.0824 - val_accuracy: 0.7677 - val_loss: 0.0822\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.0819 - val_accuracy: 0.7681 - val_loss: 0.0824\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.0829 - val_accuracy: 0.7811 - val_loss: 0.0803\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.0824 - val_accuracy: 0.7822 - val_loss: 0.0807\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.0828 - val_accuracy: 0.7769 - val_loss: 0.0803\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7850 - loss: 0.0790 - val_accuracy: 0.7681 - val_loss: 0.0817\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.0785 - val_accuracy: 0.7895 - val_loss: 0.0787\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.0826 - val_accuracy: 0.7788 - val_loss: 0.0789\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.0786 - val_accuracy: 0.7864 - val_loss: 0.0786\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.0776 - val_accuracy: 0.7868 - val_loss: 0.0787\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.0780 - val_accuracy: 0.7818 - val_loss: 0.0793\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.0780 - val_accuracy: 0.7811 - val_loss: 0.0798\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.0802 - val_accuracy: 0.7830 - val_loss: 0.0783\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.7858\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7473\n",
      "Macro Recall: 0.5464\n",
      "Macro F1-Score: 0.5862\n",
      "Macro AUC-ROC: 0.8959\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7873\n",
      "Weighted Recall: 0.7858\n",
      "Weighted F1-Score: 0.7727\n",
      "Weighted AUC-ROC: 0.9087\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.660286        0.737667          0.695370     0.901165\n",
      "1      1           0.744286        0.159274          0.233473     0.894607\n",
      "2      2           0.708265        0.475595          0.562424     0.880582\n",
      "3      3           0.777270        0.455090          0.565295     0.885545\n",
      "4      4           0.846360        0.904200          0.874197     0.917558\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2     3       4\n",
      "0  442.6   4.2   9.4   2.8   141.0\n",
      "1   49.6  14.0   1.4   2.0    20.6\n",
      "2   44.2   0.8  78.2   3.0    38.2\n",
      "3   24.4   0.2   2.6  76.0    63.8\n",
      "4  113.0   3.0  20.6  17.0  1449.8\n",
      "\n",
      "Processing week3 with best parameters...\n",
      "best parameters for week3: {'units_1': 96, 'dropout_1': 0.2, 'units_2': 160, 'dropout_2': 0.2, 'learning_rate': 0.0019833455634702653}\n",
      "Fold 1: Using file /kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6302 - loss: 0.1388 - val_accuracy: 0.6988 - val_loss: 0.1163\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6582 - loss: 0.1238 - val_accuracy: 0.7244 - val_loss: 0.1063\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6790 - loss: 0.1182 - val_accuracy: 0.7026 - val_loss: 0.1073\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6849 - loss: 0.1140 - val_accuracy: 0.7293 - val_loss: 0.1034\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6931 - loss: 0.1111 - val_accuracy: 0.7232 - val_loss: 0.1017\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7116 - loss: 0.1088 - val_accuracy: 0.7392 - val_loss: 0.1004\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.1072 - val_accuracy: 0.7282 - val_loss: 0.1007\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.1025 - val_accuracy: 0.7312 - val_loss: 0.0985\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7161 - loss: 0.1051 - val_accuracy: 0.7469 - val_loss: 0.0975\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.1061 - val_accuracy: 0.7472 - val_loss: 0.0965\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7126 - loss: 0.1040 - val_accuracy: 0.7518 - val_loss: 0.0927\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7270 - loss: 0.1038 - val_accuracy: 0.7518 - val_loss: 0.0933\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.1016 - val_accuracy: 0.7480 - val_loss: 0.0947\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.1021 - val_accuracy: 0.7579 - val_loss: 0.0927\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7315 - loss: 0.1008 - val_accuracy: 0.7408 - val_loss: 0.0954\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.1018 - val_accuracy: 0.7396 - val_loss: 0.0928\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7261 - loss: 0.1008 - val_accuracy: 0.7560 - val_loss: 0.0940\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.1008 - val_accuracy: 0.7743 - val_loss: 0.0893\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.0990 - val_accuracy: 0.7457 - val_loss: 0.0960\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 0.1025 - val_accuracy: 0.7655 - val_loss: 0.0918\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7203 - loss: 0.1002 - val_accuracy: 0.7732 - val_loss: 0.0883\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.1006 - val_accuracy: 0.7678 - val_loss: 0.0876\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.0974 - val_accuracy: 0.7663 - val_loss: 0.0886\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.0957 - val_accuracy: 0.7690 - val_loss: 0.0861\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7329 - loss: 0.0964 - val_accuracy: 0.7781 - val_loss: 0.0874\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.0965 - val_accuracy: 0.7510 - val_loss: 0.0893\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7396 - loss: 0.0957 - val_accuracy: 0.7667 - val_loss: 0.0879\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7442 - loss: 0.0974 - val_accuracy: 0.7617 - val_loss: 0.0889\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.0974 - val_accuracy: 0.7583 - val_loss: 0.0887\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 0.0989 - val_accuracy: 0.7526 - val_loss: 0.0899\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.0948 - val_accuracy: 0.7632 - val_loss: 0.0875\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7488 - loss: 0.0937 - val_accuracy: 0.7789 - val_loss: 0.0828\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0935 - val_accuracy: 0.7697 - val_loss: 0.0841\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.0930 - val_accuracy: 0.7701 - val_loss: 0.0854\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.0946 - val_accuracy: 0.7774 - val_loss: 0.0853\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.0914 - val_accuracy: 0.7827 - val_loss: 0.0838\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.0924 - val_accuracy: 0.7701 - val_loss: 0.0847\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.0888 - val_accuracy: 0.7785 - val_loss: 0.0830\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.0898 - val_accuracy: 0.7693 - val_loss: 0.0841\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.0938 - val_accuracy: 0.7785 - val_loss: 0.0828\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 0.0908 - val_accuracy: 0.7754 - val_loss: 0.0833\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.0934 - val_accuracy: 0.7754 - val_loss: 0.0830\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.0923 - val_accuracy: 0.7705 - val_loss: 0.0869\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 0.0911 - val_accuracy: 0.7739 - val_loss: 0.0837\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.0886 - val_accuracy: 0.7793 - val_loss: 0.0829\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7615 - loss: 0.0892 - val_accuracy: 0.7751 - val_loss: 0.0875\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7548 - loss: 0.0927 - val_accuracy: 0.7671 - val_loss: 0.0835\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.0904 - val_accuracy: 0.7766 - val_loss: 0.0860\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 0.0960 - val_accuracy: 0.7720 - val_loss: 0.0841\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7492 - loss: 0.0921 - val_accuracy: 0.7785 - val_loss: 0.0829\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6292 - loss: 0.1344 - val_accuracy: 0.6885 - val_loss: 0.1170\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.1197 - val_accuracy: 0.6977 - val_loss: 0.1118\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6832 - loss: 0.1128 - val_accuracy: 0.7160 - val_loss: 0.1066\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6959 - loss: 0.1109 - val_accuracy: 0.7007 - val_loss: 0.1102\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6956 - loss: 0.1093 - val_accuracy: 0.7419 - val_loss: 0.1077\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6987 - loss: 0.1120 - val_accuracy: 0.7270 - val_loss: 0.1040\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6941 - loss: 0.1073 - val_accuracy: 0.7423 - val_loss: 0.0998\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.1045 - val_accuracy: 0.7526 - val_loss: 0.1005\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.1061 - val_accuracy: 0.7385 - val_loss: 0.1001\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7203 - loss: 0.1063 - val_accuracy: 0.7400 - val_loss: 0.0997\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.1005 - val_accuracy: 0.7495 - val_loss: 0.0988\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7185 - loss: 0.1010 - val_accuracy: 0.7453 - val_loss: 0.1013\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.1017 - val_accuracy: 0.7564 - val_loss: 0.0993\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 0.1026 - val_accuracy: 0.7610 - val_loss: 0.0962\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 0.1047 - val_accuracy: 0.7655 - val_loss: 0.0951\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.1035 - val_accuracy: 0.7549 - val_loss: 0.0960\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.1011 - val_accuracy: 0.7541 - val_loss: 0.0945\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7306 - loss: 0.0977 - val_accuracy: 0.7613 - val_loss: 0.0935\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7407 - loss: 0.0962 - val_accuracy: 0.7671 - val_loss: 0.0917\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.0997 - val_accuracy: 0.7591 - val_loss: 0.0941\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.0990 - val_accuracy: 0.7655 - val_loss: 0.0929\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.0975 - val_accuracy: 0.7655 - val_loss: 0.0934\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.0970 - val_accuracy: 0.7709 - val_loss: 0.0923\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7449 - loss: 0.0938 - val_accuracy: 0.7617 - val_loss: 0.0903\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7369 - loss: 0.0974 - val_accuracy: 0.7068 - val_loss: 0.1063\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7468 - loss: 0.0960 - val_accuracy: 0.7724 - val_loss: 0.0906\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7456 - loss: 0.0959 - val_accuracy: 0.7800 - val_loss: 0.0912\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.0970 - val_accuracy: 0.7701 - val_loss: 0.0892\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.0971 - val_accuracy: 0.7705 - val_loss: 0.0895\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.0933 - val_accuracy: 0.7743 - val_loss: 0.0896\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.0958 - val_accuracy: 0.7655 - val_loss: 0.0893\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.0941 - val_accuracy: 0.7732 - val_loss: 0.0890\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.0920 - val_accuracy: 0.7701 - val_loss: 0.0894\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.0944 - val_accuracy: 0.7770 - val_loss: 0.0878\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7415 - loss: 0.0949 - val_accuracy: 0.7823 - val_loss: 0.0873\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.0916 - val_accuracy: 0.7793 - val_loss: 0.0876\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.0952 - val_accuracy: 0.7709 - val_loss: 0.0898\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0912 - val_accuracy: 0.7678 - val_loss: 0.0886\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.0906 - val_accuracy: 0.7709 - val_loss: 0.0905\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.0926 - val_accuracy: 0.7892 - val_loss: 0.0860\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.0933 - val_accuracy: 0.7655 - val_loss: 0.0882\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.0895 - val_accuracy: 0.7846 - val_loss: 0.0846\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7647 - loss: 0.0880 - val_accuracy: 0.7796 - val_loss: 0.0849\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7622 - loss: 0.0886 - val_accuracy: 0.7815 - val_loss: 0.0865\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7520 - loss: 0.0906 - val_accuracy: 0.7838 - val_loss: 0.0851\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 0.0942 - val_accuracy: 0.7838 - val_loss: 0.0874\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.0901 - val_accuracy: 0.7800 - val_loss: 0.0861\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7459 - loss: 0.0934 - val_accuracy: 0.7758 - val_loss: 0.0867\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.0880 - val_accuracy: 0.7815 - val_loss: 0.0854\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7567 - loss: 0.0895 - val_accuracy: 0.7804 - val_loss: 0.0854\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6359 - loss: 0.1328 - val_accuracy: 0.6693 - val_loss: 0.1160\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6891 - loss: 0.1121 - val_accuracy: 0.6712 - val_loss: 0.1156\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6884 - loss: 0.1130 - val_accuracy: 0.7079 - val_loss: 0.1096\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7049 - loss: 0.1071 - val_accuracy: 0.7189 - val_loss: 0.1115\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7073 - loss: 0.1086 - val_accuracy: 0.6976 - val_loss: 0.1069\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7075 - loss: 0.1057 - val_accuracy: 0.7258 - val_loss: 0.1059\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7134 - loss: 0.1076 - val_accuracy: 0.7159 - val_loss: 0.1034\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7161 - loss: 0.1058 - val_accuracy: 0.7243 - val_loss: 0.1035\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.1043 - val_accuracy: 0.7258 - val_loss: 0.1034\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.1048 - val_accuracy: 0.7334 - val_loss: 0.1040\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.1066 - val_accuracy: 0.7464 - val_loss: 0.1007\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7145 - loss: 0.1063 - val_accuracy: 0.7292 - val_loss: 0.1023\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7235 - loss: 0.1044 - val_accuracy: 0.7357 - val_loss: 0.0999\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7306 - loss: 0.1017 - val_accuracy: 0.7349 - val_loss: 0.0991\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7284 - loss: 0.1029 - val_accuracy: 0.7193 - val_loss: 0.1010\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.1025 - val_accuracy: 0.7525 - val_loss: 0.0963\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.0996 - val_accuracy: 0.7414 - val_loss: 0.0958\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.0998 - val_accuracy: 0.7426 - val_loss: 0.0948\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7245 - loss: 0.0997 - val_accuracy: 0.7372 - val_loss: 0.0951\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.0983 - val_accuracy: 0.7593 - val_loss: 0.0946\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.1014 - val_accuracy: 0.7517 - val_loss: 0.0909\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.0999 - val_accuracy: 0.7586 - val_loss: 0.0935\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7471 - loss: 0.0936 - val_accuracy: 0.7593 - val_loss: 0.0916\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.0949 - val_accuracy: 0.7449 - val_loss: 0.0971\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7438 - loss: 0.0962 - val_accuracy: 0.7273 - val_loss: 0.0968\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7365 - loss: 0.0964 - val_accuracy: 0.7410 - val_loss: 0.0949\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.0954 - val_accuracy: 0.7571 - val_loss: 0.0921\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 0.0940 - val_accuracy: 0.7548 - val_loss: 0.0894\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.0922 - val_accuracy: 0.7548 - val_loss: 0.0908\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.0951 - val_accuracy: 0.7685 - val_loss: 0.0885\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.0973 - val_accuracy: 0.7582 - val_loss: 0.0944\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.0953 - val_accuracy: 0.7643 - val_loss: 0.0885\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0925 - val_accuracy: 0.7647 - val_loss: 0.0886\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7486 - loss: 0.0915 - val_accuracy: 0.7666 - val_loss: 0.0882\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.0954 - val_accuracy: 0.7658 - val_loss: 0.0887\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.0901 - val_accuracy: 0.7796 - val_loss: 0.0860\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7592 - loss: 0.0931 - val_accuracy: 0.7632 - val_loss: 0.0879\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7437 - loss: 0.0937 - val_accuracy: 0.7582 - val_loss: 0.0876\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7522 - loss: 0.0939 - val_accuracy: 0.7582 - val_loss: 0.0874\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.0920 - val_accuracy: 0.7704 - val_loss: 0.0856\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 0.0890 - val_accuracy: 0.7471 - val_loss: 0.0942\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.0912 - val_accuracy: 0.7727 - val_loss: 0.0874\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7535 - loss: 0.0934 - val_accuracy: 0.7613 - val_loss: 0.0869\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7584 - loss: 0.0915 - val_accuracy: 0.7723 - val_loss: 0.0861\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0896 - val_accuracy: 0.7738 - val_loss: 0.0850\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7623 - loss: 0.0901 - val_accuracy: 0.7738 - val_loss: 0.0842\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7546 - loss: 0.0920 - val_accuracy: 0.7704 - val_loss: 0.0871\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.0892 - val_accuracy: 0.7693 - val_loss: 0.0835\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7575 - loss: 0.0881 - val_accuracy: 0.7719 - val_loss: 0.0833\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.0901 - val_accuracy: 0.7715 - val_loss: 0.0836\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6345 - loss: 0.1317 - val_accuracy: 0.6800 - val_loss: 0.1160\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6668 - loss: 0.1197 - val_accuracy: 0.7086 - val_loss: 0.1137\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6843 - loss: 0.1134 - val_accuracy: 0.7079 - val_loss: 0.1079\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6899 - loss: 0.1130 - val_accuracy: 0.7117 - val_loss: 0.1038\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.1117 - val_accuracy: 0.7288 - val_loss: 0.1038\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7041 - loss: 0.1101 - val_accuracy: 0.7342 - val_loss: 0.1002\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7138 - loss: 0.1067 - val_accuracy: 0.7391 - val_loss: 0.1027\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7117 - loss: 0.1062 - val_accuracy: 0.7414 - val_loss: 0.0991\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7239 - loss: 0.1031 - val_accuracy: 0.7452 - val_loss: 0.0987\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.1044 - val_accuracy: 0.7452 - val_loss: 0.0960\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.1023 - val_accuracy: 0.7422 - val_loss: 0.0973\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.1007 - val_accuracy: 0.7384 - val_loss: 0.0951\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.0996 - val_accuracy: 0.7513 - val_loss: 0.0953\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7255 - loss: 0.1009 - val_accuracy: 0.7490 - val_loss: 0.0947\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7351 - loss: 0.0987 - val_accuracy: 0.7445 - val_loss: 0.0943\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.1004 - val_accuracy: 0.7437 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.0968 - val_accuracy: 0.7498 - val_loss: 0.0917\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.0991 - val_accuracy: 0.7475 - val_loss: 0.0956\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.0984 - val_accuracy: 0.7456 - val_loss: 0.0930\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.0978 - val_accuracy: 0.7548 - val_loss: 0.0885\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.0975 - val_accuracy: 0.7468 - val_loss: 0.0933\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.0968 - val_accuracy: 0.7616 - val_loss: 0.0896\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.0949 - val_accuracy: 0.7635 - val_loss: 0.0890\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7461 - loss: 0.0935 - val_accuracy: 0.7582 - val_loss: 0.0892\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.0967 - val_accuracy: 0.7635 - val_loss: 0.0883\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.0929 - val_accuracy: 0.7597 - val_loss: 0.0957\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.0887 - val_accuracy: 0.7620 - val_loss: 0.0885\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7494 - loss: 0.0949 - val_accuracy: 0.7647 - val_loss: 0.0869\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7475 - loss: 0.0925 - val_accuracy: 0.7605 - val_loss: 0.0876\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7524 - loss: 0.0943 - val_accuracy: 0.7647 - val_loss: 0.0859\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7460 - loss: 0.0943 - val_accuracy: 0.7525 - val_loss: 0.0957\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.0930 - val_accuracy: 0.7708 - val_loss: 0.0882\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.0922 - val_accuracy: 0.7685 - val_loss: 0.0867\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7428 - loss: 0.0935 - val_accuracy: 0.7742 - val_loss: 0.0842\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.0915 - val_accuracy: 0.7609 - val_loss: 0.0875\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.0906 - val_accuracy: 0.7654 - val_loss: 0.0878\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.0943 - val_accuracy: 0.7643 - val_loss: 0.0853\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.0927 - val_accuracy: 0.7551 - val_loss: 0.0863\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 0.0913 - val_accuracy: 0.7651 - val_loss: 0.0890\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7481 - loss: 0.0928 - val_accuracy: 0.7685 - val_loss: 0.0850\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.0912 - val_accuracy: 0.7746 - val_loss: 0.0822\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7523 - loss: 0.0906 - val_accuracy: 0.7685 - val_loss: 0.0858\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.0877 - val_accuracy: 0.7555 - val_loss: 0.0906\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 0.0898 - val_accuracy: 0.7647 - val_loss: 0.0859\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 0.0892 - val_accuracy: 0.7780 - val_loss: 0.0845\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7647 - loss: 0.0881 - val_accuracy: 0.7715 - val_loss: 0.0854\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.0878 - val_accuracy: 0.7792 - val_loss: 0.0820\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.0888 - val_accuracy: 0.7670 - val_loss: 0.0850\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7613 - loss: 0.0906 - val_accuracy: 0.7773 - val_loss: 0.0832\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.0870 - val_accuracy: 0.7818 - val_loss: 0.0825\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KI_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6390 - loss: 0.1325 - val_accuracy: 0.6716 - val_loss: 0.1203\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6685 - loss: 0.1176 - val_accuracy: 0.6846 - val_loss: 0.1110\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 0.1146 - val_accuracy: 0.6957 - val_loss: 0.1081\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.1133 - val_accuracy: 0.7155 - val_loss: 0.1029\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7072 - loss: 0.1099 - val_accuracy: 0.7243 - val_loss: 0.1039\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 0.1071 - val_accuracy: 0.7319 - val_loss: 0.1010\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7198 - loss: 0.1049 - val_accuracy: 0.7300 - val_loss: 0.1028\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.1049 - val_accuracy: 0.7407 - val_loss: 0.1000\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7288 - loss: 0.1021 - val_accuracy: 0.7243 - val_loss: 0.1009\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.1031 - val_accuracy: 0.7429 - val_loss: 0.0985\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.1008 - val_accuracy: 0.7292 - val_loss: 0.1003\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7240 - loss: 0.1030 - val_accuracy: 0.7429 - val_loss: 0.0945\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.1007 - val_accuracy: 0.7506 - val_loss: 0.0975\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7371 - loss: 0.0975 - val_accuracy: 0.7357 - val_loss: 0.0979\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.0991 - val_accuracy: 0.7334 - val_loss: 0.0964\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.1003 - val_accuracy: 0.7361 - val_loss: 0.0947\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7377 - loss: 0.0988 - val_accuracy: 0.7407 - val_loss: 0.0953\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.0990 - val_accuracy: 0.7311 - val_loss: 0.0974\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.0997 - val_accuracy: 0.7601 - val_loss: 0.0909\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.0979 - val_accuracy: 0.7460 - val_loss: 0.0916\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.0978 - val_accuracy: 0.7441 - val_loss: 0.0942\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7395 - loss: 0.0971 - val_accuracy: 0.7365 - val_loss: 0.0928\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.0953 - val_accuracy: 0.7613 - val_loss: 0.0890\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7489 - loss: 0.0934 - val_accuracy: 0.7513 - val_loss: 0.0934\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7401 - loss: 0.0980 - val_accuracy: 0.7628 - val_loss: 0.0896\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7502 - loss: 0.0948 - val_accuracy: 0.7555 - val_loss: 0.0970\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.0967 - val_accuracy: 0.7387 - val_loss: 0.0946\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.0969 - val_accuracy: 0.7479 - val_loss: 0.0920\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.0941 - val_accuracy: 0.7700 - val_loss: 0.0877\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.0927 - val_accuracy: 0.7597 - val_loss: 0.0880\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.0934 - val_accuracy: 0.7536 - val_loss: 0.0887\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.0930 - val_accuracy: 0.7700 - val_loss: 0.0872\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.0924 - val_accuracy: 0.7571 - val_loss: 0.0908\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.0920 - val_accuracy: 0.7590 - val_loss: 0.0875\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.0921 - val_accuracy: 0.7551 - val_loss: 0.0906\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.0945 - val_accuracy: 0.7590 - val_loss: 0.0875\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.0949 - val_accuracy: 0.7635 - val_loss: 0.0895\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.0929 - val_accuracy: 0.7666 - val_loss: 0.0871\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.0911 - val_accuracy: 0.7571 - val_loss: 0.0890\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 0.0950 - val_accuracy: 0.7704 - val_loss: 0.0869\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.0942 - val_accuracy: 0.7551 - val_loss: 0.0890\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7406 - loss: 0.0950 - val_accuracy: 0.7605 - val_loss: 0.0873\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.0904 - val_accuracy: 0.7666 - val_loss: 0.0856\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.0894 - val_accuracy: 0.7731 - val_loss: 0.0842\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.0898 - val_accuracy: 0.7715 - val_loss: 0.0854\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7491 - loss: 0.0915 - val_accuracy: 0.7674 - val_loss: 0.0853\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7621 - loss: 0.0890 - val_accuracy: 0.7712 - val_loss: 0.0860\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.0920 - val_accuracy: 0.7628 - val_loss: 0.0851\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7494 - loss: 0.0909 - val_accuracy: 0.7723 - val_loss: 0.0849\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.0901 - val_accuracy: 0.7674 - val_loss: 0.0837\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.7759\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7259\n",
      "Macro Recall: 0.5207\n",
      "Macro F1-Score: 0.5613\n",
      "Macro AUC-ROC: 0.8789\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7743\n",
      "Weighted Recall: 0.7759\n",
      "Weighted F1-Score: 0.7606\n",
      "Weighted AUC-ROC: 0.8902\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.646324        0.737000          0.688430     0.881234\n",
      "1      1           0.701930        0.118495          0.196419     0.884825\n",
      "2      2           0.703025        0.441508          0.534856     0.865075\n",
      "3      3           0.741579        0.407186          0.519991     0.864544\n",
      "4      4           0.836818        0.899086          0.866591     0.899062\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2     3       4\n",
      "0  442.2   3.6  10.2   4.6   139.4\n",
      "1   49.6  10.4   1.0   3.6    23.0\n",
      "2   41.4   0.2  72.6   4.0    46.2\n",
      "3   23.0   0.0   2.4  68.0    73.6\n",
      "4  129.0   1.4  18.8  12.6  1441.6\n",
      "\n",
      "Processing week4 with best parameters...\n",
      "best parameters for week4: {'units_1': 128, 'dropout_1': 0.5, 'units_2': 256, 'dropout_2': 0.2, 'learning_rate': 0.0010692731625104286}\n",
      "Fold 1: Using file /kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6186 - loss: 0.1390 - val_accuracy: 0.6729 - val_loss: 0.1133\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6614 - loss: 0.1191 - val_accuracy: 0.7118 - val_loss: 0.1079\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6707 - loss: 0.1174 - val_accuracy: 0.7011 - val_loss: 0.1089\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6758 - loss: 0.1159 - val_accuracy: 0.7064 - val_loss: 0.1041\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6805 - loss: 0.1164 - val_accuracy: 0.7164 - val_loss: 0.1031\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.1070 - val_accuracy: 0.7141 - val_loss: 0.1002\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7121 - loss: 0.1081 - val_accuracy: 0.7358 - val_loss: 0.1004\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.1082 - val_accuracy: 0.7327 - val_loss: 0.0989\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.1043 - val_accuracy: 0.7259 - val_loss: 0.0989\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.1090 - val_accuracy: 0.7434 - val_loss: 0.0970\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7184 - loss: 0.1083 - val_accuracy: 0.7400 - val_loss: 0.0959\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.1045 - val_accuracy: 0.7533 - val_loss: 0.0921\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7231 - loss: 0.1031 - val_accuracy: 0.7419 - val_loss: 0.0954\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.1045 - val_accuracy: 0.7537 - val_loss: 0.0906\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7311 - loss: 0.0997 - val_accuracy: 0.7449 - val_loss: 0.0909\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7270 - loss: 0.1012 - val_accuracy: 0.7476 - val_loss: 0.0922\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7253 - loss: 0.1007 - val_accuracy: 0.7701 - val_loss: 0.0903\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.1003 - val_accuracy: 0.7724 - val_loss: 0.0891\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.0974 - val_accuracy: 0.7594 - val_loss: 0.0883\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7307 - loss: 0.1017 - val_accuracy: 0.7568 - val_loss: 0.0891\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.0983 - val_accuracy: 0.7613 - val_loss: 0.0886\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7376 - loss: 0.0990 - val_accuracy: 0.7549 - val_loss: 0.0881\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.0964 - val_accuracy: 0.7598 - val_loss: 0.0871\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.0993 - val_accuracy: 0.7796 - val_loss: 0.0863\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 0.0952 - val_accuracy: 0.7770 - val_loss: 0.0876\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.0950 - val_accuracy: 0.7800 - val_loss: 0.0858\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.0953 - val_accuracy: 0.7770 - val_loss: 0.0851\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7463 - loss: 0.0941 - val_accuracy: 0.7713 - val_loss: 0.0846\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7446 - loss: 0.0944 - val_accuracy: 0.7625 - val_loss: 0.0871\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.0978 - val_accuracy: 0.7869 - val_loss: 0.0846\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.0948 - val_accuracy: 0.7747 - val_loss: 0.0835\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.0916 - val_accuracy: 0.7758 - val_loss: 0.0842\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7486 - loss: 0.0920 - val_accuracy: 0.7697 - val_loss: 0.0854\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7493 - loss: 0.0932 - val_accuracy: 0.7827 - val_loss: 0.0817\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7437 - loss: 0.0940 - val_accuracy: 0.7781 - val_loss: 0.0820\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7459 - loss: 0.0920 - val_accuracy: 0.7754 - val_loss: 0.0830\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7548 - loss: 0.0900 - val_accuracy: 0.7823 - val_loss: 0.0813\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0905 - val_accuracy: 0.7701 - val_loss: 0.0819\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.0917 - val_accuracy: 0.7583 - val_loss: 0.0826\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.0939 - val_accuracy: 0.7884 - val_loss: 0.0827\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7456 - loss: 0.0938 - val_accuracy: 0.7960 - val_loss: 0.0819\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.0914 - val_accuracy: 0.7926 - val_loss: 0.0790\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7546 - loss: 0.0914 - val_accuracy: 0.7758 - val_loss: 0.0800\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7649 - loss: 0.0873 - val_accuracy: 0.7720 - val_loss: 0.0813\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7548 - loss: 0.0900 - val_accuracy: 0.7831 - val_loss: 0.0815\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7527 - loss: 0.0934 - val_accuracy: 0.7884 - val_loss: 0.0803\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.0906 - val_accuracy: 0.7884 - val_loss: 0.0788\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7649 - loss: 0.0879 - val_accuracy: 0.7812 - val_loss: 0.0817\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0912 - val_accuracy: 0.7846 - val_loss: 0.0787\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.0901 - val_accuracy: 0.7812 - val_loss: 0.0796\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6108 - loss: 0.1370 - val_accuracy: 0.6817 - val_loss: 0.1148\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6537 - loss: 0.1232 - val_accuracy: 0.6900 - val_loss: 0.1115\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.1137 - val_accuracy: 0.7213 - val_loss: 0.1092\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6776 - loss: 0.1129 - val_accuracy: 0.7061 - val_loss: 0.1083\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6867 - loss: 0.1122 - val_accuracy: 0.7198 - val_loss: 0.1067\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.1102 - val_accuracy: 0.7228 - val_loss: 0.1028\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.1055 - val_accuracy: 0.7560 - val_loss: 0.1028\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.1061 - val_accuracy: 0.7484 - val_loss: 0.1000\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7147 - loss: 0.1037 - val_accuracy: 0.7449 - val_loss: 0.1007\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.1028 - val_accuracy: 0.7472 - val_loss: 0.0986\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.1021 - val_accuracy: 0.7530 - val_loss: 0.0974\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7264 - loss: 0.1007 - val_accuracy: 0.7480 - val_loss: 0.0978\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.1025 - val_accuracy: 0.7571 - val_loss: 0.0950\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.1038 - val_accuracy: 0.7549 - val_loss: 0.0946\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.1026 - val_accuracy: 0.7571 - val_loss: 0.0942\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.1009 - val_accuracy: 0.7682 - val_loss: 0.0930\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.0971 - val_accuracy: 0.7690 - val_loss: 0.0948\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7308 - loss: 0.0995 - val_accuracy: 0.7781 - val_loss: 0.0912\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.0979 - val_accuracy: 0.7678 - val_loss: 0.0910\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.0989 - val_accuracy: 0.7716 - val_loss: 0.0904\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 0.0925 - val_accuracy: 0.7507 - val_loss: 0.0917\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7313 - loss: 0.0997 - val_accuracy: 0.7735 - val_loss: 0.0900\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.0951 - val_accuracy: 0.7777 - val_loss: 0.0894\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7336 - loss: 0.0976 - val_accuracy: 0.7709 - val_loss: 0.0882\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7401 - loss: 0.0951 - val_accuracy: 0.7819 - val_loss: 0.0883\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7360 - loss: 0.0958 - val_accuracy: 0.7693 - val_loss: 0.0904\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.0934 - val_accuracy: 0.7796 - val_loss: 0.0878\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7365 - loss: 0.0953 - val_accuracy: 0.7789 - val_loss: 0.0884\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7402 - loss: 0.0934 - val_accuracy: 0.7785 - val_loss: 0.0888\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.0919 - val_accuracy: 0.7754 - val_loss: 0.0879\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7461 - loss: 0.0920 - val_accuracy: 0.7774 - val_loss: 0.0865\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7506 - loss: 0.0902 - val_accuracy: 0.7777 - val_loss: 0.0857\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.0895 - val_accuracy: 0.7770 - val_loss: 0.0846\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7506 - loss: 0.0919 - val_accuracy: 0.7831 - val_loss: 0.0848\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.0914 - val_accuracy: 0.7743 - val_loss: 0.0860\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7599 - loss: 0.0893 - val_accuracy: 0.7831 - val_loss: 0.0862\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.0906 - val_accuracy: 0.7804 - val_loss: 0.0859\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.0913 - val_accuracy: 0.7823 - val_loss: 0.0869\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7539 - loss: 0.0914 - val_accuracy: 0.7774 - val_loss: 0.0849\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7524 - loss: 0.0907 - val_accuracy: 0.7888 - val_loss: 0.0844\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0899 - val_accuracy: 0.7812 - val_loss: 0.0853\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.0909 - val_accuracy: 0.7873 - val_loss: 0.0850\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7624 - loss: 0.0859 - val_accuracy: 0.7804 - val_loss: 0.0841\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7554 - loss: 0.0890 - val_accuracy: 0.7934 - val_loss: 0.0830\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.0899 - val_accuracy: 0.7857 - val_loss: 0.0849\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0876 - val_accuracy: 0.7865 - val_loss: 0.0834\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.0885 - val_accuracy: 0.7812 - val_loss: 0.0831\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.0886 - val_accuracy: 0.7861 - val_loss: 0.0827\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7513 - loss: 0.0908 - val_accuracy: 0.7762 - val_loss: 0.0826\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7617 - loss: 0.0885 - val_accuracy: 0.7854 - val_loss: 0.0842\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6339 - loss: 0.1373 - val_accuracy: 0.6796 - val_loss: 0.1197\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6746 - loss: 0.1165 - val_accuracy: 0.6743 - val_loss: 0.1133\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6808 - loss: 0.1169 - val_accuracy: 0.6903 - val_loss: 0.1117\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6918 - loss: 0.1127 - val_accuracy: 0.6732 - val_loss: 0.1116\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6906 - loss: 0.1146 - val_accuracy: 0.6945 - val_loss: 0.1113\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6986 - loss: 0.1114 - val_accuracy: 0.7105 - val_loss: 0.1051\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7020 - loss: 0.1104 - val_accuracy: 0.7128 - val_loss: 0.1047\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.1086 - val_accuracy: 0.7265 - val_loss: 0.1032\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.1064 - val_accuracy: 0.7330 - val_loss: 0.1037\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.1039 - val_accuracy: 0.7300 - val_loss: 0.1017\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.1050 - val_accuracy: 0.7300 - val_loss: 0.1005\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7287 - loss: 0.1023 - val_accuracy: 0.7227 - val_loss: 0.0983\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.1004 - val_accuracy: 0.7258 - val_loss: 0.0972\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7374 - loss: 0.0998 - val_accuracy: 0.7346 - val_loss: 0.0964\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.1001 - val_accuracy: 0.7517 - val_loss: 0.0974\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7352 - loss: 0.0979 - val_accuracy: 0.7498 - val_loss: 0.0968\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.1008 - val_accuracy: 0.7555 - val_loss: 0.0962\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7337 - loss: 0.0985 - val_accuracy: 0.7517 - val_loss: 0.0953\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7294 - loss: 0.1019 - val_accuracy: 0.7326 - val_loss: 0.0964\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 0.1008 - val_accuracy: 0.7445 - val_loss: 0.0972\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.0978 - val_accuracy: 0.7517 - val_loss: 0.0938\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.0960 - val_accuracy: 0.7525 - val_loss: 0.0928\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.0939 - val_accuracy: 0.7586 - val_loss: 0.0903\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.0946 - val_accuracy: 0.7475 - val_loss: 0.0941\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7460 - loss: 0.0960 - val_accuracy: 0.7510 - val_loss: 0.0894\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.0972 - val_accuracy: 0.7578 - val_loss: 0.0908\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7449 - loss: 0.0957 - val_accuracy: 0.7662 - val_loss: 0.0916\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.0930 - val_accuracy: 0.7639 - val_loss: 0.0890\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7475 - loss: 0.0947 - val_accuracy: 0.7613 - val_loss: 0.0886\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.0948 - val_accuracy: 0.7548 - val_loss: 0.0878\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7449 - loss: 0.0951 - val_accuracy: 0.7689 - val_loss: 0.0861\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.0962 - val_accuracy: 0.7586 - val_loss: 0.0895\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7540 - loss: 0.0929 - val_accuracy: 0.7582 - val_loss: 0.0889\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7454 - loss: 0.0953 - val_accuracy: 0.7624 - val_loss: 0.0854\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.0922 - val_accuracy: 0.7624 - val_loss: 0.0876\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7522 - loss: 0.0920 - val_accuracy: 0.7685 - val_loss: 0.0864\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.0895 - val_accuracy: 0.7525 - val_loss: 0.0883\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7476 - loss: 0.0928 - val_accuracy: 0.7651 - val_loss: 0.0866\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.0933 - val_accuracy: 0.7613 - val_loss: 0.0889\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.0923 - val_accuracy: 0.7693 - val_loss: 0.0874\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.0905 - val_accuracy: 0.7639 - val_loss: 0.0866\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.0912 - val_accuracy: 0.7765 - val_loss: 0.0864\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.0907 - val_accuracy: 0.7685 - val_loss: 0.0852\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.0908 - val_accuracy: 0.7647 - val_loss: 0.0860\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.0902 - val_accuracy: 0.7780 - val_loss: 0.0846\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7535 - loss: 0.0932 - val_accuracy: 0.7658 - val_loss: 0.0871\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.0922 - val_accuracy: 0.7681 - val_loss: 0.0846\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.0918 - val_accuracy: 0.7757 - val_loss: 0.0850\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7617 - loss: 0.0894 - val_accuracy: 0.7693 - val_loss: 0.0864\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.0948 - val_accuracy: 0.7715 - val_loss: 0.0853\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6258 - loss: 0.1382 - val_accuracy: 0.6876 - val_loss: 0.1115\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 0.1208 - val_accuracy: 0.6865 - val_loss: 0.1100\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6748 - loss: 0.1171 - val_accuracy: 0.7162 - val_loss: 0.1075\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6814 - loss: 0.1121 - val_accuracy: 0.7052 - val_loss: 0.1058\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.1084 - val_accuracy: 0.7178 - val_loss: 0.1029\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.1096 - val_accuracy: 0.7204 - val_loss: 0.1010\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6914 - loss: 0.1082 - val_accuracy: 0.7166 - val_loss: 0.1012\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.1069 - val_accuracy: 0.7407 - val_loss: 0.0973\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.1055 - val_accuracy: 0.7334 - val_loss: 0.0984\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7172 - loss: 0.1040 - val_accuracy: 0.7353 - val_loss: 0.0967\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.1063 - val_accuracy: 0.7422 - val_loss: 0.0979\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7137 - loss: 0.1044 - val_accuracy: 0.7571 - val_loss: 0.0940\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7245 - loss: 0.1035 - val_accuracy: 0.7372 - val_loss: 0.0937\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.1009 - val_accuracy: 0.7479 - val_loss: 0.0923\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.1034 - val_accuracy: 0.7574 - val_loss: 0.0930\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.1023 - val_accuracy: 0.7578 - val_loss: 0.0914\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.0971 - val_accuracy: 0.7517 - val_loss: 0.0929\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.0984 - val_accuracy: 0.7582 - val_loss: 0.0910\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.1005 - val_accuracy: 0.7593 - val_loss: 0.0888\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7297 - loss: 0.1017 - val_accuracy: 0.7586 - val_loss: 0.0889\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.0974 - val_accuracy: 0.7597 - val_loss: 0.0877\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7443 - loss: 0.0967 - val_accuracy: 0.7719 - val_loss: 0.0874\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.0957 - val_accuracy: 0.7639 - val_loss: 0.0880\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.0963 - val_accuracy: 0.7628 - val_loss: 0.0886\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7431 - loss: 0.0932 - val_accuracy: 0.7647 - val_loss: 0.0875\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.0975 - val_accuracy: 0.7597 - val_loss: 0.0880\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.0936 - val_accuracy: 0.7666 - val_loss: 0.0858\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.0945 - val_accuracy: 0.7624 - val_loss: 0.0868\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7371 - loss: 0.0953 - val_accuracy: 0.7735 - val_loss: 0.0844\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7457 - loss: 0.0940 - val_accuracy: 0.7639 - val_loss: 0.0876\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7472 - loss: 0.0935 - val_accuracy: 0.7647 - val_loss: 0.0847\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7435 - loss: 0.0962 - val_accuracy: 0.7662 - val_loss: 0.0847\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.0936 - val_accuracy: 0.7761 - val_loss: 0.0851\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.0917 - val_accuracy: 0.7708 - val_loss: 0.0864\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.0915 - val_accuracy: 0.7677 - val_loss: 0.0858\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.0952 - val_accuracy: 0.7643 - val_loss: 0.0841\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7520 - loss: 0.0915 - val_accuracy: 0.7704 - val_loss: 0.0856\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 0.0916 - val_accuracy: 0.7685 - val_loss: 0.0849\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.0940 - val_accuracy: 0.7712 - val_loss: 0.0842\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7551 - loss: 0.0902 - val_accuracy: 0.7792 - val_loss: 0.0824\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.0928 - val_accuracy: 0.7708 - val_loss: 0.0830\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.0915 - val_accuracy: 0.7742 - val_loss: 0.0841\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.0918 - val_accuracy: 0.7796 - val_loss: 0.0825\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7661 - loss: 0.0884 - val_accuracy: 0.7769 - val_loss: 0.0815\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7563 - loss: 0.0902 - val_accuracy: 0.7735 - val_loss: 0.0819\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7551 - loss: 0.0916 - val_accuracy: 0.7826 - val_loss: 0.0811\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7635 - loss: 0.0888 - val_accuracy: 0.7841 - val_loss: 0.0805\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.0886 - val_accuracy: 0.7841 - val_loss: 0.0803\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7637 - loss: 0.0897 - val_accuracy: 0.7811 - val_loss: 0.0801\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.0886 - val_accuracy: 0.7826 - val_loss: 0.0820\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/KI_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6044 - loss: 0.1413 - val_accuracy: 0.6724 - val_loss: 0.1153\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6653 - loss: 0.1198 - val_accuracy: 0.6934 - val_loss: 0.1105\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6821 - loss: 0.1156 - val_accuracy: 0.6907 - val_loss: 0.1105\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6739 - loss: 0.1162 - val_accuracy: 0.6968 - val_loss: 0.1086\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.1125 - val_accuracy: 0.7067 - val_loss: 0.1047\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.1122 - val_accuracy: 0.7098 - val_loss: 0.1047\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7158 - loss: 0.1087 - val_accuracy: 0.7349 - val_loss: 0.1013\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7196 - loss: 0.1041 - val_accuracy: 0.7208 - val_loss: 0.0995\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.1052 - val_accuracy: 0.7380 - val_loss: 0.1014\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.1068 - val_accuracy: 0.7376 - val_loss: 0.0995\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 0.1001 - val_accuracy: 0.7418 - val_loss: 0.1004\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.1024 - val_accuracy: 0.7387 - val_loss: 0.0965\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.1017 - val_accuracy: 0.7479 - val_loss: 0.0967\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.1003 - val_accuracy: 0.7456 - val_loss: 0.1008\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7294 - loss: 0.1013 - val_accuracy: 0.7433 - val_loss: 0.0965\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.1010 - val_accuracy: 0.7399 - val_loss: 0.0958\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7380 - loss: 0.1009 - val_accuracy: 0.7399 - val_loss: 0.0960\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7372 - loss: 0.0978 - val_accuracy: 0.7498 - val_loss: 0.0934\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.0983 - val_accuracy: 0.7376 - val_loss: 0.0953\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.0982 - val_accuracy: 0.7544 - val_loss: 0.0952\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.0949 - val_accuracy: 0.7521 - val_loss: 0.0930\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.0993 - val_accuracy: 0.7471 - val_loss: 0.0931\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.0999 - val_accuracy: 0.7517 - val_loss: 0.0911\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.0946 - val_accuracy: 0.7571 - val_loss: 0.0925\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.0957 - val_accuracy: 0.7658 - val_loss: 0.0909\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.0934 - val_accuracy: 0.7609 - val_loss: 0.0907\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.0952 - val_accuracy: 0.7475 - val_loss: 0.0920\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.0940 - val_accuracy: 0.7723 - val_loss: 0.0905\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.0928 - val_accuracy: 0.7582 - val_loss: 0.0886\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.0958 - val_accuracy: 0.7628 - val_loss: 0.0885\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.0945 - val_accuracy: 0.7689 - val_loss: 0.0863\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7376 - loss: 0.0948 - val_accuracy: 0.7605 - val_loss: 0.0869\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.0940 - val_accuracy: 0.7681 - val_loss: 0.0868\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.0966 - val_accuracy: 0.7620 - val_loss: 0.0892\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.0920 - val_accuracy: 0.7624 - val_loss: 0.0870\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.0926 - val_accuracy: 0.7708 - val_loss: 0.0866\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7475 - loss: 0.0949 - val_accuracy: 0.7666 - val_loss: 0.0868\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.0901 - val_accuracy: 0.7708 - val_loss: 0.0847\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.0917 - val_accuracy: 0.7624 - val_loss: 0.0864\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.0895 - val_accuracy: 0.7658 - val_loss: 0.0875\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.0907 - val_accuracy: 0.7693 - val_loss: 0.0843\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 0.0865 - val_accuracy: 0.7590 - val_loss: 0.0870\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7548 - loss: 0.0935 - val_accuracy: 0.7700 - val_loss: 0.0855\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.0885 - val_accuracy: 0.7765 - val_loss: 0.0842\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.0878 - val_accuracy: 0.7731 - val_loss: 0.0865\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.0933 - val_accuracy: 0.7788 - val_loss: 0.0852\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.0902 - val_accuracy: 0.7616 - val_loss: 0.0855\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.0932 - val_accuracy: 0.7769 - val_loss: 0.0833\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7539 - loss: 0.0910 - val_accuracy: 0.7815 - val_loss: 0.0856\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.0926 - val_accuracy: 0.7757 - val_loss: 0.0842\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.7793\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.7398\n",
      "Macro Recall: 0.5221\n",
      "Macro F1-Score: 0.5574\n",
      "Macro AUC-ROC: 0.8816\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7766\n",
      "Weighted Recall: 0.7793\n",
      "Weighted F1-Score: 0.7622\n",
      "Weighted AUC-ROC: 0.8938\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.673989        0.705667          0.688792     0.881375\n",
      "1      1           0.793402        0.091040          0.146776     0.877344\n",
      "2      2           0.672950        0.507280          0.575060     0.872331\n",
      "3      3           0.728912        0.394012          0.507615     0.873436\n",
      "4      4           0.829736        0.912436          0.868972     0.903658\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2     3       4\n",
      "0  423.4  3.2  13.6   5.4   154.4\n",
      "1   47.2  8.0   2.0   2.8    27.6\n",
      "2   35.2  0.2  83.4   4.2    41.4\n",
      "3   21.6  0.0   2.2  65.8    77.4\n",
      "4  101.8  1.0  24.6  13.0  1463.0\n"
     ]
    }
   ],
   "source": [
    "# Biến lưu kết quả tổng quát\n",
    "overall_results_5folds = []\n",
    "\n",
    "# Lặp qua từng tuần\n",
    "for week, file_paths in five_fold_files.items():\n",
    "    print(f\"\\nProcessing {week} with best parameters...\")\n",
    "    params = best_params[week].values\n",
    "    print(f\"best parameters for {week}: {params}\")\n",
    "    \n",
    "    # Biến lưu kết quả cho từng tuần\n",
    "    week_results = {\n",
    "        \"week\": week,\n",
    "        \"accuracy_per_fold\": [],\n",
    "        \"precision_per_label\": [],\n",
    "        \"recall_per_label\": [],\n",
    "        \"f1_score_per_label\": [],\n",
    "        \"auc_roc_per_label\": [],    # AUC từng lớp\n",
    "        \"auc_roc_macro\": [],        # AUC macro\n",
    "        \"auc_roc_weighted\": [],     # AUC weighted (tự tính)\n",
    "        \"precision_macro\": [],\n",
    "        \"recall_macro\": [],\n",
    "        \"f1_macro\": [],\n",
    "        \"precision_weighted\": [],\n",
    "        \"recall_weighted\": [],\n",
    "        \"f1_weighted\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"train_times\": [],\n",
    "        \"test_times\": []\n",
    "    }\n",
    "\n",
    "    # Lặp qua từng fold\n",
    "    for i in range(len(file_paths)):\n",
    "        print(f\"Fold {i+1}: Using file {file_paths[i]} as test set\")\n",
    "        \n",
    "        # Tải dữ liệu\n",
    "        test_data = pd.read_csv(file_paths[i])\n",
    "        train_data = pd.concat([pd.read_csv(file_paths[j]) for j in range(len(file_paths)) if j != i])\n",
    "        \n",
    "        # Tách X và y\n",
    "        X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                           \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_train = to_categorical(train_data['classification_encoded'], num_classes=5)\n",
    "        \n",
    "        X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                         \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_test = to_categorical(test_data['classification_encoded'], num_classes=5)\n",
    "\n",
    "        # Reshape dữ liệu cho LSTM\n",
    "        X_train = X_train.to_numpy().reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        # Xây dựng mô hình với tham số tốt nhất\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        model = build_GRU_model(params, input_shape)\n",
    "        \n",
    "        # Bắt đầu tính thời gian huấn luyện\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)\n",
    "        end_train = time.time()\n",
    "        \n",
    "        # Bắt đầu tính thời gian kiểm thử\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        \n",
    "        # Tính thời gian và lưu lại\n",
    "        train_time = end_train - start_train\n",
    "        test_time = end_test - start_test\n",
    "        week_results[\"train_times\"].append(train_time)\n",
    "        week_results[\"test_times\"].append(test_time)\n",
    "\n",
    "        # Đánh giá mô hình trên tập kiểm thử của fold hiện tại\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        week_results[\"accuracy_per_fold\"].append(accuracy)\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_test_classes = y_test.argmax(axis=1)\n",
    "        \n",
    "        # Tính các chỉ số cho mỗi fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "        conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "        \n",
    "        # Tính AUC-ROC\n",
    "        try:\n",
    "            # Tính AUC macro và theo từng lớp với OvR\n",
    "            auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "            # Tính AUC weighted: tính trọng số theo số mẫu của từng lớp\n",
    "            supports = np.bincount(y_test_classes, minlength=5)\n",
    "            auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tính AUC: {e}\")\n",
    "            auc_macro = np.nan\n",
    "            auc_per_class = [np.nan] * 5\n",
    "            auc_weighted = np.nan\n",
    "            \n",
    "        # Lưu kết quả của fold hiện tại\n",
    "        week_results[\"precision_per_label\"].append(precision)\n",
    "        week_results[\"recall_per_label\"].append(recall)\n",
    "        week_results[\"f1_score_per_label\"].append(f1)\n",
    "        week_results[\"auc_roc_per_label\"].append(auc_per_class)  # AUC từng lớp\n",
    "        week_results[\"auc_roc_macro\"].append(auc_macro)          # AUC macro\n",
    "        week_results[\"auc_roc_weighted\"].append(auc_weighted)      # AUC weighted\n",
    "        week_results[\"confusion_matrices\"].append(conf_matrix)\n",
    "        week_results[\"precision_macro\"].append(precision_macro)\n",
    "        week_results[\"recall_macro\"].append(recall_macro)\n",
    "        week_results[\"f1_macro\"].append(f1_macro)\n",
    "        week_results[\"precision_weighted\"].append(precision_weighted)\n",
    "        week_results[\"recall_weighted\"].append(recall_weighted)\n",
    "        week_results[\"f1_weighted\"].append(f1_weighted)\n",
    "\n",
    "    # Tính trung bình cho từng nhãn\n",
    "    average_precision_per_label = np.mean(week_results[\"precision_per_label\"], axis=0)\n",
    "    average_recall_per_label = np.nanmean(week_results[\"recall_per_label\"], axis=0)\n",
    "    average_f1_per_label = np.nanmean(week_results[\"f1_score_per_label\"], axis=0)\n",
    "    average_auc_per_label = np.nanmean(week_results[\"auc_roc_per_label\"], axis=0)\n",
    "    average_confusion_matrix = np.nanmean(week_results[\"confusion_matrices\"], axis=0)\n",
    "    average_train_time = sum(week_results[\"train_times\"]) / len(week_results[\"train_times\"])\n",
    "    average_test_time = sum(week_results[\"test_times\"]) / len(week_results[\"test_times\"])\n",
    "    average_accuracy = np.nanmean(week_results[\"accuracy_per_fold\"])\n",
    "    average_precision_macro = np.nanmean(week_results[\"precision_macro\"])\n",
    "    average_recall_macro = np.nanmean(week_results[\"recall_macro\"])\n",
    "    average_f1_macro = np.nanmean(week_results[\"f1_macro\"])\n",
    "    average_auc_macro = np.nanmean(week_results[\"auc_roc_macro\"])\n",
    "    average_precision_weighted = np.nanmean(week_results[\"precision_weighted\"])\n",
    "    average_recall_weighted = np.nanmean(week_results[\"recall_weighted\"])\n",
    "    average_f1_weighted = np.nanmean(week_results[\"f1_weighted\"])\n",
    "    average_auc_weighted = np.nanmean(week_results[\"auc_roc_weighted\"])\n",
    "\n",
    "\n",
    "    # Tạo DataFrame cho precision, recall, f1-score\n",
    "    labels = np.unique(y_test_classes)  # Lấy nhãn từ y_test_classes\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Average Precision\": average_precision_per_label,\n",
    "        \"Average Recall\": average_recall_per_label,\n",
    "        \"Average F1-Score\": average_f1_per_label,\n",
    "        \"Average AUC\": average_auc_per_label\n",
    "    })\n",
    "    \n",
    "    # Tạo DataFrame cho confusion matrix\n",
    "    confusion_df = pd.DataFrame(average_confusion_matrix, index=labels, columns=labels)\n",
    "    # In kết quả Accuracy và Macro metrics\n",
    "    print(\"\\n=== Average Accuracy ===\")\n",
    "    print(f\"{average_accuracy:.4f}\")\n",
    "    print(\"\\n=== Average Macro Metrics ===\")\n",
    "    print(f\"Macro Precision: {average_precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {average_recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {average_f1_macro:.4f}\")\n",
    "    print(f\"Macro AUC-ROC: {average_auc_macro:.4f}\")\n",
    "    print(\"\\n=== Average Weighted Metrics ===\")\n",
    "    print(f\"Weighted Precision: {average_precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {average_recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {average_f1_weighted:.4f}\")\n",
    "    print(f\"Weighted AUC-ROC: {average_auc_weighted:.4f}\")\n",
    "    print(\"\\n=== Average Metrics per Label ===\")\n",
    "    print(metrics_df)\n",
    "    print(\"\\n=== Average Confusion Matrix ===\")\n",
    "    print(confusion_df)\n",
    "    \n",
    "    # Cập nhật kết quả cho tuần hiện tại\n",
    "    week_results.update({\n",
    "        \"average_accuracy\": average_accuracy,\n",
    "        \"average_precision_macro\": average_precision_macro,\n",
    "        \"average_recall_macro\": average_recall_macro,\n",
    "        \"average_f1_macro\": average_f1_macro,\n",
    "        \"average_auc_macro\": average_auc_macro,\n",
    "        \"average_precision_weighted\": average_precision_weighted,\n",
    "        \"average_recall_weighted\": average_recall_weighted,\n",
    "        \"average_f1_weighted\": average_f1_weighted,\n",
    "        \"average_auc_weighted\": average_auc_weighted,\n",
    "        \"average_metrics_df\": metrics_df,\n",
    "        \"average_confusion_matrix\": confusion_df,\n",
    "        \"average_train_times\": average_train_time,\n",
    "        \"average_test_times\": average_test_time,\n",
    "    })\n",
    "    overall_results_5folds.append(week_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a64d3",
   "metadata": {
    "papermill": {
     "duration": 1.772071,
     "end_time": "2025-06-30T12:43:22.080624",
     "exception": false,
     "start_time": "2025-06-30T12:43:20.308553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kết quả cross validation trên 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e74ad86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:43:25.430851Z",
     "iopub.status.busy": "2025-06-30T12:43:25.430496Z",
     "iopub.status.idle": "2025-06-30T12:43:25.458536Z",
     "shell.execute_reply": "2025-06-30T12:43:25.455517Z"
    },
    "papermill": {
     "duration": 1.775316,
     "end_time": "2025-06-30T12:43:25.460011",
     "exception": false,
     "start_time": "2025-06-30T12:43:23.684695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for week1 ===\n",
      "Average Accurancy: 0.7792855501174927\n",
      "Average Train Time: 85.5700 seconds\n",
      "Average Test Time: 0.4399 seconds\n",
      "Average AUC Macro: 0.8816287031803715\n",
      "Average AUC Weighted: 0.8937927384391487\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.629935        0.716333          0.669509     0.877962\n",
      "1      1           0.871448        0.116536          0.199598     0.872404\n",
      "2      2           0.660003        0.468426          0.544475     0.862229\n",
      "3      3           0.632116        0.497006          0.543288     0.867065\n",
      "4      4           0.843558        0.879377          0.860779     0.894302\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2     3       4\n",
      "0  429.8   0.4  11.8   8.4   149.6\n",
      "1   52.2  10.2   2.0   2.8    20.4\n",
      "2   49.0   0.2  77.0   3.6    34.6\n",
      "3   23.6   0.0   2.2  83.0    58.2\n",
      "4  129.0   1.6  24.6  38.2  1410.0\n",
      "\n",
      "=== Results for week2 ===\n",
      "Average Accurancy: 0.7792855501174927\n",
      "Average Train Time: 84.6927 seconds\n",
      "Average Test Time: 0.4324 seconds\n",
      "Average AUC Macro: 0.8816287031803715\n",
      "Average AUC Weighted: 0.8937927384391487\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.660286        0.737667          0.695370     0.901165\n",
      "1      1           0.744286        0.159274          0.233473     0.894607\n",
      "2      2           0.708265        0.475595          0.562424     0.880582\n",
      "3      3           0.777270        0.455090          0.565295     0.885545\n",
      "4      4           0.846360        0.904200          0.874197     0.917558\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2     3       4\n",
      "0  442.6   4.2   9.4   2.8   141.0\n",
      "1   49.6  14.0   1.4   2.0    20.6\n",
      "2   44.2   0.8  78.2   3.0    38.2\n",
      "3   24.4   0.2   2.6  76.0    63.8\n",
      "4  113.0   3.0  20.6  17.0  1449.8\n",
      "\n",
      "=== Results for week3 ===\n",
      "Average Accurancy: 0.7792855501174927\n",
      "Average Train Time: 85.1143 seconds\n",
      "Average Test Time: 0.4333 seconds\n",
      "Average AUC Macro: 0.8816287031803715\n",
      "Average AUC Weighted: 0.8937927384391487\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.646324        0.737000          0.688430     0.881234\n",
      "1      1           0.701930        0.118495          0.196419     0.884825\n",
      "2      2           0.703025        0.441508          0.534856     0.865075\n",
      "3      3           0.741579        0.407186          0.519991     0.864544\n",
      "4      4           0.836818        0.899086          0.866591     0.899062\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2     3       4\n",
      "0  442.2   3.6  10.2   4.6   139.4\n",
      "1   49.6  10.4   1.0   3.6    23.0\n",
      "2   41.4   0.2  72.6   4.0    46.2\n",
      "3   23.0   0.0   2.4  68.0    73.6\n",
      "4  129.0   1.4  18.8  12.6  1441.6\n",
      "\n",
      "=== Results for week4 ===\n",
      "Average Accurancy: 0.7792855501174927\n",
      "Average Train Time: 86.0276 seconds\n",
      "Average Test Time: 0.4428 seconds\n",
      "Average AUC Macro: 0.8816287031803715\n",
      "Average AUC Weighted: 0.8937927384391487\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.673989        0.705667          0.688792     0.881375\n",
      "1      1           0.793402        0.091040          0.146776     0.877344\n",
      "2      2           0.672950        0.507280          0.575060     0.872331\n",
      "3      3           0.728912        0.394012          0.507615     0.873436\n",
      "4      4           0.829736        0.912436          0.868972     0.903658\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2     3       4\n",
      "0  423.4  3.2  13.6   5.4   154.4\n",
      "1   47.2  8.0   2.0   2.8    27.6\n",
      "2   35.2  0.2  83.4   4.2    41.4\n",
      "3   21.6  0.0   2.2  65.8    77.4\n",
      "4  101.8  1.0  24.6  13.0  1463.0\n"
     ]
    }
   ],
   "source": [
    "# Duyệt qua các tuần trong overall_results\n",
    "for week_result in overall_results_5folds:\n",
    "    week = week_result[\"week\"]\n",
    "    average_train_time = np.mean(week_result[\"train_times\"])\n",
    "    average_test_time = np.mean(week_result[\"test_times\"])\n",
    "    average_metrics_df = week_result[\"average_metrics_df\"]\n",
    "    average_accuracy = np.mean(week_results[\"accuracy_per_fold\"])\n",
    "    average_confusion_matrix = week_result[\"average_confusion_matrix\"]\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n=== Results for {week} ===\")\n",
    "    print(f\"Average Accurancy: {average_accuracy}\")\n",
    "    print(f\"Average Train Time: {average_train_time:.4f} seconds\")\n",
    "    print(f\"Average Test Time: {average_test_time:.4f} seconds\")\n",
    "    print(f\"Average AUC Macro: {average_auc_macro}\")\n",
    "    print(f\"Average AUC Weighted: {average_auc_weighted}\")\n",
    "    print(\"\\nAverage Precision, Recall, F1-Score, AUC-ROC per Label:\")\n",
    "    print(average_metrics_df)\n",
    "    print(\"\\nAverage Confusion Matrix:\")\n",
    "    print(average_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a22e99",
   "metadata": {
    "papermill": {
     "duration": 1.737036,
     "end_time": "2025-06-30T12:43:28.854449",
     "exception": false,
     "start_time": "2025-06-30T12:43:27.117413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kiểm tra trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8732d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:43:32.156620Z",
     "iopub.status.busy": "2025-06-30T12:43:32.156288Z",
     "iopub.status.idle": "2025-06-30T12:43:32.171668Z",
     "shell.execute_reply": "2025-06-30T12:43:32.171024Z"
    },
    "papermill": {
     "duration": 1.745469,
     "end_time": "2025-06-30T12:43:32.173020",
     "exception": false,
     "start_time": "2025-06-30T12:43:30.427551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mảng lưu dữ liệu của các tuần\n",
    "results = []\n",
    "\n",
    "def process_week(week_num, best_params, results):\n",
    "    print(f\"\\n=== Processing Week {week_num} ===\")\n",
    "    params = best_params[f\"week{week_num}\"].values\n",
    "    # Đường dẫn tới dữ liệu tuần tương ứng\n",
    "    train_path = f\"{BASE_PATH}/clean_week{week_num}/train/clean_data_week{week_num}.csv\"\n",
    "    test_path = f\"{BASE_PATH}/clean_week{week_num}/test/test_week{week_num}.csv\"\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                       \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data['classification_encoded']\n",
    "    \n",
    "    X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                     \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_test = test_data['classification_encoded']\n",
    "\n",
    "    # Áp dụng SMOTE cho tập huấn luyện\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Chuyển đổi nhãn sang dạng one-hot\n",
    "    y_train_resampled = to_categorical(y_train_resampled, num_classes=5)\n",
    "    y_test = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "    # Reshape dữ liệu cho LSTM\n",
    "    X_train_resampled = X_train_resampled.to_numpy().reshape((X_train_resampled.shape[0], 1, X_train_resampled.shape[1]))\n",
    "    X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Xây dựng mô hình với tham số tốt nhất\n",
    "    input_shape = (X_train_resampled.shape[1], X_train_resampled.shape[2])\n",
    "    model = build_GRU_model(params, input_shape)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled, epochs=50, validation_split=0.1, batch_size=32)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Kiểm thử mô hình\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    # Tính thời gian huấn luyện và kiểm thử\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_test_classes = y_test.argmax(axis=1)\n",
    "    \n",
    "    # Tính các chỉ số Precision, Recall, F1 cho từng lớp và macro\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    # Tính AUC-ROC (với one-vs-rest)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "        auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "        # Tính AUC weighted tự tính theo trọng số mẫu của từng lớp\n",
    "        supports = np.bincount(y_test_classes, minlength=5)\n",
    "        auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tính AUC: {e}\")\n",
    "        auc_macro = np.nan\n",
    "        auc_per_class = [np.nan] * 5\n",
    "        auc_weighted = np.nan\n",
    "\n",
    "    # Lưu kết quả vào mảng\n",
    "    results.append({\n",
    "        \"week\": week_num,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_weighted\": precision_weighted,\n",
    "        \"recall_weighted\": recall_weighted,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"auc_weighted\": auc_weighted,\n",
    "        \"auc_per_class\": auc_per_class,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    })\n",
    "    \n",
    "    # In kết quả chi tiết\n",
    "    print(\"\\n=== Precision, Recall, F1-Score per Label ===\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Label\": np.unique(y_test_classes),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }))\n",
    "\n",
    "    print(\"\\n=== Macro Averages & Accuracy ===\")\n",
    "    print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Weighted Averages ===\")\n",
    "    print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")\n",
    "    \n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(pd.DataFrame(conf_matrix, index=np.unique(y_test_classes), columns=np.unique(y_test_classes)))\n",
    "    \n",
    "    print(f\"\\nTrain Time: {train_time:.2f} seconds\")\n",
    "    print(f\"Test Time: {test_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df27222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:43:35.423848Z",
     "iopub.status.busy": "2025-06-30T12:43:35.423361Z",
     "iopub.status.idle": "2025-06-30T12:48:06.472034Z",
     "shell.execute_reply": "2025-06-30T12:48:06.471209Z"
    },
    "papermill": {
     "duration": 272.61305,
     "end_time": "2025-06-30T12:48:06.473236",
     "exception": false,
     "start_time": "2025-06-30T12:43:33.860186",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4734 - loss: 0.1983 - val_accuracy: 0.6730 - val_loss: 0.2273\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5407 - loss: 0.1757 - val_accuracy: 0.6301 - val_loss: 0.2356\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5749 - loss: 0.1647 - val_accuracy: 0.7146 - val_loss: 0.2099\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 0.1592 - val_accuracy: 0.6533 - val_loss: 0.2149\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6092 - loss: 0.1515 - val_accuracy: 0.7131 - val_loss: 0.2062\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6200 - loss: 0.1472 - val_accuracy: 0.6914 - val_loss: 0.1951\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.1453 - val_accuracy: 0.6645 - val_loss: 0.2107\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6284 - loss: 0.1447 - val_accuracy: 0.6924 - val_loss: 0.1863\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6208 - loss: 0.1446 - val_accuracy: 0.6837 - val_loss: 0.1810\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6351 - loss: 0.1419 - val_accuracy: 0.6253 - val_loss: 0.2086\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6340 - loss: 0.1398 - val_accuracy: 0.6775 - val_loss: 0.1896\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6350 - loss: 0.1387 - val_accuracy: 0.6199 - val_loss: 0.2176\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6372 - loss: 0.1392 - val_accuracy: 0.6827 - val_loss: 0.1876\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6439 - loss: 0.1361 - val_accuracy: 0.6695 - val_loss: 0.2009\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6356 - loss: 0.1393 - val_accuracy: 0.6438 - val_loss: 0.2112\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6396 - loss: 0.1352 - val_accuracy: 0.6306 - val_loss: 0.2094\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6561 - loss: 0.1325 - val_accuracy: 0.6710 - val_loss: 0.1963\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6515 - loss: 0.1350 - val_accuracy: 0.6613 - val_loss: 0.2026\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6444 - loss: 0.1369 - val_accuracy: 0.6373 - val_loss: 0.2029\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6519 - loss: 0.1341 - val_accuracy: 0.6363 - val_loss: 0.1862\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6502 - loss: 0.1334 - val_accuracy: 0.6356 - val_loss: 0.2053\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6525 - loss: 0.1325 - val_accuracy: 0.6503 - val_loss: 0.1848\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6531 - loss: 0.1322 - val_accuracy: 0.6727 - val_loss: 0.1818\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 0.1311 - val_accuracy: 0.6495 - val_loss: 0.1843\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6483 - loss: 0.1328 - val_accuracy: 0.6625 - val_loss: 0.1769\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6474 - loss: 0.1344 - val_accuracy: 0.6730 - val_loss: 0.1787\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.1329 - val_accuracy: 0.6585 - val_loss: 0.1896\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.1326 - val_accuracy: 0.6568 - val_loss: 0.2011\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.1320 - val_accuracy: 0.6179 - val_loss: 0.2022\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6492 - loss: 0.1344 - val_accuracy: 0.6406 - val_loss: 0.1776\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6492 - loss: 0.1321 - val_accuracy: 0.6560 - val_loss: 0.1815\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6554 - loss: 0.1310 - val_accuracy: 0.6458 - val_loss: 0.1908\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6592 - loss: 0.1300 - val_accuracy: 0.6835 - val_loss: 0.1808\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6580 - loss: 0.1301 - val_accuracy: 0.6308 - val_loss: 0.1936\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6584 - loss: 0.1296 - val_accuracy: 0.6523 - val_loss: 0.1902\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6557 - loss: 0.1303 - val_accuracy: 0.6598 - val_loss: 0.1949\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6558 - loss: 0.1294 - val_accuracy: 0.6445 - val_loss: 0.1760\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6599 - loss: 0.1296 - val_accuracy: 0.6505 - val_loss: 0.1877\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.1287 - val_accuracy: 0.6495 - val_loss: 0.1859\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6643 - loss: 0.1286 - val_accuracy: 0.6488 - val_loss: 0.1774\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6554 - loss: 0.1282 - val_accuracy: 0.6675 - val_loss: 0.1798\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 0.1261 - val_accuracy: 0.6667 - val_loss: 0.1773\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6673 - loss: 0.1254 - val_accuracy: 0.6588 - val_loss: 0.1750\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.1249 - val_accuracy: 0.6463 - val_loss: 0.1909\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6684 - loss: 0.1243 - val_accuracy: 0.6665 - val_loss: 0.1758\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6684 - loss: 0.1242 - val_accuracy: 0.6565 - val_loss: 0.1787\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6723 - loss: 0.1218 - val_accuracy: 0.6732 - val_loss: 0.1682\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6705 - loss: 0.1228 - val_accuracy: 0.6887 - val_loss: 0.1635\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6604 - loss: 0.1263 - val_accuracy: 0.6633 - val_loss: 0.1709\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6726 - loss: 0.1232 - val_accuracy: 0.6109 - val_loss: 0.2076\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.727564  0.605333  0.660844\n",
      "1      1   0.225275  0.759259  0.347458\n",
      "2      2   0.458015  0.582524  0.512821\n",
      "3      3   0.491935  0.580952  0.532751\n",
      "4      4   0.905724  0.804586  0.852165\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.5617\n",
      "Macro Recall: 0.6665\n",
      "Macro F1-Score: 0.5812\n",
      "Accuracy: 0.7293\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.7880\n",
      "Weighted Recall: 0.7293\n",
      "Weighted F1-Score: 0.7500\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8921\n",
      "AUC Weighted: 0.8999\n",
      "AUC per Label: [0.88001792 0.90204217 0.87830599 0.88966341 0.91057753]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  227  56  30   6   56\n",
      "1    5  41   0   1    7\n",
      "2   16  16  60   4    7\n",
      "3    8  11  11  61   14\n",
      "4   56  58  30  52  807\n",
      "\n",
      "Train Time: 270.43 seconds\n",
      "Test Time: 0.39 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(1, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2808d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:48:10.291108Z",
     "iopub.status.busy": "2025-06-30T12:48:10.290610Z",
     "iopub.status.idle": "2025-06-30T12:52:38.334025Z",
     "shell.execute_reply": "2025-06-30T12:52:38.333164Z"
    },
    "papermill": {
     "duration": 269.941094,
     "end_time": "2025-06-30T12:52:38.335253",
     "exception": false,
     "start_time": "2025-06-30T12:48:08.394159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4863 - loss: 0.1958 - val_accuracy: 0.4645 - val_loss: 0.2543\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5829 - loss: 0.1656 - val_accuracy: 0.6785 - val_loss: 0.1892\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6040 - loss: 0.1557 - val_accuracy: 0.6383 - val_loss: 0.2168\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6209 - loss: 0.1487 - val_accuracy: 0.6690 - val_loss: 0.2093\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6201 - loss: 0.1479 - val_accuracy: 0.6855 - val_loss: 0.2237\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6333 - loss: 0.1418 - val_accuracy: 0.7219 - val_loss: 0.1904\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.1377 - val_accuracy: 0.6530 - val_loss: 0.1801\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6467 - loss: 0.1364 - val_accuracy: 0.6658 - val_loss: 0.1942\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.1314 - val_accuracy: 0.5852 - val_loss: 0.2156\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6569 - loss: 0.1306 - val_accuracy: 0.6934 - val_loss: 0.1746\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6629 - loss: 0.1265 - val_accuracy: 0.6643 - val_loss: 0.1889\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.1256 - val_accuracy: 0.6164 - val_loss: 0.1999\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6708 - loss: 0.1241 - val_accuracy: 0.6593 - val_loss: 0.1848\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 0.1246 - val_accuracy: 0.6932 - val_loss: 0.1621\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6738 - loss: 0.1217 - val_accuracy: 0.6296 - val_loss: 0.1996\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6760 - loss: 0.1207 - val_accuracy: 0.6775 - val_loss: 0.1913\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6772 - loss: 0.1190 - val_accuracy: 0.6755 - val_loss: 0.1785\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6830 - loss: 0.1187 - val_accuracy: 0.6725 - val_loss: 0.1782\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6773 - loss: 0.1181 - val_accuracy: 0.6608 - val_loss: 0.1791\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6823 - loss: 0.1163 - val_accuracy: 0.6520 - val_loss: 0.1907\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6850 - loss: 0.1167 - val_accuracy: 0.6695 - val_loss: 0.1745\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6868 - loss: 0.1150 - val_accuracy: 0.6663 - val_loss: 0.1775\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6844 - loss: 0.1138 - val_accuracy: 0.6590 - val_loss: 0.1755\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6823 - loss: 0.1159 - val_accuracy: 0.6391 - val_loss: 0.1727\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.1134 - val_accuracy: 0.6558 - val_loss: 0.1540\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6915 - loss: 0.1114 - val_accuracy: 0.6610 - val_loss: 0.1774\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.1108 - val_accuracy: 0.6513 - val_loss: 0.1733\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6930 - loss: 0.1109 - val_accuracy: 0.6857 - val_loss: 0.1587\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.1118 - val_accuracy: 0.6747 - val_loss: 0.1643\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7011 - loss: 0.1076 - val_accuracy: 0.6777 - val_loss: 0.1619\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6978 - loss: 0.1091 - val_accuracy: 0.6957 - val_loss: 0.1331\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6965 - loss: 0.1093 - val_accuracy: 0.6822 - val_loss: 0.1585\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6958 - loss: 0.1086 - val_accuracy: 0.6760 - val_loss: 0.1749\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.1092 - val_accuracy: 0.6565 - val_loss: 0.1536\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6996 - loss: 0.1093 - val_accuracy: 0.6553 - val_loss: 0.1632\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.1072 - val_accuracy: 0.6747 - val_loss: 0.1712\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7040 - loss: 0.1059 - val_accuracy: 0.6575 - val_loss: 0.1531\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7013 - loss: 0.1064 - val_accuracy: 0.6296 - val_loss: 0.1681\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7079 - loss: 0.1046 - val_accuracy: 0.6436 - val_loss: 0.1832\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7067 - loss: 0.1045 - val_accuracy: 0.6643 - val_loss: 0.1874\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7075 - loss: 0.1033 - val_accuracy: 0.6600 - val_loss: 0.1559\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7083 - loss: 0.1042 - val_accuracy: 0.6660 - val_loss: 0.1472\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.1028 - val_accuracy: 0.6892 - val_loss: 0.1585\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7093 - loss: 0.1035 - val_accuracy: 0.6730 - val_loss: 0.1662\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.1030 - val_accuracy: 0.6710 - val_loss: 0.1445\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7147 - loss: 0.1015 - val_accuracy: 0.5316 - val_loss: 0.1921\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7156 - loss: 0.1017 - val_accuracy: 0.6725 - val_loss: 0.1506\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7090 - loss: 0.1028 - val_accuracy: 0.6850 - val_loss: 0.1483\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.1008 - val_accuracy: 0.6695 - val_loss: 0.1624\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.1021 - val_accuracy: 0.6620 - val_loss: 0.1628\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.783383  0.704000  0.741573\n",
      "1      1   0.248322  0.685185  0.364532\n",
      "2      2   0.541284  0.572816  0.556604\n",
      "3      3   0.627273  0.657143  0.641860\n",
      "4      4   0.904813  0.843470  0.873065\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.6210\n",
      "Macro Recall: 0.6925\n",
      "Macro F1-Score: 0.6355\n",
      "Accuracy: 0.7774\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8148\n",
      "Weighted Recall: 0.7774\n",
      "Weighted F1-Score: 0.7916\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9187\n",
      "AUC Weighted: 0.9250\n",
      "AUC per Label: [0.9236996  0.9305322  0.90327583 0.90682178 0.92930158]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  264  43  14   1   53\n",
      "1    9  37   1   0    7\n",
      "2   15  17  59   2   10\n",
      "3    4   8   5  69   19\n",
      "4   45  44  30  38  846\n",
      "\n",
      "Train Time: 267.42 seconds\n",
      "Test Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(2, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "466641ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:52:42.655340Z",
     "iopub.status.busy": "2025-06-30T12:52:42.655035Z",
     "iopub.status.idle": "2025-06-30T12:57:14.085309Z",
     "shell.execute_reply": "2025-06-30T12:57:14.084332Z"
    },
    "papermill": {
     "duration": 273.571455,
     "end_time": "2025-06-30T12:57:14.086592",
     "exception": false,
     "start_time": "2025-06-30T12:52:40.515137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4652 - loss: 0.1993 - val_accuracy: 0.5266 - val_loss: 0.2608\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5626 - loss: 0.1690 - val_accuracy: 0.7131 - val_loss: 0.2214\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5880 - loss: 0.1629 - val_accuracy: 0.6505 - val_loss: 0.2272\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6082 - loss: 0.1546 - val_accuracy: 0.7002 - val_loss: 0.1967\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6143 - loss: 0.1515 - val_accuracy: 0.6835 - val_loss: 0.1827\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6192 - loss: 0.1489 - val_accuracy: 0.6633 - val_loss: 0.2198\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6268 - loss: 0.1448 - val_accuracy: 0.6311 - val_loss: 0.2198\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6375 - loss: 0.1427 - val_accuracy: 0.7229 - val_loss: 0.1899\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6348 - loss: 0.1423 - val_accuracy: 0.6780 - val_loss: 0.2149\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6450 - loss: 0.1381 - val_accuracy: 0.6171 - val_loss: 0.2225\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6404 - loss: 0.1386 - val_accuracy: 0.6538 - val_loss: 0.1903\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6435 - loss: 0.1384 - val_accuracy: 0.6356 - val_loss: 0.2152\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6468 - loss: 0.1365 - val_accuracy: 0.6473 - val_loss: 0.1824\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 0.1336 - val_accuracy: 0.6483 - val_loss: 0.2013\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6559 - loss: 0.1332 - val_accuracy: 0.6528 - val_loss: 0.1703\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.1330 - val_accuracy: 0.6386 - val_loss: 0.1983\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6489 - loss: 0.1344 - val_accuracy: 0.6478 - val_loss: 0.1723\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6567 - loss: 0.1341 - val_accuracy: 0.6388 - val_loss: 0.1878\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6564 - loss: 0.1316 - val_accuracy: 0.6633 - val_loss: 0.1819\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 0.1301 - val_accuracy: 0.6071 - val_loss: 0.2144\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.1304 - val_accuracy: 0.6578 - val_loss: 0.1828\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6607 - loss: 0.1309 - val_accuracy: 0.7084 - val_loss: 0.1822\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6612 - loss: 0.1298 - val_accuracy: 0.6106 - val_loss: 0.1905\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6621 - loss: 0.1296 - val_accuracy: 0.6433 - val_loss: 0.2012\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 0.1288 - val_accuracy: 0.6336 - val_loss: 0.1928\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6698 - loss: 0.1258 - val_accuracy: 0.6730 - val_loss: 0.1681\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6657 - loss: 0.1282 - val_accuracy: 0.6548 - val_loss: 0.1927\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6665 - loss: 0.1265 - val_accuracy: 0.6368 - val_loss: 0.1765\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6641 - loss: 0.1268 - val_accuracy: 0.5847 - val_loss: 0.2157\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6664 - loss: 0.1262 - val_accuracy: 0.6558 - val_loss: 0.2094\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6752 - loss: 0.1245 - val_accuracy: 0.6633 - val_loss: 0.1703\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6724 - loss: 0.1225 - val_accuracy: 0.6401 - val_loss: 0.1930\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.1238 - val_accuracy: 0.6770 - val_loss: 0.1660\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6669 - loss: 0.1262 - val_accuracy: 0.6588 - val_loss: 0.1770\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6747 - loss: 0.1229 - val_accuracy: 0.6575 - val_loss: 0.1796\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6676 - loss: 0.1259 - val_accuracy: 0.6727 - val_loss: 0.1617\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.1213 - val_accuracy: 0.6298 - val_loss: 0.1803\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6746 - loss: 0.1240 - val_accuracy: 0.6872 - val_loss: 0.1929\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6766 - loss: 0.1241 - val_accuracy: 0.6341 - val_loss: 0.2051\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6744 - loss: 0.1222 - val_accuracy: 0.6323 - val_loss: 0.1879\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6831 - loss: 0.1203 - val_accuracy: 0.6942 - val_loss: 0.1583\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6831 - loss: 0.1202 - val_accuracy: 0.6785 - val_loss: 0.1755\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6846 - loss: 0.1209 - val_accuracy: 0.6603 - val_loss: 0.1800\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.1210 - val_accuracy: 0.6513 - val_loss: 0.1701\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6866 - loss: 0.1201 - val_accuracy: 0.6625 - val_loss: 0.1666\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6835 - loss: 0.1211 - val_accuracy: 0.6695 - val_loss: 0.1644\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6821 - loss: 0.1195 - val_accuracy: 0.6835 - val_loss: 0.1593\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6814 - loss: 0.1202 - val_accuracy: 0.6351 - val_loss: 0.1969\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6871 - loss: 0.1195 - val_accuracy: 0.6655 - val_loss: 0.1559\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6859 - loss: 0.1193 - val_accuracy: 0.6493 - val_loss: 0.1891\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.753125  0.642667  0.693525\n",
      "1      1   0.211957  0.722222  0.327731\n",
      "2      2   0.495798  0.572816  0.531532\n",
      "3      3   0.584746  0.657143  0.618834\n",
      "4      4   0.909900  0.815553  0.860147\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.5911\n",
      "Macro Recall: 0.6821\n",
      "Macro F1-Score: 0.6064\n",
      "Accuracy: 0.7476\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8042\n",
      "Weighted Recall: 0.7476\n",
      "Weighted F1-Score: 0.7684\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8979\n",
      "AUC Weighted: 0.9053\n",
      "AUC per Label: [0.89922108 0.91161669 0.88996974 0.87676128 0.91182575]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  241  59  21   1   53\n",
      "1    6  39   2   0    7\n",
      "2   17  18  59   2    7\n",
      "3    5  13   4  69   14\n",
      "4   51  55  33  46  818\n",
      "\n",
      "Train Time: 270.76 seconds\n",
      "Test Time: 0.39 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(3, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70478348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T12:57:18.981452Z",
     "iopub.status.busy": "2025-06-30T12:57:18.981144Z",
     "iopub.status.idle": "2025-06-30T13:01:52.250026Z",
     "shell.execute_reply": "2025-06-30T13:01:52.249134Z"
    },
    "papermill": {
     "duration": 275.666389,
     "end_time": "2025-06-30T13:01:52.251342",
     "exception": false,
     "start_time": "2025-06-30T12:57:16.584953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4537 - loss: 0.2036 - val_accuracy: 0.5982 - val_loss: 0.2554\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5487 - loss: 0.1756 - val_accuracy: 0.6588 - val_loss: 0.2060\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 0.1628 - val_accuracy: 0.6795 - val_loss: 0.2322\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6025 - loss: 0.1588 - val_accuracy: 0.6543 - val_loss: 0.2380\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 0.1533 - val_accuracy: 0.6645 - val_loss: 0.2445\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 0.1512 - val_accuracy: 0.6061 - val_loss: 0.2123\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6137 - loss: 0.1496 - val_accuracy: 0.6308 - val_loss: 0.2315\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6269 - loss: 0.1460 - val_accuracy: 0.6450 - val_loss: 0.2034\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.1442 - val_accuracy: 0.5964 - val_loss: 0.2329\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6355 - loss: 0.1414 - val_accuracy: 0.6737 - val_loss: 0.2009\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6425 - loss: 0.1390 - val_accuracy: 0.6204 - val_loss: 0.2129\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 0.1376 - val_accuracy: 0.6635 - val_loss: 0.2143\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.1383 - val_accuracy: 0.6391 - val_loss: 0.1841\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6455 - loss: 0.1372 - val_accuracy: 0.6298 - val_loss: 0.1895\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6479 - loss: 0.1355 - val_accuracy: 0.6233 - val_loss: 0.2044\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6438 - loss: 0.1358 - val_accuracy: 0.6470 - val_loss: 0.1938\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6449 - loss: 0.1349 - val_accuracy: 0.6488 - val_loss: 0.1921\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6541 - loss: 0.1332 - val_accuracy: 0.6767 - val_loss: 0.1840\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6564 - loss: 0.1328 - val_accuracy: 0.6480 - val_loss: 0.1901\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6473 - loss: 0.1338 - val_accuracy: 0.6648 - val_loss: 0.1850\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6599 - loss: 0.1312 - val_accuracy: 0.6490 - val_loss: 0.1856\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6545 - loss: 0.1328 - val_accuracy: 0.6326 - val_loss: 0.2001\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6673 - loss: 0.1278 - val_accuracy: 0.6590 - val_loss: 0.1779\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 0.1329 - val_accuracy: 0.6795 - val_loss: 0.1907\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6553 - loss: 0.1324 - val_accuracy: 0.6672 - val_loss: 0.2064\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6586 - loss: 0.1298 - val_accuracy: 0.6618 - val_loss: 0.1815\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6637 - loss: 0.1279 - val_accuracy: 0.6792 - val_loss: 0.1815\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6605 - loss: 0.1308 - val_accuracy: 0.6460 - val_loss: 0.1821\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6607 - loss: 0.1294 - val_accuracy: 0.6550 - val_loss: 0.1699\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6646 - loss: 0.1270 - val_accuracy: 0.6613 - val_loss: 0.1834\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6634 - loss: 0.1280 - val_accuracy: 0.6613 - val_loss: 0.1876\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 0.1285 - val_accuracy: 0.6633 - val_loss: 0.1736\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6655 - loss: 0.1256 - val_accuracy: 0.6979 - val_loss: 0.1801\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6609 - loss: 0.1289 - val_accuracy: 0.6977 - val_loss: 0.1585\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6745 - loss: 0.1238 - val_accuracy: 0.6670 - val_loss: 0.1801\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6703 - loss: 0.1235 - val_accuracy: 0.6628 - val_loss: 0.1883\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6673 - loss: 0.1237 - val_accuracy: 0.6810 - val_loss: 0.1814\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6705 - loss: 0.1241 - val_accuracy: 0.6663 - val_loss: 0.1920\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.1266 - val_accuracy: 0.6281 - val_loss: 0.1982\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6684 - loss: 0.1264 - val_accuracy: 0.6510 - val_loss: 0.1788\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6754 - loss: 0.1224 - val_accuracy: 0.6393 - val_loss: 0.1923\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6756 - loss: 0.1234 - val_accuracy: 0.6600 - val_loss: 0.1738\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6747 - loss: 0.1240 - val_accuracy: 0.6256 - val_loss: 0.1919\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6782 - loss: 0.1214 - val_accuracy: 0.6588 - val_loss: 0.1884\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.1227 - val_accuracy: 0.6174 - val_loss: 0.2015\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6816 - loss: 0.1206 - val_accuracy: 0.6403 - val_loss: 0.1850\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6801 - loss: 0.1210 - val_accuracy: 0.6578 - val_loss: 0.1842\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6824 - loss: 0.1208 - val_accuracy: 0.6613 - val_loss: 0.1828\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6766 - loss: 0.1204 - val_accuracy: 0.6615 - val_loss: 0.1717\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.1206 - val_accuracy: 0.6630 - val_loss: 0.1740\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.756839  0.664000  0.707386\n",
      "1      1   0.225989  0.740741  0.346320\n",
      "2      2   0.558824  0.553398  0.556098\n",
      "3      3   0.552000  0.657143  0.600000\n",
      "4      4   0.912900  0.825523  0.867016\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.6013\n",
      "Macro Recall: 0.6882\n",
      "Macro F1-Score: 0.6154\n",
      "Accuracy: 0.7579\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8093\n",
      "Weighted Recall: 0.7579\n",
      "Weighted F1-Score: 0.7767\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9061\n",
      "AUC Weighted: 0.9123\n",
      "AUC per Label: [0.90693017 0.89281211 0.9144153  0.89975492 0.91643281]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  249  60  13   3   50\n",
      "1    6  40   0   1    7\n",
      "2   20  18  57   2    6\n",
      "3    4  12   4  69   16\n",
      "4   50  47  28  50  828\n",
      "\n",
      "Train Time: 272.59 seconds\n",
      "Test Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(4, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ec903d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T13:01:57.666007Z",
     "iopub.status.busy": "2025-06-30T13:01:57.665651Z",
     "iopub.status.idle": "2025-06-30T13:01:57.680667Z",
     "shell.execute_reply": "2025-06-30T13:01:57.679715Z"
    },
    "papermill": {
     "duration": 2.655464,
     "end_time": "2025-06-30T13:01:57.681968",
     "exception": false,
     "start_time": "2025-06-30T13:01:55.026504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Results for All Weeks ===\n",
      "Week 1:\n",
      "  Train Time: 270.43 seconds\n",
      "  Test Time: 0.39 seconds\n",
      "  Accurancy: 0.7292682926829268\n",
      "  Precision: [0.7275641  0.22527473 0.45801527 0.49193548 0.90572391]\n",
      "  Recall: [0.60533333 0.75925926 0.58252427 0.58095238 0.80458624]\n",
      "  F1-Score: [0.66084425 0.34745763 0.51282051 0.53275109 0.85216473]\n",
      "  Macro Precision: 0.5617026969218548\n",
      "  Macro Recall: 0.6665310973331611\n",
      "  Macro F1-Score: 0.5812076425469462\n",
      "  Confusion Matrix:\n",
      "[[227  56  30   6  56]\n",
      " [  5  41   0   1   7]\n",
      " [ 16  16  60   4   7]\n",
      " [  8  11  11  61  14]\n",
      " [ 56  58  30  52 807]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8864\n",
      "AUC Weighted: 0.8949\n",
      "AUC per Label: [0.88313963 0.88892651 0.87743109 0.87949681 0.90295643]\n",
      "Week 2:\n",
      "  Train Time: 267.42 seconds\n",
      "  Test Time: 0.38 seconds\n",
      "  Accurancy: 0.7774390243902439\n",
      "  Precision: [0.78338279 0.24832215 0.5412844  0.62727273 0.90481283]\n",
      "  Recall: [0.704      0.68518519 0.57281553 0.65714286 0.84346959]\n",
      "  F1-Score: [0.74157303 0.36453202 0.55660377 0.64186047 0.87306502]\n",
      "  Macro Precision: 0.621014980427113\n",
      "  Macro Recall: 0.6925226335069892\n",
      "  Macro F1-Score: 0.6355268615186719\n",
      "  Confusion Matrix:\n",
      "[[264  43  14   1  53]\n",
      " [  9  37   1   0   7]\n",
      " [ 15  17  59   2  10]\n",
      " [  4   8   5  69  19]\n",
      " [ 45  44  30  38 846]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8864\n",
      "AUC Weighted: 0.8949\n",
      "AUC per Label: [0.88313963 0.88892651 0.87743109 0.87949681 0.90295643]\n",
      "Week 3:\n",
      "  Train Time: 270.76 seconds\n",
      "  Test Time: 0.39 seconds\n",
      "  Accurancy: 0.7475609756097561\n",
      "  Precision: [0.753125   0.21195652 0.49579832 0.58474576 0.90989989]\n",
      "  Recall: [0.64266667 0.72222222 0.57281553 0.65714286 0.81555334]\n",
      "  F1-Score: [0.69352518 0.32773109 0.53153153 0.61883408 0.86014721]\n",
      "  Macro Precision: 0.5911050985088042\n",
      "  Macro Recall: 0.6820801239984776\n",
      "  Macro F1-Score: 0.6063538196003253\n",
      "  Confusion Matrix:\n",
      "[[241  59  21   1  53]\n",
      " [  6  39   2   0   7]\n",
      " [ 17  18  59   2   7]\n",
      " [  5  13   4  69  14]\n",
      " [ 51  55  33  46 818]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8864\n",
      "AUC Weighted: 0.8949\n",
      "AUC per Label: [0.88313963 0.88892651 0.87743109 0.87949681 0.90295643]\n",
      "Week 4:\n",
      "  Train Time: 272.59 seconds\n",
      "  Test Time: 0.38 seconds\n",
      "  Accurancy: 0.7579268292682927\n",
      "  Precision: [0.75683891 0.2259887  0.55882353 0.552      0.91289967]\n",
      "  Recall: [0.664      0.74074074 0.55339806 0.65714286 0.82552343]\n",
      "  F1-Score: [0.70738636 0.34632035 0.55609756 0.6        0.86701571]\n",
      "  Macro Precision: 0.6013101609982126\n",
      "  Macro Recall: 0.6881610171693785\n",
      "  Macro F1-Score: 0.6153639955477205\n",
      "  Confusion Matrix:\n",
      "[[249  60  13   3  50]\n",
      " [  6  40   0   1   7]\n",
      " [ 20  18  57   2   6]\n",
      " [  4  12   4  69  16]\n",
      " [ 50  47  28  50 828]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.8864\n",
      "AUC Weighted: 0.8949\n",
      "AUC per Label: [0.88313963 0.88892651 0.87743109 0.87949681 0.90295643]\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu của các tuần\n",
    "print(\"\\n=== Summary Results for All Weeks ===\")\n",
    "for result in results:\n",
    "    print(f\"Week {result['week']}:\")\n",
    "    print(f\"  Train Time: {result['train_time']:.2f} seconds\")\n",
    "    print(f\"  Test Time: {result['test_time']:.2f} seconds\")\n",
    "    print(f\"  Accurancy: {result['accuracy']}\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1-Score: {result['f1_score']}\")\n",
    "    print(f\"  Macro Precision: {result['precision_macro']}\")\n",
    "    print(f\"  Macro Recall: {result['recall_macro']}\")\n",
    "    print(f\"  Macro F1-Score: {result['f1_macro']}\")\n",
    "    print(f\"  Confusion Matrix:\\n{result['confusion_matrix']}\")\n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6328310,
     "sourceId": 12320977,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8777.179176,
   "end_time": "2025-06-30T13:02:03.627069",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-30T10:35:46.447893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
