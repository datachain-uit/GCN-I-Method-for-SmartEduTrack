{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2962f2c6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-06T04:33:04.463363Z",
     "iopub.status.busy": "2025-04-06T04:33:04.463138Z",
     "iopub.status.idle": "2025-04-06T04:33:07.600268Z",
     "shell.execute_reply": "2025-04-06T04:33:07.599500Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 3.143926,
     "end_time": "2025-04-06T04:33:07.601537",
     "exception": false,
     "start_time": "2025-04-06T04:33:04.457611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clean_raw_data.csv\n",
      "/kaggle/input/clean_data_mean.csv\n",
      "/kaggle/input/raw_data.csv\n",
      "/kaggle/input/clean_data_GCN.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_data_minmax_fill-zero.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/FillZero_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_data_minmax_GCN_version4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_data_Fill-1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Mean_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_data_minmax_Fill-1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Fill-1_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_data_minmax_GCN_version3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version3/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_data_minmax_GCN.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/GCN_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/Listwise-deletion.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Listwise-deletion_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline_version2/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/Median_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_data_minmax_KNN.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/KNN_minmax_baseline/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/raw_data/clean_week4/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/val/val_week1_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/test/test_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/clean_data_week2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week2/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/val/val_week1_2_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/test/test_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/clean_data_week3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week3/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/val/val_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/test/test_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/clean_data_week1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week1/train/5-folds/data_part_5.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/val/val_week1_2_3_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/test/test_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/clean_data_week4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_2.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_3.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_4.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_1.csv\n",
      "/kaggle/input/new_raw/clean_data/clean_week4/train/5-folds/data_part_5.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015115bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T04:33:07.613168Z",
     "iopub.status.busy": "2025-04-06T04:33:07.612795Z",
     "iopub.status.idle": "2025-04-06T04:33:30.687947Z",
     "shell.execute_reply": "2025-04-06T04:33:30.687250Z"
    },
    "papermill": {
     "duration": 23.082178,
     "end_time": "2025-04-06T04:33:30.689493",
     "exception": false,
     "start_time": "2025-04-06T04:33:07.607315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6cc719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T04:33:30.700782Z",
     "iopub.status.busy": "2025-04-06T04:33:30.700354Z",
     "iopub.status.idle": "2025-04-06T04:33:30.705050Z",
     "shell.execute_reply": "2025-04-06T04:33:30.704407Z"
    },
    "papermill": {
     "duration": 0.011338,
     "end_time": "2025-04-06T04:33:30.706242",
     "exception": false,
     "start_time": "2025-04-06T04:33:30.694904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Biến global cho base path\n",
    "BASE_PATH = \"/kaggle/input/GCN_minmax_baseline_version4\"\n",
    "# Tuần và số phần fold\n",
    "weeks = ['week1', 'week2', 'week3', 'week4']\n",
    "fold_parts = 5\n",
    "\n",
    "# Tạo five_fold_files\n",
    "five_fold_files = {\n",
    "    week: [\n",
    "        f\"{BASE_PATH}/clean_{week}/train/5-folds/data_part_{i}.csv\"\n",
    "        for i in range(1, fold_parts + 1)\n",
    "    ]\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Tạo file_validation\n",
    "file_validation = {\n",
    "    'week1': [f\"{BASE_PATH}/clean_week1/val/val_week1.csv\"],\n",
    "    'week2': [f\"{BASE_PATH}/clean_week2/val/val_week1_2.csv\"],\n",
    "    'week3': [f\"{BASE_PATH}/clean_week3/val/val_week1_2_3.csv\"],\n",
    "    'week4': [f\"{BASE_PATH}/clean_week4/val/val_week1_2_3_4.csv\"]\n",
    "}\n",
    "\n",
    "# Tạo file_test\n",
    "file_test = {\n",
    "    week: [f\"{BASE_PATH}/clean_{week}/test/test_{week}.csv\"]\n",
    "    for week in weeks\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4d498",
   "metadata": {
    "papermill": {
     "duration": 0.004569,
     "end_time": "2025-04-06T04:33:30.717005",
     "exception": false,
     "start_time": "2025-04-06T04:33:30.712436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tìm siêu tham số tốt nhất cho từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e0ce37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T04:33:30.727424Z",
     "iopub.status.busy": "2025-04-06T04:33:30.727193Z",
     "iopub.status.idle": "2025-04-06T04:33:30.736309Z",
     "shell.execute_reply": "2025-04-06T04:33:30.735524Z"
    },
    "papermill": {
     "duration": 0.015766,
     "end_time": "2025-04-06T04:33:30.737537",
     "exception": false,
     "start_time": "2025-04-06T04:33:30.721771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Tạo hàm train cho từng tuần\n",
    "def train_week_model(week_number, file_paths_train, file_validataion):\n",
    "    # Đọc dữ liệu\n",
    "    train_data = pd.read_csv(file_paths_train)\n",
    "    val_data = pd.read_csv(file_validataion)\n",
    "    \n",
    "    # Tách đặc trưng và nhãn\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data[\"classification_encoded\"]\n",
    "\n",
    "    X_val = val_data.drop(columns=[\"classification_encoded\", \"user_id\", \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_val = val_data[\"classification_encoded\"]\n",
    "    \n",
    "    # Áp dụng Over-sampling cho dữ liệu huấn luyện bằng SMOTE\n",
    "    oversampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Reshape dữ liệu cho mô hình BiLSTM\n",
    "    X_train_res = X_train_res.values.reshape(X_train_res.shape[0], X_train_res.shape[1], 1)\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    \n",
    "    # One-hot encode nhãn\n",
    "    y_train_res = tf.keras.utils.to_categorical(y_train_res, num_classes=5)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "    \n",
    "    def build_model(hp):\n",
    "        inputs = tf.keras.Input(shape=(X_train_res.shape[1], 1))  # Khởi tạo đầu vào\n",
    "        \n",
    "        # Chỉ sử dụng một lớp Bidirectional LSTM\n",
    "        x = layers.Bidirectional(layers.LSTM(\n",
    "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "            return_sequences=False  # Thay đổi thành False vì đây là lớp LSTM duy nhất\n",
    "        ))(inputs)\n",
    "        x = layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "        \n",
    "        # Lớp đầu ra\n",
    "        outputs = layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        # Khởi tạo mô hình\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile với Focal Loss\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                          learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                      loss=focal_loss(gamma=2., alpha=0.25),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    # Khởi tạo RandomSearch tuner\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='my_dir',\n",
    "        project_name=f'bilstm_tuning_week{week_number}'\n",
    "    )\n",
    "    \n",
    "    # Tìm kiếm siêu tham số tốt nhất\n",
    "    tuner.search(X_train_res, y_train_res,\n",
    "                 epochs=20,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 batch_size=32)\n",
    "    \n",
    "    # Trả về kết quả tối ưu cho tuần\n",
    "    best_params = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f7f510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T04:33:30.747647Z",
     "iopub.status.busy": "2025-04-06T04:33:30.747427Z",
     "iopub.status.idle": "2025-04-06T04:33:30.750723Z",
     "shell.execute_reply": "2025-04-06T04:33:30.750170Z"
    },
    "papermill": {
     "duration": 0.009741,
     "end_time": "2025-04-06T04:33:30.751948",
     "exception": false,
     "start_time": "2025-04-06T04:33:30.742207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa đường dẫn đến dữ liệu cho từng tuần\n",
    "file_paths_train = {\n",
    "    week: f\"{BASE_PATH}/clean_{week}/train/clean_data_{week}.csv\"\n",
    "    for week in weeks\n",
    "}\n",
    "\n",
    "# Định nghĩa file_validation theo quy luật riêng\n",
    "file_validation = {\n",
    "    f\"week{idx + 1}\": f\"{BASE_PATH}/clean_week{idx + 1}/val/val_week{'_'.join(str(i) for i in range(1, idx + 2))}.csv\"\n",
    "    for idx in range(len(weeks))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ec0832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T04:33:30.762150Z",
     "iopub.status.busy": "2025-04-06T04:33:30.761905Z",
     "iopub.status.idle": "2025-04-06T06:11:27.398805Z",
     "shell.execute_reply": "2025-04-06T06:11:27.397893Z"
    },
    "papermill": {
     "duration": 5876.643467,
     "end_time": "2025-04-06T06:11:27.400243",
     "exception": false,
     "start_time": "2025-04-06T04:33:30.756776",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 42s]\n",
      "val_accuracy: 0.9627822041511536\n",
      "\n",
      "Best val_accuracy So Far: 0.9932885766029358\n",
      "Total elapsed time: 00h 26m 31s\n",
      "Best Parameters for Week 1:\n",
      "units_1: 256\n",
      "dropout_1: 0.5\n",
      "learning_rate: 0.000560184624787185\n",
      "\n",
      "Best Parameters for Week 2:\n",
      "units_1: 256\n",
      "dropout_1: 0.5\n",
      "learning_rate: 0.0009867496902904826\n",
      "\n",
      "Best Parameters for Week 3:\n",
      "units_1: 192\n",
      "dropout_1: 0.4\n",
      "learning_rate: 0.000822314112616515\n",
      "\n",
      "Best Parameters for Week 4:\n",
      "units_1: 160\n",
      "dropout_1: 0.2\n",
      "learning_rate: 0.004256409192507239\n"
     ]
    }
   ],
   "source": [
    "# Tìm tham số tốt nhất cho từng tuần\n",
    "best_params_week1 = train_week_model(1, file_paths_train[\"week1\"], file_validation[\"week1\"])\n",
    "best_params_week2 = train_week_model(2, file_paths_train[\"week2\"], file_validation[\"week2\"])\n",
    "best_params_week3 = train_week_model(3, file_paths_train[\"week3\"], file_validation[\"week3\"])\n",
    "best_params_week4 = train_week_model(4, file_paths_train[\"week4\"], file_validation[\"week4\"])\n",
    "\n",
    "# In thông tin chi tiết các tham số tối ưu\n",
    "print(\"Best Parameters for Week 1:\")\n",
    "for param_name in best_params_week1.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week1.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 2:\")\n",
    "for param_name in best_params_week2.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week2.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 3:\")\n",
    "for param_name in best_params_week3.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week3.get(param_name)}\")\n",
    "\n",
    "print(\"\\nBest Parameters for Week 4:\")\n",
    "for param_name in best_params_week4.values.keys():\n",
    "    print(f\"{param_name}: {best_params_week4.get(param_name)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22320121",
   "metadata": {
    "papermill": {
     "duration": 0.004851,
     "end_time": "2025-04-06T06:11:27.411132",
     "exception": false,
     "start_time": "2025-04-06T06:11:27.406281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Danh sách tham số tốt nhất của từng tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6045a428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:11:27.421689Z",
     "iopub.status.busy": "2025-04-06T06:11:27.421453Z",
     "iopub.status.idle": "2025-04-06T06:11:27.425169Z",
     "shell.execute_reply": "2025-04-06T06:11:27.424547Z"
    },
    "papermill": {
     "duration": 0.010283,
     "end_time": "2025-04-06T06:11:27.426294",
     "exception": false,
     "start_time": "2025-04-06T06:11:27.416011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Danh sách tham số tốt nhất\n",
    "best_params = {\n",
    "    \"week1\": best_params_week1,\n",
    "    \"week2\": best_params_week2,\n",
    "    \"week3\": best_params_week3,\n",
    "    \"week4\": best_params_week4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a386c04c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:11:27.437562Z",
     "iopub.status.busy": "2025-04-06T06:11:27.437334Z",
     "iopub.status.idle": "2025-04-06T06:11:27.443807Z",
     "shell.execute_reply": "2025-04-06T06:11:27.443191Z"
    },
    "papermill": {
     "duration": 0.013593,
     "end_time": "2025-04-06T06:11:27.444960",
     "exception": false,
     "start_time": "2025-04-06T06:11:27.431367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Định nghĩa Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "# # Xây dựng mô hình BiLSTM\n",
    "# def build_Bilstm_model(params, input_shape):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "#     # Bidirectional LSTM layer 1\n",
    "#     x = layers.Bidirectional(layers.LSTM(\n",
    "#         units=params.get('units_1'),\n",
    "#         return_sequences=True\n",
    "#     ))(inputs)\n",
    "#     x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "#     # Bidirectional LSTM layer 2\n",
    "#     x = layers.Bidirectional(layers.LSTM(\n",
    "#         units=params.get('units_2', 32),\n",
    "#         return_sequences=False\n",
    "#     ))(x)\n",
    "#     x = layers.Dropout(rate=params.get('dropout_2', 0.2))(x)\n",
    "    \n",
    "#     # Lớp đầu ra\n",
    "#     outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "#     # Khởi tạo mô hình\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     # Compile với Focal Loss\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "#                       learning_rate=params['learning_rate']),\n",
    "#                   loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "def build_Bilstm_model(params, input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)  # Định nghĩa đầu vào\n",
    "    \n",
    "    # Chỉ sử dụng một lớp Bidirectional LSTM\n",
    "    x = layers.Bidirectional(layers.LSTM(\n",
    "        units=params.get('units_1', 64),\n",
    "        return_sequences=False  # Đặt thành False vì đây là lớp LSTM cuối cùng\n",
    "    ))(inputs)\n",
    "    x = layers.Dropout(rate=params.get('dropout_1', 0.2))(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile với Focal Loss\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss=focal_loss(gamma=params.get('gamma', 2.), alpha=params.get('alpha', 0.25)),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac40223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:11:27.455667Z",
     "iopub.status.busy": "2025-04-06T06:11:27.455445Z",
     "iopub.status.idle": "2025-04-06T06:41:45.052968Z",
     "shell.execute_reply": "2025-04-06T06:41:45.052037Z"
    },
    "papermill": {
     "duration": 1817.604873,
     "end_time": "2025-04-06T06:41:45.054577",
     "exception": false,
     "start_time": "2025-04-06T06:11:27.449704",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing week1 with best parameters...\n",
      "best parameters for week1: {'units_1': 256, 'dropout_1': 0.5, 'learning_rate': 0.000560184624787185}\n",
      "Fold 1: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5828 - loss: 0.1583 - val_accuracy: 0.7122 - val_loss: 0.1077\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6747 - loss: 0.1227 - val_accuracy: 0.7213 - val_loss: 0.1048\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6965 - loss: 0.1135 - val_accuracy: 0.7217 - val_loss: 0.1017\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6993 - loss: 0.1140 - val_accuracy: 0.7263 - val_loss: 0.1013\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.1067 - val_accuracy: 0.7358 - val_loss: 0.0973\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.1069 - val_accuracy: 0.7461 - val_loss: 0.0951\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7310 - loss: 0.1034 - val_accuracy: 0.7476 - val_loss: 0.0982\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 0.1001 - val_accuracy: 0.7690 - val_loss: 0.0908\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7534 - loss: 0.0996 - val_accuracy: 0.7751 - val_loss: 0.0870\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7499 - loss: 0.0987 - val_accuracy: 0.7739 - val_loss: 0.0849\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.0942 - val_accuracy: 0.7827 - val_loss: 0.0843\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.0957 - val_accuracy: 0.7770 - val_loss: 0.0837\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7640 - loss: 0.0937 - val_accuracy: 0.7823 - val_loss: 0.0827\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.0926 - val_accuracy: 0.7819 - val_loss: 0.0835\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.0963 - val_accuracy: 0.7884 - val_loss: 0.0813\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7645 - loss: 0.0915 - val_accuracy: 0.7926 - val_loss: 0.0803\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.0899 - val_accuracy: 0.7949 - val_loss: 0.0807\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.0894 - val_accuracy: 0.7896 - val_loss: 0.0843\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7655 - loss: 0.0900 - val_accuracy: 0.7846 - val_loss: 0.0820\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.0876 - val_accuracy: 0.7899 - val_loss: 0.0810\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.0883 - val_accuracy: 0.7922 - val_loss: 0.0783\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.0879 - val_accuracy: 0.7957 - val_loss: 0.0779\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.0902 - val_accuracy: 0.7964 - val_loss: 0.0787\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 0.0879 - val_accuracy: 0.7987 - val_loss: 0.0780\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.0864 - val_accuracy: 0.7934 - val_loss: 0.0795\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.0875 - val_accuracy: 0.7930 - val_loss: 0.0772\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7781 - loss: 0.0848 - val_accuracy: 0.7907 - val_loss: 0.0771\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.0854 - val_accuracy: 0.7930 - val_loss: 0.0782\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 0.0891 - val_accuracy: 0.7941 - val_loss: 0.0781\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7749 - loss: 0.0864 - val_accuracy: 0.7892 - val_loss: 0.0788\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7861 - loss: 0.0863 - val_accuracy: 0.7934 - val_loss: 0.0804\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.0860 - val_accuracy: 0.7972 - val_loss: 0.0764\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 0.0857 - val_accuracy: 0.8033 - val_loss: 0.0746\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.0836 - val_accuracy: 0.8018 - val_loss: 0.0748\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.0827 - val_accuracy: 0.8090 - val_loss: 0.0746\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.0849 - val_accuracy: 0.8018 - val_loss: 0.0747\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.0852 - val_accuracy: 0.7945 - val_loss: 0.0755\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.0843 - val_accuracy: 0.7964 - val_loss: 0.0745\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.0866 - val_accuracy: 0.8040 - val_loss: 0.0749\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.0850 - val_accuracy: 0.8006 - val_loss: 0.0733\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.0830 - val_accuracy: 0.8124 - val_loss: 0.0722\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.0819 - val_accuracy: 0.7995 - val_loss: 0.0734\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.0807 - val_accuracy: 0.8048 - val_loss: 0.0717\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.0839 - val_accuracy: 0.7998 - val_loss: 0.0721\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7798 - loss: 0.0837 - val_accuracy: 0.8025 - val_loss: 0.0740\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7831 - loss: 0.0829 - val_accuracy: 0.8021 - val_loss: 0.0737\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.0821 - val_accuracy: 0.8071 - val_loss: 0.0733\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.0779 - val_accuracy: 0.8044 - val_loss: 0.0723\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.0824 - val_accuracy: 0.7983 - val_loss: 0.0727\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.0825 - val_accuracy: 0.8075 - val_loss: 0.0731\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5753 - loss: 0.1546 - val_accuracy: 0.7030 - val_loss: 0.1105\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.1213 - val_accuracy: 0.7225 - val_loss: 0.1079\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6938 - loss: 0.1124 - val_accuracy: 0.7156 - val_loss: 0.1057\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7029 - loss: 0.1108 - val_accuracy: 0.7343 - val_loss: 0.1042\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.1063 - val_accuracy: 0.7377 - val_loss: 0.1023\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.1076 - val_accuracy: 0.7610 - val_loss: 0.0961\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.0993 - val_accuracy: 0.7629 - val_loss: 0.0965\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.0993 - val_accuracy: 0.7701 - val_loss: 0.0919\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7471 - loss: 0.0961 - val_accuracy: 0.7819 - val_loss: 0.0921\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.0950 - val_accuracy: 0.7751 - val_loss: 0.0931\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 0.0948 - val_accuracy: 0.7903 - val_loss: 0.0875\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.0962 - val_accuracy: 0.7987 - val_loss: 0.0863\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 0.0908 - val_accuracy: 0.7922 - val_loss: 0.0859\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7662 - loss: 0.0909 - val_accuracy: 0.7941 - val_loss: 0.0862\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.0925 - val_accuracy: 0.7937 - val_loss: 0.0851\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.0929 - val_accuracy: 0.8037 - val_loss: 0.0833\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.0876 - val_accuracy: 0.7922 - val_loss: 0.0846\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.0896 - val_accuracy: 0.8014 - val_loss: 0.0830\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.0919 - val_accuracy: 0.7945 - val_loss: 0.0840\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7709 - loss: 0.0906 - val_accuracy: 0.7838 - val_loss: 0.0882\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.0878 - val_accuracy: 0.7998 - val_loss: 0.0856\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.0873 - val_accuracy: 0.8059 - val_loss: 0.0872\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.0886 - val_accuracy: 0.7998 - val_loss: 0.0814\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.0896 - val_accuracy: 0.7998 - val_loss: 0.0832\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.0894 - val_accuracy: 0.8010 - val_loss: 0.0806\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7748 - loss: 0.0859 - val_accuracy: 0.7983 - val_loss: 0.0806\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.0866 - val_accuracy: 0.8105 - val_loss: 0.0805\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.0859 - val_accuracy: 0.8044 - val_loss: 0.0812\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 0.0887 - val_accuracy: 0.8094 - val_loss: 0.0820\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.0866 - val_accuracy: 0.8014 - val_loss: 0.0807\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.0843 - val_accuracy: 0.7964 - val_loss: 0.0831\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.0847 - val_accuracy: 0.7941 - val_loss: 0.0850\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7886 - loss: 0.0830 - val_accuracy: 0.8052 - val_loss: 0.0818\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.0871 - val_accuracy: 0.8090 - val_loss: 0.0782\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.0837 - val_accuracy: 0.7987 - val_loss: 0.0820\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.0850 - val_accuracy: 0.7911 - val_loss: 0.0851\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7749 - loss: 0.0857 - val_accuracy: 0.7995 - val_loss: 0.0794\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.0820 - val_accuracy: 0.8006 - val_loss: 0.0798\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.0864 - val_accuracy: 0.8090 - val_loss: 0.0789\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.0842 - val_accuracy: 0.8120 - val_loss: 0.0774\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7832 - loss: 0.0840 - val_accuracy: 0.8079 - val_loss: 0.0758\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.0825 - val_accuracy: 0.8079 - val_loss: 0.0774\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7780 - loss: 0.0845 - val_accuracy: 0.8033 - val_loss: 0.0809\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 0.0826 - val_accuracy: 0.8040 - val_loss: 0.0804\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.0815 - val_accuracy: 0.8052 - val_loss: 0.0766\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.0830 - val_accuracy: 0.8063 - val_loss: 0.0772\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.0831 - val_accuracy: 0.8079 - val_loss: 0.0757\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.0837 - val_accuracy: 0.8155 - val_loss: 0.0766\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.0812 - val_accuracy: 0.8086 - val_loss: 0.0773\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.0819 - val_accuracy: 0.8193 - val_loss: 0.0762\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 3: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5967 - loss: 0.1475 - val_accuracy: 0.6949 - val_loss: 0.1147\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 0.1238 - val_accuracy: 0.7014 - val_loss: 0.1074\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 0.1152 - val_accuracy: 0.7155 - val_loss: 0.1064\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7137 - loss: 0.1087 - val_accuracy: 0.7288 - val_loss: 0.1040\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.1067 - val_accuracy: 0.7307 - val_loss: 0.1027\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.1040 - val_accuracy: 0.7456 - val_loss: 0.0989\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.1034 - val_accuracy: 0.7498 - val_loss: 0.0954\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.1005 - val_accuracy: 0.7601 - val_loss: 0.0932\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7443 - loss: 0.0994 - val_accuracy: 0.7609 - val_loss: 0.0947\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.0947 - val_accuracy: 0.7498 - val_loss: 0.0922\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7552 - loss: 0.0961 - val_accuracy: 0.7853 - val_loss: 0.0884\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.0945 - val_accuracy: 0.7777 - val_loss: 0.0903\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7681 - loss: 0.0914 - val_accuracy: 0.7765 - val_loss: 0.0880\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.0938 - val_accuracy: 0.7811 - val_loss: 0.0880\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7723 - loss: 0.0923 - val_accuracy: 0.7750 - val_loss: 0.0885\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7623 - loss: 0.0940 - val_accuracy: 0.7719 - val_loss: 0.0869\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7681 - loss: 0.0923 - val_accuracy: 0.7838 - val_loss: 0.0849\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.0912 - val_accuracy: 0.7731 - val_loss: 0.0854\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.0880 - val_accuracy: 0.7860 - val_loss: 0.0851\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7700 - loss: 0.0900 - val_accuracy: 0.7757 - val_loss: 0.0862\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.0867 - val_accuracy: 0.7674 - val_loss: 0.0853\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.0875 - val_accuracy: 0.7822 - val_loss: 0.0818\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.0885 - val_accuracy: 0.7864 - val_loss: 0.0811\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 0.0879 - val_accuracy: 0.7876 - val_loss: 0.0821\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.0897 - val_accuracy: 0.7887 - val_loss: 0.0831\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.0855 - val_accuracy: 0.7933 - val_loss: 0.0818\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 0.0861 - val_accuracy: 0.7857 - val_loss: 0.0815\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.0877 - val_accuracy: 0.7914 - val_loss: 0.0817\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.0879 - val_accuracy: 0.7879 - val_loss: 0.0807\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.0866 - val_accuracy: 0.7849 - val_loss: 0.0833\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.0871 - val_accuracy: 0.7887 - val_loss: 0.0841\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.0875 - val_accuracy: 0.7872 - val_loss: 0.0792\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.0871 - val_accuracy: 0.7952 - val_loss: 0.0797\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.0861 - val_accuracy: 0.7979 - val_loss: 0.0779\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.0869 - val_accuracy: 0.7883 - val_loss: 0.0807\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.0834 - val_accuracy: 0.7937 - val_loss: 0.0788\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.0845 - val_accuracy: 0.7971 - val_loss: 0.0786\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.0853 - val_accuracy: 0.7822 - val_loss: 0.0808\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.0841 - val_accuracy: 0.7914 - val_loss: 0.0788\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.0855 - val_accuracy: 0.7952 - val_loss: 0.0781\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.0846 - val_accuracy: 0.7948 - val_loss: 0.0787\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.0841 - val_accuracy: 0.7956 - val_loss: 0.0767\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.0844 - val_accuracy: 0.7963 - val_loss: 0.0766\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.0853 - val_accuracy: 0.7937 - val_loss: 0.0783\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.0825 - val_accuracy: 0.7906 - val_loss: 0.0773\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 0.0825 - val_accuracy: 0.7994 - val_loss: 0.0769\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.0844 - val_accuracy: 0.7963 - val_loss: 0.0784\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7839 - loss: 0.0819 - val_accuracy: 0.7941 - val_loss: 0.0789\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.0830 - val_accuracy: 0.7899 - val_loss: 0.0775\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.0797 - val_accuracy: 0.7944 - val_loss: 0.0763\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5807 - loss: 0.1572 - val_accuracy: 0.7006 - val_loss: 0.1088\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6653 - loss: 0.1229 - val_accuracy: 0.7235 - val_loss: 0.1056\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6912 - loss: 0.1161 - val_accuracy: 0.7212 - val_loss: 0.1030\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7038 - loss: 0.1101 - val_accuracy: 0.7399 - val_loss: 0.1021\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.1080 - val_accuracy: 0.7109 - val_loss: 0.1004\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7253 - loss: 0.1040 - val_accuracy: 0.7616 - val_loss: 0.0935\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7314 - loss: 0.1045 - val_accuracy: 0.7521 - val_loss: 0.0954\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.1014 - val_accuracy: 0.7696 - val_loss: 0.0923\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7502 - loss: 0.0969 - val_accuracy: 0.7761 - val_loss: 0.0906\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7441 - loss: 0.0969 - val_accuracy: 0.7830 - val_loss: 0.0885\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7633 - loss: 0.0944 - val_accuracy: 0.7796 - val_loss: 0.0873\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7626 - loss: 0.0917 - val_accuracy: 0.7651 - val_loss: 0.0893\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7465 - loss: 0.0985 - val_accuracy: 0.7841 - val_loss: 0.0859\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.0933 - val_accuracy: 0.7876 - val_loss: 0.0862\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.0934 - val_accuracy: 0.7750 - val_loss: 0.0855\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.0926 - val_accuracy: 0.7967 - val_loss: 0.0835\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.0919 - val_accuracy: 0.7971 - val_loss: 0.0827\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7683 - loss: 0.0897 - val_accuracy: 0.7902 - val_loss: 0.0842\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.0885 - val_accuracy: 0.7979 - val_loss: 0.0828\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.0888 - val_accuracy: 0.8021 - val_loss: 0.0814\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.0882 - val_accuracy: 0.7910 - val_loss: 0.0851\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.0876 - val_accuracy: 0.7990 - val_loss: 0.0823\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.0861 - val_accuracy: 0.7979 - val_loss: 0.0828\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7754 - loss: 0.0870 - val_accuracy: 0.7986 - val_loss: 0.0830\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.0845 - val_accuracy: 0.7914 - val_loss: 0.0823\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.0894 - val_accuracy: 0.8024 - val_loss: 0.0810\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7776 - loss: 0.0864 - val_accuracy: 0.7979 - val_loss: 0.0802\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.0858 - val_accuracy: 0.8063 - val_loss: 0.0830\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.0861 - val_accuracy: 0.8009 - val_loss: 0.0824\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.0819 - val_accuracy: 0.7868 - val_loss: 0.0887\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7750 - loss: 0.0877 - val_accuracy: 0.7952 - val_loss: 0.0809\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.0864 - val_accuracy: 0.7971 - val_loss: 0.0796\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.0852 - val_accuracy: 0.8032 - val_loss: 0.0799\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.0853 - val_accuracy: 0.8078 - val_loss: 0.0776\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.0870 - val_accuracy: 0.8093 - val_loss: 0.0776\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.0832 - val_accuracy: 0.8036 - val_loss: 0.0789\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7901 - loss: 0.0828 - val_accuracy: 0.7986 - val_loss: 0.0798\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.0854 - val_accuracy: 0.8093 - val_loss: 0.0785\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7853 - loss: 0.0834 - val_accuracy: 0.8040 - val_loss: 0.0785\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.0847 - val_accuracy: 0.8108 - val_loss: 0.0788\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7804 - loss: 0.0841 - val_accuracy: 0.8101 - val_loss: 0.0771\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.0862 - val_accuracy: 0.8108 - val_loss: 0.0781\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.0832 - val_accuracy: 0.8116 - val_loss: 0.0775\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.0829 - val_accuracy: 0.7998 - val_loss: 0.0803\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.0831 - val_accuracy: 0.8108 - val_loss: 0.0775\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7879 - loss: 0.0825 - val_accuracy: 0.8078 - val_loss: 0.0766\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7873 - loss: 0.0813 - val_accuracy: 0.8032 - val_loss: 0.0768\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.0797 - val_accuracy: 0.8135 - val_loss: 0.0761\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7839 - loss: 0.0835 - val_accuracy: 0.8158 - val_loss: 0.0768\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.0817 - val_accuracy: 0.8150 - val_loss: 0.0772\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week1/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5834 - loss: 0.1576 - val_accuracy: 0.6915 - val_loss: 0.1108\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6820 - loss: 0.1190 - val_accuracy: 0.7029 - val_loss: 0.1079\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6962 - loss: 0.1122 - val_accuracy: 0.7182 - val_loss: 0.1060\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7163 - loss: 0.1104 - val_accuracy: 0.7223 - val_loss: 0.1027\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.1062 - val_accuracy: 0.7300 - val_loss: 0.1000\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7298 - loss: 0.1053 - val_accuracy: 0.7246 - val_loss: 0.0994\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.1039 - val_accuracy: 0.7414 - val_loss: 0.0945\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7405 - loss: 0.1015 - val_accuracy: 0.7357 - val_loss: 0.0942\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7385 - loss: 0.0988 - val_accuracy: 0.7567 - val_loss: 0.0909\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.1010 - val_accuracy: 0.7670 - val_loss: 0.0923\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7472 - loss: 0.0973 - val_accuracy: 0.7677 - val_loss: 0.0898\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7588 - loss: 0.0959 - val_accuracy: 0.7773 - val_loss: 0.0867\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 0.0943 - val_accuracy: 0.7704 - val_loss: 0.0874\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7531 - loss: 0.0967 - val_accuracy: 0.7796 - val_loss: 0.0864\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.0942 - val_accuracy: 0.7818 - val_loss: 0.0860\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7678 - loss: 0.0927 - val_accuracy: 0.7700 - val_loss: 0.0854\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.0902 - val_accuracy: 0.7815 - val_loss: 0.0846\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 0.0930 - val_accuracy: 0.7815 - val_loss: 0.0837\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7768 - loss: 0.0888 - val_accuracy: 0.7681 - val_loss: 0.0885\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7653 - loss: 0.0910 - val_accuracy: 0.7784 - val_loss: 0.0821\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.0883 - val_accuracy: 0.7773 - val_loss: 0.0832\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7730 - loss: 0.0886 - val_accuracy: 0.7815 - val_loss: 0.0846\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.0849 - val_accuracy: 0.7868 - val_loss: 0.0814\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.0892 - val_accuracy: 0.7788 - val_loss: 0.0818\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7743 - loss: 0.0901 - val_accuracy: 0.7838 - val_loss: 0.0809\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7707 - loss: 0.0888 - val_accuracy: 0.7838 - val_loss: 0.0819\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.0865 - val_accuracy: 0.7841 - val_loss: 0.0807\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.0907 - val_accuracy: 0.7918 - val_loss: 0.0815\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7879 - loss: 0.0843 - val_accuracy: 0.7933 - val_loss: 0.0813\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.0894 - val_accuracy: 0.7891 - val_loss: 0.0778\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.0874 - val_accuracy: 0.7963 - val_loss: 0.0788\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.0851 - val_accuracy: 0.7910 - val_loss: 0.0793\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7707 - loss: 0.0875 - val_accuracy: 0.7906 - val_loss: 0.0779\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.0880 - val_accuracy: 0.7845 - val_loss: 0.0795\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.0857 - val_accuracy: 0.7906 - val_loss: 0.0777\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7841 - loss: 0.0863 - val_accuracy: 0.7822 - val_loss: 0.0794\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.0859 - val_accuracy: 0.7868 - val_loss: 0.0778\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7867 - loss: 0.0837 - val_accuracy: 0.7841 - val_loss: 0.0804\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7914 - loss: 0.0837 - val_accuracy: 0.7994 - val_loss: 0.0779\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.0838 - val_accuracy: 0.7933 - val_loss: 0.0770\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.0854 - val_accuracy: 0.7979 - val_loss: 0.0753\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.0835 - val_accuracy: 0.7914 - val_loss: 0.0784\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.0852 - val_accuracy: 0.7891 - val_loss: 0.0774\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.0828 - val_accuracy: 0.7914 - val_loss: 0.0793\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.0856 - val_accuracy: 0.7967 - val_loss: 0.0779\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7842 - loss: 0.0830 - val_accuracy: 0.7895 - val_loss: 0.0761\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.0838 - val_accuracy: 0.7899 - val_loss: 0.0752\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7760 - loss: 0.0849 - val_accuracy: 0.7967 - val_loss: 0.0761\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.0808 - val_accuracy: 0.7960 - val_loss: 0.0771\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.0806 - val_accuracy: 0.7941 - val_loss: 0.0760\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average Accuracy ===\n",
      "0.8061\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.6626\n",
      "Macro Recall: 0.5398\n",
      "Macro F1-Score: 0.5650\n",
      "Macro AUC-ROC: 0.9078\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.7860\n",
      "Weighted Recall: 0.8061\n",
      "Weighted F1-Score: 0.7866\n",
      "Weighted AUC-ROC: 0.9300\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.710910        0.685667          0.696167     0.911810\n",
      "1      1           0.361905        0.040909          0.066880     0.881914\n",
      "2      2           0.750833        0.465898          0.572889     0.892486\n",
      "3      3           0.632899        0.552096          0.586440     0.907098\n",
      "4      4           0.856668        0.954219          0.902533     0.945703\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0    1     2     3       4\n",
      "0  411.4  0.2  12.6  24.6   151.2\n",
      "1   49.2  3.6   2.4   6.4    26.0\n",
      "2   40.6  0.2  76.6  11.0    36.0\n",
      "3   28.4  0.2   2.2  92.2    44.0\n",
      "4   52.2  0.2   8.8  12.2  1530.0\n",
      "\n",
      "Processing week2 with best parameters...\n",
      "best parameters for week2: {'units_1': 256, 'dropout_1': 0.5, 'learning_rate': 0.0009867496902904826}\n",
      "Fold 1: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5772 - loss: 0.1626 - val_accuracy: 0.7080 - val_loss: 0.1090\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6793 - loss: 0.1204 - val_accuracy: 0.7179 - val_loss: 0.1039\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6909 - loss: 0.1149 - val_accuracy: 0.7415 - val_loss: 0.0978\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.1078 - val_accuracy: 0.7888 - val_loss: 0.0910\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7332 - loss: 0.1036 - val_accuracy: 0.7915 - val_loss: 0.0856\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7613 - loss: 0.0976 - val_accuracy: 0.7854 - val_loss: 0.0843\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7705 - loss: 0.0934 - val_accuracy: 0.8140 - val_loss: 0.0772\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.0913 - val_accuracy: 0.8216 - val_loss: 0.0768\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.0868 - val_accuracy: 0.8109 - val_loss: 0.0792\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7798 - loss: 0.0908 - val_accuracy: 0.8361 - val_loss: 0.0709\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.0863 - val_accuracy: 0.8277 - val_loss: 0.0692\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.0860 - val_accuracy: 0.8418 - val_loss: 0.0690\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.0829 - val_accuracy: 0.8208 - val_loss: 0.0695\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.0817 - val_accuracy: 0.8147 - val_loss: 0.0714\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.0756 - val_accuracy: 0.8357 - val_loss: 0.0651\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.0761 - val_accuracy: 0.8422 - val_loss: 0.0657\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.0769 - val_accuracy: 0.8406 - val_loss: 0.0633\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0707 - val_accuracy: 0.8471 - val_loss: 0.0630\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.0754 - val_accuracy: 0.8262 - val_loss: 0.0662\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8242 - loss: 0.0712 - val_accuracy: 0.8544 - val_loss: 0.0634\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.0748 - val_accuracy: 0.8342 - val_loss: 0.0638\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.0701 - val_accuracy: 0.8517 - val_loss: 0.0610\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.0692 - val_accuracy: 0.8528 - val_loss: 0.0570\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.0690 - val_accuracy: 0.8452 - val_loss: 0.0574\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.0683 - val_accuracy: 0.8635 - val_loss: 0.0548\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.0694 - val_accuracy: 0.8593 - val_loss: 0.0564\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.0655 - val_accuracy: 0.8742 - val_loss: 0.0516\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8368 - loss: 0.0656 - val_accuracy: 0.8677 - val_loss: 0.0517\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.0639 - val_accuracy: 0.8624 - val_loss: 0.0515\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.0634 - val_accuracy: 0.8628 - val_loss: 0.0518\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.0632 - val_accuracy: 0.8700 - val_loss: 0.0534\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.0623 - val_accuracy: 0.8841 - val_loss: 0.0474\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8433 - loss: 0.0604 - val_accuracy: 0.8673 - val_loss: 0.0517\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.0611 - val_accuracy: 0.8711 - val_loss: 0.0484\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.0615 - val_accuracy: 0.8753 - val_loss: 0.0477\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 0.0593 - val_accuracy: 0.8742 - val_loss: 0.0480\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 0.0566 - val_accuracy: 0.8868 - val_loss: 0.0456\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.0566 - val_accuracy: 0.8811 - val_loss: 0.0470\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.0565 - val_accuracy: 0.8826 - val_loss: 0.0439\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.0568 - val_accuracy: 0.8894 - val_loss: 0.0459\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 0.0579 - val_accuracy: 0.8784 - val_loss: 0.0455\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.0572 - val_accuracy: 0.8727 - val_loss: 0.0450\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.0554 - val_accuracy: 0.8845 - val_loss: 0.0443\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.0543 - val_accuracy: 0.8887 - val_loss: 0.0423\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8539 - loss: 0.0551 - val_accuracy: 0.8788 - val_loss: 0.0441\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.0561 - val_accuracy: 0.8856 - val_loss: 0.0438\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.0539 - val_accuracy: 0.8894 - val_loss: 0.0409\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.0576 - val_accuracy: 0.8868 - val_loss: 0.0419\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.0547 - val_accuracy: 0.8940 - val_loss: 0.0396\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.0508 - val_accuracy: 0.8875 - val_loss: 0.0407\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6279 - loss: 0.1408 - val_accuracy: 0.6946 - val_loss: 0.1095\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6879 - loss: 0.1156 - val_accuracy: 0.7083 - val_loss: 0.1052\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7091 - loss: 0.1096 - val_accuracy: 0.7457 - val_loss: 0.1005\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7255 - loss: 0.1059 - val_accuracy: 0.7892 - val_loss: 0.0938\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.1009 - val_accuracy: 0.7735 - val_loss: 0.0918\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.1002 - val_accuracy: 0.7804 - val_loss: 0.0932\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.0888 - val_accuracy: 0.8109 - val_loss: 0.0795\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7744 - loss: 0.0888 - val_accuracy: 0.8147 - val_loss: 0.0782\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.0869 - val_accuracy: 0.8155 - val_loss: 0.0794\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7847 - loss: 0.0863 - val_accuracy: 0.8075 - val_loss: 0.0783\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.0846 - val_accuracy: 0.8117 - val_loss: 0.0781\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.0811 - val_accuracy: 0.8387 - val_loss: 0.0721\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.0804 - val_accuracy: 0.8307 - val_loss: 0.0732\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.0834 - val_accuracy: 0.8326 - val_loss: 0.0696\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.0772 - val_accuracy: 0.8441 - val_loss: 0.0709\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.0784 - val_accuracy: 0.8364 - val_loss: 0.0712\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.0759 - val_accuracy: 0.8368 - val_loss: 0.0674\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.0753 - val_accuracy: 0.8460 - val_loss: 0.0674\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.0768 - val_accuracy: 0.8483 - val_loss: 0.0654\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.0733 - val_accuracy: 0.8281 - val_loss: 0.0676\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8220 - loss: 0.0729 - val_accuracy: 0.8494 - val_loss: 0.0672\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.0714 - val_accuracy: 0.8490 - val_loss: 0.0630\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.0736 - val_accuracy: 0.8441 - val_loss: 0.0626\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.0717 - val_accuracy: 0.8429 - val_loss: 0.0632\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.0706 - val_accuracy: 0.8513 - val_loss: 0.0614\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8282 - loss: 0.0680 - val_accuracy: 0.8631 - val_loss: 0.0570\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.0678 - val_accuracy: 0.8669 - val_loss: 0.0557\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.0676 - val_accuracy: 0.8536 - val_loss: 0.0580\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8320 - loss: 0.0663 - val_accuracy: 0.8654 - val_loss: 0.0567\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.0653 - val_accuracy: 0.8628 - val_loss: 0.0560\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.0637 - val_accuracy: 0.8612 - val_loss: 0.0559\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 0.0635 - val_accuracy: 0.8715 - val_loss: 0.0527\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.0633 - val_accuracy: 0.8643 - val_loss: 0.0533\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.0659 - val_accuracy: 0.8803 - val_loss: 0.0509\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 0.0618 - val_accuracy: 0.8784 - val_loss: 0.0476\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.0620 - val_accuracy: 0.8715 - val_loss: 0.0514\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.0600 - val_accuracy: 0.8719 - val_loss: 0.0517\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.0604 - val_accuracy: 0.8715 - val_loss: 0.0498\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.0581 - val_accuracy: 0.8765 - val_loss: 0.0499\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 0.0568 - val_accuracy: 0.8730 - val_loss: 0.0469\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.0587 - val_accuracy: 0.8822 - val_loss: 0.0463\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.0577 - val_accuracy: 0.8689 - val_loss: 0.0547\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.0557 - val_accuracy: 0.8799 - val_loss: 0.0481\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.0577 - val_accuracy: 0.8818 - val_loss: 0.0492\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 0.0564 - val_accuracy: 0.8833 - val_loss: 0.0462\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.0576 - val_accuracy: 0.8803 - val_loss: 0.0483\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0533 - val_accuracy: 0.8776 - val_loss: 0.0456\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8531 - loss: 0.0561 - val_accuracy: 0.8894 - val_loss: 0.0420\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.0595 - val_accuracy: 0.8715 - val_loss: 0.0536\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.0562 - val_accuracy: 0.8807 - val_loss: 0.0470\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 3: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6213 - loss: 0.1444 - val_accuracy: 0.6937 - val_loss: 0.1119\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 0.1181 - val_accuracy: 0.7086 - val_loss: 0.1101\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7050 - loss: 0.1150 - val_accuracy: 0.7544 - val_loss: 0.0989\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7316 - loss: 0.1047 - val_accuracy: 0.7620 - val_loss: 0.0938\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.1000 - val_accuracy: 0.7742 - val_loss: 0.0890\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 0.0971 - val_accuracy: 0.7975 - val_loss: 0.0824\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 0.0888 - val_accuracy: 0.7929 - val_loss: 0.0821\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7760 - loss: 0.0918 - val_accuracy: 0.8124 - val_loss: 0.0773\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.0879 - val_accuracy: 0.7914 - val_loss: 0.0806\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.0849 - val_accuracy: 0.8143 - val_loss: 0.0742\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.0831 - val_accuracy: 0.8196 - val_loss: 0.0723\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.0854 - val_accuracy: 0.8291 - val_loss: 0.0738\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.0801 - val_accuracy: 0.8265 - val_loss: 0.0739\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.0806 - val_accuracy: 0.8391 - val_loss: 0.0693\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.0792 - val_accuracy: 0.8265 - val_loss: 0.0700\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.0770 - val_accuracy: 0.8173 - val_loss: 0.0721\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 0.0792 - val_accuracy: 0.8436 - val_loss: 0.0641\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8154 - loss: 0.0741 - val_accuracy: 0.8459 - val_loss: 0.0647\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.0760 - val_accuracy: 0.8398 - val_loss: 0.0628\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.0747 - val_accuracy: 0.8455 - val_loss: 0.0613\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8155 - loss: 0.0716 - val_accuracy: 0.8501 - val_loss: 0.0609\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.0700 - val_accuracy: 0.8391 - val_loss: 0.0615\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.0700 - val_accuracy: 0.8494 - val_loss: 0.0574\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.0707 - val_accuracy: 0.8570 - val_loss: 0.0567\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.0674 - val_accuracy: 0.8555 - val_loss: 0.0565\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.0729 - val_accuracy: 0.8547 - val_loss: 0.0564\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.0659 - val_accuracy: 0.8669 - val_loss: 0.0520\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.0649 - val_accuracy: 0.8661 - val_loss: 0.0557\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8413 - loss: 0.0646 - val_accuracy: 0.8566 - val_loss: 0.0548\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.0659 - val_accuracy: 0.8741 - val_loss: 0.0509\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.0623 - val_accuracy: 0.8677 - val_loss: 0.0519\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 0.0630 - val_accuracy: 0.8505 - val_loss: 0.0557\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 0.0616 - val_accuracy: 0.8768 - val_loss: 0.0487\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.0609 - val_accuracy: 0.8665 - val_loss: 0.0490\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.0617 - val_accuracy: 0.8795 - val_loss: 0.0471\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.0618 - val_accuracy: 0.8844 - val_loss: 0.0457\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8461 - loss: 0.0586 - val_accuracy: 0.8604 - val_loss: 0.0486\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 0.0565 - val_accuracy: 0.8772 - val_loss: 0.0451\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.0601 - val_accuracy: 0.8627 - val_loss: 0.0524\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.0571 - val_accuracy: 0.8902 - val_loss: 0.0418\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8508 - loss: 0.0567 - val_accuracy: 0.8715 - val_loss: 0.0526\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8539 - loss: 0.0560 - val_accuracy: 0.8848 - val_loss: 0.0419\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8456 - loss: 0.0575 - val_accuracy: 0.8902 - val_loss: 0.0420\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.0527 - val_accuracy: 0.8692 - val_loss: 0.0479\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.0566 - val_accuracy: 0.8860 - val_loss: 0.0455\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.0559 - val_accuracy: 0.8894 - val_loss: 0.0437\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.0560 - val_accuracy: 0.8860 - val_loss: 0.0429\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.0547 - val_accuracy: 0.8966 - val_loss: 0.0381\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.0523 - val_accuracy: 0.9027 - val_loss: 0.0380\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 0.0521 - val_accuracy: 0.8955 - val_loss: 0.0391\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6131 - loss: 0.1476 - val_accuracy: 0.7246 - val_loss: 0.1129\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6863 - loss: 0.1157 - val_accuracy: 0.7117 - val_loss: 0.1076\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 0.1122 - val_accuracy: 0.7727 - val_loss: 0.0960\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.1050 - val_accuracy: 0.7757 - val_loss: 0.0891\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.0995 - val_accuracy: 0.7826 - val_loss: 0.0880\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.0993 - val_accuracy: 0.7902 - val_loss: 0.0848\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7693 - loss: 0.0949 - val_accuracy: 0.7990 - val_loss: 0.0810\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.0890 - val_accuracy: 0.8173 - val_loss: 0.0755\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.0887 - val_accuracy: 0.8265 - val_loss: 0.0749\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7910 - loss: 0.0845 - val_accuracy: 0.8089 - val_loss: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.0841 - val_accuracy: 0.8211 - val_loss: 0.0742\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.0796 - val_accuracy: 0.8200 - val_loss: 0.0734\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7930 - loss: 0.0829 - val_accuracy: 0.8375 - val_loss: 0.0701\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8072 - loss: 0.0787 - val_accuracy: 0.8501 - val_loss: 0.0664\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.0771 - val_accuracy: 0.8345 - val_loss: 0.0674\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.0786 - val_accuracy: 0.8486 - val_loss: 0.0646\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.0764 - val_accuracy: 0.8387 - val_loss: 0.0661\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8234 - loss: 0.0746 - val_accuracy: 0.8291 - val_loss: 0.0726\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.0755 - val_accuracy: 0.8375 - val_loss: 0.0639\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8234 - loss: 0.0742 - val_accuracy: 0.8486 - val_loss: 0.0626\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.0717 - val_accuracy: 0.8360 - val_loss: 0.0652\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.0718 - val_accuracy: 0.8455 - val_loss: 0.0623\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.0662 - val_accuracy: 0.8463 - val_loss: 0.0610\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.0697 - val_accuracy: 0.8589 - val_loss: 0.0592\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.0705 - val_accuracy: 0.8513 - val_loss: 0.0607\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.0671 - val_accuracy: 0.8677 - val_loss: 0.0547\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.0652 - val_accuracy: 0.8585 - val_loss: 0.0551\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.0663 - val_accuracy: 0.8616 - val_loss: 0.0563\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.0655 - val_accuracy: 0.8642 - val_loss: 0.0543\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8427 - loss: 0.0626 - val_accuracy: 0.8654 - val_loss: 0.0519\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.0614 - val_accuracy: 0.8574 - val_loss: 0.0566\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8435 - loss: 0.0613 - val_accuracy: 0.8604 - val_loss: 0.0529\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.0624 - val_accuracy: 0.8711 - val_loss: 0.0518\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.0617 - val_accuracy: 0.8814 - val_loss: 0.0470\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8556 - loss: 0.0576 - val_accuracy: 0.8822 - val_loss: 0.0471\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 0.0589 - val_accuracy: 0.8726 - val_loss: 0.0484\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8477 - loss: 0.0583 - val_accuracy: 0.8799 - val_loss: 0.0463\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.0581 - val_accuracy: 0.8829 - val_loss: 0.0468\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.0593 - val_accuracy: 0.8741 - val_loss: 0.0463\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8555 - loss: 0.0553 - val_accuracy: 0.8764 - val_loss: 0.0497\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.0584 - val_accuracy: 0.8555 - val_loss: 0.0540\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.0560 - val_accuracy: 0.8856 - val_loss: 0.0424\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.0542 - val_accuracy: 0.8799 - val_loss: 0.0462\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.0548 - val_accuracy: 0.8879 - val_loss: 0.0446\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.0534 - val_accuracy: 0.8837 - val_loss: 0.0451\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.0529 - val_accuracy: 0.8837 - val_loss: 0.0446\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.0534 - val_accuracy: 0.8795 - val_loss: 0.0424\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 0.0527 - val_accuracy: 0.8791 - val_loss: 0.0460\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8593 - loss: 0.0535 - val_accuracy: 0.8940 - val_loss: 0.0416\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.0530 - val_accuracy: 0.8802 - val_loss: 0.0431\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 5: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week2/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.1447 - val_accuracy: 0.7128 - val_loss: 0.1113\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6829 - loss: 0.1187 - val_accuracy: 0.7304 - val_loss: 0.1077\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6933 - loss: 0.1137 - val_accuracy: 0.7426 - val_loss: 0.1022\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.1088 - val_accuracy: 0.7754 - val_loss: 0.0913\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7475 - loss: 0.0997 - val_accuracy: 0.7906 - val_loss: 0.0857\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7666 - loss: 0.0951 - val_accuracy: 0.7975 - val_loss: 0.0844\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7709 - loss: 0.0927 - val_accuracy: 0.8227 - val_loss: 0.0786\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7850 - loss: 0.0900 - val_accuracy: 0.8112 - val_loss: 0.0747\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.0884 - val_accuracy: 0.8162 - val_loss: 0.0769\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.0912 - val_accuracy: 0.8280 - val_loss: 0.0748\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.0910 - val_accuracy: 0.8154 - val_loss: 0.0742\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7942 - loss: 0.0845 - val_accuracy: 0.8169 - val_loss: 0.0713\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.0820 - val_accuracy: 0.8204 - val_loss: 0.0698\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7949 - loss: 0.0831 - val_accuracy: 0.8436 - val_loss: 0.0646\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8111 - loss: 0.0787 - val_accuracy: 0.8295 - val_loss: 0.0663\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.0771 - val_accuracy: 0.8310 - val_loss: 0.0633\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.0754 - val_accuracy: 0.8417 - val_loss: 0.0631\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.0770 - val_accuracy: 0.8452 - val_loss: 0.0616\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.0777 - val_accuracy: 0.8486 - val_loss: 0.0584\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.0746 - val_accuracy: 0.8516 - val_loss: 0.0613\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.0733 - val_accuracy: 0.8406 - val_loss: 0.0592\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.0713 - val_accuracy: 0.8471 - val_loss: 0.0571\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8233 - loss: 0.0712 - val_accuracy: 0.8589 - val_loss: 0.0550\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.0677 - val_accuracy: 0.8509 - val_loss: 0.0571\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.0731 - val_accuracy: 0.8585 - val_loss: 0.0566\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.0682 - val_accuracy: 0.8574 - val_loss: 0.0548\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.0682 - val_accuracy: 0.8520 - val_loss: 0.0539\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.0657 - val_accuracy: 0.8612 - val_loss: 0.0516\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.0647 - val_accuracy: 0.8791 - val_loss: 0.0487\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 0.0658 - val_accuracy: 0.8684 - val_loss: 0.0522\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.0649 - val_accuracy: 0.8745 - val_loss: 0.0481\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.0626 - val_accuracy: 0.8787 - val_loss: 0.0459\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8383 - loss: 0.0619 - val_accuracy: 0.8738 - val_loss: 0.0491\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8378 - loss: 0.0628 - val_accuracy: 0.8642 - val_loss: 0.0527\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.0602 - val_accuracy: 0.8722 - val_loss: 0.0475\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.0638 - val_accuracy: 0.8909 - val_loss: 0.0452\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.0611 - val_accuracy: 0.8799 - val_loss: 0.0434\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.0649 - val_accuracy: 0.8814 - val_loss: 0.0441\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8444 - loss: 0.0608 - val_accuracy: 0.8890 - val_loss: 0.0424\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8565 - loss: 0.0555 - val_accuracy: 0.8921 - val_loss: 0.0442\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.0575 - val_accuracy: 0.8760 - val_loss: 0.0458\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.0570 - val_accuracy: 0.8833 - val_loss: 0.0462\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.0587 - val_accuracy: 0.8940 - val_loss: 0.0404\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.0555 - val_accuracy: 0.8947 - val_loss: 0.0402\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.0564 - val_accuracy: 0.8871 - val_loss: 0.0429\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.0574 - val_accuracy: 0.8902 - val_loss: 0.0410\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.0556 - val_accuracy: 0.8852 - val_loss: 0.0456\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0549 - val_accuracy: 0.8829 - val_loss: 0.0422\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.0541 - val_accuracy: 0.8886 - val_loss: 0.0411\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.0551 - val_accuracy: 0.8886 - val_loss: 0.0390\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.8865\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.8530\n",
      "Macro Recall: 0.7419\n",
      "Macro F1-Score: 0.7810\n",
      "Macro AUC-ROC: 0.9722\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.8875\n",
      "Weighted Recall: 0.8865\n",
      "Weighted F1-Score: 0.8819\n",
      "Weighted AUC-ROC: 0.9796\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.804623        0.857667          0.828706     0.974905\n",
      "1      1           0.900394        0.676176          0.764479     0.989934\n",
      "2      2           0.858946        0.493888          0.625651     0.946353\n",
      "3      3           0.767549        0.714970          0.736562     0.963866\n",
      "4      4           0.933275        0.966942          0.949564     0.985826\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1     2      3       4\n",
      "0  514.6   1.4   4.2    4.6    75.2\n",
      "1    9.4  59.2   2.8   12.2     4.0\n",
      "2   53.2   2.0  81.2   12.0    16.0\n",
      "3   25.4   3.0   2.8  119.4    16.4\n",
      "4   40.0   0.6   3.6    8.8  1550.4\n",
      "\n",
      "Processing week3 with best parameters...\n",
      "best parameters for week3: {'units_1': 192, 'dropout_1': 0.4, 'learning_rate': 0.000822314112616515}\n",
      "Fold 1: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5694 - loss: 0.1612 - val_accuracy: 0.7198 - val_loss: 0.1078\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6925 - loss: 0.1161 - val_accuracy: 0.7854 - val_loss: 0.0950\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 0.1038 - val_accuracy: 0.7861 - val_loss: 0.0891\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7640 - loss: 0.0979 - val_accuracy: 0.8288 - val_loss: 0.0761\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.0887 - val_accuracy: 0.8517 - val_loss: 0.0703\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.0816 - val_accuracy: 0.8494 - val_loss: 0.0668\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.0778 - val_accuracy: 0.8547 - val_loss: 0.0623\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.0756 - val_accuracy: 0.8567 - val_loss: 0.0600\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.0750 - val_accuracy: 0.8490 - val_loss: 0.0653\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.0713 - val_accuracy: 0.8582 - val_loss: 0.0623\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.0671 - val_accuracy: 0.8730 - val_loss: 0.0516\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.0622 - val_accuracy: 0.8761 - val_loss: 0.0511\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.0608 - val_accuracy: 0.8826 - val_loss: 0.0484\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0612 - val_accuracy: 0.8868 - val_loss: 0.0472\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.0570 - val_accuracy: 0.8913 - val_loss: 0.0461\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8672 - loss: 0.0549 - val_accuracy: 0.8963 - val_loss: 0.0441\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.0558 - val_accuracy: 0.9051 - val_loss: 0.0436\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8734 - loss: 0.0524 - val_accuracy: 0.8864 - val_loss: 0.0467\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.0536 - val_accuracy: 0.8872 - val_loss: 0.0445\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8668 - loss: 0.0525 - val_accuracy: 0.8891 - val_loss: 0.0420\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.0498 - val_accuracy: 0.8913 - val_loss: 0.0408\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.0487 - val_accuracy: 0.9062 - val_loss: 0.0373\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.0484 - val_accuracy: 0.8818 - val_loss: 0.0411\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8758 - loss: 0.0477 - val_accuracy: 0.8852 - val_loss: 0.0449\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.0485 - val_accuracy: 0.9055 - val_loss: 0.0364\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.0465 - val_accuracy: 0.9070 - val_loss: 0.0379\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.0445 - val_accuracy: 0.9150 - val_loss: 0.0333\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8845 - loss: 0.0454 - val_accuracy: 0.9005 - val_loss: 0.0388\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.0441 - val_accuracy: 0.8974 - val_loss: 0.0412\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.0425 - val_accuracy: 0.9123 - val_loss: 0.0341\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.0444 - val_accuracy: 0.9112 - val_loss: 0.0347\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.0428 - val_accuracy: 0.9169 - val_loss: 0.0307\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.0401 - val_accuracy: 0.9215 - val_loss: 0.0309\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.0402 - val_accuracy: 0.9154 - val_loss: 0.0317\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.0399 - val_accuracy: 0.9173 - val_loss: 0.0314\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.0395 - val_accuracy: 0.9169 - val_loss: 0.0320\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.0382 - val_accuracy: 0.9218 - val_loss: 0.0300\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.0394 - val_accuracy: 0.9108 - val_loss: 0.0342\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.0404 - val_accuracy: 0.9100 - val_loss: 0.0320\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.0397 - val_accuracy: 0.9203 - val_loss: 0.0288\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8917 - loss: 0.0397 - val_accuracy: 0.9180 - val_loss: 0.0304\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.0346 - val_accuracy: 0.9074 - val_loss: 0.0330\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9019 - loss: 0.0383 - val_accuracy: 0.9245 - val_loss: 0.0272\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9079 - loss: 0.0345 - val_accuracy: 0.9264 - val_loss: 0.0312\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9041 - loss: 0.0363 - val_accuracy: 0.9226 - val_loss: 0.0270\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.0369 - val_accuracy: 0.9199 - val_loss: 0.0285\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.0346 - val_accuracy: 0.9146 - val_loss: 0.0324\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9017 - loss: 0.0368 - val_accuracy: 0.9287 - val_loss: 0.0271\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.0358 - val_accuracy: 0.9283 - val_loss: 0.0263\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.0346 - val_accuracy: 0.9245 - val_loss: 0.0269\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 2: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 0.1519 - val_accuracy: 0.6340 - val_loss: 0.1138\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6859 - loss: 0.1163 - val_accuracy: 0.7591 - val_loss: 0.1000\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7360 - loss: 0.1011 - val_accuracy: 0.7964 - val_loss: 0.0871\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.0913 - val_accuracy: 0.8254 - val_loss: 0.0785\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.0862 - val_accuracy: 0.8429 - val_loss: 0.0738\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.0791 - val_accuracy: 0.8498 - val_loss: 0.0676\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8182 - loss: 0.0760 - val_accuracy: 0.8555 - val_loss: 0.0650\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.0760 - val_accuracy: 0.8658 - val_loss: 0.0603\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.0703 - val_accuracy: 0.8635 - val_loss: 0.0564\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.0641 - val_accuracy: 0.8738 - val_loss: 0.0565\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.0643 - val_accuracy: 0.8746 - val_loss: 0.0541\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.0617 - val_accuracy: 0.8719 - val_loss: 0.0536\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8535 - loss: 0.0619 - val_accuracy: 0.8761 - val_loss: 0.0524\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0573 - val_accuracy: 0.8933 - val_loss: 0.0461\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8615 - loss: 0.0569 - val_accuracy: 0.8833 - val_loss: 0.0483\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8626 - loss: 0.0544 - val_accuracy: 0.8852 - val_loss: 0.0466\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8765 - loss: 0.0504 - val_accuracy: 0.8723 - val_loss: 0.0565\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8731 - loss: 0.0515 - val_accuracy: 0.8891 - val_loss: 0.0449\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.0481 - val_accuracy: 0.8948 - val_loss: 0.0412\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.0453 - val_accuracy: 0.8917 - val_loss: 0.0417\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.0462 - val_accuracy: 0.8925 - val_loss: 0.0406\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.0490 - val_accuracy: 0.9016 - val_loss: 0.0371\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.0447 - val_accuracy: 0.9112 - val_loss: 0.0354\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.0438 - val_accuracy: 0.9199 - val_loss: 0.0362\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.0444 - val_accuracy: 0.9039 - val_loss: 0.0342\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 0.0431 - val_accuracy: 0.8982 - val_loss: 0.0373\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.0432 - val_accuracy: 0.8978 - val_loss: 0.0365\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.0425 - val_accuracy: 0.9100 - val_loss: 0.0333\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.0427 - val_accuracy: 0.9081 - val_loss: 0.0350\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.0417 - val_accuracy: 0.9146 - val_loss: 0.0324\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8923 - loss: 0.0403 - val_accuracy: 0.9173 - val_loss: 0.0307\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.0379 - val_accuracy: 0.9199 - val_loss: 0.0298\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8954 - loss: 0.0377 - val_accuracy: 0.9112 - val_loss: 0.0321\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.0401 - val_accuracy: 0.9135 - val_loss: 0.0312\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.0390 - val_accuracy: 0.9077 - val_loss: 0.0328\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9032 - loss: 0.0376 - val_accuracy: 0.9131 - val_loss: 0.0311\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.0372 - val_accuracy: 0.9127 - val_loss: 0.0315\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8966 - loss: 0.0391 - val_accuracy: 0.9180 - val_loss: 0.0311\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8936 - loss: 0.0389 - val_accuracy: 0.9165 - val_loss: 0.0299\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.0358 - val_accuracy: 0.9253 - val_loss: 0.0289\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.0385 - val_accuracy: 0.9177 - val_loss: 0.0302\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9050 - loss: 0.0373 - val_accuracy: 0.9295 - val_loss: 0.0283\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9062 - loss: 0.0336 - val_accuracy: 0.9180 - val_loss: 0.0286\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.0362 - val_accuracy: 0.9055 - val_loss: 0.0365\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.0331 - val_accuracy: 0.9173 - val_loss: 0.0321\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.0358 - val_accuracy: 0.9154 - val_loss: 0.0311\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9032 - loss: 0.0359 - val_accuracy: 0.9291 - val_loss: 0.0281\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.0359 - val_accuracy: 0.9146 - val_loss: 0.0292\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.0329 - val_accuracy: 0.9226 - val_loss: 0.0275\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9105 - loss: 0.0337 - val_accuracy: 0.9215 - val_loss: 0.0297\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6124 - loss: 0.1435 - val_accuracy: 0.6854 - val_loss: 0.1091\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6933 - loss: 0.1155 - val_accuracy: 0.7208 - val_loss: 0.1006\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7360 - loss: 0.1038 - val_accuracy: 0.7769 - val_loss: 0.0929\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 0.0955 - val_accuracy: 0.8139 - val_loss: 0.0829\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.0824 - val_accuracy: 0.8265 - val_loss: 0.0770\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.0801 - val_accuracy: 0.8402 - val_loss: 0.0712\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.0769 - val_accuracy: 0.8448 - val_loss: 0.0680\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8368 - loss: 0.0719 - val_accuracy: 0.8589 - val_loss: 0.0604\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.0714 - val_accuracy: 0.8619 - val_loss: 0.0620\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.0664 - val_accuracy: 0.8658 - val_loss: 0.0623\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.0639 - val_accuracy: 0.8734 - val_loss: 0.0528\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.0650 - val_accuracy: 0.8905 - val_loss: 0.0505\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.0597 - val_accuracy: 0.8726 - val_loss: 0.0526\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.0599 - val_accuracy: 0.8860 - val_loss: 0.0474\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.0551 - val_accuracy: 0.8879 - val_loss: 0.0470\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.0527 - val_accuracy: 0.8860 - val_loss: 0.0479\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.0545 - val_accuracy: 0.8841 - val_loss: 0.0422\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8709 - loss: 0.0534 - val_accuracy: 0.8955 - val_loss: 0.0429\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8855 - loss: 0.0473 - val_accuracy: 0.9012 - val_loss: 0.0398\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8785 - loss: 0.0484 - val_accuracy: 0.9001 - val_loss: 0.0388\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8804 - loss: 0.0480 - val_accuracy: 0.9005 - val_loss: 0.0391\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8816 - loss: 0.0476 - val_accuracy: 0.8989 - val_loss: 0.0397\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.0476 - val_accuracy: 0.9073 - val_loss: 0.0365\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.0451 - val_accuracy: 0.8913 - val_loss: 0.0395\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8820 - loss: 0.0451 - val_accuracy: 0.9031 - val_loss: 0.0367\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8836 - loss: 0.0445 - val_accuracy: 0.9020 - val_loss: 0.0365\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.0435 - val_accuracy: 0.9111 - val_loss: 0.0324\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.0421 - val_accuracy: 0.9111 - val_loss: 0.0337\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.0417 - val_accuracy: 0.9138 - val_loss: 0.0336\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.0415 - val_accuracy: 0.9138 - val_loss: 0.0320\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.0417 - val_accuracy: 0.9024 - val_loss: 0.0370\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8882 - loss: 0.0433 - val_accuracy: 0.9207 - val_loss: 0.0307\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8878 - loss: 0.0421 - val_accuracy: 0.9062 - val_loss: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.0395 - val_accuracy: 0.9119 - val_loss: 0.0322\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.0409 - val_accuracy: 0.9104 - val_loss: 0.0310\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.0386 - val_accuracy: 0.9100 - val_loss: 0.0337\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.0396 - val_accuracy: 0.9207 - val_loss: 0.0296\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.0358 - val_accuracy: 0.9058 - val_loss: 0.0342\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8978 - loss: 0.0383 - val_accuracy: 0.9050 - val_loss: 0.0334\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.0370 - val_accuracy: 0.9279 - val_loss: 0.0279\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.0375 - val_accuracy: 0.9237 - val_loss: 0.0282\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9006 - loss: 0.0365 - val_accuracy: 0.8959 - val_loss: 0.0350\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.0378 - val_accuracy: 0.9146 - val_loss: 0.0291\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.0349 - val_accuracy: 0.9153 - val_loss: 0.0295\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.0370 - val_accuracy: 0.9218 - val_loss: 0.0275\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.0355 - val_accuracy: 0.9272 - val_loss: 0.0262\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.0350 - val_accuracy: 0.9233 - val_loss: 0.0278\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.0347 - val_accuracy: 0.9031 - val_loss: 0.0382\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9016 - loss: 0.0343 - val_accuracy: 0.9237 - val_loss: 0.0262\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9088 - loss: 0.0337 - val_accuracy: 0.9275 - val_loss: 0.0261\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6132 - loss: 0.1440 - val_accuracy: 0.7288 - val_loss: 0.1030\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7021 - loss: 0.1119 - val_accuracy: 0.7616 - val_loss: 0.0948\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.1017 - val_accuracy: 0.7952 - val_loss: 0.0861\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.0913 - val_accuracy: 0.8040 - val_loss: 0.0805\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.0878 - val_accuracy: 0.8024 - val_loss: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8063 - loss: 0.0809 - val_accuracy: 0.8467 - val_loss: 0.0655\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.0779 - val_accuracy: 0.8581 - val_loss: 0.0630\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 0.0717 - val_accuracy: 0.8608 - val_loss: 0.0595\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.0693 - val_accuracy: 0.8669 - val_loss: 0.0606\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.0653 - val_accuracy: 0.8753 - val_loss: 0.0551\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.0638 - val_accuracy: 0.8768 - val_loss: 0.0517\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.0597 - val_accuracy: 0.8722 - val_loss: 0.0557\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.0588 - val_accuracy: 0.8753 - val_loss: 0.0507\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.0568 - val_accuracy: 0.8963 - val_loss: 0.0491\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.0514 - val_accuracy: 0.8928 - val_loss: 0.0449\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.0525 - val_accuracy: 0.8970 - val_loss: 0.0446\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.0520 - val_accuracy: 0.9047 - val_loss: 0.0427\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.0480 - val_accuracy: 0.9012 - val_loss: 0.0404\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0477 - val_accuracy: 0.8997 - val_loss: 0.0393\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8806 - loss: 0.0478 - val_accuracy: 0.8989 - val_loss: 0.0394\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8796 - loss: 0.0476 - val_accuracy: 0.9008 - val_loss: 0.0377\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.0455 - val_accuracy: 0.9069 - val_loss: 0.0360\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.0440 - val_accuracy: 0.8986 - val_loss: 0.0384\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.0401 - val_accuracy: 0.9085 - val_loss: 0.0348\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.0417 - val_accuracy: 0.9127 - val_loss: 0.0337\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.0414 - val_accuracy: 0.9096 - val_loss: 0.0373\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.0428 - val_accuracy: 0.9108 - val_loss: 0.0342\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.0412 - val_accuracy: 0.9111 - val_loss: 0.0365\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.0394 - val_accuracy: 0.9050 - val_loss: 0.0372\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.0407 - val_accuracy: 0.9050 - val_loss: 0.0333\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.0394 - val_accuracy: 0.9123 - val_loss: 0.0332\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.0394 - val_accuracy: 0.9157 - val_loss: 0.0316\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.0400 - val_accuracy: 0.9077 - val_loss: 0.0366\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.0405 - val_accuracy: 0.9191 - val_loss: 0.0301\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8970 - loss: 0.0388 - val_accuracy: 0.9169 - val_loss: 0.0310\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.0354 - val_accuracy: 0.9169 - val_loss: 0.0299\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.0352 - val_accuracy: 0.9157 - val_loss: 0.0312\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9044 - loss: 0.0364 - val_accuracy: 0.9222 - val_loss: 0.0301\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.0370 - val_accuracy: 0.9180 - val_loss: 0.0305\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9070 - loss: 0.0330 - val_accuracy: 0.9100 - val_loss: 0.0383\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.0389 - val_accuracy: 0.9092 - val_loss: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 0.0360 - val_accuracy: 0.9237 - val_loss: 0.0289\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.0365 - val_accuracy: 0.9150 - val_loss: 0.0304\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8992 - loss: 0.0366 - val_accuracy: 0.9226 - val_loss: 0.0299\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8992 - loss: 0.0364 - val_accuracy: 0.9222 - val_loss: 0.0284\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9050 - loss: 0.0362 - val_accuracy: 0.9180 - val_loss: 0.0296\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.0359 - val_accuracy: 0.9233 - val_loss: 0.0285\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.0340 - val_accuracy: 0.9115 - val_loss: 0.0331\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9017 - loss: 0.0345 - val_accuracy: 0.9275 - val_loss: 0.0276\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 0.0344 - val_accuracy: 0.9066 - val_loss: 0.0318\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week3/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6242 - loss: 0.1425 - val_accuracy: 0.7101 - val_loss: 0.1091\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.1169 - val_accuracy: 0.7429 - val_loss: 0.1023\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.1033 - val_accuracy: 0.7677 - val_loss: 0.0902\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7723 - loss: 0.0944 - val_accuracy: 0.8021 - val_loss: 0.0814\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.0890 - val_accuracy: 0.7963 - val_loss: 0.0810\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.0808 - val_accuracy: 0.8234 - val_loss: 0.0709\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.0760 - val_accuracy: 0.8612 - val_loss: 0.0655\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8328 - loss: 0.0737 - val_accuracy: 0.8570 - val_loss: 0.0600\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8439 - loss: 0.0698 - val_accuracy: 0.8497 - val_loss: 0.0640\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8410 - loss: 0.0703 - val_accuracy: 0.8795 - val_loss: 0.0550\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.0649 - val_accuracy: 0.8726 - val_loss: 0.0541\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.0628 - val_accuracy: 0.8677 - val_loss: 0.0546\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.0634 - val_accuracy: 0.8730 - val_loss: 0.0506\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8535 - loss: 0.0615 - val_accuracy: 0.8867 - val_loss: 0.0476\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.0592 - val_accuracy: 0.8844 - val_loss: 0.0487\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.0555 - val_accuracy: 0.8928 - val_loss: 0.0448\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.0526 - val_accuracy: 0.8471 - val_loss: 0.0534\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.0574 - val_accuracy: 0.8955 - val_loss: 0.0422\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8748 - loss: 0.0493 - val_accuracy: 0.8993 - val_loss: 0.0385\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.0490 - val_accuracy: 0.8982 - val_loss: 0.0407\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8820 - loss: 0.0492 - val_accuracy: 0.8944 - val_loss: 0.0412\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.0470 - val_accuracy: 0.8818 - val_loss: 0.0426\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.0482 - val_accuracy: 0.9016 - val_loss: 0.0370\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.0468 - val_accuracy: 0.8905 - val_loss: 0.0396\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8846 - loss: 0.0443 - val_accuracy: 0.9146 - val_loss: 0.0328\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8852 - loss: 0.0437 - val_accuracy: 0.9172 - val_loss: 0.0323\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.0409 - val_accuracy: 0.9085 - val_loss: 0.0331\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.0462 - val_accuracy: 0.9161 - val_loss: 0.0315\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.0423 - val_accuracy: 0.9047 - val_loss: 0.0344\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.0391 - val_accuracy: 0.9150 - val_loss: 0.0303\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.0411 - val_accuracy: 0.9157 - val_loss: 0.0294\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.0393 - val_accuracy: 0.9058 - val_loss: 0.0327\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 0.0389 - val_accuracy: 0.9199 - val_loss: 0.0285\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.0397 - val_accuracy: 0.9169 - val_loss: 0.0306\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.0374 - val_accuracy: 0.9096 - val_loss: 0.0302\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9042 - loss: 0.0366 - val_accuracy: 0.9066 - val_loss: 0.0365\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8923 - loss: 0.0406 - val_accuracy: 0.9245 - val_loss: 0.0317\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.0375 - val_accuracy: 0.9260 - val_loss: 0.0294\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.0388 - val_accuracy: 0.9188 - val_loss: 0.0287\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.0367 - val_accuracy: 0.9268 - val_loss: 0.0262\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.0373 - val_accuracy: 0.9245 - val_loss: 0.0260\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9019 - loss: 0.0361 - val_accuracy: 0.9138 - val_loss: 0.0302\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.0352 - val_accuracy: 0.9176 - val_loss: 0.0289\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.0368 - val_accuracy: 0.9191 - val_loss: 0.0284\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.0341 - val_accuracy: 0.9211 - val_loss: 0.0279\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.0380 - val_accuracy: 0.9146 - val_loss: 0.0302\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.0342 - val_accuracy: 0.9272 - val_loss: 0.0263\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9056 - loss: 0.0356 - val_accuracy: 0.9169 - val_loss: 0.0294\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9041 - loss: 0.0371 - val_accuracy: 0.9188 - val_loss: 0.0294\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9042 - loss: 0.0354 - val_accuracy: 0.9203 - val_loss: 0.0252\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.9201\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.8777\n",
      "Macro Recall: 0.8141\n",
      "Macro F1-Score: 0.8346\n",
      "Macro AUC-ROC: 0.9852\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.9220\n",
      "Weighted Recall: 0.9201\n",
      "Weighted F1-Score: 0.9182\n",
      "Weighted AUC-ROC: 0.9887\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.915265        0.908333          0.911456     0.986954\n",
      "1      1           0.942972        0.709561          0.793276     0.992712\n",
      "2      2           0.805929        0.643585          0.709125     0.969401\n",
      "3      3           0.773839        0.835928          0.797515     0.985331\n",
      "4      4           0.950639        0.973057          0.961615     0.991479\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  545.0   0.4    5.4    4.0    45.2\n",
      "1    0.8  62.2    4.6   17.4     2.6\n",
      "2   20.0   1.0  105.8   16.2    21.4\n",
      "3    4.0   1.4    9.8  139.6    12.2\n",
      "4   26.2   1.0    8.2    7.8  1560.2\n",
      "\n",
      "Processing week4 with best parameters...\n",
      "best parameters for week4: {'units_1': 160, 'dropout_1': 0.2, 'learning_rate': 0.004256409192507239}\n",
      "Fold 1: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_1.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6352 - loss: 0.1304 - val_accuracy: 0.6679 - val_loss: 0.1115\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.1097 - val_accuracy: 0.8075 - val_loss: 0.0916\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.1003 - val_accuracy: 0.8509 - val_loss: 0.0737\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.0870 - val_accuracy: 0.8410 - val_loss: 0.0708\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.0872 - val_accuracy: 0.8643 - val_loss: 0.0638\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.0788 - val_accuracy: 0.8570 - val_loss: 0.0685\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.0768 - val_accuracy: 0.8563 - val_loss: 0.0606\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.0751 - val_accuracy: 0.8364 - val_loss: 0.0655\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.0775 - val_accuracy: 0.8589 - val_loss: 0.0635\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8324 - loss: 0.0708 - val_accuracy: 0.8525 - val_loss: 0.0612\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.0692 - val_accuracy: 0.8765 - val_loss: 0.0557\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 0.0681 - val_accuracy: 0.8433 - val_loss: 0.0662\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8452 - loss: 0.0673 - val_accuracy: 0.8654 - val_loss: 0.0567\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.0663 - val_accuracy: 0.8868 - val_loss: 0.0528\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.0627 - val_accuracy: 0.8780 - val_loss: 0.0511\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.0616 - val_accuracy: 0.9066 - val_loss: 0.0387\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8620 - loss: 0.0589 - val_accuracy: 0.8742 - val_loss: 0.0606\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 0.0593 - val_accuracy: 0.9089 - val_loss: 0.0394\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.0524 - val_accuracy: 0.9051 - val_loss: 0.0397\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.0557 - val_accuracy: 0.9276 - val_loss: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8801 - loss: 0.0501 - val_accuracy: 0.9077 - val_loss: 0.0358\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0531 - val_accuracy: 0.8875 - val_loss: 0.0471\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.0557 - val_accuracy: 0.9131 - val_loss: 0.0354\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8812 - loss: 0.0503 - val_accuracy: 0.9077 - val_loss: 0.0360\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.0508 - val_accuracy: 0.9268 - val_loss: 0.0300\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.0497 - val_accuracy: 0.9184 - val_loss: 0.0352\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8788 - loss: 0.0510 - val_accuracy: 0.9161 - val_loss: 0.0328\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.0452 - val_accuracy: 0.9119 - val_loss: 0.0348\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.0482 - val_accuracy: 0.8910 - val_loss: 0.0519\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.0520 - val_accuracy: 0.9276 - val_loss: 0.0303\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8839 - loss: 0.0473 - val_accuracy: 0.9325 - val_loss: 0.0283\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.0480 - val_accuracy: 0.9287 - val_loss: 0.0260\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8925 - loss: 0.0442 - val_accuracy: 0.9150 - val_loss: 0.0356\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8697 - loss: 0.0530 - val_accuracy: 0.9013 - val_loss: 0.0353\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.0481 - val_accuracy: 0.9146 - val_loss: 0.0389\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.0679 - val_accuracy: 0.8868 - val_loss: 0.0434\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.0561 - val_accuracy: 0.9135 - val_loss: 0.0391\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.0625 - val_accuracy: 0.8940 - val_loss: 0.0429\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.0521 - val_accuracy: 0.9318 - val_loss: 0.0272\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.0584 - val_accuracy: 0.9234 - val_loss: 0.0280\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8711 - loss: 0.0506 - val_accuracy: 0.9398 - val_loss: 0.0258\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.0522 - val_accuracy: 0.9157 - val_loss: 0.0338\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.0472 - val_accuracy: 0.9260 - val_loss: 0.0282\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.0506 - val_accuracy: 0.9276 - val_loss: 0.0315\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.0512 - val_accuracy: 0.9188 - val_loss: 0.0352\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.0438 - val_accuracy: 0.9390 - val_loss: 0.0242\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8771 - loss: 0.0479 - val_accuracy: 0.8986 - val_loss: 0.0356\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.0450 - val_accuracy: 0.9241 - val_loss: 0.0295\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.0448 - val_accuracy: 0.9325 - val_loss: 0.0273\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.0513 - val_accuracy: 0.9386 - val_loss: 0.0249\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Fold 2: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_2.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6325 - loss: 0.1335 - val_accuracy: 0.7110 - val_loss: 0.1168\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6858 - loss: 0.1186 - val_accuracy: 0.7716 - val_loss: 0.1010\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.0963 - val_accuracy: 0.8342 - val_loss: 0.0783\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.0841 - val_accuracy: 0.8490 - val_loss: 0.0696\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.0822 - val_accuracy: 0.8608 - val_loss: 0.0657\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.0798 - val_accuracy: 0.8498 - val_loss: 0.0641\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8165 - loss: 0.0804 - val_accuracy: 0.8364 - val_loss: 0.0693\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.0714 - val_accuracy: 0.8547 - val_loss: 0.0615\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.0676 - val_accuracy: 0.8483 - val_loss: 0.0643\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.0712 - val_accuracy: 0.8570 - val_loss: 0.0600\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8449 - loss: 0.0701 - val_accuracy: 0.8769 - val_loss: 0.0508\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8541 - loss: 0.0674 - val_accuracy: 0.8624 - val_loss: 0.0562\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8496 - loss: 0.0645 - val_accuracy: 0.8593 - val_loss: 0.0606\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.0660 - val_accuracy: 0.8925 - val_loss: 0.0459\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 0.0623 - val_accuracy: 0.8974 - val_loss: 0.0454\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 0.0599 - val_accuracy: 0.8925 - val_loss: 0.0436\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.0613 - val_accuracy: 0.9188 - val_loss: 0.0349\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.0572 - val_accuracy: 0.8940 - val_loss: 0.0456\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.0523 - val_accuracy: 0.8967 - val_loss: 0.0429\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.0557 - val_accuracy: 0.9138 - val_loss: 0.0426\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.0553 - val_accuracy: 0.8959 - val_loss: 0.0435\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.0544 - val_accuracy: 0.8963 - val_loss: 0.0452\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.0570 - val_accuracy: 0.9169 - val_loss: 0.0324\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.0515 - val_accuracy: 0.9287 - val_loss: 0.0302\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.0563 - val_accuracy: 0.9238 - val_loss: 0.0309\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.0462 - val_accuracy: 0.9131 - val_loss: 0.0360\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.0485 - val_accuracy: 0.9302 - val_loss: 0.0299\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.0530 - val_accuracy: 0.9203 - val_loss: 0.0300\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 0.0458 - val_accuracy: 0.8913 - val_loss: 0.0519\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0506 - val_accuracy: 0.9241 - val_loss: 0.0269\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.0480 - val_accuracy: 0.9150 - val_loss: 0.0322\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8861 - loss: 0.0451 - val_accuracy: 0.9123 - val_loss: 0.0384\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.0446 - val_accuracy: 0.8513 - val_loss: 0.0632\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.0507 - val_accuracy: 0.9196 - val_loss: 0.0298\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8660 - loss: 0.0492 - val_accuracy: 0.9116 - val_loss: 0.0305\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8787 - loss: 0.0479 - val_accuracy: 0.9100 - val_loss: 0.0306\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.0531 - val_accuracy: 0.9199 - val_loss: 0.0363\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.0513 - val_accuracy: 0.9276 - val_loss: 0.0297\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.0472 - val_accuracy: 0.9257 - val_loss: 0.0300\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.0525 - val_accuracy: 0.9142 - val_loss: 0.0337\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8615 - loss: 0.0553 - val_accuracy: 0.9035 - val_loss: 0.0422\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.0477 - val_accuracy: 0.8586 - val_loss: 0.0529\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.0511 - val_accuracy: 0.9268 - val_loss: 0.0334\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.0513 - val_accuracy: 0.9138 - val_loss: 0.0312\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8936 - loss: 0.0429 - val_accuracy: 0.9215 - val_loss: 0.0382\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8807 - loss: 0.0484 - val_accuracy: 0.9100 - val_loss: 0.0313\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8818 - loss: 0.0462 - val_accuracy: 0.9272 - val_loss: 0.0265\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.0426 - val_accuracy: 0.9169 - val_loss: 0.0294\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.0368 - val_accuracy: 0.9157 - val_loss: 0.0362\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.0482 - val_accuracy: 0.9409 - val_loss: 0.0211\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 3: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_3.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6288 - loss: 0.1392 - val_accuracy: 0.6884 - val_loss: 0.1141\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7195 - loss: 0.1102 - val_accuracy: 0.8108 - val_loss: 0.0891\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.0964 - val_accuracy: 0.8288 - val_loss: 0.0795\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.0815 - val_accuracy: 0.8539 - val_loss: 0.0665\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.0838 - val_accuracy: 0.8429 - val_loss: 0.0713\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.0855 - val_accuracy: 0.8352 - val_loss: 0.0729\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.0798 - val_accuracy: 0.8589 - val_loss: 0.0654\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.0698 - val_accuracy: 0.8566 - val_loss: 0.0641\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.0763 - val_accuracy: 0.8749 - val_loss: 0.0565\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.0745 - val_accuracy: 0.8711 - val_loss: 0.0562\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8455 - loss: 0.0674 - val_accuracy: 0.8780 - val_loss: 0.0533\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.0704 - val_accuracy: 0.8818 - val_loss: 0.0522\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.0594 - val_accuracy: 0.8989 - val_loss: 0.0386\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.0554 - val_accuracy: 0.8902 - val_loss: 0.0468\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.0623 - val_accuracy: 0.9054 - val_loss: 0.0386\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.0550 - val_accuracy: 0.8833 - val_loss: 0.0495\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 0.0623 - val_accuracy: 0.8295 - val_loss: 0.0684\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.0576 - val_accuracy: 0.8947 - val_loss: 0.0396\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.0501 - val_accuracy: 0.8833 - val_loss: 0.0458\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8632 - loss: 0.0557 - val_accuracy: 0.9054 - val_loss: 0.0371\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8809 - loss: 0.0500 - val_accuracy: 0.9191 - val_loss: 0.0344\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8641 - loss: 0.0566 - val_accuracy: 0.9012 - val_loss: 0.0402\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.0572 - val_accuracy: 0.9012 - val_loss: 0.0421\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 0.0555 - val_accuracy: 0.9172 - val_loss: 0.0316\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.0541 - val_accuracy: 0.9294 - val_loss: 0.0298\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.0516 - val_accuracy: 0.9054 - val_loss: 0.0419\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.0464 - val_accuracy: 0.8837 - val_loss: 0.0500\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.0473 - val_accuracy: 0.9241 - val_loss: 0.0310\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.0499 - val_accuracy: 0.8966 - val_loss: 0.0380\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8739 - loss: 0.0493 - val_accuracy: 0.9214 - val_loss: 0.0342\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8816 - loss: 0.0479 - val_accuracy: 0.9081 - val_loss: 0.0342\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.0467 - val_accuracy: 0.9283 - val_loss: 0.0287\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8899 - loss: 0.0447 - val_accuracy: 0.9268 - val_loss: 0.0300\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8820 - loss: 0.0484 - val_accuracy: 0.8646 - val_loss: 0.0466\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.0484 - val_accuracy: 0.9195 - val_loss: 0.0307\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.0419 - val_accuracy: 0.8741 - val_loss: 0.0503\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.0502 - val_accuracy: 0.8741 - val_loss: 0.0429\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.0502 - val_accuracy: 0.9355 - val_loss: 0.0279\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8923 - loss: 0.0412 - val_accuracy: 0.9359 - val_loss: 0.0232\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.0426 - val_accuracy: 0.9226 - val_loss: 0.0312\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 0.0456 - val_accuracy: 0.9134 - val_loss: 0.0353\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.0467 - val_accuracy: 0.9062 - val_loss: 0.0371\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8832 - loss: 0.0454 - val_accuracy: 0.9329 - val_loss: 0.0235\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.0430 - val_accuracy: 0.9283 - val_loss: 0.0288\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8790 - loss: 0.0464 - val_accuracy: 0.9416 - val_loss: 0.0237\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.0446 - val_accuracy: 0.9096 - val_loss: 0.0402\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.0460 - val_accuracy: 0.9428 - val_loss: 0.0230\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.0448 - val_accuracy: 0.9394 - val_loss: 0.0277\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8904 - loss: 0.0445 - val_accuracy: 0.9359 - val_loss: 0.0250\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.0493 - val_accuracy: 0.9279 - val_loss: 0.0258\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 4: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_4.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6408 - loss: 0.1311 - val_accuracy: 0.7128 - val_loss: 0.1085\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7165 - loss: 0.1133 - val_accuracy: 0.7998 - val_loss: 0.0871\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.1011 - val_accuracy: 0.8150 - val_loss: 0.0822\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.0917 - val_accuracy: 0.8360 - val_loss: 0.0767\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7917 - loss: 0.0897 - val_accuracy: 0.7872 - val_loss: 0.0836\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8143 - loss: 0.0793 - val_accuracy: 0.8440 - val_loss: 0.0701\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.0829 - val_accuracy: 0.8318 - val_loss: 0.0792\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.0770 - val_accuracy: 0.8417 - val_loss: 0.0748\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.0757 - val_accuracy: 0.8448 - val_loss: 0.0695\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.0810 - val_accuracy: 0.8650 - val_loss: 0.0577\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.0723 - val_accuracy: 0.8608 - val_loss: 0.0540\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.0745 - val_accuracy: 0.8467 - val_loss: 0.0699\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.0793 - val_accuracy: 0.8616 - val_loss: 0.0578\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.0748 - val_accuracy: 0.8692 - val_loss: 0.0518\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 0.0696 - val_accuracy: 0.8715 - val_loss: 0.0522\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.0785 - val_accuracy: 0.8680 - val_loss: 0.0693\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.0813 - val_accuracy: 0.8631 - val_loss: 0.0585\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.0653 - val_accuracy: 0.8482 - val_loss: 0.0641\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.0707 - val_accuracy: 0.8760 - val_loss: 0.0493\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8441 - loss: 0.0640 - val_accuracy: 0.8749 - val_loss: 0.0485\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8298 - loss: 0.0725 - val_accuracy: 0.8844 - val_loss: 0.0439\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 0.0668 - val_accuracy: 0.8810 - val_loss: 0.0493\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.0657 - val_accuracy: 0.8814 - val_loss: 0.0428\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.0656 - val_accuracy: 0.8715 - val_loss: 0.0487\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.0619 - val_accuracy: 0.8905 - val_loss: 0.0501\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.0666 - val_accuracy: 0.8711 - val_loss: 0.0515\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8447 - loss: 0.0657 - val_accuracy: 0.8829 - val_loss: 0.0450\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.0574 - val_accuracy: 0.8993 - val_loss: 0.0373\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.0644 - val_accuracy: 0.9035 - val_loss: 0.0425\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.0585 - val_accuracy: 0.9218 - val_loss: 0.0431\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.0636 - val_accuracy: 0.8955 - val_loss: 0.0507\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.0563 - val_accuracy: 0.8894 - val_loss: 0.0461\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.0583 - val_accuracy: 0.9066 - val_loss: 0.0328\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8719 - loss: 0.0522 - val_accuracy: 0.9012 - val_loss: 0.0359\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8620 - loss: 0.0560 - val_accuracy: 0.9268 - val_loss: 0.0283\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.0529 - val_accuracy: 0.9047 - val_loss: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8709 - loss: 0.0530 - val_accuracy: 0.9165 - val_loss: 0.0419\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.0582 - val_accuracy: 0.9130 - val_loss: 0.0331\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8638 - loss: 0.0556 - val_accuracy: 0.9336 - val_loss: 0.0263\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8826 - loss: 0.0467 - val_accuracy: 0.9432 - val_loss: 0.0276\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8818 - loss: 0.0486 - val_accuracy: 0.8764 - val_loss: 0.0553\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.0479 - val_accuracy: 0.8837 - val_loss: 0.0437\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.0487 - val_accuracy: 0.8963 - val_loss: 0.0524\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8826 - loss: 0.0471 - val_accuracy: 0.9165 - val_loss: 0.0354\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.0459 - val_accuracy: 0.9355 - val_loss: 0.0263\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.0447 - val_accuracy: 0.8520 - val_loss: 0.0538\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.0495 - val_accuracy: 0.9397 - val_loss: 0.0280\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0502 - val_accuracy: 0.9405 - val_loss: 0.0264\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.0433 - val_accuracy: 0.9237 - val_loss: 0.0251\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.0471 - val_accuracy: 0.9447 - val_loss: 0.0242\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Fold 5: Using file /kaggle/input/GCN_minmax_baseline_version4/clean_week4/train/5-folds/data_part_5.csv as test set\n",
      "Epoch 1/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6313 - loss: 0.1356 - val_accuracy: 0.6911 - val_loss: 0.1196\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7078 - loss: 0.1167 - val_accuracy: 0.8143 - val_loss: 0.0832\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7708 - loss: 0.0975 - val_accuracy: 0.8516 - val_loss: 0.0674\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.0890 - val_accuracy: 0.8371 - val_loss: 0.0694\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.0821 - val_accuracy: 0.8600 - val_loss: 0.0640\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.0799 - val_accuracy: 0.8547 - val_loss: 0.0586\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.0813 - val_accuracy: 0.8566 - val_loss: 0.0571\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.0772 - val_accuracy: 0.8562 - val_loss: 0.0580\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8307 - loss: 0.0758 - val_accuracy: 0.8326 - val_loss: 0.0704\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.0770 - val_accuracy: 0.8608 - val_loss: 0.0577\n",
      "Epoch 11/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 0.0731 - val_accuracy: 0.8284 - val_loss: 0.0680\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.0769 - val_accuracy: 0.8608 - val_loss: 0.0572\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.0717 - val_accuracy: 0.8833 - val_loss: 0.0520\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.0717 - val_accuracy: 0.8726 - val_loss: 0.0494\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 0.0654 - val_accuracy: 0.8982 - val_loss: 0.0433\n",
      "Epoch 16/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.0661 - val_accuracy: 0.8997 - val_loss: 0.0453\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8645 - loss: 0.0581 - val_accuracy: 0.8921 - val_loss: 0.0401\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.0639 - val_accuracy: 0.9027 - val_loss: 0.0394\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.0568 - val_accuracy: 0.9211 - val_loss: 0.0323\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.0585 - val_accuracy: 0.9191 - val_loss: 0.0345\n",
      "Epoch 21/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8717 - loss: 0.0548 - val_accuracy: 0.9172 - val_loss: 0.0319\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8733 - loss: 0.0538 - val_accuracy: 0.8879 - val_loss: 0.0487\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.0597 - val_accuracy: 0.9062 - val_loss: 0.0365\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8711 - loss: 0.0544 - val_accuracy: 0.8917 - val_loss: 0.0401\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.0561 - val_accuracy: 0.8928 - val_loss: 0.0485\n",
      "Epoch 26/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.0512 - val_accuracy: 0.8848 - val_loss: 0.0375\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8535 - loss: 0.0591 - val_accuracy: 0.9268 - val_loss: 0.0329\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.0540 - val_accuracy: 0.9127 - val_loss: 0.0332\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8745 - loss: 0.0522 - val_accuracy: 0.9230 - val_loss: 0.0294\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.0489 - val_accuracy: 0.9226 - val_loss: 0.0327\n",
      "Epoch 31/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.0568 - val_accuracy: 0.9050 - val_loss: 0.0473\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.0468 - val_accuracy: 0.9195 - val_loss: 0.0298\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8749 - loss: 0.0504 - val_accuracy: 0.9283 - val_loss: 0.0260\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.0446 - val_accuracy: 0.8898 - val_loss: 0.0392\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.0579 - val_accuracy: 0.9111 - val_loss: 0.0395\n",
      "Epoch 36/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.0532 - val_accuracy: 0.9367 - val_loss: 0.0227\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.0453 - val_accuracy: 0.9249 - val_loss: 0.0293\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.0566 - val_accuracy: 0.9077 - val_loss: 0.0336\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.0497 - val_accuracy: 0.9100 - val_loss: 0.0343\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.0523 - val_accuracy: 0.9157 - val_loss: 0.0284\n",
      "Epoch 41/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.0586 - val_accuracy: 0.9310 - val_loss: 0.0268\n",
      "Epoch 42/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.0514 - val_accuracy: 0.9195 - val_loss: 0.0269\n",
      "Epoch 43/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.0486 - val_accuracy: 0.9115 - val_loss: 0.0294\n",
      "Epoch 44/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8775 - loss: 0.0497 - val_accuracy: 0.8989 - val_loss: 0.0409\n",
      "Epoch 45/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.0520 - val_accuracy: 0.9058 - val_loss: 0.0340\n",
      "Epoch 46/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.0452 - val_accuracy: 0.9272 - val_loss: 0.0246\n",
      "Epoch 47/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.0462 - val_accuracy: 0.9104 - val_loss: 0.0312\n",
      "Epoch 48/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.0532 - val_accuracy: 0.8421 - val_loss: 0.0651\n",
      "Epoch 49/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.0494 - val_accuracy: 0.9306 - val_loss: 0.0220\n",
      "Epoch 50/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.0438 - val_accuracy: 0.9291 - val_loss: 0.0277\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "=== Average Accuracy ===\n",
      "0.9362\n",
      "\n",
      "=== Average Macro Metrics ===\n",
      "Macro Precision: 0.8620\n",
      "Macro Recall: 0.7980\n",
      "Macro F1-Score: 0.8073\n",
      "Macro AUC-ROC: 0.9848\n",
      "\n",
      "=== Average Weighted Metrics ===\n",
      "Weighted Precision: 0.9406\n",
      "Weighted Recall: 0.9362\n",
      "Weighted F1-Score: 0.9332\n",
      "Weighted AUC-ROC: 0.9936\n",
      "\n",
      "=== Average Metrics per Label ===\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.917329        0.957333          0.936186     0.992136\n",
      "1      1           0.818155        0.600758          0.634781     0.981160\n",
      "2      2           0.829626        0.633799          0.705078     0.968885\n",
      "3      3           0.758467        0.807186          0.771682     0.983569\n",
      "4      4           0.986385        0.991145          0.988703     0.998410\n",
      "\n",
      "=== Average Confusion Matrix ===\n",
      "       0     1      2      3       4\n",
      "0  574.4   0.6    7.2    7.6    10.2\n",
      "1    2.6  52.6    5.6   23.6     3.2\n",
      "2   34.0   7.4  104.2   14.4     4.4\n",
      "3    6.6  10.0   11.2  134.8     4.4\n",
      "4    9.2   0.2    2.2    2.6  1589.2\n"
     ]
    }
   ],
   "source": [
    "# Biến lưu kết quả tổng quát\n",
    "overall_results_5folds = []\n",
    "\n",
    "# Lặp qua từng tuần\n",
    "for week, file_paths in five_fold_files.items():\n",
    "    print(f\"\\nProcessing {week} with best parameters...\")\n",
    "    params = best_params[week].values\n",
    "    print(f\"best parameters for {week}: {params}\")\n",
    "    \n",
    "    # Biến lưu kết quả cho từng tuần\n",
    "    week_results = {\n",
    "        \"week\": week,\n",
    "        \"accuracy_per_fold\": [],\n",
    "        \"precision_per_label\": [],\n",
    "        \"recall_per_label\": [],\n",
    "        \"f1_score_per_label\": [],\n",
    "        \"auc_roc_per_label\": [],    # AUC từng lớp\n",
    "        \"auc_roc_macro\": [],        # AUC macro\n",
    "        \"auc_roc_weighted\": [],     # AUC weighted (tự tính)\n",
    "        \"precision_macro\": [],\n",
    "        \"recall_macro\": [],\n",
    "        \"f1_macro\": [],\n",
    "        \"precision_weighted\": [],\n",
    "        \"recall_weighted\": [],\n",
    "        \"f1_weighted\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"train_times\": [],\n",
    "        \"test_times\": []\n",
    "    }\n",
    "\n",
    "    # Lặp qua từng fold\n",
    "    for i in range(len(file_paths)):\n",
    "        print(f\"Fold {i+1}: Using file {file_paths[i]} as test set\")\n",
    "        \n",
    "        # Tải dữ liệu\n",
    "        test_data = pd.read_csv(file_paths[i])\n",
    "        train_data = pd.concat([pd.read_csv(file_paths[j]) for j in range(len(file_paths)) if j != i])\n",
    "        \n",
    "        # Tách X và y\n",
    "        X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                           \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_train = to_categorical(train_data['classification_encoded'], num_classes=5)\n",
    "        \n",
    "        X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                         \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "        y_test = to_categorical(test_data['classification_encoded'], num_classes=5)\n",
    "\n",
    "        # Reshape dữ liệu cho LSTM\n",
    "        X_train = X_train.to_numpy().reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        # Xây dựng mô hình với tham số tốt nhất\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        model = build_Bilstm_model(params, input_shape)\n",
    "        \n",
    "        # Bắt đầu tính thời gian huấn luyện\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)\n",
    "        end_train = time.time()\n",
    "        \n",
    "        # Bắt đầu tính thời gian kiểm thử\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        \n",
    "        # Tính thời gian và lưu lại\n",
    "        train_time = end_train - start_train\n",
    "        test_time = end_test - start_test\n",
    "        week_results[\"train_times\"].append(train_time)\n",
    "        week_results[\"test_times\"].append(test_time)\n",
    "\n",
    "        # Đánh giá mô hình trên tập kiểm thử của fold hiện tại\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        week_results[\"accuracy_per_fold\"].append(accuracy)\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_test_classes = y_test.argmax(axis=1)\n",
    "        \n",
    "        # Tính các chỉ số cho mỗi fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "        conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "        \n",
    "        # Tính AUC-ROC\n",
    "        try:\n",
    "            # Tính AUC macro và theo từng lớp với OvR\n",
    "            auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "            # Tính AUC weighted: tính trọng số theo số mẫu của từng lớp\n",
    "            supports = np.bincount(y_test_classes, minlength=5)\n",
    "            auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tính AUC: {e}\")\n",
    "            auc_macro = np.nan\n",
    "            auc_per_class = [np.nan] * 5\n",
    "            auc_weighted = np.nan\n",
    "            \n",
    "        # Lưu kết quả của fold hiện tại\n",
    "        week_results[\"precision_per_label\"].append(precision)\n",
    "        week_results[\"recall_per_label\"].append(recall)\n",
    "        week_results[\"f1_score_per_label\"].append(f1)\n",
    "        week_results[\"auc_roc_per_label\"].append(auc_per_class)  # AUC từng lớp\n",
    "        week_results[\"auc_roc_macro\"].append(auc_macro)          # AUC macro\n",
    "        week_results[\"auc_roc_weighted\"].append(auc_weighted)      # AUC weighted\n",
    "        week_results[\"confusion_matrices\"].append(conf_matrix)\n",
    "        week_results[\"precision_macro\"].append(precision_macro)\n",
    "        week_results[\"recall_macro\"].append(recall_macro)\n",
    "        week_results[\"f1_macro\"].append(f1_macro)\n",
    "        week_results[\"precision_weighted\"].append(precision_weighted)\n",
    "        week_results[\"recall_weighted\"].append(recall_weighted)\n",
    "        week_results[\"f1_weighted\"].append(f1_weighted)\n",
    "\n",
    "    # Tính trung bình cho từng nhãn\n",
    "    average_precision_per_label = np.mean(week_results[\"precision_per_label\"], axis=0)\n",
    "    average_recall_per_label = np.nanmean(week_results[\"recall_per_label\"], axis=0)\n",
    "    average_f1_per_label = np.nanmean(week_results[\"f1_score_per_label\"], axis=0)\n",
    "    average_auc_per_label = np.nanmean(week_results[\"auc_roc_per_label\"], axis=0)\n",
    "    average_confusion_matrix = np.nanmean(week_results[\"confusion_matrices\"], axis=0)\n",
    "    average_train_time = sum(week_results[\"train_times\"]) / len(week_results[\"train_times\"])\n",
    "    average_test_time = sum(week_results[\"test_times\"]) / len(week_results[\"test_times\"])\n",
    "    average_accuracy = np.nanmean(week_results[\"accuracy_per_fold\"])\n",
    "    average_precision_macro = np.nanmean(week_results[\"precision_macro\"])\n",
    "    average_recall_macro = np.nanmean(week_results[\"recall_macro\"])\n",
    "    average_f1_macro = np.nanmean(week_results[\"f1_macro\"])\n",
    "    average_auc_macro = np.nanmean(week_results[\"auc_roc_macro\"])\n",
    "    average_precision_weighted = np.nanmean(week_results[\"precision_weighted\"])\n",
    "    average_recall_weighted = np.nanmean(week_results[\"recall_weighted\"])\n",
    "    average_f1_weighted = np.nanmean(week_results[\"f1_weighted\"])\n",
    "    average_auc_weighted = np.nanmean(week_results[\"auc_roc_weighted\"])\n",
    "\n",
    "\n",
    "    # Tạo DataFrame cho precision, recall, f1-score\n",
    "    labels = np.unique(y_test_classes)  # Lấy nhãn từ y_test_classes\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Average Precision\": average_precision_per_label,\n",
    "        \"Average Recall\": average_recall_per_label,\n",
    "        \"Average F1-Score\": average_f1_per_label,\n",
    "        \"Average AUC\": average_auc_per_label\n",
    "    })\n",
    "    \n",
    "    # Tạo DataFrame cho confusion matrix\n",
    "    confusion_df = pd.DataFrame(average_confusion_matrix, index=labels, columns=labels)\n",
    "    # In kết quả Accuracy và Macro metrics\n",
    "    print(\"\\n=== Average Accuracy ===\")\n",
    "    print(f\"{average_accuracy:.4f}\")\n",
    "    print(\"\\n=== Average Macro Metrics ===\")\n",
    "    print(f\"Macro Precision: {average_precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {average_recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {average_f1_macro:.4f}\")\n",
    "    print(f\"Macro AUC-ROC: {average_auc_macro:.4f}\")\n",
    "    print(\"\\n=== Average Weighted Metrics ===\")\n",
    "    print(f\"Weighted Precision: {average_precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {average_recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {average_f1_weighted:.4f}\")\n",
    "    print(f\"Weighted AUC-ROC: {average_auc_weighted:.4f}\")\n",
    "    print(\"\\n=== Average Metrics per Label ===\")\n",
    "    print(metrics_df)\n",
    "    print(\"\\n=== Average Confusion Matrix ===\")\n",
    "    print(confusion_df)\n",
    "    \n",
    "    # Cập nhật kết quả cho tuần hiện tại\n",
    "    week_results.update({\n",
    "        \"average_accuracy\": average_accuracy,\n",
    "        \"average_precision_macro\": average_precision_macro,\n",
    "        \"average_recall_macro\": average_recall_macro,\n",
    "        \"average_f1_macro\": average_f1_macro,\n",
    "        \"average_auc_macro\": average_auc_macro,\n",
    "        \"average_precision_weighted\": average_precision_weighted,\n",
    "        \"average_recall_weighted\": average_recall_weighted,\n",
    "        \"average_f1_weighted\": average_f1_weighted,\n",
    "        \"average_auc_weighted\": average_auc_weighted,\n",
    "        \"average_metrics_df\": metrics_df,\n",
    "        \"average_confusion_matrix\": confusion_df,\n",
    "        \"average_train_times\": average_train_time,\n",
    "        \"average_test_times\": average_test_time,\n",
    "    })\n",
    "    overall_results_5folds.append(week_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614cf9e",
   "metadata": {
    "papermill": {
     "duration": 1.570773,
     "end_time": "2025-04-06T06:41:48.380427",
     "exception": false,
     "start_time": "2025-04-06T06:41:46.809654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kết quả cross validation trên 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9785e0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:41:51.697972Z",
     "iopub.status.busy": "2025-04-06T06:41:51.697637Z",
     "iopub.status.idle": "2025-04-06T06:41:51.726401Z",
     "shell.execute_reply": "2025-04-06T06:41:51.725251Z"
    },
    "papermill": {
     "duration": 1.586912,
     "end_time": "2025-04-06T06:41:51.727693",
     "exception": false,
     "start_time": "2025-04-06T06:41:50.140781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for week1 ===\n",
      "Average Accurancy: 0.936241066455841\n",
      "Average Train Time: 89.5028 seconds\n",
      "Average Test Time: 0.5254 seconds\n",
      "Average AUC Macro: 0.9848319630401814\n",
      "Average AUC Weighted: 0.9936011768483498\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.710910        0.685667          0.696167     0.911810\n",
      "1      1           0.361905        0.040909          0.066880     0.881914\n",
      "2      2           0.750833        0.465898          0.572889     0.892486\n",
      "3      3           0.632899        0.552096          0.586440     0.907098\n",
      "4      4           0.856668        0.954219          0.902533     0.945703\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0    1     2     3       4\n",
      "0  411.4  0.2  12.6  24.6   151.2\n",
      "1   49.2  3.6   2.4   6.4    26.0\n",
      "2   40.6  0.2  76.6  11.0    36.0\n",
      "3   28.4  0.2   2.2  92.2    44.0\n",
      "4   52.2  0.2   8.8  12.2  1530.0\n",
      "\n",
      "=== Results for week2 ===\n",
      "Average Accurancy: 0.936241066455841\n",
      "Average Train Time: 90.1138 seconds\n",
      "Average Test Time: 0.5165 seconds\n",
      "Average AUC Macro: 0.9848319630401814\n",
      "Average AUC Weighted: 0.9936011768483498\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.804623        0.857667          0.828706     0.974905\n",
      "1      1           0.900394        0.676176          0.764479     0.989934\n",
      "2      2           0.858946        0.493888          0.625651     0.946353\n",
      "3      3           0.767549        0.714970          0.736562     0.963866\n",
      "4      4           0.933275        0.966942          0.949564     0.985826\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1     2      3       4\n",
      "0  514.6   1.4   4.2    4.6    75.2\n",
      "1    9.4  59.2   2.8   12.2     4.0\n",
      "2   53.2   2.0  81.2   12.0    16.0\n",
      "3   25.4   3.0   2.8  119.4    16.4\n",
      "4   40.0   0.6   3.6    8.8  1550.4\n",
      "\n",
      "=== Results for week3 ===\n",
      "Average Accurancy: 0.936241066455841\n",
      "Average Train Time: 91.0403 seconds\n",
      "Average Test Time: 0.4994 seconds\n",
      "Average AUC Macro: 0.9848319630401814\n",
      "Average AUC Weighted: 0.9936011768483498\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.915265        0.908333          0.911456     0.986954\n",
      "1      1           0.942972        0.709561          0.793276     0.992712\n",
      "2      2           0.805929        0.643585          0.709125     0.969401\n",
      "3      3           0.773839        0.835928          0.797515     0.985331\n",
      "4      4           0.950639        0.973057          0.961615     0.991479\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  545.0   0.4    5.4    4.0    45.2\n",
      "1    0.8  62.2    4.6   17.4     2.6\n",
      "2   20.0   1.0  105.8   16.2    21.4\n",
      "3    4.0   1.4    9.8  139.6    12.2\n",
      "4   26.2   1.0    8.2    7.8  1560.2\n",
      "\n",
      "=== Results for week4 ===\n",
      "Average Accurancy: 0.936241066455841\n",
      "Average Train Time: 89.0307 seconds\n",
      "Average Test Time: 0.4979 seconds\n",
      "Average AUC Macro: 0.9848319630401814\n",
      "Average AUC Weighted: 0.9936011768483498\n",
      "\n",
      "Average Precision, Recall, F1-Score, AUC-ROC per Label:\n",
      "   Label  Average Precision  Average Recall  Average F1-Score  Average AUC\n",
      "0      0           0.917329        0.957333          0.936186     0.992136\n",
      "1      1           0.818155        0.600758          0.634781     0.981160\n",
      "2      2           0.829626        0.633799          0.705078     0.968885\n",
      "3      3           0.758467        0.807186          0.771682     0.983569\n",
      "4      4           0.986385        0.991145          0.988703     0.998410\n",
      "\n",
      "Average Confusion Matrix:\n",
      "       0     1      2      3       4\n",
      "0  574.4   0.6    7.2    7.6    10.2\n",
      "1    2.6  52.6    5.6   23.6     3.2\n",
      "2   34.0   7.4  104.2   14.4     4.4\n",
      "3    6.6  10.0   11.2  134.8     4.4\n",
      "4    9.2   0.2    2.2    2.6  1589.2\n"
     ]
    }
   ],
   "source": [
    "# Duyệt qua các tuần trong overall_results\n",
    "for week_result in overall_results_5folds:\n",
    "    week = week_result[\"week\"]\n",
    "    average_train_time = np.mean(week_result[\"train_times\"])\n",
    "    average_test_time = np.mean(week_result[\"test_times\"])\n",
    "    average_metrics_df = week_result[\"average_metrics_df\"]\n",
    "    average_accuracy = np.mean(week_results[\"accuracy_per_fold\"])\n",
    "    average_confusion_matrix = week_result[\"average_confusion_matrix\"]\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n=== Results for {week} ===\")\n",
    "    print(f\"Average Accurancy: {average_accuracy}\")\n",
    "    print(f\"Average Train Time: {average_train_time:.4f} seconds\")\n",
    "    print(f\"Average Test Time: {average_test_time:.4f} seconds\")\n",
    "    print(f\"Average AUC Macro: {average_auc_macro}\")\n",
    "    print(f\"Average AUC Weighted: {average_auc_weighted}\")\n",
    "    print(\"\\nAverage Precision, Recall, F1-Score, AUC-ROC per Label:\")\n",
    "    print(average_metrics_df)\n",
    "    print(\"\\nAverage Confusion Matrix:\")\n",
    "    print(average_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bbb5fd",
   "metadata": {
    "papermill": {
     "duration": 1.694916,
     "end_time": "2025-04-06T06:41:55.057147",
     "exception": false,
     "start_time": "2025-04-06T06:41:53.362231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kiểm tra trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "255b9b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:41:58.240438Z",
     "iopub.status.busy": "2025-04-06T06:41:58.239964Z",
     "iopub.status.idle": "2025-04-06T06:41:58.256128Z",
     "shell.execute_reply": "2025-04-06T06:41:58.255070Z"
    },
    "papermill": {
     "duration": 1.649062,
     "end_time": "2025-04-06T06:41:58.257929",
     "exception": false,
     "start_time": "2025-04-06T06:41:56.608867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mảng lưu dữ liệu của các tuần\n",
    "results = []\n",
    "\n",
    "def process_week(week_num, best_params, results):\n",
    "    print(f\"\\n=== Processing Week {week_num} ===\")\n",
    "    params = best_params[f\"week{week_num}\"].values\n",
    "    # Đường dẫn tới dữ liệu tuần tương ứng\n",
    "    train_path = f\"{BASE_PATH}/clean_week{week_num}/train/clean_data_week{week_num}.csv\"\n",
    "    test_path = f\"{BASE_PATH}/clean_week{week_num}/test/test_week{week_num}.csv\"\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Tách X và y\n",
    "    X_train = train_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                       \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_train = train_data['classification_encoded']\n",
    "    \n",
    "    X_test = test_data.drop(columns=[\"classification_encoded\", \"user_id\",\n",
    "                                     \"course_id\", \"school\", \"enroll_time\", \"classification\"])\n",
    "    y_test = test_data['classification_encoded']\n",
    "\n",
    "    # Áp dụng SMOTE cho tập huấn luyện\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Chuyển đổi nhãn sang dạng one-hot\n",
    "    y_train_resampled = to_categorical(y_train_resampled, num_classes=5)\n",
    "    y_test = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "    # Reshape dữ liệu cho LSTM\n",
    "    X_train_resampled = X_train_resampled.to_numpy().reshape((X_train_resampled.shape[0], 1, X_train_resampled.shape[1]))\n",
    "    X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Xây dựng mô hình với tham số tốt nhất\n",
    "    input_shape = (X_train_resampled.shape[1], X_train_resampled.shape[2])\n",
    "    model = build_Bilstm_model(params, input_shape)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled, epochs=50, validation_split=0.1, batch_size=32)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Kiểm thử mô hình\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    # Tính thời gian huấn luyện và kiểm thử\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_test_classes = y_test.argmax(axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average=None)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    # Tính AUC-ROC (với one-vs-rest)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "        auc_per_class = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=None)\n",
    "        # Tính AUC weighted tự tính theo trọng số mẫu của từng lớp\n",
    "        supports = np.bincount(y_test_classes, minlength=5)\n",
    "        auc_weighted = np.sum(auc_per_class * supports) / np.sum(supports)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tính AUC: {e}\")\n",
    "        auc_macro = np.nan\n",
    "        auc_per_class = [np.nan] * 5\n",
    "        auc_weighted = np.nan\n",
    "\n",
    "    # Lưu kết quả vào mảng\n",
    "    results.append({\n",
    "        \"week\": week_num,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_weighted\": precision_weighted,\n",
    "        \"recall_weighted\": recall_weighted,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"auc_weighted\": auc_weighted,\n",
    "        \"auc_per_class\": auc_per_class,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    })\n",
    "    \n",
    "    # In kết quả chi tiết\n",
    "    print(\"\\n=== Precision, Recall, F1-Score per Label ===\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Label\": np.unique(y_test_classes),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }))\n",
    "\n",
    "    print(\"\\n=== Macro Averages & Accuracy ===\")\n",
    "    print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Weighted Averages ===\")\n",
    "    print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {auc_macro:.4f}\")\n",
    "    print(f\"AUC Weighted: {auc_weighted:.4f}\")\n",
    "    print(f\"AUC per Label: {auc_per_class}\")\n",
    "    \n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    print(pd.DataFrame(conf_matrix, index=np.unique(y_test_classes), columns=np.unique(y_test_classes)))\n",
    "    \n",
    "    print(f\"\\nTrain Time: {train_time:.2f} seconds\")\n",
    "    print(f\"Test Time: {test_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e442f73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:42:01.659305Z",
     "iopub.status.busy": "2025-04-06T06:42:01.658927Z",
     "iopub.status.idle": "2025-04-06T06:46:42.407934Z",
     "shell.execute_reply": "2025-04-06T06:46:42.407070Z"
    },
    "papermill": {
     "duration": 282.36881,
     "end_time": "2025-04-06T06:46:42.409269",
     "exception": false,
     "start_time": "2025-04-06T06:42:00.040459",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4526 - loss: 0.2092 - val_accuracy: 0.4490 - val_loss: 0.2782\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5628 - loss: 0.1720 - val_accuracy: 0.6860 - val_loss: 0.1737\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5786 - loss: 0.1635 - val_accuracy: 0.5854 - val_loss: 0.2225\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6079 - loss: 0.1539 - val_accuracy: 0.5253 - val_loss: 0.2337\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6106 - loss: 0.1483 - val_accuracy: 0.6049 - val_loss: 0.1904\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6256 - loss: 0.1445 - val_accuracy: 0.5612 - val_loss: 0.2507\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6243 - loss: 0.1413 - val_accuracy: 0.6326 - val_loss: 0.1770\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.1383 - val_accuracy: 0.5438 - val_loss: 0.2532\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6472 - loss: 0.1339 - val_accuracy: 0.6293 - val_loss: 0.1825\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 0.1325 - val_accuracy: 0.5692 - val_loss: 0.2282\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6523 - loss: 0.1316 - val_accuracy: 0.5994 - val_loss: 0.1886\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6531 - loss: 0.1304 - val_accuracy: 0.6326 - val_loss: 0.2024\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6559 - loss: 0.1303 - val_accuracy: 0.5538 - val_loss: 0.2338\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.1276 - val_accuracy: 0.6209 - val_loss: 0.1897\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6679 - loss: 0.1239 - val_accuracy: 0.5425 - val_loss: 0.2250\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6702 - loss: 0.1246 - val_accuracy: 0.6136 - val_loss: 0.2008\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6724 - loss: 0.1228 - val_accuracy: 0.6278 - val_loss: 0.1908\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6770 - loss: 0.1201 - val_accuracy: 0.6084 - val_loss: 0.1992\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6779 - loss: 0.1208 - val_accuracy: 0.5670 - val_loss: 0.1879\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6840 - loss: 0.1191 - val_accuracy: 0.5266 - val_loss: 0.2156\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6847 - loss: 0.1169 - val_accuracy: 0.5864 - val_loss: 0.1921\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6830 - loss: 0.1163 - val_accuracy: 0.5992 - val_loss: 0.1770\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6854 - loss: 0.1167 - val_accuracy: 0.6478 - val_loss: 0.1625\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6862 - loss: 0.1172 - val_accuracy: 0.6401 - val_loss: 0.1446\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6864 - loss: 0.1152 - val_accuracy: 0.6099 - val_loss: 0.1709\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 0.1140 - val_accuracy: 0.6241 - val_loss: 0.1754\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.1128 - val_accuracy: 0.6431 - val_loss: 0.1607\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.1143 - val_accuracy: 0.5740 - val_loss: 0.1904\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.1111 - val_accuracy: 0.6276 - val_loss: 0.1664\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6971 - loss: 0.1113 - val_accuracy: 0.6134 - val_loss: 0.1675\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6947 - loss: 0.1129 - val_accuracy: 0.5428 - val_loss: 0.1912\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6994 - loss: 0.1109 - val_accuracy: 0.6453 - val_loss: 0.1572\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6955 - loss: 0.1104 - val_accuracy: 0.5919 - val_loss: 0.1879\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6996 - loss: 0.1088 - val_accuracy: 0.5959 - val_loss: 0.1817\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.1096 - val_accuracy: 0.5909 - val_loss: 0.1786\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7044 - loss: 0.1101 - val_accuracy: 0.6408 - val_loss: 0.1729\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.1068 - val_accuracy: 0.6116 - val_loss: 0.1690\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.1068 - val_accuracy: 0.5904 - val_loss: 0.1608\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7056 - loss: 0.1075 - val_accuracy: 0.6593 - val_loss: 0.1870\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7056 - loss: 0.1077 - val_accuracy: 0.5814 - val_loss: 0.1790\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7132 - loss: 0.1063 - val_accuracy: 0.5884 - val_loss: 0.1776\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7118 - loss: 0.1029 - val_accuracy: 0.6692 - val_loss: 0.1496\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7085 - loss: 0.1051 - val_accuracy: 0.5969 - val_loss: 0.1896\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.1061 - val_accuracy: 0.5884 - val_loss: 0.1553\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7130 - loss: 0.1039 - val_accuracy: 0.6029 - val_loss: 0.1461\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7133 - loss: 0.1042 - val_accuracy: 0.6228 - val_loss: 0.1722\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 0.1022 - val_accuracy: 0.6273 - val_loss: 0.1910\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.1046 - val_accuracy: 0.5735 - val_loss: 0.1992\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.1037 - val_accuracy: 0.5453 - val_loss: 0.1671\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.1047 - val_accuracy: 0.5852 - val_loss: 0.1759\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.674312  0.784000  0.725031\n",
      "1      1   0.385321  0.777778  0.515337\n",
      "2      2   0.464000  0.563107  0.508772\n",
      "3      3   0.686747  0.542857  0.606383\n",
      "4      4   0.940248  0.831505  0.882540\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.6301\n",
      "Macro Recall: 0.6998\n",
      "Macro F1-Score: 0.6476\n",
      "Accuracy: 0.7835\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.8150\n",
      "Weighted Recall: 0.7835\n",
      "Weighted F1-Score: 0.7933\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9329\n",
      "AUC Weighted: 0.9385\n",
      "AUC per Label: [0.90377655 0.96193545 0.91301931 0.93250194 0.95345361]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  294  27  18   3   33\n",
      "1    6  42   3   0    3\n",
      "2   30   8  58   3    4\n",
      "3   10  10  15  57   13\n",
      "4   96  22  31  20  834\n",
      "\n",
      "Train Time: 280.03 seconds\n",
      "Test Time: 0.45 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(1, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "757ecc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:46:46.226108Z",
     "iopub.status.busy": "2025-04-06T06:46:46.225543Z",
     "iopub.status.idle": "2025-04-06T06:51:29.890786Z",
     "shell.execute_reply": "2025-04-06T06:51:29.890014Z"
    },
    "papermill": {
     "duration": 285.572839,
     "end_time": "2025-04-06T06:51:29.892243",
     "exception": false,
     "start_time": "2025-04-06T06:46:44.319404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: 0.2035 - val_accuracy: 0.4657 - val_loss: 0.2717\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5561 - loss: 0.1708 - val_accuracy: 0.4425 - val_loss: 0.2941\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6073 - loss: 0.1502 - val_accuracy: 0.6116 - val_loss: 0.1753\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6651 - loss: 0.1292 - val_accuracy: 0.6381 - val_loss: 0.1878\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7021 - loss: 0.1129 - val_accuracy: 0.5707 - val_loss: 0.1832\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.1033 - val_accuracy: 0.6201 - val_loss: 0.1523\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7461 - loss: 0.0917 - val_accuracy: 0.6595 - val_loss: 0.1497\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7635 - loss: 0.0851 - val_accuracy: 0.7047 - val_loss: 0.1080\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.0798 - val_accuracy: 0.7376 - val_loss: 0.1043\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7787 - loss: 0.0766 - val_accuracy: 0.7009 - val_loss: 0.1066\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7921 - loss: 0.0727 - val_accuracy: 0.6865 - val_loss: 0.1354\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.0693 - val_accuracy: 0.7219 - val_loss: 0.0926\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.0657 - val_accuracy: 0.7625 - val_loss: 0.0792\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8154 - loss: 0.0634 - val_accuracy: 0.7423 - val_loss: 0.1037\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.0619 - val_accuracy: 0.7166 - val_loss: 0.0920\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.0599 - val_accuracy: 0.7024 - val_loss: 0.0945\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.0575 - val_accuracy: 0.7221 - val_loss: 0.0855\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.0585 - val_accuracy: 0.7830 - val_loss: 0.0601\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 0.0560 - val_accuracy: 0.7548 - val_loss: 0.0564\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.0567 - val_accuracy: 0.7563 - val_loss: 0.0781\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.0535 - val_accuracy: 0.7089 - val_loss: 0.0866\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.0530 - val_accuracy: 0.7373 - val_loss: 0.0766\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.0529 - val_accuracy: 0.7486 - val_loss: 0.0729\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.0542 - val_accuracy: 0.7565 - val_loss: 0.0784\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.0513 - val_accuracy: 0.7314 - val_loss: 0.0900\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.0506 - val_accuracy: 0.8192 - val_loss: 0.0474\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8479 - loss: 0.0523 - val_accuracy: 0.8401 - val_loss: 0.0633\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.0489 - val_accuracy: 0.7870 - val_loss: 0.0507\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.0500 - val_accuracy: 0.8309 - val_loss: 0.0647\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 0.0478 - val_accuracy: 0.7448 - val_loss: 0.1116\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.0490 - val_accuracy: 0.7256 - val_loss: 0.0776\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 0.0470 - val_accuracy: 0.7314 - val_loss: 0.1136\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.0449 - val_accuracy: 0.7957 - val_loss: 0.0543\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.0459 - val_accuracy: 0.9162 - val_loss: 0.0305\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.0458 - val_accuracy: 0.6977 - val_loss: 0.0902\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.0470 - val_accuracy: 0.8997 - val_loss: 0.0439\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.0461 - val_accuracy: 0.7703 - val_loss: 0.0784\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.0459 - val_accuracy: 0.7526 - val_loss: 0.0911\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.0455 - val_accuracy: 0.7765 - val_loss: 0.0690\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.0469 - val_accuracy: 0.8107 - val_loss: 0.0628\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.0423 - val_accuracy: 0.8526 - val_loss: 0.0449\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.0437 - val_accuracy: 0.8895 - val_loss: 0.0409\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8709 - loss: 0.0451 - val_accuracy: 0.8818 - val_loss: 0.0536\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.0433 - val_accuracy: 0.7768 - val_loss: 0.0724\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.0412 - val_accuracy: 0.7995 - val_loss: 0.0620\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.0436 - val_accuracy: 0.8768 - val_loss: 0.0313\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.0430 - val_accuracy: 0.8344 - val_loss: 0.0599\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.0431 - val_accuracy: 0.7797 - val_loss: 0.0674\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.0411 - val_accuracy: 0.7835 - val_loss: 0.0627\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 0.0413 - val_accuracy: 0.9189 - val_loss: 0.0281\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.892031  0.925333  0.908377\n",
      "1      1   0.913793  0.981481  0.946429\n",
      "2      2   0.760000  0.922330  0.833333\n",
      "3      3   0.895238  0.895238  0.895238\n",
      "4      4   0.980270  0.941176  0.960326\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.8883\n",
      "Macro Recall: 0.9331\n",
      "Macro F1-Score: 0.9087\n",
      "Accuracy: 0.9348\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.9386\n",
      "Weighted Recall: 0.9348\n",
      "Weighted F1-Score: 0.9358\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9890\n",
      "AUC Weighted: 0.9881\n",
      "AUC per Label: [0.98301344 0.99478072 0.98661495 0.99089189 0.98951967]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2   3    4\n",
      "0  347   3  10   2   13\n",
      "1    1  53   0   0    0\n",
      "2    5   0  95   2    1\n",
      "3    1   0   5  94    5\n",
      "4   35   2  15   7  944\n",
      "\n",
      "Train Time: 282.88 seconds\n",
      "Test Time: 0.50 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(2, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d629b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:51:34.489247Z",
     "iopub.status.busy": "2025-04-06T06:51:34.488902Z",
     "iopub.status.idle": "2025-04-06T06:56:24.642470Z",
     "shell.execute_reply": "2025-04-06T06:56:24.641643Z"
    },
    "papermill": {
     "duration": 292.342246,
     "end_time": "2025-04-06T06:56:24.643862",
     "exception": false,
     "start_time": "2025-04-06T06:51:32.301616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4793 - loss: 0.1981 - val_accuracy: 0.6161 - val_loss: 0.2024\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6569 - loss: 0.1377 - val_accuracy: 0.6877 - val_loss: 0.1554\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 0.0976 - val_accuracy: 0.7012 - val_loss: 0.1334\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7861 - loss: 0.0791 - val_accuracy: 0.7556 - val_loss: 0.0897\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.0679 - val_accuracy: 0.7166 - val_loss: 0.0988\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.0601 - val_accuracy: 0.7673 - val_loss: 0.0775\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8448 - loss: 0.0552 - val_accuracy: 0.7533 - val_loss: 0.0874\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8455 - loss: 0.0521 - val_accuracy: 0.7358 - val_loss: 0.0839\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.0508 - val_accuracy: 0.9060 - val_loss: 0.0303\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.0440 - val_accuracy: 0.6660 - val_loss: 0.1314\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.0450 - val_accuracy: 0.8666 - val_loss: 0.0422\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.0426 - val_accuracy: 0.7383 - val_loss: 0.0845\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.0408 - val_accuracy: 0.8329 - val_loss: 0.0547\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.0384 - val_accuracy: 0.7126 - val_loss: 0.1039\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.0384 - val_accuracy: 0.8002 - val_loss: 0.0525\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8897 - loss: 0.0371 - val_accuracy: 0.8713 - val_loss: 0.0458\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.0360 - val_accuracy: 0.9012 - val_loss: 0.0318\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8977 - loss: 0.0336 - val_accuracy: 0.8865 - val_loss: 0.0377\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8936 - loss: 0.0355 - val_accuracy: 0.8117 - val_loss: 0.0544\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9034 - loss: 0.0331 - val_accuracy: 0.8603 - val_loss: 0.0437\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.0341 - val_accuracy: 0.9556 - val_loss: 0.0147\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.0328 - val_accuracy: 0.9252 - val_loss: 0.0239\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9030 - loss: 0.0329 - val_accuracy: 0.8139 - val_loss: 0.0604\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.0337 - val_accuracy: 0.9137 - val_loss: 0.0253\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9004 - loss: 0.0342 - val_accuracy: 0.9434 - val_loss: 0.0193\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.0307 - val_accuracy: 0.8097 - val_loss: 0.0511\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.0320 - val_accuracy: 0.9142 - val_loss: 0.0306\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.0291 - val_accuracy: 0.8448 - val_loss: 0.0498\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9082 - loss: 0.0313 - val_accuracy: 0.8885 - val_loss: 0.0379\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9138 - loss: 0.0291 - val_accuracy: 0.7456 - val_loss: 0.0834\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9130 - loss: 0.0294 - val_accuracy: 0.8646 - val_loss: 0.0526\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.0290 - val_accuracy: 0.8730 - val_loss: 0.0397\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.0284 - val_accuracy: 0.9304 - val_loss: 0.0246\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.0278 - val_accuracy: 0.8833 - val_loss: 0.0411\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.0277 - val_accuracy: 0.8902 - val_loss: 0.0467\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.0281 - val_accuracy: 0.9322 - val_loss: 0.0219\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.0290 - val_accuracy: 0.8456 - val_loss: 0.0485\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.0288 - val_accuracy: 0.8661 - val_loss: 0.0632\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.0279 - val_accuracy: 0.9282 - val_loss: 0.0193\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.0282 - val_accuracy: 0.8336 - val_loss: 0.0523\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.0261 - val_accuracy: 0.9279 - val_loss: 0.0224\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9100 - loss: 0.0300 - val_accuracy: 0.9344 - val_loss: 0.0226\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.0261 - val_accuracy: 0.9716 - val_loss: 0.0091\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.0280 - val_accuracy: 0.8578 - val_loss: 0.0578\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.0278 - val_accuracy: 0.9289 - val_loss: 0.0293\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.0276 - val_accuracy: 0.8613 - val_loss: 0.0419\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.0270 - val_accuracy: 0.9189 - val_loss: 0.0341\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.0245 - val_accuracy: 0.9666 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.0244 - val_accuracy: 0.8688 - val_loss: 0.0357\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9221 - loss: 0.0258 - val_accuracy: 0.9426 - val_loss: 0.0186\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.867347  0.906667  0.886571\n",
      "1      1   0.928571  0.962963  0.945455\n",
      "2      2   0.605096  0.922330  0.730769\n",
      "3      3   0.893805  0.961905  0.926606\n",
      "4      4   0.989154  0.909272  0.947532\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.8568\n",
      "Macro Recall: 0.9326\n",
      "Macro F1-Score: 0.8874\n",
      "Accuracy: 0.9146\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.9291\n",
      "Weighted Recall: 0.9146\n",
      "Weighted F1-Score: 0.9186\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9914\n",
      "AUC Weighted: 0.9914\n",
      "AUC per Label: [0.98383557 0.99850544 0.98400617 0.99680472 0.99408994]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2    3    4\n",
      "0  340   2  25    0    8\n",
      "1    1  52   1    0    0\n",
      "2    5   0  95    2    1\n",
      "3    1   0   2  101    1\n",
      "4   45   2  34   10  912\n",
      "\n",
      "Train Time: 289.39 seconds\n",
      "Test Time: 0.46 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(3, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874b4b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:56:29.652559Z",
     "iopub.status.busy": "2025-04-06T06:56:29.652248Z",
     "iopub.status.idle": "2025-04-06T07:01:18.978860Z",
     "shell.execute_reply": "2025-04-06T07:01:18.977976Z"
    },
    "papermill": {
     "duration": 291.862986,
     "end_time": "2025-04-06T07:01:18.980302",
     "exception": false,
     "start_time": "2025-04-06T06:56:27.117316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Week 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4571 - loss: 0.1998 - val_accuracy: 0.4976 - val_loss: 0.1815\n",
      "Epoch 2/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5788 - loss: 0.1558 - val_accuracy: 0.4211 - val_loss: 0.2284\n",
      "Epoch 3/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7013 - loss: 0.1104 - val_accuracy: 0.4338 - val_loss: 0.2124\n",
      "Epoch 4/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7486 - loss: 0.0894 - val_accuracy: 0.7191 - val_loss: 0.1074\n",
      "Epoch 5/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 0.0812 - val_accuracy: 0.5672 - val_loss: 0.1609\n",
      "Epoch 6/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.0773 - val_accuracy: 0.7713 - val_loss: 0.0640\n",
      "Epoch 7/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.0669 - val_accuracy: 0.8678 - val_loss: 0.0405\n",
      "Epoch 8/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.0611 - val_accuracy: 0.7189 - val_loss: 0.1304\n",
      "Epoch 9/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.0638 - val_accuracy: 0.8843 - val_loss: 0.0409\n",
      "Epoch 10/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.0640 - val_accuracy: 0.7653 - val_loss: 0.0722\n",
      "Epoch 11/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.0669 - val_accuracy: 0.8656 - val_loss: 0.0508\n",
      "Epoch 12/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.0558 - val_accuracy: 0.7825 - val_loss: 0.0649\n",
      "Epoch 13/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.0574 - val_accuracy: 0.9129 - val_loss: 0.0195\n",
      "Epoch 14/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.0520 - val_accuracy: 0.9656 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.0619 - val_accuracy: 0.8997 - val_loss: 0.0291\n",
      "Epoch 16/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.0564 - val_accuracy: 0.9239 - val_loss: 0.0304\n",
      "Epoch 17/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.0587 - val_accuracy: 0.8478 - val_loss: 0.0402\n",
      "Epoch 18/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.0495 - val_accuracy: 0.9519 - val_loss: 0.0192\n",
      "Epoch 19/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.0521 - val_accuracy: 0.9444 - val_loss: 0.0187\n",
      "Epoch 20/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.0450 - val_accuracy: 0.8431 - val_loss: 0.0592\n",
      "Epoch 21/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.0484 - val_accuracy: 0.9953 - val_loss: 0.0020\n",
      "Epoch 22/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.0443 - val_accuracy: 0.9080 - val_loss: 0.0281\n",
      "Epoch 23/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.0440 - val_accuracy: 0.8236 - val_loss: 0.0476\n",
      "Epoch 24/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.0445 - val_accuracy: 0.9177 - val_loss: 0.0315\n",
      "Epoch 25/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.0508 - val_accuracy: 0.9738 - val_loss: 0.0072\n",
      "Epoch 26/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.0433 - val_accuracy: 0.6782 - val_loss: 0.0721\n",
      "Epoch 27/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8753 - loss: 0.0442 - val_accuracy: 0.9157 - val_loss: 0.0236\n",
      "Epoch 28/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.0399 - val_accuracy: 0.9414 - val_loss: 0.0158\n",
      "Epoch 29/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.0516 - val_accuracy: 0.9551 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8735 - loss: 0.0438 - val_accuracy: 0.9112 - val_loss: 0.0307\n",
      "Epoch 31/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.0531 - val_accuracy: 0.9312 - val_loss: 0.0161\n",
      "Epoch 32/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.0436 - val_accuracy: 0.8942 - val_loss: 0.0308\n",
      "Epoch 33/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.0452 - val_accuracy: 0.9800 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8717 - loss: 0.0439 - val_accuracy: 0.9648 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.0386 - val_accuracy: 0.9638 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.0459 - val_accuracy: 0.9499 - val_loss: 0.0168\n",
      "Epoch 37/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8765 - loss: 0.0451 - val_accuracy: 0.9726 - val_loss: 0.0065\n",
      "Epoch 38/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8982 - loss: 0.0358 - val_accuracy: 0.9586 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 0.0476 - val_accuracy: 0.8965 - val_loss: 0.0352\n",
      "Epoch 40/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8826 - loss: 0.0419 - val_accuracy: 0.9005 - val_loss: 0.0224\n",
      "Epoch 41/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.0424 - val_accuracy: 0.6885 - val_loss: 0.1115\n",
      "Epoch 42/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.0521 - val_accuracy: 0.9631 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.0633 - val_accuracy: 0.9431 - val_loss: 0.0134\n",
      "Epoch 44/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.0402 - val_accuracy: 0.9466 - val_loss: 0.0183\n",
      "Epoch 45/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.0508 - val_accuracy: 0.8897 - val_loss: 0.0310\n",
      "Epoch 46/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.0489 - val_accuracy: 0.9618 - val_loss: 0.0122\n",
      "Epoch 47/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8775 - loss: 0.0419 - val_accuracy: 0.9686 - val_loss: 0.0082\n",
      "Epoch 48/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.0468 - val_accuracy: 0.9691 - val_loss: 0.0076\n",
      "Epoch 49/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8921 - loss: 0.0382 - val_accuracy: 0.8646 - val_loss: 0.0348\n",
      "Epoch 50/50\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8727 - loss: 0.0444 - val_accuracy: 0.9815 - val_loss: 0.0049\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "=== Precision, Recall, F1-Score per Label ===\n",
      "   Label  Precision    Recall  F1-Score\n",
      "0      0   0.967123  0.941333  0.954054\n",
      "1      1   0.825397  0.962963  0.888889\n",
      "2      2   0.822917  0.766990  0.793970\n",
      "3      3   0.784615  0.971429  0.868085\n",
      "4      4   0.998986  0.982054  0.990447\n",
      "\n",
      "=== Macro Averages & Accuracy ===\n",
      "Macro Precision: 0.8798\n",
      "Macro Recall: 0.9250\n",
      "Macro F1-Score: 0.8991\n",
      "Accuracy: 0.9579\n",
      "\n",
      "=== Weighted Averages ===\n",
      "Weighted Precision: 0.9612\n",
      "Weighted Recall: 0.9579\n",
      "Weighted F1-Score: 0.9586\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9918\n",
      "AUC Weighted: 0.9949\n",
      "AUC per Label: [0.98867141 0.98577834 0.99092293 0.99574376 0.99811241]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "     0   1   2    3    4\n",
      "0  353   2  13    6    1\n",
      "1    0  52   1    1    0\n",
      "2    6   1  79   17    0\n",
      "3    1   0   2  102    0\n",
      "4    5   8   1    4  985\n",
      "\n",
      "Train Time: 288.54 seconds\n",
      "Test Time: 0.46 seconds\n"
     ]
    }
   ],
   "source": [
    "process_week(4, best_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba4fdec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T07:01:24.590143Z",
     "iopub.status.busy": "2025-04-06T07:01:24.589771Z",
     "iopub.status.idle": "2025-04-06T07:01:24.605750Z",
     "shell.execute_reply": "2025-04-06T07:01:24.604726Z"
    },
    "papermill": {
     "duration": 2.86473,
     "end_time": "2025-04-06T07:01:24.607432",
     "exception": false,
     "start_time": "2025-04-06T07:01:21.742702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Results for All Weeks ===\n",
      "Week 1:\n",
      "  Train Time: 280.03 seconds\n",
      "  Test Time: 0.45 seconds\n",
      "  Accurancy: 0.7835365853658537\n",
      "  Precision: [0.67431193 0.3853211  0.464      0.68674699 0.94024803]\n",
      "  Recall: [0.784      0.77777778 0.5631068  0.54285714 0.83150548]\n",
      "  F1-Score: [0.72503083 0.51533742 0.50877193 0.60638298 0.88253968]\n",
      "  Macro Precision: 0.630125608506448\n",
      "  Macro Recall: 0.6998494400601556\n",
      "  Macro F1-Score: 0.6476125681082199\n",
      "  Confusion Matrix:\n",
      "[[294  27  18   3  33]\n",
      " [  6  42   3   0   3]\n",
      " [ 30   8  58   3   4]\n",
      " [ 10  10  15  57  13]\n",
      " [ 96  22  31  20 834]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9329\n",
      "AUC Weighted: 0.9385\n",
      "AUC per Label: [0.90377655 0.96193545 0.91301931 0.93250194 0.95345361]\n",
      "Week 2:\n",
      "  Train Time: 282.88 seconds\n",
      "  Test Time: 0.50 seconds\n",
      "  Accurancy: 0.9347560975609757\n",
      "  Precision: [0.89203085 0.9137931  0.76       0.8952381  0.98026999]\n",
      "  Recall: [0.92533333 0.98148148 0.9223301  0.8952381  0.94117647]\n",
      "  F1-Score: [0.90837696 0.94642857 0.83333333 0.8952381  0.96032553]\n",
      "  Macro Precision: 0.8882664073262407\n",
      "  Macro Recall: 0.9331118955457048\n",
      "  Macro F1-Score: 0.9087404994860269\n",
      "  Confusion Matrix:\n",
      "[[347   3  10   2  13]\n",
      " [  1  53   0   0   0]\n",
      " [  5   0  95   2   1]\n",
      " [  1   0   5  94   5]\n",
      " [ 35   2  15   7 944]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9890\n",
      "AUC Weighted: 0.9881\n",
      "AUC per Label: [0.98301344 0.99478072 0.98661495 0.99089189 0.98951967]\n",
      "Week 3:\n",
      "  Train Time: 289.39 seconds\n",
      "  Test Time: 0.46 seconds\n",
      "  Accurancy: 0.9146341463414634\n",
      "  Precision: [0.86734694 0.92857143 0.60509554 0.89380531 0.98915401]\n",
      "  Recall: [0.90666667 0.96296296 0.9223301  0.96190476 0.90927218]\n",
      "  F1-Score: [0.88657106 0.94545455 0.73076923 0.9266055  0.94753247]\n",
      "  Macro Precision: 0.856794646299582\n",
      "  Macro Recall: 0.9326273344142842\n",
      "  Macro F1-Score: 0.8873865608811962\n",
      "  Confusion Matrix:\n",
      "[[340   2  25   0   8]\n",
      " [  1  52   1   0   0]\n",
      " [  5   0  95   2   1]\n",
      " [  1   0   2 101   1]\n",
      " [ 45   2  34  10 912]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9914\n",
      "AUC Weighted: 0.9914\n",
      "AUC per Label: [0.98383557 0.99850544 0.98400617 0.99680472 0.99408994]\n",
      "Week 4:\n",
      "  Train Time: 288.54 seconds\n",
      "  Test Time: 0.46 seconds\n",
      "  Accurancy: 0.9579268292682926\n",
      "  Precision: [0.96712329 0.82539683 0.82291667 0.78461538 0.9989858 ]\n",
      "  Recall: [0.94133333 0.96296296 0.76699029 0.97142857 0.98205384]\n",
      "  F1-Score: [0.95405405 0.88888889 0.79396985 0.86808511 0.99044746]\n",
      "  Macro Precision: 0.8798075931134296\n",
      "  Macro Recall: 0.92495379949431\n",
      "  Macro F1-Score: 0.8990890719215698\n",
      "  Confusion Matrix:\n",
      "[[353   2  13   6   1]\n",
      " [  0  52   1   1   0]\n",
      " [  6   1  79  17   0]\n",
      " [  1   0   2 102   0]\n",
      " [  5   8   1   4 985]]\n",
      "\n",
      "=== AUC-ROC ===\n",
      "AUC Macro: 0.9918\n",
      "AUC Weighted: 0.9949\n",
      "AUC per Label: [0.98867141 0.98577834 0.99092293 0.99574376 0.99811241]\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu của các tuần\n",
    "print(\"\\n=== Summary Results for All Weeks ===\")\n",
    "for result in results:\n",
    "    print(f\"Week {result['week']}:\")\n",
    "    print(f\"  Train Time: {result['train_time']:.2f} seconds\")\n",
    "    print(f\"  Test Time: {result['test_time']:.2f} seconds\")\n",
    "    print(f\"  Accurancy: {result['accuracy']}\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1-Score: {result['f1_score']}\")\n",
    "    print(f\"  Macro Precision: {result['precision_macro']}\")\n",
    "    print(f\"  Macro Recall: {result['recall_macro']}\")\n",
    "    print(f\"  Macro F1-Score: {result['f1_macro']}\")\n",
    "    print(f\"  Confusion Matrix:\\n{result['confusion_matrix']}\")\n",
    "    print(\"\\n=== AUC-ROC ===\")\n",
    "    print(f\"AUC Macro: {result['auc_macro']:.4f}\")\n",
    "    print(f\"AUC Weighted: {result['auc_weighted']:.4f}\")\n",
    "    print(f\"AUC per Label: {result['auc_per_class']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf297c",
   "metadata": {
    "papermill": {
     "duration": 2.74348,
     "end_time": "2025-04-06T07:01:30.099915",
     "exception": false,
     "start_time": "2025-04-06T07:01:27.356435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6328310,
     "sourceId": 11252263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8915.370104,
   "end_time": "2025-04-06T07:01:36.102208",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-06T04:33:00.732104",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
